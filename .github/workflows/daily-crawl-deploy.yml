name: ğŸ“… Daily Documentation Crawl & Deploy

on:
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM UTC
  workflow_dispatch:  # Manual trigger

defaults:
  run:
    shell: bash

jobs:
  crawl-and-deploy:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    # Prevent multiple crawl operations from running simultaneously
    concurrency:
      group: daily-crawl
      cancel-in-progress: false
    
    steps:
      - name: â¬‡ï¸ Checkout code
        uses: actions/checkout@v4
        
      - name: ğŸ§… Setup Bun
        uses: oven-sh/setup-bun@v2
        with:
          bun-version: latest
          
      - name: ğŸ“¦ Install dependencies
        run: bun install --frozen-lockfile
        
      - name: ğŸ‘€ Environment info
        run: |
          echo "Event name: ${{ github.event_name }}"
          echo "SHA:        ${{ github.sha }}"
          echo "Bun ver:    $(bun --version)"
          echo "Node ver:   $(node --version)"
          echo "Crawl time: $(date)"
        
      - name: ğŸ•·ï¸ Run documentation crawl
        run: |
          echo "ğŸ•·ï¸ Starting documentation crawl..."
          bun run crawl --force-reindex
          echo "âœ… Crawl completed successfully!"
        
      - name: âœ… Verify crawl output
        run: |
          if [ ! -f "public/docs-index.json" ]; then
            echo "âŒ Crawl failed - no output file generated"
            exit 1
          fi
          
          echo "ğŸ“Š Crawl statistics:"
          echo "   File size: $(du -h public/docs-index.json | cut -f1)"
          echo "   Line count: $(wc -l < public/docs-index.json)"
          echo "   Last modified: $(date -r public/docs-index.json)"
          
          # Basic JSON validation
          if ! bun -e "JSON.parse(await Bun.file('public/docs-index.json').text())"; then
            echo "âŒ Generated JSON is invalid"
            exit 1
          fi
          
          echo "âœ… Crawl output validation passed!"
          
      - name: ğŸ”¨ Build project with updated content
        id: build_artifacts
        run: |
          echo "ğŸš€ Building project with fresh crawl data..."
          bun run build
          
          # Add .nojekyll for proper static hosting
          touch dist/.nojekyll
          
          echo "ğŸ“Š Build summary with updated content:"
          du -sh dist/
          echo "Total files: $(find dist -type f | wc -l)"
          echo "Index file included: $([ -f 'dist/docs-index.json' ] && echo 'Yes' || echo 'No')"
        env:
          NODE_ENV: production
          
      - name: ğŸš€ Deploy to preview (ArNS undername)
        id: deploy_preview
        run: |
          echo "ğŸ” Deploying fresh content to preview environment..."
          
          # Verify build artifacts exist
          if [ ! -d "dist" ]; then
            echo "âŒ Build artifacts not found"
            exit 1
          fi
          
          npx permaweb-deploy \
            --undername=preview \
            --ant-process=${{ secrets.ANT_PROCESS }} \
            --deploy-folder=dist \
            --verbose
          
          echo "deployment_url=https://preview_llms-builder.ar.io" >> $GITHUB_OUTPUT
        env:
          DEPLOY_KEY: ${{ secrets.DEPLOY_KEY }}
          ANT_PROCESS: ${{ secrets.ANT_PROCESS }}
          
      - name: ğŸš€ Deploy to Vercel (Fast Preview Mirror)
        run: |
          echo "ğŸŒ Deploying to Vercel for fast preview access..."
          bun run deploy:preview
        env:
          VERCEL_TOKEN: ${{ secrets.VERCEL_TOKEN }}
          
      - name: ğŸ“¡ Deploy to production (Main ArNS)
        id: deploy_production
        run: |
          echo "ğŸ“¡ Deploying fresh content to production..."
          
          npx permaweb-deploy \
            --ant-process=${{ secrets.ANT_PROCESS }} \
            --deploy-folder=dist \
            --verbose
          
          echo "deployment_url=https://permaweb-llms-builder.ar.io" >> $GITHUB_OUTPUT
        env:
          DEPLOY_KEY: ${{ secrets.DEPLOY_KEY }}
          ANT_PROCESS: ${{ secrets.ANT_PROCESS }}
          
      - name: ğŸ“ˆ Report crawl & deployment summary
        run: |
          echo "## ğŸ“Š Daily Crawl & Deployment Summary" >> $GITHUB_STEP_SUMMARY
          echo "- **Timestamp**: $(date)" >> $GITHUB_STEP_SUMMARY
          echo "- **Index file size**: $(du -h public/docs-index.json | cut -f1)" >> $GITHUB_STEP_SUMMARY
          echo "- **Total entries**: $(wc -l < public/docs-index.json)" >> $GITHUB_STEP_SUMMARY
          echo "- **Build artifacts**: $(find dist -type f | wc -l) files" >> $GITHUB_STEP_SUMMARY
          echo "- **Preview**: âœ… ${{ steps.deploy_preview.outputs.deployment_url }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Preview (Vercel)**: âœ… Fast mirror deployed" >> $GITHUB_STEP_SUMMARY
          echo "- **Production**: âœ… ${{ steps.deploy_production.outputs.deployment_url }}" >> $GITHUB_STEP_SUMMARY
          
          echo ""
          echo "ğŸ‰ Daily content update complete!"
          echo "Preview: ${{ steps.deploy_preview.outputs.deployment_url }}"
          echo "Production: ${{ steps.deploy_production.outputs.deployment_url }}" 