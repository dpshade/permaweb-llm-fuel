# Permaweb Documentation Collection

Generated on: 2025-08-14T12:15:31.413Z
Total documents: 133
Total words: 70251

## Table of Contents

### Included Documents

1. [AO Compute Unit (CU)](https://docs.ar.io/gateways/cu)
2. [ariowayfinder-react](https://docs.ar.io/wayfinder/react)
3. [Arns Viewer](https://docs.ar.io/build/guides/arns-viewer)
4. [Arns Viewer](https://docs.ar.io/guides/arns-viewer)
5. [Deploy a dApp with ArDrive web](https://docs.ar.io/build/guides/ardrive-web)
6. [Deploy a dApp with ArDrive web](https://docs.ar.io/guides/ardrive-web)
7. [Permaweb Deploy](https://docs.ar.io/guides/permaweb-deploy)
8. [Permaweb Deploy](https://docs.ar.io/build/guides/permaweb-deploy)
9. [Linux Setup](https://docs.ar.io/gateways/linux-setup)
10. [Advanced](https://docs.ar.io/gateways/advanced)
11. [Advanced Config](https://docs.ar.io/gateways/ar-io-node/advanced-config.html)
12. [Upgrading](https://docs.ar.io/gateways/upgrading)
13. [Uploading to Arweave](https://docs.ar.io/guides/uploading-to-arweave)
14. [Getting Started](https://docs.ar.io/wayfinder/getting-started)
15. [Gql](https://docs.ar.io/guides/gql)
16. [Gql](https://docs.ar.io/build/guides/gql)
17. [ARIO Gateway Grafana](https://docs.ar.io/gateways/grafana)
18. [Windows Setup](https://docs.ar.io/gateways/windows-setup)
19. [Gateway Network](https://docs.ar.io/gateways/gateway-network)
20. [Telemetry](https://docs.ar.io/wayfinder/core/telemetry)
21. [Managing Undernames](https://docs.ar.io/guides/managing-undernames)
22. [Managing Undernames](https://docs.ar.io/build/guides/managing-undernames)
23. [Get Delegations](https://docs.ar.io/ar-io-sdk/ario/gateways/get-delegations)
24. [Admin](https://docs.ar.io/gateways/admin)
25. [useWayfinder](https://docs.ar.io/wayfinder/react/use-wayfinder)
26. [ARIO Node Release Notes](https://docs.ar.io/gateways/release-notes)
27. [ARIO Node Release Notes](https://docs.ar.io/gateways/release-notes#)
28. [Introduction](https://docs.ar.io/introduction)
29. [Parquet and ClickHouse Usage Guide](https://docs.ar.io/gateways/parquet)
30. [Observation and Incentives](https://docs.ar.io/gateways/observer)
31. [Local Storage](https://docs.ar.io/wayfinder/core/gateway-providers/local-storage)
32. [Bundler](https://docs.ar.io/gateways/bundler)
33. [Importing SQLite Database Snapshots](https://docs.ar.io/gateways/snapshots)
34. [Arlink Deploy](https://docs.ar.io/build/guides/arlink)
35. [Arlink Deploy](https://docs.ar.io/guides/arlink)
36. [ARIO Network Testnet](https://docs.ar.io/guides/testnet)
37. [Ar Io Sdk](https://docs.ar.io/ar-io-sdk)
38. [joinNetwork](https://docs.ar.io/ar-io-sdk/ario/gateways/join-network)
39. [Get Arns Returned Name](https://docs.ar.io/ar-io-sdk/ario/arns/get-arns-returned-name)
40. [Arweave Name System (ArNS)](https://docs.ar.io/arns)
41. [Get Arns Returned Names](https://docs.ar.io/ar-io-sdk/ario/arns/get-arns-returned-names)
42. [Redelegate Stake](https://docs.ar.io/ar-io-sdk/ario/gateways/redelegate-stake)
43. [Get Allowed Delegates](https://docs.ar.io/ar-io-sdk/ario/gateways/get-allowed-delegates)
44. [Join the Gateway Network](https://docs.ar.io/gateways/join-network)
45. [Staking](https://docs.ar.io/staking)
46. [getTokenCost](https://docs.ar.io/ar-io-sdk/ario/arns/get-token-cost)
47. [Get Redelegation Fee](https://docs.ar.io/ar-io-sdk/ario/gateways/get-redelegation-fee)
48. [Register an IP Asset on Arweave](https://docs.ar.io/guides/story)
49. [Wayfinder](https://docs.ar.io/wayfinder)
50. [Network](https://docs.ar.io/wayfinder/core/gateway-providers/network)
51. [Content Moderation](https://docs.ar.io/gateways/moderation)
52. [Core](https://docs.ar.io/wayfinder/core)
53. [Release Name](https://docs.ar.io/ar-io-sdk/ants/release-name)
54. [Gateway Architecture](https://docs.ar.io/gateways)
55. [upgradeRecord](https://docs.ar.io/ar-io-sdk/ario/arns/upgrade-record)
56. [setUndernameRecord](https://docs.ar.io/ar-io-sdk/ants/set-undername-record)
57. [ANT Configuration](https://docs.ar.io/ar-io-sdk/ants/configuration)
58. [getGatewayVaults](https://docs.ar.io/ar-io-sdk/ario/gateways/get-gateway-vaults)
59. [setBaseNameRecord](https://docs.ar.io/ar-io-sdk/ants/set-base-name-record)
60. [Get Gateway Delegates](https://docs.ar.io/ar-io-sdk/ario/gateways/get-gateway-delegates)
61. [getDemandFactorSettings](https://docs.ar.io/ar-io-sdk/ario/arns/get-demand-factor-settings)
62. [Get Demand Factor](https://docs.ar.io/ar-io-sdk/ario/arns/get-demand-factor)
63. [getRecords](https://docs.ar.io/ar-io-sdk/ants/get-records)
64. [Gateway Providers](https://docs.ar.io/wayfinder/core/gateway-providers)
65. [setRecord](https://docs.ar.io/ar-io-sdk/ants/set-record)
66. [getRegistrationFees](https://docs.ar.io/ar-io-sdk/ario/arns/get-registration-fees)
67. [The ARIO Token](https://docs.ar.io/token)
68. [Gateway Troubleshooting FAQ](https://docs.ar.io/gateways/troubleshooting)
69. [getState](https://docs.ar.io/ar-io-sdk/ants/get-state)
70. [Glossary](https://docs.ar.io/glossary)
71. [getInfo](https://docs.ar.io/ar-io-sdk/ants/get-info)
72. [getArNSRecord](https://docs.ar.io/ar-io-sdk/ario/arns/get-arns-record)
73. [Remove Primary Names](https://docs.ar.io/ar-io-sdk/ants/remove-primary-names)
74. [Reassign Name](https://docs.ar.io/ar-io-sdk/ants/reassign-name)
75. [Instant Withdrawal](https://docs.ar.io/ar-io-sdk/ario/gateways/instant-withdrawal)
76. [Simple Cache](https://docs.ar.io/wayfinder/core/gateway-providers/simple-cache)
77. [getBalance](https://docs.ar.io/ar-io-sdk/ants/get-balance)
78. [Gateway ArNS Resolution](https://docs.ar.io/gateways/arns-resolution)
79. [Leave Network](https://docs.ar.io/ar-io-sdk/ario/gateways/leave-network)
80. [Increase Operator Stake](https://docs.ar.io/ar-io-sdk/ario/gateways/increase-operator-stake)
81. [Decrease Operator Stake](https://docs.ar.io/ar-io-sdk/ario/gateways/decrease-operator-stake)
82. [Getting Started](https://docs.ar.io/ar-io-sdk/getting-started)
83. [getBalances](https://docs.ar.io/ar-io-sdk/ants/get-balances)
84. [removeRecord](https://docs.ar.io/ar-io-sdk/ants/remove-record)
85. [getArNSReservedNames](https://docs.ar.io/ar-io-sdk/ario/arns/get-arns-reserved-names)
86. [getArNSReservedName](https://docs.ar.io/ar-io-sdk/ario/arns/get-arns-reserved-name)
87. [removeUndernameRecord](https://docs.ar.io/ar-io-sdk/ants/remove-undername-record)
88. [ARIO Configuration](https://docs.ar.io/ar-io-sdk/ario/configuration)
89. [Managing Primary Names](https://docs.ar.io/guides/primary-names)
90. [Data Root Verification Strategy](https://docs.ar.io/wayfinder/core/verification-strategies/data-root-verification)
91. [ARIO Node Filtering System](https://docs.ar.io/gateways/filters)
92. [Static](https://docs.ar.io/wayfinder/core/gateway-providers/static)
93. [Normalized Addresses](https://docs.ar.io/concepts/normalized-addresses)
94. [Update Gateway Settings](https://docs.ar.io/ar-io-sdk/ario/gateways/update-gateway-settings)
95. [Extend Lease](https://docs.ar.io/ar-io-sdk/ario/arns/extend-lease)
96. [addController](https://docs.ar.io/ar-io-sdk/ants/add-controller)
97. [Optimizing Data Handling in ARIO Gateway](https://docs.ar.io/gateways/optimize-data)
98. [transfer](https://docs.ar.io/ar-io-sdk/ants/transfer)
99. [getCostDetails](https://docs.ar.io/ar-io-sdk/ario/arns/get-cost-details)
100. [setKeywords](https://docs.ar.io/ar-io-sdk/ants/set-keywords)
101. [Signature Verification Strategy](https://docs.ar.io/wayfinder/core/verification-strategies/signature-verification)
102. [approvePrimaryNameRequest](https://docs.ar.io/ar-io-sdk/ants/approve-primary-name-request)
103. [ARIO Gateway Environment Variables](https://docs.ar.io/gateways/env)
104. [Increase Undername Limit](https://docs.ar.io/ar-io-sdk/ario/arns/increase-undername-limit)
105. [ARIO SDK Release Notes](https://docs.ar.io/ar-io-sdk/release-notes)
106. [Remove Controller](https://docs.ar.io/ar-io-sdk/ants/remove-controller)
107. [getGateway](https://docs.ar.io/ar-io-sdk/ario/gateways/get-gateway)
108. [getGateways](https://docs.ar.io/ar-io-sdk/ario/gateways/get-gateways)
109. [ARIO Documentation](https://docs.ar.io/)
110. [Set Logo](https://docs.ar.io/ar-io-sdk/ants/set-logo)
111. [ANTs on Bazar](https://docs.ar.io/guides/ants-on-bazar)
112. [ANTs on Bazar](https://docs.ar.io/learn/guides/ants-on-bazar)
113. [cancelWithdrawal](https://docs.ar.io/ar-io-sdk/ario/gateways/cancel-withdrawal)
114. [Increase Delegate Stake](https://docs.ar.io/ar-io-sdk/ario/gateways/increase-delegate-stake)
115. [Decrease Delegate Stake](https://docs.ar.io/ar-io-sdk/ario/gateways/decrease-delegate-stake)
116. [getArNSRecords](https://docs.ar.io/ar-io-sdk/ario/arns/get-arns-records)
117. [Set Name](https://docs.ar.io/ar-io-sdk/ants/set-name)
118. [Set Ticker](https://docs.ar.io/ar-io-sdk/ants/set-ticker)
119. [Set Description](https://docs.ar.io/ar-io-sdk/ants/set-description)
120. [getHandlers](https://docs.ar.io/ar-io-sdk/ants/get-handlers)
121. [Verification Strategies](https://docs.ar.io/wayfinder/core/verification-strategies)
122. [Gateway Apex Domain Content Resolution](https://docs.ar.io/gateways/apex)
123. [buyRecord](https://docs.ar.io/ar-io-sdk/ario/arns/buy-record)
124. [StaticRoutingStrategy](https://docs.ar.io/wayfinder/core/routing-strategies/static)
125. [Hash Verification Strategy](https://docs.ar.io/wayfinder/core/verification-strategies/hash-verification)
126. [ARIO Network Composition](https://docs.ar.io/network-composition)
127. [Random](https://docs.ar.io/wayfinder/core/routing-strategies/random)
128. [Quick Start Guides](https://docs.ar.io/guides)
129. [ARIO Smart Contract](https://docs.ar.io/ario-contract)
130. [Fastest Ping](https://docs.ar.io/wayfinder/core/routing-strategies/fastest-ping)
131. [Round Robin](https://docs.ar.io/wayfinder/core/routing-strategies/round-robin)
132. [Preferred With Fallback](https://docs.ar.io/wayfinder/core/routing-strategies/preferred-with-fallback)
133. [Routing Strategies](https://docs.ar.io/wayfinder/core/routing-strategies)

---

# 1. AO Compute Unit (CU) - ARIO Docs

Document Number: 1
Source: https://docs.ar.io/gateways/cu
Words: 1013
Quality Score: 0.588
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Overview An AO Compute Unit (CU) is a critical component in the AO ecosystem responsible for executing AO processes and maintaining their state. CUs serve as the computational backbone of the AO network by:Processing Messages: CUs receive and process messages sent to AO processes Executing WASM Modules: CUs run the WebAssembly (WASM) code that defines process behavior Maintaining State: CUs track and update the state of AO processes Creating Checkpoints: CUs periodically save process state to the Arweave network as checkpoints Running a CU alongside your gateway allows you to:Process AO requests locally rather than relying on external services Improve response times for AO-related queries Contribute computational resources to the AO network Ensure your gateway has reliable access to AO functionality For more detailed information about Compute Units, please refer to the AO Cookbook: Units.System Requirements Before deploying a CU, ensure your system meets the following requirements:Recommended: At least 16GB RAM for optimal CU operation Minimum: 4GB RAM is possible with adjusted memory limits (see resource allocation settings) At least 100GB disk space dedicated to CU operation These requirements are separate from your gateway requirements Running a CU is resource-intensive. Make sure your system has sufficient resources to handle both the gateway and the CU. While you can run a CU with less than the recommended RAM, you'll need to adjust the memory limits accordingly.Deploying an AO CU Step 1: Navigate to Gateway Directory First, navigate to the root directory of your gateway:Step 2: Configure Environment Variables Copy the example environment file:Default.env.ao.example Contents The default .env.ao.example file contains the following settings:These default settings are configured to work with a gateway running on the same machine, but you'll need to modify them as described below.Open the .env.ao file in your preferred text editor:Configure the following settings:CU_WALLET: Replace '[wallet json here]' with the JSON from an Arweave wallet.The entire JSON must be placed on a single line for proper registration.PROCESS_CHECKPOINT_TRUSTED_OWNERS: This is a comma-separated list of trusted wallet addresses:PROCESS_CHECKPOINT_TRUSTED_OWNERS=fcoN_xJeisVsPXA-trzVAuIiqO3ydLQxM-L4XbrQKzY Adding Your Own Wallet If you are uploading your own checkpoints, you should add your own CU wallet address after the default value, separated by a comma:PROCESS_CHECKPOINT_TRUSTED_OWNERS=fcoN_xJeisVsPXA-trzVAuIiqO3ydLQxM-L4XbrQKzY,YOUR_WALLET_ADDRESS_HERE This allows your CU to trust checkpoints from both the official source and your own wallet.GATEWAY_URL: By default, this is set to use your own gateway:GATEWAY_URL=http://envoy:3000 A gateway must be set to index all ANS-104 data items from AO or the CU will not operate properly. Most users will want to set this to:GATEWAY_URL=https://arweave.net UPLOADER_URL: By default, this is set to use a bundler sidecar run by your gateway:UPLOADER_URL=http://envoy:3000/bundler Important: Checkpoint Uploads Require Payment Checkpoints are uploaded to Arweave, so the upload must be paid for. You must ensure your wallet has sufficient funds:If using https://up.arweave.net (recommended), your CU_WALLET must contain Turbo Credits If using your own bundler or another service, you'll need the appropriate token (AR or other) Without proper funding, checkpoints will fail to upload and your CU may not function correctly The simplest option for most users is to use:UPLOADER_URL=https://up.arweave.net This requires your CU_WALLET to contain Turbo Credits.Optional: Disable Checkpoint Creation: If you want to disable checkpoint uploads, add:DISABLE_PROCESS_CHECKPOINT_CREATION=true Example of a Completed.env.ao File Here's an example of what your completed .env.ao file might look like with common settings:After making your changes, save and exit the nano editor:Press Ctrl+X to exit Press Y to confirm saving changes Press Enter to confirm the filename Optional Resource Allocation Settings You can fine-tune the CU's resource usage by adding these optional environment variables:PROCESS_WASM_MEMORY_MAX_LIMIT: Sets the maximum memory limit (in bytes) for WASM processes.Important Memory Requirement To work with the AR.IO process, PROCESS_WASM_MEMORY_MAX_LIMIT must be at least 17179869184 (16GB).Note: This doesn't mean your server needs 16GB of RAM. This is the maximum memory limit the CU will support for processes. Most processes don't use their maximum allocated memory.You can set this value to 16GB even if your server only has 4GB of RAM. However, if a process requires more memory than your server has available, the CU will fail when evaluating messages that need more memory.WASM_EVALUATION_MAX_WORKERS: Sets the maximum number of worker threads for WASM evaluation.Worker Thread Configuration This will default to (available CPUs - 1) if not specified. If you're running a gateway and unbundling on the same server, consider setting this to 2 or less to avoid overloading your CPU.PROCESS_WASM_COMPUTE_MAX_LIMIT: The maximum Compute-Limit, in bytes, supported for ao processes (defaults to 9 billion) PROCESS_WASM_COMPUTE_MAX_LIMIT=9000000000 NODE_OPTIONS: Sets Node.js memory allocation for the Docker container.Resource Tuning Start with conservative values and monitor performance. You can adjust these settings based on your system's capabilities and the CU's performance.Step 3: Start the CU Container Once your environment file is configured, start the CU container:This command uses the following flags:--env-file .env.ao: Specifies the environment file to use -f docker-compose.ao.yaml: Specifies the Docker Compose file to use up: Creates and starts the containers -d: Runs containers in detached mode (background) Step 4: Check the Logs To check the logs of your CU container:This command uses the following flags:-f: Follows the log output (continuous dis) --tail=20: Shows only the last 20 lines of logs Exit the logs by pressing Ctrl+C.Connecting Your Gateway to the CU To make your gateway use your local CU:Add the following line to your gateway's .env file:AO_CU_URL=http://ao-cu:6363 This assumes the CU is running on the same machine as the gateway.Restart your gateway:Accessing Your CU Once properly set up and connected to your gateway, you can access your CU via:https:///ao/cu This endpoint allows you to interact with your CU directly through your gateway's domain.Important Notes Initial Processing Time: A CU will need to process AO history before it can give valid responses. This process can take several hours.Gateway Fallback: A gateway on release 27 or above will fallback to arweave.net if its default CU is not responding quickly enough, so gateway operations will not be significantly impacted during the initial processing.Monitoring Progress: Check the CU logs after pointing a gateway at it to watch the process of working through AO history:Resource Usage: Running a CU is resource-intensive. Monitor your system's performance to ensure it can handle both the gateway and CU workloads.

---

# 2. ariowayfinder-react - ARIO Docs

Document Number: 2
Source: https://docs.ar.io/wayfinder/react
Words: 163
Quality Score: 0.577
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Overview The @ar.io/wayfinder-react package provides React-specific components and hooks for integrating Wayfinder into React applications. It offers a provider pattern for configuration and convenient hooks for fetching data with built-in loading states and error handling.Installation Quick Start 1. Add the Wayfinder Context Provider 2. Use Hooks in Your Components Advanced Configuration import { WayfinderProvider } from '@ar.io/wayfinder-react'
import {
NetworkGatewaysProvider,
PreferredWithFallbackRoutingStrategy,
FastestPingRoutingStrategy,
HashVerificationStrategy,
StaticGatewaysProvider,
} from '@ar.io/wayfinder-core'
import { ARIO } from '@ar.io/sdk'
function App() {
return (

console.log('Gateway selected:', event.selectedGateway),
onRoutingFailed: (error) => console.error('Routing failed:', error),
},
}}
verificationSettings={{
enabled: true,
strategy: new HashVerificationStrategy({
trustedGateways: ['https://arweave.net'],
}),
strict: false,
events: {
onVerificationSucceeded: (event) =>
console.log('Verified:', event.txId),
onVerificationFailed: (error) =>
console.error('Verification failed:', error),
},
}}
telemetrySettings={{
enabled: process.env.NODE_ENV === 'production',
clientName: 'my-react-app',
clientVersion: process.env.REACT_APP_VERSION || '1.0.0',
sampleRate: 0.05,
exporterUrl: process.env.REACT_APP_TELEMETRY_URL,
}}
>

)
} Related useWayfinder: Access the complete Wayfinder instance useWayfinderRequest: Direct access to the request function useWayfinderUrl: URL resolution with loading states For more advanced configuration options, see the Core Documentation.

---

# 3. ARIO Docs

Document Number: 3
Source: https://docs.ar.io/build/guides/arns-viewer
Words: 875
Quality Score: 0.567
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

ArNS Viewer Overview This guide will walk you through creating a project that uses the AR.IO SDK to interact with ArNS names in a web environment. It provides all the steps and context needed to help you get up and running smoothly, allowing you to effectively use these technologies.We will be using ARNext, a new framework based on Next.js, to simplify deployment to the Arweave permaweb. ARNext provides flexibility for deploying seamlessly to Arweave using an ArNS name, an Arweave transaction ID, or traditional services like Vercel—all without requiring major code modifications. This means you can deploy the same project across different environments with minimal effort.The guide will focus on the following core functionalities of the AR.IO SDK:Retrieving a List of All Active ArNS Names: Learn how to use the SDK to get and dis a list of active ArNS names.Querying Detailed Records for a Specific ArNS Name: Learn how to access detailed records for a specific ArNS name using its ANT (Arweave Name Token).Updating and Creating Records on an ArNS Name: Learn how to modify and add records to an ArNS name, showcasing the capabilities of ANT for dynamic web content.By the end of this guide, you will have a complete, functional project that not only demonstrates how to use the AR.IO SDK but also shows the ease and flexibility of deploying applications to the Arweave permaweb. Whether you are an experienced developer or just starting out, this guide will help you understand the key aspects of building and deploying on Arweave.Getting Started Prerequisites Node v20.17 or greater git Install ARNext ARNext is a brand new framework that is still in development. It supports installation using npx, and you will need the proper Node version for the installation to be successful.You can then move your terminal into that newly created folder with:or open the folder in an IDE like VSCode, and open a new terminal inside that IDE in order to complete the next steps.Sanity Check It is good practice when starting a new project to view it in localhost without any changes, to make sure everything is installed and working correctly. To do this, run:or, if you prefer yarn:By default, the project will be served on port 3000, so you can access it by navigating to localhost:3000 in any browser. You should see something that looks like this: With this complete, you are ready to move on to customizing for your own project.Install AR.IO SDK Next, install the AR.IO SDK.or Polyfills Polyfills are used to provide missing functionality in certain environments. For example, browsers do not have direct access to a computer's file system, but many JavaScript libraries are designed to work in both browser and Node.js environments. These libraries might include references to fs, the module used by Node.js to interact with the file system. Since fs is not available in browsers, we need a polyfill to handle these references and ensure the application runs properly in a browser environment.Installation The below command will install several packages as development dependencies, which should be sufficient to handle most polyfill needs for projects that interact with Arweave.or Next Config With the polyfill packages installed, we need to tell our app how to use them. In NextJS, which ARNext is built on, this is done in the next.config.js file in the root of the project. The default config file will look like this:This configuration allows the app to determine if it is being served via an Arweave transaction Id, or through a more traditional method. From here, we need to add in the additional configurations for resolving our polyfills. The updated next.config.js will look like this:With that, you are ready to start customizing your app.Strip Default Content The first step in building your custom app is to remove the default content and create a clean slate. Follow these steps:Update the Home Page Navigate to pages > index.js, which serves as the main home page.Delete everything in this file and replace it with the following placeholder:Remove Unused Pages The folder pages > posts > [id].js will not be used in this project. Delete the entire posts folder to keep the project organized and free of unnecessary files.Create Header Create a new components folder Inside that, create a Header.js file, leave it blank for now.Create Routes Create a new file at components > ArweaveRoutes.js to handle routing between pages. Leave it simple for now.Your project is now a blank slate, ready for your own custom design and functionality. This clean setup will make it easier to build and maintain your application as you move forward.Add Utilities There are a few functions that we might end up wanting to use in multiple different pages in our finished product. So we can put these in a separate file and export them, so that other pages can import them to use. Start by creating a utils folder in the root of the project, then create 2 files inside of it:auth.js: This will contain the functions required for connecting an Arweave wallet using ArConnect arweave.js: This is where we will put most of our AR.IO SDK functions for interacting with Arweave import { ARIO, ANT, ArconnectSigner } from "@ar.io/sdk/web";
/**
* Initialize ArIO and fetch all ArNS records.
* @returns {Promise

---

# 4. ARIO Docs

Document Number: 4
Source: https://docs.ar.io/guides/arns-viewer
Words: 875
Quality Score: 0.567
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

ArNS Viewer Overview This guide will walk you through creating a project that uses the AR.IO SDK to interact with ArNS names in a web environment. It provides all the steps and context needed to help you get up and running smoothly, allowing you to effectively use these technologies.We will be using ARNext, a new framework based on Next.js, to simplify deployment to the Arweave permaweb. ARNext provides flexibility for deploying seamlessly to Arweave using an ArNS name, an Arweave transaction ID, or traditional services like Vercel—all without requiring major code modifications. This means you can deploy the same project across different environments with minimal effort.The guide will focus on the following core functionalities of the AR.IO SDK:Retrieving a List of All Active ArNS Names: Learn how to use the SDK to get and dis a list of active ArNS names.Querying Detailed Records for a Specific ArNS Name: Learn how to access detailed records for a specific ArNS name using its ANT (Arweave Name Token).Updating and Creating Records on an ArNS Name: Learn how to modify and add records to an ArNS name, showcasing the capabilities of ANT for dynamic web content.By the end of this guide, you will have a complete, functional project that not only demonstrates how to use the AR.IO SDK but also shows the ease and flexibility of deploying applications to the Arweave permaweb. Whether you are an experienced developer or just starting out, this guide will help you understand the key aspects of building and deploying on Arweave.Getting Started Prerequisites Node v20.17 or greater git Install ARNext ARNext is a brand new framework that is still in development. It supports installation using npx, and you will need the proper Node version for the installation to be successful.You can then move your terminal into that newly created folder with:or open the folder in an IDE like VSCode, and open a new terminal inside that IDE in order to complete the next steps.Sanity Check It is good practice when starting a new project to view it in localhost without any changes, to make sure everything is installed and working correctly. To do this, run:or, if you prefer yarn:By default, the project will be served on port 3000, so you can access it by navigating to localhost:3000 in any browser. You should see something that looks like this: With this complete, you are ready to move on to customizing for your own project.Install AR.IO SDK Next, install the AR.IO SDK.or Polyfills Polyfills are used to provide missing functionality in certain environments. For example, browsers do not have direct access to a computer's file system, but many JavaScript libraries are designed to work in both browser and Node.js environments. These libraries might include references to fs, the module used by Node.js to interact with the file system. Since fs is not available in browsers, we need a polyfill to handle these references and ensure the application runs properly in a browser environment.Installation The below command will install several packages as development dependencies, which should be sufficient to handle most polyfill needs for projects that interact with Arweave.or Next Config With the polyfill packages installed, we need to tell our app how to use them. In NextJS, which ARNext is built on, this is done in the next.config.js file in the root of the project. The default config file will look like this:This configuration allows the app to determine if it is being served via an Arweave transaction Id, or through a more traditional method. From here, we need to add in the additional configurations for resolving our polyfills. The updated next.config.js will look like this:With that, you are ready to start customizing your app.Strip Default Content The first step in building your custom app is to remove the default content and create a clean slate. Follow these steps:Update the Home Page Navigate to pages > index.js, which serves as the main home page.Delete everything in this file and replace it with the following placeholder:Remove Unused Pages The folder pages > posts > [id].js will not be used in this project. Delete the entire posts folder to keep the project organized and free of unnecessary files.Create Header Create a new components folder Inside that, create a Header.js file, leave it blank for now.Create Routes Create a new file at components > ArweaveRoutes.js to handle routing between pages. Leave it simple for now.Your project is now a blank slate, ready for your own custom design and functionality. This clean setup will make it easier to build and maintain your application as you move forward.Add Utilities There are a few functions that we might end up wanting to use in multiple different pages in our finished product. So we can put these in a separate file and export them, so that other pages can import them to use. Start by creating a utils folder in the root of the project, then create 2 files inside of it:auth.js: This will contain the functions required for connecting an Arweave wallet using ArConnect arweave.js: This is where we will put most of our AR.IO SDK functions for interacting with Arweave import { ARIO, ANT, ArconnectSigner } from "@ar.io/sdk/web";
/**
* Initialize ArIO and fetch all ArNS records.
* @returns {Promise

---

# 5. Deploy a dApp with ArDrive web - ARIO Docs

Document Number: 5
Source: https://docs.ar.io/build/guides/ardrive-web
Words: 787
Quality Score: 0.561
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

ArDrive Web Deployment Guide Overview This guide will outline the simple steps needed to deploy your dApp or website onto the Arweave blockchain using the ArDrive web app and friendly UI.Simple apps and websites should work right out of the box. However, for advanced applications, this assumes you have already prepared your dApp to use hash routing and relative file paths, and built static files for any dApp in a language or framework that requires it (like React). your dApp for deployment here.Deploying Step 1: Log into ArDrive Go to the ArDrive web app and log in using the method of your choosing. If you don't already have an account, you will need to follow the instructions to set one up.Step 2: Select or Create a Drive Once logged in, navigate to the drive where you want your project to be hosted. If you haven't created a drive yet, or if you want a new one specifically for this project, click the big red "New" button at the top left and create a new drive. Remember, the drive needs to be set to public for your dApp to be accessible to others.Step 3: Upload your project With your drive selected, click the big red "New" button again, but this time, select "Upload Folder". Navigate to your project's root directory, or the built directory if required, and select it. This will upload the entire directory, maintaining your project's file structure.Step 4: Confirm Upload You'll be given a chance to review the upload and the associated cost. If everything looks right, click "Confirm". Remember, uploading to Arweave isnt free, but the cost is usually quite small and the benefits of having your dApp or website hosted on the permaweb are significant.Step 5: Create the Manifest While ArDrive diss your uploaded files as a traditional file structure, with files and folders inside other folders, thats not how they actually exist on Arweave. The manifest acts as a map to all the files your dApp needs to function. After you confirm your upload, navigate into your newly created folder by double clicking on it. Click the big red "New" button again and select "New Manifest" in the "Advanced" section. You'll be prompted to name the manifest and choose where to save it. Be sure to save it inside the folder you just created.Step 6: Get the Data TX ID Once the manifest is created, click on it to expand its details. In the "details" tab, on the bottom right, there's a line labeled "Data TX ID". This is the unique identifier for your uploaded dApp on Arweave. Copy this value.Step 7: View and Share your dApp Your dApp or website is now available on the permaweb forever! Append the Data TX ID you just copied to the end of an Arweave gateway URL, like https://arweave.net/. It might take a few minutes for all of your files to finish propagating through the network, but once they do your dApp or website will be accessible to anyone, anywhere, at any time.Step 8: Assign a Friendly Name The Data TX ID you copied in Step 6 is long and difficult to remember. To make it easier to access your dApp or website, you can assign a friendly name to it using ArNS. If you already own an ArNS name, you will be prompted during the creation of
your manifest if you want to assign one. If you do not, you can purchase one from arns.app.You can also assign an ArNS name to an existing manifest (or any other file) by clicking on the three dots on the right side of the file and selecting "Assign ArNS name".Updating your dApp Files uploaded to Arweave are permanent and immutable. They cannot be changed. However, the Arweave File System (ArFS) protocol used (and created) by ArDrive lets you "replace" them with new versions while still being able to access the old ones. You can do this with entire dApps as well. The old files won't be dised in the ArDrive web app unless you click on a file to view its history.Once you have made changes to your dApp or website, and built the static directory for it, you can upload the entire folder again to the same location where you uploaded the original. Follow all the same steps listed above for uploading your dApp. You will need to create a new manifest to correctly point to the updated files. Give it the same name as the old manifest in order to "replace" it. Creating the new manifest will generate a new TX ID used to view the updated dApp.The old version of the dApp will always be available to anyone who has the correct TX ID.

---

# 6. Deploy a dApp with ArDrive web - ARIO Docs

Document Number: 6
Source: https://docs.ar.io/guides/ardrive-web
Words: 787
Quality Score: 0.561
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

ArDrive Web Deployment Guide Overview This guide will outline the simple steps needed to deploy your dApp or website onto the Arweave blockchain using the ArDrive web app and friendly UI.Simple apps and websites should work right out of the box. However, for advanced applications, this assumes you have already prepared your dApp to use hash routing and relative file paths, and built static files for any dApp in a language or framework that requires it (like React). your dApp for deployment here.Deploying Step 1: Log into ArDrive Go to the ArDrive web app and log in using the method of your choosing. If you don't already have an account, you will need to follow the instructions to set one up.Step 2: Select or Create a Drive Once logged in, navigate to the drive where you want your project to be hosted. If you haven't created a drive yet, or if you want a new one specifically for this project, click the big red "New" button at the top left and create a new drive. Remember, the drive needs to be set to public for your dApp to be accessible to others.Step 3: Upload your project With your drive selected, click the big red "New" button again, but this time, select "Upload Folder". Navigate to your project's root directory, or the built directory if required, and select it. This will upload the entire directory, maintaining your project's file structure.Step 4: Confirm Upload You'll be given a chance to review the upload and the associated cost. If everything looks right, click "Confirm". Remember, uploading to Arweave isnt free, but the cost is usually quite small and the benefits of having your dApp or website hosted on the permaweb are significant.Step 5: Create the Manifest While ArDrive diss your uploaded files as a traditional file structure, with files and folders inside other folders, thats not how they actually exist on Arweave. The manifest acts as a map to all the files your dApp needs to function. After you confirm your upload, navigate into your newly created folder by double clicking on it. Click the big red "New" button again and select "New Manifest" in the "Advanced" section. You'll be prompted to name the manifest and choose where to save it. Be sure to save it inside the folder you just created.Step 6: Get the Data TX ID Once the manifest is created, click on it to expand its details. In the "details" tab, on the bottom right, there's a line labeled "Data TX ID". This is the unique identifier for your uploaded dApp on Arweave. Copy this value.Step 7: View and Share your dApp Your dApp or website is now available on the permaweb forever! Append the Data TX ID you just copied to the end of an Arweave gateway URL, like https://arweave.net/. It might take a few minutes for all of your files to finish propagating through the network, but once they do your dApp or website will be accessible to anyone, anywhere, at any time.Step 8: Assign a Friendly Name The Data TX ID you copied in Step 6 is long and difficult to remember. To make it easier to access your dApp or website, you can assign a friendly name to it using ArNS. If you already own an ArNS name, you will be prompted during the creation of
your manifest if you want to assign one. If you do not, you can purchase one from arns.app.You can also assign an ArNS name to an existing manifest (or any other file) by clicking on the three dots on the right side of the file and selecting "Assign ArNS name".Updating your dApp Files uploaded to Arweave are permanent and immutable. They cannot be changed. However, the Arweave File System (ArFS) protocol used (and created) by ArDrive lets you "replace" them with new versions while still being able to access the old ones. You can do this with entire dApps as well. The old files won't be dised in the ArDrive web app unless you click on a file to view its history.Once you have made changes to your dApp or website, and built the static directory for it, you can upload the entire folder again to the same location where you uploaded the original. Follow all the same steps listed above for uploading your dApp. You will need to create a new manifest to correctly point to the updated files. Give it the same name as the old manifest in order to "replace" it. Creating the new manifest will generate a new TX ID used to view the updated dApp.The old version of the dApp will always be available to anyone who has the correct TX ID.

---

# 7. ARIO Docs

Document Number: 7
Source: https://docs.ar.io/guides/permaweb-deploy
Words: 1059
Quality Score: 0.554
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Deploy a Website or Application Overview With the growing popularity of permanently deployed apps, hosted on Arweave, along with the growing list of tools offered by AR.IO, several methods have been developed to automate the process of deploying a website and updating the ArNS name pointed at it. A particularly useful tool for this is permaweb-deploy from Forward Research.permaweb-deploy is a cli tool that handles uploading a build folder to Arweave using Turbo, creating a manifest, and then updating an ArNS name to point at the new manifest. It being a cli tool makes it very easy to incorporate into a github actions flow. Setting up an automated deployment with permaweb-deploy is simple, but does require a few steps.ENV Security Before automating your deployments, be sure to build your app and check for exposed environmental secrets. Some app frameworks or build flows will build your app with the secrets exposed, and if you are using a tool like permaweb-deploy, those secrets will be uploaded to Arweave. Since the permaweb is permanent, this could pose a security risk, especially with a copy of your wallet keyfile required for the deployment automation.Getting Started Installing package permaweb-deploy is an npm package, and must be installed in any project before it can be used. If you are using npm, you can install the package with the below command:If you prefer yarn for your package installations, the process is slightly more involved. permaweb-deploy is not designed for installation with yarn, so you must provide the additional argument ignore-engines in order to skip over the yarn version error you would normally get with installation. There are two methods for doing so:Directly in the install command In a .yarnc file You can provide a file, named .yarnc in the same directory as your package.json in order to assign specific instructions to all of your yarn commands. Creating a .yarnc file with the line will have the same effect as providing the flag directly in your yarn command Adding a Deploy Script The simplest way to utilize the permaweb-deploy tool is to build it into a script in your package.json. Here you will provide all of the variables that permaweb-deploy needs in order to function properly, as well as ensure that your app is statically built before being uploaded.Be sure to replace with the name of the ArNS name you want to deploy to.The above example shows a build script for a vuepress app, which will build the app into a static folder for deployment, and a deploy script which runs build and then permaweb-deploy. Your build script will look different depending on the framework you are using, but most will provide that for you when you create your app.The permaweb-deploy command has two required arguments:--deploy-folder This is the relative path (from your package.json) to the build folder you want to upload. In a vuepress app, that will be ./src/.vuepress/dist unless you manually specify otherwise in your vuepress configuration. It will be different depending on your chosen framework and if you have modified the default location.--arns-name This is the ArNS name you want to deploy to. It must be an ArNS name that the wallet used to authenticate has ownership or controller privileges over, otherwise the deployment will fail at authentication in the ao process that controls the ArNS name.Undernames The --arns-name flag MUST be the top level name, not and undername. That is, if you want to deploy to undername_arnsname you must set --arns-name arnsname and not --arns-name undername_arnsname.There is the additional, optional flag --undername. If you want to deploy your app to an undername on an ArNS name, provide that name with this flag.--arns-name arnsname --undername undername Testnet Permaweb-deploy supports both Mainnet and Testnet deployments. By default, it will deploy to Mainnet. To deploy to Testnet, you can provide the --ario-process flag as "testnet". If not provided, deployments will default to Mainnet.Providing Arweave Wallet Keys While using permaweb-deploy, you will be uploading data to Arweave using Turbo, as well as performing protected actions on an Arweave Name Token. Because of this, you will need to provide the keys to an Arweave wallet in order for the actions to be successful. The wallet must contain Turbo Credits to pay for the upload, and it must either be a controller or the owner of the ArNS name you are trying to update.permaweb-deploy requires your wallet keyfile be encoded in base64 format. You can convert a local keyfile to base64, and copy the new value to your clipboard by using one of the below commands, depending on your operating system:Linux Mac Windows (CMD) Be sure to replace wallet.json with the path to your chosen wallet keyfile. Once you have this value saved to your clipboard, you can move on to the next step.Create Github Secrets Anyone who has your wallet keyfile (including the base64 formatted keyfile) has full control over your wallet and any of its assets. Because of this, you do not want to include it directly in your package.json script. Instead, keep the value safe by storing it in a github secret. You will create the secrets in the settings tab on your github repo, and the secrets will act as environmental variables in the github actions workflow.You will need to create 1 secret DEPLOY_KEY: This is the base64 encoded version of your Arweave wallet keyfile.Create Action Workflow Github Actions allow you to perform specific actions whenever you push code to github. They are handled by using .yaml files provided in /.github/workflows.To get started, create a new file named deploy.yaml in the workflows directory, then paste the below inside of it:The above tells github to perform these actions when you push new code to the branch main It then sets up a vps with nodejs v 20. When that is complete, it installs dependencies for your project using npm (You will need to add a step to install yarn if that is your preferred package manager), and runs your deploy script, which builds your static folder and then runs permaweb-deploy. It also loads your github secrets into environmental variables that can be used by your deploy script.Deploying App With the above setup complete, the only thing you need to do to deploy a new version of a permasite app to Arweave is push the updated code to branch main on github. Everything else is fully automated.

---

# 8. ARIO Docs

Document Number: 8
Source: https://docs.ar.io/build/guides/permaweb-deploy
Words: 1059
Quality Score: 0.554
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Deploy a Website or Application Overview With the growing popularity of permanently deployed apps, hosted on Arweave, along with the growing list of tools offered by AR.IO, several methods have been developed to automate the process of deploying a website and updating the ArNS name pointed at it. A particularly useful tool for this is permaweb-deploy from Forward Research.permaweb-deploy is a cli tool that handles uploading a build folder to Arweave using Turbo, creating a manifest, and then updating an ArNS name to point at the new manifest. It being a cli tool makes it very easy to incorporate into a github actions flow. Setting up an automated deployment with permaweb-deploy is simple, but does require a few steps.ENV Security Before automating your deployments, be sure to build your app and check for exposed environmental secrets. Some app frameworks or build flows will build your app with the secrets exposed, and if you are using a tool like permaweb-deploy, those secrets will be uploaded to Arweave. Since the permaweb is permanent, this could pose a security risk, especially with a copy of your wallet keyfile required for the deployment automation.Getting Started Installing package permaweb-deploy is an npm package, and must be installed in any project before it can be used. If you are using npm, you can install the package with the below command:If you prefer yarn for your package installations, the process is slightly more involved. permaweb-deploy is not designed for installation with yarn, so you must provide the additional argument ignore-engines in order to skip over the yarn version error you would normally get with installation. There are two methods for doing so:Directly in the install command In a .yarnc file You can provide a file, named .yarnc in the same directory as your package.json in order to assign specific instructions to all of your yarn commands. Creating a .yarnc file with the line will have the same effect as providing the flag directly in your yarn command Adding a Deploy Script The simplest way to utilize the permaweb-deploy tool is to build it into a script in your package.json. Here you will provide all of the variables that permaweb-deploy needs in order to function properly, as well as ensure that your app is statically built before being uploaded.Be sure to replace with the name of the ArNS name you want to deploy to.The above example shows a build script for a vuepress app, which will build the app into a static folder for deployment, and a deploy script which runs build and then permaweb-deploy. Your build script will look different depending on the framework you are using, but most will provide that for you when you create your app.The permaweb-deploy command has two required arguments:--deploy-folder This is the relative path (from your package.json) to the build folder you want to upload. In a vuepress app, that will be ./src/.vuepress/dist unless you manually specify otherwise in your vuepress configuration. It will be different depending on your chosen framework and if you have modified the default location.--arns-name This is the ArNS name you want to deploy to. It must be an ArNS name that the wallet used to authenticate has ownership or controller privileges over, otherwise the deployment will fail at authentication in the ao process that controls the ArNS name.Undernames The --arns-name flag MUST be the top level name, not and undername. That is, if you want to deploy to undername_arnsname you must set --arns-name arnsname and not --arns-name undername_arnsname.There is the additional, optional flag --undername. If you want to deploy your app to an undername on an ArNS name, provide that name with this flag.--arns-name arnsname --undername undername Testnet Permaweb-deploy supports both Mainnet and Testnet deployments. By default, it will deploy to Mainnet. To deploy to Testnet, you can provide the --ario-process flag as "testnet". If not provided, deployments will default to Mainnet.Providing Arweave Wallet Keys While using permaweb-deploy, you will be uploading data to Arweave using Turbo, as well as performing protected actions on an Arweave Name Token. Because of this, you will need to provide the keys to an Arweave wallet in order for the actions to be successful. The wallet must contain Turbo Credits to pay for the upload, and it must either be a controller or the owner of the ArNS name you are trying to update.permaweb-deploy requires your wallet keyfile be encoded in base64 format. You can convert a local keyfile to base64, and copy the new value to your clipboard by using one of the below commands, depending on your operating system:Linux Mac Windows (CMD) Be sure to replace wallet.json with the path to your chosen wallet keyfile. Once you have this value saved to your clipboard, you can move on to the next step.Create Github Secrets Anyone who has your wallet keyfile (including the base64 formatted keyfile) has full control over your wallet and any of its assets. Because of this, you do not want to include it directly in your package.json script. Instead, keep the value safe by storing it in a github secret. You will create the secrets in the settings tab on your github repo, and the secrets will act as environmental variables in the github actions workflow.You will need to create 1 secret DEPLOY_KEY: This is the base64 encoded version of your Arweave wallet keyfile.Create Action Workflow Github Actions allow you to perform specific actions whenever you push code to github. They are handled by using .yaml files provided in /.github/workflows.To get started, create a new file named deploy.yaml in the workflows directory, then paste the below inside of it:The above tells github to perform these actions when you push new code to the branch main It then sets up a vps with nodejs v 20. When that is complete, it installs dependencies for your project using npm (You will need to add a step to install yarn if that is your preferred package manager), and runs your deploy script, which builds your static folder and then runs permaweb-deploy. It also loads your github secrets into environmental variables that can be used by your deploy script.Deploying App With the above setup complete, the only thing you need to do to deploy a new version of a permasite app to Arweave is push the updated code to branch main on github. Everything else is fully automated.

---

# 9. ARIO Docs

Document Number: 9
Source: https://docs.ar.io/gateways/linux-setup
Words: 1273
Quality Score: 0.554
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Linux Installation Instructions Overview The following instructions will guide you through the process of installing the AR.IO node on a Linux machine, specifically Ubuntu 22.04.3 desktop on a home computer. Actual steps may differ slightly on different versions or distributions. This guide will cover how to set up your node, point a domain name to your home network, and create an nginx server for routing traffic to your node. No prior coding experience is required.System Requirements Please note, The AR.IO Node software is still in development and testing, all system requirements are subject to change.External storage devices should be formatted as ext4.Minimum requirements The hardware specifications listed below represent the minimum system requirements at which the AR.IO Node has been tested. While your Node may still operate on systems with lesser specifications, please note that AR.IO cannot guarantee performance or functionality under those conditions. Use below-minimum hardware at your own risk.4 core CPU 4 GB Ram 500 GB storage (SSD recommended) Stable 50 Mbps internet connection Recommended 12 core CPU 32 GB Ram 2 TB SSD storage Stable 1 Gbps internet connection Install Packages If you would like to quickly install all required and suggested packages, you can run the following 4 commands in your terminal, and skip to installing the Node.Required packages Update your software:Enable your firewall and open necessary ports:Install nginx:Install git:Install Docker:Test Docker installation:Install Certbot:Suggested packages These packages are not required to run a node in its basic form. However, they will become necessary for more advanced usage or customization.Install ssh (optional, for remote access to your Linux machine):Install NVM (Node Version Manager):Install Node.js:Install Yarn:Install build tools:Install SQLite:Install the Node Navigate to the desired installation location:NOTE: Your indexing databases will be created in the project directory unless otherwise specified in your.env file, not your Docker environment. So, if you are using an external hard drive, you should install the node directly to that external drive.Clone the ar-io-node repository and navigate into it:Create an environment file:Paste the following content into the new file, replacing with the domain address you are using to access the node, and with the public address of your Arweave wallet, save, and exit:The GRAPHQL values set the proxy for GQL queries to arweave.net, You may use any available gateway that supports GQL queries. If omitted, your node can support GQL queries on locally indexed transactions, but only L1 transactions are indexed by default.START_HEIGHT is an optional line. It sets the block number where your node will start downloading and indexing transactions headers. Omitting this line will begin indexing at block 0.RUN_OBSERVER turns on the Observer to generate Network Compliance Reports. This is required for full participation in the AR.IO Network. Set to false to run your gateway without Observer.ARNS_ROOT_HOST sets the starting point for resolving ARNS names, which are accessed as a subdomain of a gateway. It should be set to the url you are pointing to your node, excluding any protocol prefix. For example, use node-ar.io and not https://node-ar.io. If you are using a subdomain to access your node and do not set this value, the node will not understand incoming requests.AR_IO_WALLET is optional, and sets the wallet you want associated with your Gateway. An associated wallet is required to join the AR.IO network.OBSERVER_WALLET is the public address of the wallet used to sign Observer transactions. This is required for Observer to run, but may be omitted if you are running a gateway outside of the AR.IO network and do not plan to run Observer. You will need to supply the keyfile to this wallet in the next step.More advanced configuration options can be found at ar.io/docs Supply Your Observer Wallet Keyfile:If you are running Observer, you need to provide a wallet keyfile in order to sign report upload transactions. The keyfile must be saved in the wallets directory in the root of the repository. Name the file .json, replacing "" with the public address of the wallet. This should match your OBSERVER_WALLET environmental variable. Arweave wallets and obtaining keyfiles here Payment For Observer Report Uploads By default, the Observer will use Turbo Credits to pay for uploading reports to Arweave. This allows reports under 100kb to be uploaded for free, but larger reports will fail if the Observer wallet does not contain Credits. Including REPORT_DATA_SINK=arweave in your .env file will configure the Observer to use AR tokens instead of Turbo Credits, without any free limit.Start the Docker container:Explanation of flags:up: Start the Docker containers.-d: Run the containers as background processes (detached mode).NOTE: Effective with Release #3, it is no longer required to include the --build flag when starting your gateway. Docker will automatically build using the image specified in the docker-compose.yaml file.To ensure your node is running correctly, follow the next two steps.Check the logs for errors:Explanation of flags:-f: Follow the logs in real time.--tail=0: Ignore all logs from before running the command.NOTE: Previous versions of these instructions advised checking a gateway's ability to fetch content using localhost. Subsequent security updates prevent this without first unsetting ARNS_ROOT_HOST in your .env.Set up Networking The following guide assumes you are running your node on a local home computer.Register a Domain Name:
Choose a domain registrar (e.g., Namecheap) to register a domain name.Point the Domain at Your Home Internet:Obtain your public IP address by visiting https://www.whatsmyip.org/ or running:Create an A record with your registrar for your domain and wildcard subdomains, using your public IP address. For example, if your domain is "ar.io," create a record for "ar.io" and "*.ar.io." Set up Port Forwarding:Obtain the local IP address of the machine where the node is installed by running:If there are multiple lines of output, choose the one starting with 192 (usually).Enter your router's IP address in the address bar of a browser (e.g., 192.168.0.1).If you're unsure of your router's IP address, consult your router's documentation or contact your Internet Service Provider (ISP).Navigate to the port forwarding settings in your router configuration.The exact steps may vary depending on your router model. Consult your router's documentation or support for detailed steps.Set up port forwarding rules to forward incoming traffic on ports 80 (HTTP) and 443 (HTTPS) to the same ports on the machine running your node. You may also forward port 22 if you want to enable SSH access to your node from outside your home network.Create SSL (HTTPS) Certificates for Your Domain:Follow the instructions to create the required TXT records for your domain in your chosen registrar. Use a DNS checker to verify the propagation of each record.Email Notifications Previous versions of these instructions advised providing an email address to Certbot. As of June 2025, LetsEncrypt (the certificate authority used by Certbot) no longer supports email notifications.IMPORTANT: Wild card subdomain (*..com) cannot auto renew without obtaining an API key from your domain registrar. Not all registrars offer this. Certbot certificates expire every 90 days. Be sure to consult with your chosen registrar to see if they offer an API for this purpose, or run the above command again to renew your certificates. You will receive an email warning at the address you provided to remind you when it is time to renew.Configure nginx:
nginx is a free and open-source web server and reverse proxy server. It will handle incoming traffic, provide SSL certificates, and redirect the traffic to your node.Open the default configuration file:Replace the file's contents with the following configuration (replace "" when necessary):Save and exit nano.Test the configuration:If there are no errors, restart nginx:Your node should now be running and connected to the internet. Test it by entering https:///3lyxgbgEvqNSvJrTX2J7CfRychUD5KClFhhVLyTPNCQ in your browser.Note: If you encounter any issues during the installation process, please seek assistance from the AR.IO community.

---

# 10. ARIO Docs

Document Number: 10
Source: https://docs.ar.io/gateways/advanced
Words: 781
Quality Score: 0.551
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Advanced Configuration Overview The Getting Started guides for windows and linux contain all the information needed to start your AR.IO Gateway node successfully with basic configurations. There are also ever expanding advanced configuration options that allow you to run your node in a way that is customized to your specific use case.Most of the below options can be added to your .env file in order to customize its operation. Any changes made to your .env require you to the docker containers running your node, and restarting them with the --build flag in order for the changes to take effect. See ENV for a complete list of environmental variables you can set.Data Storage Location You can set a custom location for your AR.IO Gateway to save the data it pulls from the Arweave network. There are three primary types of data stored, and you can set a unique storage location for each of these independently. These are "chunks data", "contiguous data", and "headers data". The custom location for each of these can be set in your.env file like this:Be sure to replace "" with the path to the location where you would like the data stored. If these values are omitted, the data will be stored in the "data" directory inside your Gateway code repository.Admin API Key HTTP endpoints under "/ar-io/admin" are protected by an admin API key. These endpoints allow you to get certain analytics data or make adjustments to your node as it's running. When your node starts, it reads your environmental variables to see if a key is set. If not, a random key is generated. The key name is ADMIN_API_KEY and it should be set in your .env file like this:ADMIN_API_KEY=SUPER_SECRET_PASSWORD View examples of the admin endpoints here Wallet Association In order to participate in the greater AR.IO network, Gateway nodes need to associate themselves with an Arweave wallet. This can be configured by setting the AR_IO_WALLET key value in your .env file.AR_IO_WALLET=1seRanklLU_1VTGowDZdD7s_-7k1qowT6oeFZHUZiZo Unbundling AR.IO Gateway nodes support unbundling and indexing ANS-104 bundle data. This is disabled by default, but can be turned on with several different configuration options. You can set these configurations with the ANS104_UNBUNDLE_FILTER and ANS104_INDEX_FILTER keys in your.env:The following types of filters are supported:Content Moderation You are able to set your Gateway to block specific transactions or data-items you don't want to serve. Unlike previous configuration options in this list, blocking content can be achieved without the need to add to your.env file and rebuild your Gateway. Instead, make a PUT request to your Gateway at /ar-io/admin/block-data. As this is an admin endpoint, you will need to have configured your ADMIN_API_KEY. Using curl as an example, the request should be formatted as follows:id (string): This will be the transaction ID of the content you want to add to your block list.notes (string): Internal notes regarding why a particular ID is blocked.source (string): Identifier of a particular source of IDs to block. (e.g. the name of a block list) notes and source are used for documentation only, and have no effect on your block list itself.Contiguous Data Cleanup Transaction data on Arweave is stored in a chunked manner. It is commonly retrieved, however, in the the transaction data's original, contiguous form with all of its component chunks assembled end-to-end. Gateways cache contiguous representations of the transaction data to assist in various workloads, including serving transaction data to clients, allowing for efficient utilization of valuable system resources. Gateway operators will need to determine for themselves the best balance between disk space and other resource usage based on the size of their gateway and their particular use case.Contiguous data cache cleanup can be enabled using the CONTIGUOUS_DATA_CACHE_CLEANUP_THRESHOLD environmental variable. This variable sets the number of seconds from the creation of a file in the contiguous data cache after which that file will be deleted. For example:CONTIGUOUS_DATA_CACHE_CLEANUP_THRESHOLD=10000 will clear items from the contiguous data cache after ten thousand (10,000) seconds.ArNS Resolver Gateways, by default, forward requests to resolve ArNS names to arweave.dev. Starting with Release 9 gateways can instead build and maintain their own local cache. Doing so removes external dependencies and allows faster resolution.View the code for the ArNS resolver service here: https://github.com/ar-io/arns-resolver NOTE: The ArNS resolver is still an experimental feature. It is possible it may behave in unexpected ways when presented with rare edge case scenarios.In order to enable the local ArNS resolver, three environmental variables will need to be set:RUN_RESOLVER is a boolean representing an on/off switch for the local resolver.TRUSTED_ARNS_RESOLVER_TYPE sets the method the gateway uses for resolving ArNS names. Use resolver for the local resolver, or gateway for default functionality.TRUSTED_ARNS_RESOLVER_URL is the url a gateway will use to request ArNS name resolution.

---

# 11. ARIO Docs

Document Number: 11
Source: https://docs.ar.io/gateways/ar-io-node/advanced-config.html
Words: 781
Quality Score: 0.551
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Advanced Configuration Overview The Getting Started guides for windows and linux contain all the information needed to start your AR.IO Gateway node successfully with basic configurations. There are also ever expanding advanced configuration options that allow you to run your node in a way that is customized to your specific use case.Most of the below options can be added to your .env file in order to customize its operation. Any changes made to your .env require you to the docker containers running your node, and restarting them with the --build flag in order for the changes to take effect. See ENV for a complete list of environmental variables you can set.Data Storage Location You can set a custom location for your AR.IO Gateway to save the data it pulls from the Arweave network. There are three primary types of data stored, and you can set a unique storage location for each of these independently. These are "chunks data", "contiguous data", and "headers data". The custom location for each of these can be set in your.env file like this:Be sure to replace "" with the path to the location where you would like the data stored. If these values are omitted, the data will be stored in the "data" directory inside your Gateway code repository.Admin API Key HTTP endpoints under "/ar-io/admin" are protected by an admin API key. These endpoints allow you to get certain analytics data or make adjustments to your node as it's running. When your node starts, it reads your environmental variables to see if a key is set. If not, a random key is generated. The key name is ADMIN_API_KEY and it should be set in your .env file like this:ADMIN_API_KEY=SUPER_SECRET_PASSWORD View examples of the admin endpoints here Wallet Association In order to participate in the greater AR.IO network, Gateway nodes need to associate themselves with an Arweave wallet. This can be configured by setting the AR_IO_WALLET key value in your .env file.AR_IO_WALLET=1seRanklLU_1VTGowDZdD7s_-7k1qowT6oeFZHUZiZo Unbundling AR.IO Gateway nodes support unbundling and indexing ANS-104 bundle data. This is disabled by default, but can be turned on with several different configuration options. You can set these configurations with the ANS104_UNBUNDLE_FILTER and ANS104_INDEX_FILTER keys in your.env:The following types of filters are supported:Content Moderation You are able to set your Gateway to block specific transactions or data-items you don't want to serve. Unlike previous configuration options in this list, blocking content can be achieved without the need to add to your.env file and rebuild your Gateway. Instead, make a PUT request to your Gateway at /ar-io/admin/block-data. As this is an admin endpoint, you will need to have configured your ADMIN_API_KEY. Using curl as an example, the request should be formatted as follows:id (string): This will be the transaction ID of the content you want to add to your block list.notes (string): Internal notes regarding why a particular ID is blocked.source (string): Identifier of a particular source of IDs to block. (e.g. the name of a block list) notes and source are used for documentation only, and have no effect on your block list itself.Contiguous Data Cleanup Transaction data on Arweave is stored in a chunked manner. It is commonly retrieved, however, in the the transaction data's original, contiguous form with all of its component chunks assembled end-to-end. Gateways cache contiguous representations of the transaction data to assist in various workloads, including serving transaction data to clients, allowing for efficient utilization of valuable system resources. Gateway operators will need to determine for themselves the best balance between disk space and other resource usage based on the size of their gateway and their particular use case.Contiguous data cache cleanup can be enabled using the CONTIGUOUS_DATA_CACHE_CLEANUP_THRESHOLD environmental variable. This variable sets the number of seconds from the creation of a file in the contiguous data cache after which that file will be deleted. For example:CONTIGUOUS_DATA_CACHE_CLEANUP_THRESHOLD=10000 will clear items from the contiguous data cache after ten thousand (10,000) seconds.ArNS Resolver Gateways, by default, forward requests to resolve ArNS names to arweave.dev. Starting with Release 9 gateways can instead build and maintain their own local cache. Doing so removes external dependencies and allows faster resolution.View the code for the ArNS resolver service here: https://github.com/ar-io/arns-resolver NOTE: The ArNS resolver is still an experimental feature. It is possible it may behave in unexpected ways when presented with rare edge case scenarios.In order to enable the local ArNS resolver, three environmental variables will need to be set:RUN_RESOLVER is a boolean representing an on/off switch for the local resolver.TRUSTED_ARNS_RESOLVER_TYPE sets the method the gateway uses for resolving ArNS names. Use resolver for the local resolver, or gateway for default functionality.TRUSTED_ARNS_RESOLVER_URL is the url a gateway will use to request ArNS name resolution.

---

# 12. ARIO Docs

Document Number: 12
Source: https://docs.ar.io/gateways/upgrading
Words: 350
Quality Score: 0.547
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Upgrading your Gateway To ensure the optimal performance and security of your AR.IO Gateway, it's essential to regularly upgrade to the latest version. Notably, indexed data resides separate from Docker. As a result, neither upgrading the Gateway nor pruning Docker will erase your data or progress. Here's how you can perform the upgrade:Prerequisites Your Gateway should have been cloned using git. If you haven't, follow the installation instructions for windows or linux.Checking your Release Number Effective with release 3, you can view the currently implemented release on any gateway by visiting https:///ar-io/info in a browser. Be sure to replace with the domain of the gateway you are checking.If the release number dised includes -pre it means that your gateway is using the develop branch of the github repo for the gateway code. Follow steps in our troubleshooting guide to switch over to the more stable main branch.Announcements will be made in our discord server showing each new release.Upgrade Steps Pull the latest changes from the repository Navigate to your cloned repository directory and execute the following command:Shut down Docker Depending on your operating system, use the respective commands:Linux Windows Prune Docker (Optional) It's a good practice to clean up unused Docker resources. Again, use the command based on your OS:NOTE: This will erase all inactive docker containers on your machine. If you use docker for anything beyond running a gateway be extremely careful using this command.Linux Windows Check for New Environmental Variables Read the update release change logs and community announcements to see if the new version includes any new environmental variables that you should set before restarting your gateway.Restart the Docker container Finally, start the Docker container again to implement the changes:Linux Windows NOTE: Effective with Release #3, it is no longer required to include the --build flag when starting your gateway. Docker will automatically build using the image specified in the docker-commpose.yaml file.That's it! Your AR.IO Gateway is now upgraded to the latest version. Ensure to test and verify that everything is functioning as expected. If you encounter any issues, reach out to the AR.IO community for assistance.

---

# 13. Uploading to Arweave - ARIO Docs

Document Number: 13
Source: https://docs.ar.io/guides/uploading-to-arweave
Words: 337
Quality Score: 0.540
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Uploading to Arweave Overview While AR.IO provides powerful tools for accessing and interacting with data on Arweave, that data must first be uploaded to the network. This guide will walk you through the process of uploading data to Arweave using the Turbo SDK, which provides a streamlined experience for data uploads.Installing Turbo SDK Authentication Node.js Environment Browser Environment Purchasing Turbo Credits Turbo Credits are the payment medium used by the Turbo Upload Service. Each Credit represents a 1:1 conversion from the upload power of the Arweave native token (AR). Turbo Credits can be purchased with fiat currency via the Turbo Top Up App, or with supported cryptocurrencies via the Turbo SDK. Credits and available methods for purchasing them here.Node.js Environment Browser Environment In a browser environment, the topUpWithTokens method is not available. Instead, you'll need to manually send tokens to the Turbo wallet address and then submit the transaction for processing. Here are detailed examples for each supported chain:Browser Top-Up Examples Note: The wait times for chain settlement are approximate and may need adjustment based on network conditions:Ethereum: ~15 minutes Solana: ~400-600 milliseconds Arweave: ~30-36 minutes Polygon: ~2-3 seconds Base: ~2-5 seconds KYVE: ~5 minutes Once you have purchased Turbo credits, you can upload files and folders to Arweave. The process is the same regardless of which token type you used for authentication, but differs between Node.js and browser environments.Node.js Environment Node.js Upload Examples Browser Environment Browser Upload Examples Important Notes:For single file uploads, always include a Content-Type tag to ensure proper file viewing The fileStreamFactory must return a NEW stream each time it's called Folder uploads automatically detect and set Content-Type tags for all files You can specify additional tags in dataItemOpts for both file and folder uploads The maxConcurrentUploads option controls how many files are uploaded simultaneously Use throwOnFailure: true to ensure all files are uploaded successfully Complete Examples Here are complete examples showing how to authenticate, check balances, and handle lazy funding for uploads. These examples demonstrate the full workflow from start to finish.

---

# 14. ARIO Docs

Document Number: 14
Source: https://docs.ar.io/wayfinder/getting-started
Words: 564
Quality Score: 0.538
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Getting Started with Wayfinder Wayfinder provides decentralized and verified access to data stored on Arweave. This guide will help you get started with the core concepts and basic usage.Installation Choose the package that fits your project:Core Library (JavaScript/TypeScript) React Components Quick Start Basic Usage The simplest way to get started is with the default configuration:React Integration For React applications, use the wayfinder-react package:import { LocalStorageGatewaysProvider, NetworkGatewaysProvider } from '@ar.io/wayfinder-core'
import { WayfinderProvider, useWayfinder } from '@ar.io/wayfinder-react'
// Wrap your app with the provider
function App() {
return (

)
}
function YourComponent() {
const txId = 'your-transaction-id'; // Replace with actual txId
// Use custom hooks for URL resolution and data fetching
const request = useWayfinderRequest();
// store the fetched data
const [data, setData] = useState(null);
const [dataLoading, setDataLoading] = useState(false);
const [dataError, setDataError] = useState(null);
useEffect(() => {
(async () => {
try {
setDataLoading(true);
setDataError(null);
// fetch the data for the txId using wayfinder
const response = await request(`ar://${txId}`, {
verificationSettings: {
enabled: true, // enable verification on the request
strict: true, // don't use the data if it's not verified
},
});
const data = await response.arrayBuffer(); // or response.json() if you want to parse the data as JSON
setData(data);
} catch (error) {
setDataError(error as Error);
} finally {
setDataLoading(false);
}
})();
}, [request, txId]);
return (
{dataLoading && Loading data...}
{dataError && Error loading data: {dataError.message}}
{data}
);
} Available Strategies Routing Strategies ← Swipe to see more → Strategy Description Use Case FastestPingRoutingStrategy Selects gateway with lowest latency Performance-critical applications PreferredWithFallbackRoutingStrategy Tries preferred gateway first, falls back to others When you have a trusted primary gateway RoundRobinRoutingStrategy Distributes requests evenly across gateways Load balancing and fair distribution RandomRoutingStrategy Randomly selects from available gateways Simple load distribution ← Swipe to see more → Verification Strategies Verification strategies may be dependent on the gateway being used having the
data indexed locally. A gateway cannot verify data it doesn't have access to
or hasn't indexed yet.Advanced Configuration For production applications, you'll want to configure gateway providers, routing strategies, and verification:import {
Wayfinder,
NetworkGatewaysProvider,
FastestPingRoutingStrategy,
HashVerificationStrategy,
} from '@ar.io/wayfinder-core'
import { ARIO } from '@ar.io/sdk'
const wayfinder = new Wayfinder({
// Discover gateways from the AR.IO Network
gatewaysProvider: new SimpleCacheGatewaysProvider({
gatewaysProvider: new NetworkGatewaysProvider({
ario: ARIO.mainnet(),
limit: 10,
sortBy: 'operatorStake',
sortOrder: 'desc',
}),
}),
// Use fastest ping routing strategy
routingSettings: {
strategy: new FastestPingRoutingStrategy({
timeoutMs: 500,
}),
events: {
onRoutingSucceeded: (event) => {
console.log('Selected gateway:', event.selectedGateway)
},
},
},
// Enable data verification
verificationSettings: {
enabled: true,
strategy: new HashVerificationStrategy({
trustedGateways: ['https://arweave.net'],
}),
events: {
onVerificationSucceeded: (event) => {
console.log('Verification passed for:', event.txId)
},
onVerificationFailed: (event) => {
console.log('Verification failed for:', event.txId)
},
},
},
// Enable telemetry
telemetrySettings: {
enabled: true,
clientName: 'my-app',
clientVersion: '1.0.0',
sampleRate: 0.1, // 10% sampling
},
}) Core Concepts Gateway Providers Gateway providers discover and manage the list of available AR.IO gateways:NetworkGatewaysProvider: Fetches gateways from the AR.IO Network StaticGatewaysProvider: Uses a predefined list of gateways SimpleCacheGatewaysProvider: Caches gateway lists for performance in-memory LocalStorageGatewaysProvider Caches gateway lists for performance in window.localStorage Routing Strategies Routing strategies determine which gateway to use for each request:FastestPingRoutingStrategy: Selects the gateway with lowest latency PreferredWithFallbackRoutingStrategy: Tries a preferred gateway first RoundRobinRoutingStrategy: Distributes requests evenly RandomRoutingStrategy: Randomly selects gateways Verification Strategies Verification strategies ensure data integrity:HashVerificationStrategy: Verifies data against trusted gateway hashes SignatureVerificationStrategy: Validates Arweave transaction signatures DataRootVerificationStrategy: Verifies against transaction data roots

---

# 15. ARIO Docs

Document Number: 15
Source: https://docs.ar.io/guides/gql
Words: 1295
Quality Score: 0.534
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

GraphQL Overview GraphQL is a powerful query language designed for modern web applications to efficiently fetch data. It enables precise queries, allowing users to specify exactly which data they need and in what format, significantly reducing the amount of unnecessary data transferred. This approach is ideal for dealing with complex systems and large datasets, as it minimizes bandwidth and improves performance. GraphQL operates through a single endpoint, streamlining the way applications communicate with databases.The integration of GraphQL with Arweave introduces a refined method for interacting with decentralized data storage. Arweave allows for the tagging of uploaded data, facilitating enhanced searchability and retrievability within its blockchain network. Utilizing GraphQL, users can perform targeted queries that leverage these tags, ensuring the retrieval of specific data swiftly and efficiently. This capability is particularly beneficial for the development of decentralized applications (dApps), the archival of content in a permanent and unalterable form, and the establishment of data marketplaces where precision and efficiency in data access are paramount.Together, GraphQL and Arweave form a compelling combination, offering developers and users a robust framework for managing and querying data in a decentralized environment. This integration not only promotes the efficient and scalable retrieval of data but also supports the creation of more sophisticated and data-intensive applications on the decentralized web, maintaining a balance between technical depth and accessibility.Constructing a Query Basic Syntax In GraphQL, you start with a root field and use braces to outline the fields you want to retrieve, allowing for precise, hierarchical data requests. For instance:This query demonstrates fetching transactions and their tags, illustrating the hierarchical nature of GraphQL queries.Customizing Searches with Tags Arweave utilizes a tagging system for transactions, enabling intricate search capabilities. You can filter queries using these tags:This example filters transactions by a specific application name, and returns the id, size, and type of the transaction, showcasing how to customize queries for targeted data retrieval.NOTE: Tags are not the only option for filtering results, but are extremely useful due to the ability to add custom tags during the upload process.Understanding Edges and Nodes In the realm of GraphQL queries, especially when interfacing with Arweave, grasping the concept of edges and nodes is pivotal for constructing efficient and effective queries. This structure is not unique to Arweave but is particularly relevant due to the decentralized and interconnected nature of the data stored on its blockchain.Nodes: At the heart of GraphQL's query structure, nodes represent individual data points or entities. In the context of Arweave, a node could be a transaction, a block, or any piece of data stored within the network. Nodes are the primary targets of your query, containing the data you wish to retrieve, such as transaction IDs, tags, or the content of data transactions.Edges: Serving as the glue between nodes, edges are constructs that outline the relationship between different nodes. They can contain metadata about the connection, such as the nature of the relationship or additional attributes that describe how nodes are linked. In many GraphQL implementations, including those that interact with Arweave, edges are used to navigate through collections of related data, making them crucial for understanding the data's structure and lineage.This hierarchical model is especially useful for querying complex and relational data sets, allowing for detailed navigation and efficient data retrieval within Arweave's decentralized storage system. By effectively utilizing the edges and nodes structure, you can precisely target the data you need, whether it's filtering transactions by tags, fetching related transactions, or exploring the blockchain's structure.Pagination To add pagination to your GraphQL queries, you can use the first, last, before, and after parameters. These parameters control the slice of data you're querying, making data retrieval more efficient and manageable.first: Specify the number of items to retrieve from the start of the list or dataset.last: Specify the number of items to retrieve from the end of the list or dataset.This query fetches the first 10 transactions.To navigate through your dataset, you can use after and before in conjunction with first or last. These parameters accept cursors, which are typically provided in the response of your initial query.after: Fetch items after the specified cursor, used with first.before: Fetch items before the specified cursor, used with last.This query fetches the next 10 transactions following the transaction with the cursor "cursorOfLastItem".If no pagination terms are set, GraphQL servers may apply default limits to prevent excessively large datasets from being returned in a single query, potentially impacting performance. The default behavior can vary based on the server's configuration but often involves returning a predefined maximum number of items.For instance, without specifying first or last, a query to the transactions field might return the first 5-10 transactions by default, depending on the server settings.This behavior ensures that server resources are not overwhelmed by large requests and that client applications receive data in manageable chunks.General Tips for Optimizing Queries To optimize your GraphQL queries in Arweave, follow these general guidelines:Specificity: Query with the most precise tags possible to narrow the search scope and enhance performance.Minimalism: Limit your query to the essential set of tags to reduce processing time and data transfer.Schema Design: Design your app's schema to reflect query patterns, possibly introducing tags that encapsulate frequent combinations of criteria.Include Non-tag Fields: Adding fields like owner can refine your search, making your queries more efficient.Order Your Tags: Arrange tags from most specific to most general to leverage Arweave's indexing more effectively.By incorporating these strategies, developers can achieve faster and more precise data access from Arweave, enhancing the performance and responsiveness of decentralized applications. This balanced approach to query construction and optimization is key to navigating the expansive and decentralized storage landscape Arweave provides.Making a Query Executing GraphQL queries within the Arweave ecosystem offers flexibility and multiple avenues for developers and users alike. Whether you prefer a hands-on, manual approach to constructing and testing queries, or you aim for automation and integration within your applications, Arweave provides the tools necessary to interact with its decentralized data storage seamlessly.GraphQL ground For those new to GraphQL or seeking to fine-tune their queries before implementation, the GraphQL ground offers an invaluable resource. This interactive interface allows users to manually construct queries, explore the schema, and immediately see the results of their queries. Accessible via web browsers, the ground can be found at the /graphql endpoint of most Arweave indexing services, such as https://arweave.dev/graphql. Here, you can experiment with different queries, understand the structure of the data, and refine your approach without writing a single line of code in your application.Steps for Accessing the GraphQL ground:Navigate to https://arweave.dev/graphql, or the graphql endpoint of any AR.IO gateway, in your web browser.Enter your GraphQL query in the provided interface.Press the "" button to execute the query to see real-time results and debug as needed.Using an API For application development and automation, making GraphQL queries programmatically is essential. You can send POST requests directly to the GraphQL endpoint of any indexing service that supports it, such as arweave.net or any AR.IO gateway. These requests should contain your query in the body, allowing for dynamic and automated data retrieval within your application.When selecting an indexing service, consider the data coverage and reliability of the gateway to ensure it meets your application's needs. Different gateways might have varying degrees of indexed data available, so choosing one that is consistently up-to-date and comprehensive is key.Example of making a programmatic query:Using an SDK For an even more integrated experience, some Software Development Kits (SDKs) offer direct methods for executing GraphQL queries. The Arweave SDK, for example, provides built-in functionalities to interact with the blockchain, simplifying the process of making queries. By leveraging these SDKs, developers can bypass the intricacies of manual HTTP request construction, focusing instead on the logic and design of their applications.Example of using the Arweave SDK for GraphQL queries:

---

# 16. ARIO Docs

Document Number: 16
Source: https://docs.ar.io/build/guides/gql
Words: 1295
Quality Score: 0.534
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

GraphQL Overview GraphQL is a powerful query language designed for modern web applications to efficiently fetch data. It enables precise queries, allowing users to specify exactly which data they need and in what format, significantly reducing the amount of unnecessary data transferred. This approach is ideal for dealing with complex systems and large datasets, as it minimizes bandwidth and improves performance. GraphQL operates through a single endpoint, streamlining the way applications communicate with databases.The integration of GraphQL with Arweave introduces a refined method for interacting with decentralized data storage. Arweave allows for the tagging of uploaded data, facilitating enhanced searchability and retrievability within its blockchain network. Utilizing GraphQL, users can perform targeted queries that leverage these tags, ensuring the retrieval of specific data swiftly and efficiently. This capability is particularly beneficial for the development of decentralized applications (dApps), the archival of content in a permanent and unalterable form, and the establishment of data marketplaces where precision and efficiency in data access are paramount.Together, GraphQL and Arweave form a compelling combination, offering developers and users a robust framework for managing and querying data in a decentralized environment. This integration not only promotes the efficient and scalable retrieval of data but also supports the creation of more sophisticated and data-intensive applications on the decentralized web, maintaining a balance between technical depth and accessibility.Constructing a Query Basic Syntax In GraphQL, you start with a root field and use braces to outline the fields you want to retrieve, allowing for precise, hierarchical data requests. For instance:This query demonstrates fetching transactions and their tags, illustrating the hierarchical nature of GraphQL queries.Customizing Searches with Tags Arweave utilizes a tagging system for transactions, enabling intricate search capabilities. You can filter queries using these tags:This example filters transactions by a specific application name, and returns the id, size, and type of the transaction, showcasing how to customize queries for targeted data retrieval.NOTE: Tags are not the only option for filtering results, but are extremely useful due to the ability to add custom tags during the upload process.Understanding Edges and Nodes In the realm of GraphQL queries, especially when interfacing with Arweave, grasping the concept of edges and nodes is pivotal for constructing efficient and effective queries. This structure is not unique to Arweave but is particularly relevant due to the decentralized and interconnected nature of the data stored on its blockchain.Nodes: At the heart of GraphQL's query structure, nodes represent individual data points or entities. In the context of Arweave, a node could be a transaction, a block, or any piece of data stored within the network. Nodes are the primary targets of your query, containing the data you wish to retrieve, such as transaction IDs, tags, or the content of data transactions.Edges: Serving as the glue between nodes, edges are constructs that outline the relationship between different nodes. They can contain metadata about the connection, such as the nature of the relationship or additional attributes that describe how nodes are linked. In many GraphQL implementations, including those that interact with Arweave, edges are used to navigate through collections of related data, making them crucial for understanding the data's structure and lineage.This hierarchical model is especially useful for querying complex and relational data sets, allowing for detailed navigation and efficient data retrieval within Arweave's decentralized storage system. By effectively utilizing the edges and nodes structure, you can precisely target the data you need, whether it's filtering transactions by tags, fetching related transactions, or exploring the blockchain's structure.Pagination To add pagination to your GraphQL queries, you can use the first, last, before, and after parameters. These parameters control the slice of data you're querying, making data retrieval more efficient and manageable.first: Specify the number of items to retrieve from the start of the list or dataset.last: Specify the number of items to retrieve from the end of the list or dataset.This query fetches the first 10 transactions.To navigate through your dataset, you can use after and before in conjunction with first or last. These parameters accept cursors, which are typically provided in the response of your initial query.after: Fetch items after the specified cursor, used with first.before: Fetch items before the specified cursor, used with last.This query fetches the next 10 transactions following the transaction with the cursor "cursorOfLastItem".If no pagination terms are set, GraphQL servers may apply default limits to prevent excessively large datasets from being returned in a single query, potentially impacting performance. The default behavior can vary based on the server's configuration but often involves returning a predefined maximum number of items.For instance, without specifying first or last, a query to the transactions field might return the first 5-10 transactions by default, depending on the server settings.This behavior ensures that server resources are not overwhelmed by large requests and that client applications receive data in manageable chunks.General Tips for Optimizing Queries To optimize your GraphQL queries in Arweave, follow these general guidelines:Specificity: Query with the most precise tags possible to narrow the search scope and enhance performance.Minimalism: Limit your query to the essential set of tags to reduce processing time and data transfer.Schema Design: Design your app's schema to reflect query patterns, possibly introducing tags that encapsulate frequent combinations of criteria.Include Non-tag Fields: Adding fields like owner can refine your search, making your queries more efficient.Order Your Tags: Arrange tags from most specific to most general to leverage Arweave's indexing more effectively.By incorporating these strategies, developers can achieve faster and more precise data access from Arweave, enhancing the performance and responsiveness of decentralized applications. This balanced approach to query construction and optimization is key to navigating the expansive and decentralized storage landscape Arweave provides.Making a Query Executing GraphQL queries within the Arweave ecosystem offers flexibility and multiple avenues for developers and users alike. Whether you prefer a hands-on, manual approach to constructing and testing queries, or you aim for automation and integration within your applications, Arweave provides the tools necessary to interact with its decentralized data storage seamlessly.GraphQL ground For those new to GraphQL or seeking to fine-tune their queries before implementation, the GraphQL ground offers an invaluable resource. This interactive interface allows users to manually construct queries, explore the schema, and immediately see the results of their queries. Accessible via web browsers, the ground can be found at the /graphql endpoint of most Arweave indexing services, such as https://arweave.dev/graphql. Here, you can experiment with different queries, understand the structure of the data, and refine your approach without writing a single line of code in your application.Steps for Accessing the GraphQL ground:Navigate to https://arweave.dev/graphql, or the graphql endpoint of any AR.IO gateway, in your web browser.Enter your GraphQL query in the provided interface.Press the "" button to execute the query to see real-time results and debug as needed.Using an API For application development and automation, making GraphQL queries programmatically is essential. You can send POST requests directly to the GraphQL endpoint of any indexing service that supports it, such as arweave.net or any AR.IO gateway. These requests should contain your query in the body, allowing for dynamic and automated data retrieval within your application.When selecting an indexing service, consider the data coverage and reliability of the gateway to ensure it meets your application's needs. Different gateways might have varying degrees of indexed data available, so choosing one that is consistently up-to-date and comprehensive is key.Example of making a programmatic query:Using an SDK For an even more integrated experience, some Software Development Kits (SDKs) offer direct methods for executing GraphQL queries. The Arweave SDK, for example, provides built-in functionalities to interact with the blockchain, simplifying the process of making queries. By leveraging these SDKs, developers can bypass the intricacies of manual HTTP request construction, focusing instead on the logic and design of their applications.Example of using the Arweave SDK for GraphQL queries:

---

# 17. ARIO Gateway Grafana - ARIO Docs

Document Number: 17
Source: https://docs.ar.io/gateways/grafana
Words: 694
Quality Score: 0.531
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Grafana Analytics Overview AR.IO gateways track a significant number of performance and operation metrics using Prometheus.
A Grafana sidecar can be deployed to visualize these metrics, and provide an easy way to monitor the health of the gateway.
The Grafana sidecar is deployed as a separate docker container that uses the same network as the gateway, and is deployed in a similar manner.Deploying Grafana The file that controls the deployment of the Grafana sidecar is docker-compose.grafana.yaml. So to deploy Grafana, run the following command:The -f flag is used to specify the path to the docker-compose file, and the up -d flag is used to deploy the container in detached mode.Terminal Location This command assumes that you are running the command from the root directory of the gateway. If you are running the command from a different directory, you will need to adjust the path to the docker-compose file.Checking the logs To check the logs of the Grafana sidecar, run the following command:The -f flag is used to follow the logs, and the --tail=25 flag is used to specify the number of lines to show from the end of the logs, in this case 25.Exit the logs by pressing Ctrl+C.In some cases, the Grafana sidecar may encounter permission errors. There are two primary solutions to this issue:Modify Directory Permissions The simplest solution is to modify the permissions of the directory that contains the Grafana data.This will give the grafana user ownership of the directory and all its contents.Terminal Location This command assumes that you are running the command from the root directory of the gateway. If you are running the command from a different directory, you will need to adjust the path to the docker-compose file.Check the logs again to ensure that the issue is resolved.Change the Grafana User The second solution is to change the user that Grafana runs as. This can be done by modifying the docker-compose.grafana.yaml file to use a different user. It is suggested to use "root" or "0" to ensure that the container has the necessary permissions.In any editor, open the docker-compose.grafana.yaml file and add "user: root" to the grafana service.Once this is done, restart the Grafana sidecar by running the following command:Check the logs again to ensure that the issue is resolved.Configure Nginx The Grafana sidecar is deployed on the same network as the gateway, and can be accessed in a browser by navigating to http://localhost:1024 from the machine running the gateway.
In order to be able to access Grafana from outside the network running the gateway, Nginx, which is already used to route gateway traffic, can be configured to route Grafana traffic to the correct port.In any editor, open the relevant Nginx configuration file. If the setup guide configuration was used, that file will be located at /etc/nginx/sites-available/default.Add the following block to the configuration file inside the server block for https (443) traffic:The full configuration file should look like this:Be sure to replace with the domain of the gateway.Once the configuration is saved, test the configuration by running the following command:This will print out a message indicating that the configuration is valid.Then, restart Nginx by running the following command:Once this is done, Grafana can be accessed by navigating to https:///grafana in a browser.Accessing Grafana To access Grafana, navigate to https:///grafana in a browser.The default credentials are:Username: admin Password: admin Once logged in for the first time, you will be prompted to change the password.Credential Reset Updated credentials may be lost if the Grafana sidecar is restarted. Be sure to log into Grafana immediately after every start up to ensure Grafana cannot be accessed with the default credentials.Dashboards The Grafana sidecar comes preloaded with three dashboards:ar-io-node: Contains general gateway metrics, like the last block indexed, ArNS resolution times, and CPU usage.ar-io-node bundle indexing: Contains metrics related to bundle indexing, like the number of bundles and data items indexed.ar-io-node queue lengths: Contains metrics related to the queue lengths of the gateway, like Arweave Client requests and transaction importer data.Additional dashboards can be added in order to monitor different aspects of the gateway.The Grafana landing page contains tutorials for how to configure dashboards, as well as additional features such as alerting.

---

# 18. ARIO Docs

Document Number: 18
Source: https://docs.ar.io/gateways/windows-setup
Words: 1299
Quality Score: 0.524
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Windows Installation Instructions Overview This guide provides step-by-step instructions for setting up the AR.IO node on a Windows computer. It covers installing necessary software, cloning the repository, creating an environment file, starting the Docker container, setting up networking, and installing and configuring NGINX Docker. No prior coding experience is required.Prerequisites Before starting the installation process, ensure you have the following:A Windows computer Administrative privileges on the computer Install Required Packages Install Docker:Download Docker Desktop for Windows from here.Run the installer and follow the prompts.During installation, make sure to select the option to use WSL (Windows Subsystem for Linux) rather than Hyper-V.Restart your PC.Update Windows Subsystem for Linux (WSL):Open the command prompt as an administrator:Press Windows Key + R.Type cmd and press Enter.Right-click on the "Command Prompt" application in the search results.Select "Run as administrator" from the context menu.Run the following commands:Restart Docker Desktop.Install Git:Download Git for Windows from here.Run the installer and use the default settings.Clone the Repository Clone the main repository:Open the command prompt:Press Windows Key + R.Type cmd and press Enter.Navigate to the directory where you want to clone the repository:Use the cd command to change directories. For example, to navigate to the Documents directory:More detailed instructions on navigating with the cd command can be found here NOTE: Your database of Arweave Transaction Headers will be created in the project directory, not Docker. So, if you are using an external hard drive to turn an old machine into a node, install the node directly to that external drive.Run the following command:Create the Environment File Create an environmental variables file:Open a text editor (e.g., Notepad):Press Windows Key and search for "Notepad".Click on "Notepad" to open the text editor.Paste the following content into the new file, replacing with the domain address you are using to access the node, and with the public address of your Arweave wallet:The GRAPHQL values set the proxy for GQL queries to arweave.net, You may use any available gateway that supports GQL queries. If omitted, your node can support GQL queries on locally indexed transactions, but only L1 transactions are indexed by default.START_HEIGHT is an optional line. It sets the block number where your node will start downloading and indexing transactions headers. Omitting this line will begin indexing at block 0.RUN_OBSERVER turns on the Observer to generate Network Compliance Reports. This is required for full participation in the AR.IO Network. Set to false to run your gateway without Observer.ARNS_ROOT_HOST sets the starting point for resolving ARNS names, which are accessed as a subdomain of a gateway. It should be set to the url you are pointing to your node, excluding any protocol prefix. For example, use node-ar.io and not https://node-ar.io. If you are using a subdomain to access your node and do not set this value, the node will not understand incoming requests.AR_IO_WALLET is optional, and sets the wallet you want associated with your Gateway. An associated wallet is required to join the AR.IO network.OBSERVER_WALLET is the public address of the wallet used to sign Observer transactions. This is required for Observer to run, but may be omitted if you are running a gateway outside of the AR.IO network and do not plan to run Observer. You will need to supply the keyfile to this wallet in the next step.Advanced configuration options can be found at docs.ar.io Save the file with the name ".env" and make sure to select "All Files" as the file type. This helps to ensure the file saves as ".env" and not ".env.txt" Note: The .env file should be saved inside the same directory where you cloned the repository (e.g., ar-io-node).Supply Your Observer Wallet Keyfile:If you are running Observer, you need to provide a wallet keyfile in order to sign report upload transactions. The keyfile must be saved in the wallets directory in the root of the repository. Name the file .json, replacing "" with the public address of the wallet. This should match your OBSERVER_WALLET environmental variable. Arweave wallets and obtaining keyfiles here Start the Docker Containers Start the Docker container:Open the command prompt:Press Windows Key + R.Type cmd and press Enter.Navigate to the directory where you cloned the repository (e.g., ar-io-node):Use the cd command to change directories. For example, if the repository is located in the Documents directory, you would enter:If the directory path contains spaces, enclose it in double quotation marks. For example:Use the dir command to list the contents of the current directory and verify that you're in the correct location:dir Once you are in the correct directory, run the following command to start the Docker container:Explanation of flags:up: Start the Docker containers.-d: Run the containers as background processes (detached mode).NOTE: Effective with Release #3, it is no longer required to include the --build flag when starting your gateway. Docker will automatically build using the image specified in the docker-commpose.yaml file.The gateway can be shut down using the command:If prompted by the firewall, allow access for Docker when requested.Set Up Router Port Forwarding To expose your node to the internet and use a custom domain, follow these steps:Obtain a Domain Name:Choose a domain registrar (e.g., Namecheap) and purchase a domain name.Point the Domain at Your Home Network:In your browser, go to https://www.whatsmyip.org/ to dis your public ip address. It can be found at the top of the screen. Note this number down.Access your domain registrar's settings (e.g., Namecheap's cPanel).Navigate to the DNS settings for your domain. In cPanel this is under the "Zone Editor" tab.Create an A record with your registrar for your domain and wildcard subdomains, using your public IP address. For example, if your domain is "ar.io," create a record for "ar.io" and "*.ar.io." Instructions may vary depending on the domain registrar and cPanel. Consult your registrar's documentation or support for detailed steps.Obtain the Local IP Address of Your Machine:Open the command prompt:Press Windows Key + R.Type cmd and press Enter.Run the following command:ipconfig Look for the network adapter that is currently connected to your network (e.g., Ethernet or Wi-Fi).Note down the IPv4 Address associated with the network adapter. It should be in the format of 192.168.X.X or 10.X.X.X.This IP address will be used for port forwarding.Set Up Router Port Forwarding:Access your home router settings:Open a web browser.Enter your router's IP address in the address bar (e.g., 192.168.0.1).If you're unsure of your router's IP address, consult your router's documentation or contact your Internet Service Provider (ISP).Navigate to the port forwarding settings in your router configuration.The exact steps may vary depending on your router model. Consult your router's documentation or support for detailed steps.Set up port forwarding rules to forward incoming traffic on ports 80 and 443 to the local IP address of your machine where the node is installed.Configure the ports to point to the local IP address noted in the previous step.Save the settings.Install and Configure NGINX Docker Clone the NGINX Docker repository:Open the command prompt:Press Windows Key + R.Type cmd and press Enter.Navigate to the directory where you want to clone the repository (This should not be done inside the directory for the node):Use the cd command to change directories. For example, to navigate to the Documents directory:Run the following command:Note: This NGINX container was designed to easily automate many of the more technical aspects of setting up NGNIX and obtaining an ssl certificate so your node can be accessed with https. However, wildcard domain certifications cannot be universally automated due to significant security concerns. Be sure to follow the instructions in this project for obtaining wildcard domain certificates in order for your node to function properly.Follow the instructions provided in the repository for setting up NGINX Docker.Congratulations! Your AR.IO node is now running and connected to the internet. Test it by entering https:///3lyxgbgEvqNSvJrTX2J7CfRychUD5KClFhhVLyTPNCQ in your browser.Note: If you encounter any issues during the installation process, please seek assistance from the AR.IO community.

---

# 19. Gateway Network - ARIO Docs

Document Number: 19
Source: https://docs.ar.io/gateways/gateway-network
Words: 651
Quality Score: 0.523
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Overview The AR.IO Network consists of AR.IO gateway nodes, which are identified by their registered Arweave wallet addresses and either their IP addresses or hostnames, as stored in the network's smart contract Gateway Address Registry (GAR).These nodes adhere to the AR.IO Network’s protocols, creating a collaborative environment of gateway nodes that vary in scale and specialization.
The network promotes a fundamental level of service quality and trust minimization among its participants.Being part of the network grants AR.IO gateways an array of advantages, such as:Simplified advertising of services and discovery by end users via the Gateway Address Registry.More rapid bootstrapping of key gateway operational data due to prioritized data request fulfillment among gateways joined to the network.Sharing of data processing results.Auditability and transparency through the use of AGPL-3 licenses, which mandate public disclosure of any software changes, thereby reinforcing the network's integrity and reliability.Improved network reliability and performance through an incentive protocol, which uses a system of evaluations and rewards to encourage high-quality service from gateways.Eligibility to accept delegated staking improving a gateway’s discoverability and reward opportunities.Gateway Address Registry (GAR) Any gateway operator that wishes to join the AR.IO Network must register their node in the AR.IO smart contract’s “Gateway Address Registry”, known as the GAR.
Registration involves staking a minimum amount of ARIO tokens and providing additional metadata describing the gateway service offered.After joining the network, the operator’s gateway can be easily discovered by permaweb apps, its health can be observed, and it can participate in data sharing protocols.
A gateway becomes eligible to participate in the network’s incentive protocol in the epoch following the one they joined in.The GAR advertises the specific attributes of each gateway including its stake, delegates, settings and services.
This enables permaweb apps and users to discover which gateways are currently available and meet their needs.
Apps that read the GAR can sort and filter it using the gateway metadata, for example, ranking gateways with the highest stake, reward performance, or feature set at the top of the list.
This would allow users to prefer the higher staked, more rewarded gateways with certain capabilities over lower staked, less rewarded gateways.Data Sharing A key advantage and incentive for networked AR.IO gateways over standalone gateways is their ability to preferentially share various kinds of Arweave data among one another.
Each gateway advertises its registered Arweave wallet address, so other network participants know who they are.Gateways can identify AR.IO Network peers by evaluating the Gateway Address Registry (GAR) within the AR.IO smart contract.
They utilize that peer list to request as-yet-uncached data on behalf of their requesting clients or in service of their internal workflows.
This can include requests for transaction header data, data items, and chunks. The Arweave Network shall act as the back for all block data, transaction header data, and chunk data.Additionally, gateways that receive requests for cache-missed data from other gateways can provide a higher quality of service to other AR.IO gateways than that which is provided to general users, apps, and infrastructure.
However, gateways are not forced to share data with one another and can choose not to share their data if the intended recipient is acting maliciously.
Such behaviors might include failure to reciprocate in data sharing, engaging in dishonest activities / observation, or distributing invalid data.Data Verification Gateway data verification is achieved by linking content hashes of transactions and data items to data roots on the Arweave base layer chain.
Gateways index the chain from a trusted Arweave node and compute data roots for the base layer transaction data they download, ensuring that their data aligns with what was originally uploaded to Arweave.
For base layer bundles that have already been verified, gateways compute hashes of individual data items, establishing a connection between the data root, the verified bundle, and the data items it contains.
Gateways then expose these hashes and their verification status to users via HTTP headers on data responses.

---

# 20. ARIO Docs

Document Number: 20
Source: https://docs.ar.io/wayfinder/core/telemetry
Words: 178
Quality Score: 0.515
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Telemetry Configuration Wayfinder includes optional telemetry support built on the OpenTelemetry standard. Telemetry is completely opt-in and disabled by default.Overview Wayfinder's telemetry system:100% Opt-in: Disabled by default, only enabled when you explicitly configure it OpenTelemetry Standard: Built on the industry-standard OpenTelemetry framework Your Choice of Destination: Send data to your own servers Configurable: Full control over what data is collected and where it goes All telemetry is disabled by default. It only activates when you
explicitly enable it in your configuration.Basic Configuration Minimal Setup Send to Your Own Infrastructure Configuration Options Client Identification You can identify your client application and version in telemetry data:Frequently Asked Questions Q: Is telemetry enabled by default?A: No, telemetry is completely disabled by default and only activates when you explicitly configure it.Q: Can I use my own telemetry backend?A: Yes, specify your own exporterUrl to send data to any OpenTelemetry-compatible backend.Q: Does this affect performance?A: Minimal impact when using appropriate sampling rates (1-10% for production).Q: Can I disable telemetry after enabling it?A: Yes, simply set enabled: false or remove the telemetrySettings configuration entirely.

---

# 21. Managing Undernames - ARIO Docs

Document Number: 21
Source: https://docs.ar.io/guides/managing-undernames
Words: 302
Quality Score: 0.512
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Overview ArNS undernames are subdomains of top level ArNS domains. They are separated from the main ArNS domain using an underscore "_" in place of the more typically used dot ".".Records for undernames can be set using the setRecord method on the AR.IO SDK, or removed by using the removeRecord method.
The process for setting/removing a record for an undername vs. a top level ArNS domain is nearly identical, the only difference being the undername parameter. When managing a record on a top level ArNS domain, this must be set to @, while updates to an undername should provide the undername being updated.Chaining Undernames Undernames can be created on other undernames, for example ar://og_logo_ardrive. In this example the undername og exists under the undername logo on the ArNS name ardrive.For the purpose of the undername parameter in the AR.IO SDK, this should be written as a single undername, including the separating underscores:og_logo Creating an Undername There are no special steps required to create an undername (provided the selected ArNS name has available undername space). Simply setting a record for an undername that does not exist will create the undername.Updating an Undername If an undername already exists, its record can easily be updated using the same setRecord method.Removing an Undername An existing undername can be removed by using the removeRecord method on the AR.IO SDK.
The undername parameter should be set to the undername being removed.Increasing Undername Support By default, ArNS names support up to 10 undernames. This number can be increased, for a fee. This is done using the increaseUndernameLimit method on the ARIO class of the AR.IO SDK, rather than the ANT class.
The quantity (qty) parameter specifies the number of ADDITIONAL undernames to be supported. i.e. increasing from 10 undernames to 15 would require the qty parameter set to 5.

---

# 22. Managing Undernames - ARIO Docs

Document Number: 22
Source: https://docs.ar.io/build/guides/managing-undernames
Words: 302
Quality Score: 0.512
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Overview ArNS undernames are subdomains of top level ArNS domains. They are separated from the main ArNS domain using an underscore "_" in place of the more typically used dot ".".Records for undernames can be set using the setRecord method on the AR.IO SDK, or removed by using the removeRecord method.
The process for setting/removing a record for an undername vs. a top level ArNS domain is nearly identical, the only difference being the undername parameter. When managing a record on a top level ArNS domain, this must be set to @, while updates to an undername should provide the undername being updated.Chaining Undernames Undernames can be created on other undernames, for example ar://og_logo_ardrive. In this example the undername og exists under the undername logo on the ArNS name ardrive.For the purpose of the undername parameter in the AR.IO SDK, this should be written as a single undername, including the separating underscores:og_logo Creating an Undername There are no special steps required to create an undername (provided the selected ArNS name has available undername space). Simply setting a record for an undername that does not exist will create the undername.Updating an Undername If an undername already exists, its record can easily be updated using the same setRecord method.Removing an Undername An existing undername can be removed by using the removeRecord method on the AR.IO SDK.
The undername parameter should be set to the undername being removed.Increasing Undername Support By default, ArNS names support up to 10 undernames. This number can be increased, for a fee. This is done using the increaseUndernameLimit method on the ARIO class of the AR.IO SDK, rather than the ANT class.
The quantity (qty) parameter specifies the number of ADDITIONAL undernames to be supported. i.e. increasing from 10 undernames to 15 would require the qty parameter set to 5.

---

# 23. ARIO Docs

Document Number: 23
Source: https://docs.ar.io/ar-io-sdk/ario/gateways/get-delegations
Words: 56
Quality Score: 0.510
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

getDelegations getDelegations is a method on the ARIO class that retrieves all active and vaulted stakes across all gateways for a specific address. Results are paginated and sorted by the specified criteria. The cursor parameter represents the last delegationId (a combination of gateway address and delegation start timestamp) from the previous request.getDelegations does not require authentication.

---

# 24. ARIO Docs

Document Number: 24
Source: https://docs.ar.io/gateways/admin
Words: 325
Quality Score: 0.509
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

AR.IO HTTP API Admin Endpoints Overview The AR.IO HTTP API offers several endpoints that allow access to internal information and the ability to make adjustments without restarting your Gateway. Each of these endpoints behind /ar-io/admin/ have access restricted, so you will need to have set up your ADMIN_API_KEY variable and include "Authorization: "Bearer ${ADMIN_API_KEY}" in the header of your request.When testing endpoints at /api-docs, you can enter your ADMIN_API_KEY using the green "Authorize" button near the top of the page, or by clicking any of the open lock icons next to a password protected end point.Debug The ar-io/admin/debug endpoint provides a comprehensive view of the current state of your Gateway. This endpoint has been designed to offer developers and administrators insights into the operational status of the gateway, including any errors or warnings that have occurred since the last startup.Example response Queue Transaction The ar-io/admin/queue-tx endpoint allows you to prioritize processing of a specific transaction, based on that transaction's ID. The id key must be set in the body of your request, and a POST request should be used.This endpoint will also enable you to prioritize opening and indexing bundles by providing the L1 TX ID for the bundle, but only if your Gateway is operating with the ANS104_UNBUNDLE_FILTER and ANS104_INDEX_FILTER keys set.Your Gateway will either respond with an error, or { message: 'TX queued' } Block Data The ar-io/admin/block-data endpoint allows you to tell your Gateway to refuse to serve certain data. In order to add to this block list, make a PUT request to this endpoint with the following in the body:id: This should be the transaction id of the content you want to block.notes: Notes regarding the reason this content was blocked. For documentation purposes only.source: Identifier for the source of TX IDs you are blocking. For example, the name of a public block list. For documentation purposes only.Your Gateway will either respond with an error, or { message: 'Content blocked' }

---

# 25. useWayfinder - ARIO Docs

Document Number: 25
Source: https://docs.ar.io/wayfinder/react/use-wayfinder
Words: 857
Quality Score: 0.505
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Overview The useWayfinder hook provides access to the complete Wayfinder instance from the React context. This hook gives you full control over all Wayfinder methods and is ideal for advanced usage scenarios where you need access to multiple Wayfinder capabilities.Signature Usage Basic Usage Advanced Usage with Event Listeners import { useWayfinder } from '@ar.io/wayfinder-react'
import { useEffect, useState } from 'react'
function AdvancedComponent() {
const { wayfinder } = useWayfinder()
const [events, setEvents] = useState([])
useEffect(() => {
// Listen to routing events
const handleRoutingSuccess = (event) => {
setEvents((prev) => [
...prev,
{
type: 'routing-success',
data: event,
timestamp: Date.now(),
},
])
}
const handleRoutingFailed = (error) => {
setEvents((prev) => [
...prev,
{
type: 'routing-failed',
data: error,
timestamp: Date.now(),
},
])
}
const handleVerificationSuccess = (event) => {
setEvents((prev) => [
...prev,
{
type: 'verification-success',
data: event,
timestamp: Date.now(),
},
])
}
// Subscribe to events
wayfinder.emitter.on('routing-succeeded', handleRoutingSuccess)
wayfinder.emitter.on('routing-failed', handleRoutingFailed)
wayfinder.emitter.on('verification-succeeded', handleVerificationSuccess)
// Cleanup
return () => {
wayfinder.emitter.off('routing-succeeded', handleRoutingSuccess)
wayfinder.emitter.off('routing-failed', handleRoutingFailed)
wayfinder.emitter.off('verification-succeeded', handleVerificationSuccess)
}
}, [wayfinder])
return (
Wayfinder Events

{events.map((event, index) => (

{event.type} - {new Date(event.timestamp).toLocaleTimeString()}

))}
)
} Custom Request with Overrides import { useWayfinder } from '@ar.io/wayfinder-react'
import { useState } from 'react'
import {
StaticRoutingStrategy,
HashVerificationStrategy,
} from '@ar.io/wayfinder-core'
function CustomRequestComponent({ txId }) {
const { wayfinder } = useWayfinder()
const [data, setData] = useState(null)
const [loading, setLoading] = useState(false)
const [error, setError] = useState(null)
const fetchWithCustomSettings = async () => {
setLoading(true)
setError(null)
try {
// Override routing and verification for this specific request
const response = await wayfinder.request(`ar://${txId}`, {
routingSettings: {
strategy: new StaticRoutingStrategy({
gateway: 'https://arweave.net',
}),
},
verificationSettings: {
enabled: true,
strict: true,
strategy: new HashVerificationStrategy({
trustedGateways: ['https://arweave.net'],
}),
},
})
const text = await response.text()
setData(text)
} catch (err) {
setError(err)
} finally {
setLoading(false)
}
}
return (
{loading
? 'Fetching with custom settings...'
: 'Fetch with Custom Settings'}

{error && Error: {error.message}}
{data && {data}}
)
} Provider Context Error The hook throws an error if used outside of a WayfinderProvider:Proper Error Handling import { useWayfinder } from '@ar.io/wayfinder-react'
import { useState, useCallback } from 'react'
function RobustComponent() {
const { wayfinder } = useWayfinder()
const [error, setError] = useState(null)
const [data, setData] = useState(null)
const [loading, setLoading] = useState(false)
const handleRequest = useCallback(
async (txId) => {
setLoading(true)
setError(null)
try {
const response = await wayfinder.request(`ar://${txId}`)
const result = await response.text()
setData(result)
} catch (err) {
setError(err)
// Log different error types
if (err.name === 'TimeoutError') {
console.error('Request timed out')
} else if (err.name === 'VerificationError') {
console.error('Data verification failed')
} else if (err.name === 'NetworkError') {
console.error('Network error occurred')
} else {
console.error('Unknown error:', err)
}
} finally {
setLoading(false)
}
},
[wayfinder],
)
const clearError = useCallback(() => {
setError(null)
}, [])
return (
{error && (

Error: {error.message}
Dismiss
handleRequest('retry')}>Retry

)}
{loading && }
{data && {data}}
)
} Performance Considerations Memoization The Wayfinder instance is automatically memoized in the provider, but you should memoize callbacks that use it:Event Listener Cleanup Always clean up event listeners to prevent memory leaks:TypeScript Support Typed Usage import { useWayfinder } from '@ar.io/wayfinder-react'
import { WayfinderContextValue } from '@ar.io/wayfinder-react'
import { Wayfinder, WayfinderEvent } from '@ar.io/wayfinder-core'
interface ComponentProps {
txId: string
onSuccess?: (data: string) => void
onError?: (error: Error) => void
}
const TypedComponent: React.FC = ({
txId,
onSuccess,
onError,
}) => {
const context: WayfinderContextValue = useWayfinder()
const wayfinder: Wayfinder = context.wayfinder
const handleFetch = async (): Promise => {
try {
const response = await wayfinder.request(`ar://${txId}`)
const data = await response.text()
onSuccess?.(data)
} catch (error) {
onError?.(error as Error)
}
}
// Type-safe event handling
const handleRoutingEvent = (
event: WayfinderEvent['routing-succeeded'],
): void => {
console.log('Selected gateway:', event.selectedGateway)
}
return Fetch Data
} Custom Hook with TypeScript import { useWayfinder } from '@ar.io/wayfinder-react'
import { useState, useCallback } from 'react'
interface UseWayfinderDataResult {
data: string | null
loading: boolean
error: Error | null
fetchData: (txId: string) => Promise
clearData: () => void
}
function useWayfinderData(): UseWayfinderDataResult {
const { wayfinder } = useWayfinder()
const [data, setData] = useState(null)
const [loading, setLoading] = useState(false)
const [error, setError] = useState(null)
const fetchData = useCallback(
async (txId: string): Promise => {
setLoading(true)
setError(null)
try {
const response = await wayfinder.request(`ar://${txId}`)
const result = await response.text()
setData(result)
} catch (err) {
setError(err as Error)
} finally {
setLoading(false)
}
},
[wayfinder],
)
const clearData = useCallback((): void => {
setData(null)
setError(null)
}, [])
return {
data,
loading,
error,
fetchData,
clearData,
}
}
// Usage
function MyComponent() {
const { data, loading, error, fetchData, clearData } = useWayfinderData()
return (
fetchData('transaction-id')}>Fetch
Clear
{loading && }
{error && Error: {error.message}}
{data && {data}}
)
} Testing Mocking the Hook When to Use Use useWayfinder when you need:Full Wayfinder API access: Access to all methods like request(), resolveUrl(), and event emitters Event monitoring: Listening to routing, verification, or other Wayfinder events Custom request configurations: Overriding routing or verification settings per request Advanced integrations: Building complex components that need multiple Wayfinder capabilities Custom abstractions: Creating your own hooks or utilities that wrap Wayfinder functionality For simpler use cases, consider:useWayfinderRequest for basic data fetching useWayfinderUrl for URL resolution with loading states

---

# 26. ARIO Node Release Notes - ARIO Docs

Document Number: 26
Source: https://docs.ar.io/gateways/release-notes
Words: 8187
Quality Score: 0.505
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

AR.IO Release Notes Overview Welcome to the documentation page for the AR.IO gateway release notes. Here, you will find detailed information about each version of the AR.IO gateway, including the enhancements, bug fixes, and any other changes introduced in every release. This page serves as a comprehensive resource to keep you informed about the latest developments and updates in the AR.IO gateway. For those interested in exploring the source code, each release's code is readily accessible at our GitHub repository: AR.IO gateway change logs. Stay updated with the continuous improvements and advancements in the AR.IO gateway by referring to this page for all release-related information.[Release 43] - 2025-07-21 This is a recommended release that enables data verification by default for data items linked to ArNS names, improves chunk broadcasting efficiency, and adds automatic chunk data cache cleanup.Added Added automatic chunk data cache cleanup functionality with configurable retention period. Chunks are now automatically removed after 4 hours by default (configurable via CHUNK_DATA_CACHE_CLEANUP_THRESHOLD). The cleanup can be disabled by setting ENABLE_CHUNK_DATA_CACHE_CLEANUP=false. This helps manage disk space usage while maintaining cache performance benefits.Added demand-driven opt-out background verification for ArNS data. When ArNS names are requested, the system now proactively verifies the underlying data asynchronously in the background by unbundling verified chunk data retrieved directly from Arweave nodes. This ensures ArNS-served content is prioritized for verification, improving data integrity guarantees for frequently accessed named content.Changed Simplified chunk data storage by removing the dual-storage approach (by-hash and by-dataroot with symlinks). Chunks are now stored directly by data root only, reducing complexity and improving performance.Revamped chunk broadcasting architecture from 3-tier system to unified peer-based approach. Chunk broadcasting now uses individual fastq queues per peer with configurable concurrency and queue depth protection. Added support for preferred chunk POST peers via PREFERRED_CHUNK_POST_URLS environment variable. Configuration defaults have been optimized: CHUNK_POST_PEER_CONCURRENCY now defaults to match CHUNK_POST_MIN_SUCCESS_COUNT (3) to avoid over-broadcasting, and CHUNK_POST_PER_NODE_CONCURRENCY defaults to match CHUNK_POST_QUEUE_DEPTH_THRESHOLD (10) for consistent per-node load management. This change improves broadcast reliability and performance while simplifying the codebase by removing circuit breakers and tier-based logic.Modified DataVerificationWorker to ensure data item IDs (not just root IDs) have their retry count incremented, preventing IDs from being stuck without retry attempts. This improves the reliability of the data verification process.Fixed Fixed experiment bash Parquet export script generating filenames with count_star() instead of actual row counts for blocks and tags files. The script now correctly uses the -noheader flag when retrieving counts for filename generation.Fixed missing directory existence checks in FsCleanupWorker to prevent errors when attempting to scan non-existent directories during filesystem cleanup operations.[Release 42] - 2025-07-14 This is an optional release that improves peer request traceability, adds HyperBEAM URL support, and includes draft AI-generated technical documentation.Added Added support for optional HyperBEAM URL configuration via AO_ANT_HYPERBEAM_URL environment variable. In the future this allows ANT processes to use HyperBEAM nodes for caching and serving state, reducing pressure on compute units for simple read requests.Added AI-generated technical documentation covering AR.IO gateway architecture, data retrieval, Arweave connectivity, ArNS name resolution system, centralization analysis, and database architecture. These guides in docs/drafts/ are generally correct but should not be considered authoritative.Added origin and release information to query string parameters in outbound requests to both peer gateways and trusted gateways. Data requests now include ar-io-hops, ar-io-origin, ar-io-origin-release, ar-io-arns-record, and ar-io-arns-basename as query parameters, improving network observability and request tracing across the entire gateway network.Changed Implemented X-AR-IO header initialization for outbound peer requests while removing x-ar-io-origin and x-ar-io-origin-node-release headers from responses. This change maintains necessary header functionality for peer communication while reducing unnecessary header overhead in responses.Updated @ar.io/sdk dependency to support optional HyperBEAM URL functionality.[Release 41] - 2025-06-30 Added Added preferred chunk GET node URLs configuration via PREFERRED_CHUNK_GET_NODE_URLS environment variable to enable chunk-specific peer prioritization. Preferred URLs receive a weight of 100 for prioritization and the system selects 10 peers per attempt by default.Added hash validation for peer data fetching by including X-AR-IO-Expected-Digest header in peer requests when hash is available, validating peer responses against expected hash, and immediately rejecting mismatched data.Added DOCKER_NETWORK_NAME environment variable to configure the Docker network name used by Docker Compose.Added draft guide for running a community gateway.Added draft data verification architecture document.Changed Removed trusted node fallback for chunk retrieval. Chunks are now retrieved exclusively from peers, with the retry count increased from 3 to 50 to ensure reliability without the trusted node fallback.Fixed Fixed inverted logic preventing symlink creation in FsChunkDataStore.Fixed Content-Length header for range requests and 304 responses, properly setting header for single and multipart range requests and removing entity headers from 304 Not Modified responses per RFC 7232.Fixed MaxListenersExceeded warnings by adding setMaxListeners to read-through data cache.Fixed potential memory leaks in read-through data cache by using once instead of on for error and end event listeners.[Release 40] - 2025-06-23 This is an optional release that primarily improves caching when data is fetched from peers.Added Added experimental flush-to-stable script for manual database maintenance. This script allows operators to manually flush stable chain and data item tables, mirroring the logic of StandaloneSqliteDatabase.flushStableDataItems. WARNING: This script is experimental and directly modifies database contents. Use with caution and ensure proper backups before running.Changed Replaced yesql with custom SQL loader that handles comments better, improving SQL file parsing and maintenance.Switched to SPDX license headers to reduce LLM token usage, making the codebase more efficient for AI-assisted development.Improved untrusted data handling and hash validation in cache operations. The cache now allows caching when a hash is available for validation even for untrusted data sources, but only finalizes the cache when the computed hash matches a known trusted hash. This prevents cache poisoning while still allowing data caching from untrusted sources when the data can be validated.[Release 39] - 2025-06-17 This release enhances observability and reliability with new cache metrics, improved data verification capabilities, and automatic failover between chain data sources. The addition of ArNS-aware headers enables better data prioritization across the gateway network. This is a recommended but not urgent upgrade.Added Added filesystem cache metrics with cycle-based tracking. Two new Prometheus metrics track cache utilization: cache_objects_total (number of objects in cache) and cache_size_bytes (total cache size in bytes). Both metrics include store_type and data_type labels to differentiate between cache types (e.g., headers, contiguous_data). Metrics are updated after each complete cache scan cycle, providing accurate visibility into filesystem cache usage.Added X-AR-IO-Data-Id header to all data responses. This header shows the actual data ID being served, whether from a direct ID request or manifest path resolution, providing transparency about the content being delivered.Added automatic data item indexing when data verification is enabled. When ENABLE_BACKGROUND_DATA_VERIFICATION is set to true, the system now automatically enables data item indexing (ANS104_UNBUNDLE_FILTER) with an always: true filter if no filter is explicitly configured. This ensures bundles are unbundled to verify that data items are actually contained in the bundle associated with the Arweave transaction's data root.Added ArNS headers to outbound gateway requests to enable data prioritization. The generateRequestAttributes function now includes ArNS context headers (X-ArNS-Name, X-ArNS-Basename, X-ArNS-Record) in requests to other gateways and Arweave nodes, allowing downstream gateways to effectively prioritize ArNS data requests.Added configurable Docker Compose host port environment variables (CORE_PORT, ENVOY_PORT, CLICKHOUSE_PORT, CLICKHOUSE_PORT_2, CLICKHOUSE_PORT_3, OBSERVER_PORT) to allow flexible port mapping while maintaining container-internal port compatibility and security.Added Envoy aggregate cluster configuration for automatic failover between primary and fallback chain data sources. The primary cluster (default: arweave.net:443) uses passive outlier detection while the fallback cluster (default: peers.arweave.xyz:1984) uses active health checks. This enables zero-downtime failover between HTTPS and HTTP endpoints with configurable FALLBACK_NODE_HOST and FALLBACK_NODE_PORT environment variables.Changed Streamlined background data retrieval to reduce reliance on centralized sources. The default BACKGROUND_RETRIEVAL_ORDER now only includes chunks,s3, removing trusted-gateways and tx-data from the default configuration. This prioritizes verifiable chunk data and S3 storage for background operations like unbundling.Removed ar-io.net from default trusted gateways list and removed TRUSTED_GATEWAY_URL default value to reduce load on ar-io.net now that P2P data retrieval is re-enabled. Existing deployments with TRUSTED_GATEWAY_URL explicitly set will continue to work for backwards compatibility.[Release 38] - 2025-06-09 This release focuses on data integrity and security improvements, introducing trusted data verification and enhanced header information for data requests. Upgrading to this release is recommended but not urgent.Added Added X-AR-IO-Trusted header to indicate data source trustworthiness in responses. This header helps clients understand whether data comes from a trusted source and works alongside the existing X-AR-IO-Verified header to provide data integrity information. The system now filters peer data by requiring peers to indicate their content is either verified or trusted, protecting against misconfigured peers that may inadvertently serve unintended content (e.g., provider default landing pages) instead of actual Arweave data.Added If-None-Match header support for HTTP conditional requests enabling better client-side caching efficiency. When clients send an If-None-Match header that matches the ETag, the gateway returns a 304 Not Modified response with an empty body, reducing bandwidth usage and improving performance.Added digest and hash headers for data HEAD requests to enable client-side data integrity verification.Added EC2 IMDS (instance-profile) credential support for S3 data access, improving AWS authentication in cloud environments.Added trusted data flag to prevent caching of data from untrusted sources, ensuring only verified and reliable content is stored locally while still allowing serving of untrusted data when necessary.Changed Re-enabled ar-io-peers as fallback data source in configuration for improved data availability.Updated trusted node configuration to use arweave.net as the default trusted node URL.Updated ETag header format to use properly quoted strings (e.g., "hash" instead of hash) following HTTP/1.1 specification standards for improved compatibility with caching proxies and clients.[Release 37] - 2025-06-03 This is a recommended release due to the included observer robustness improvements. It also adds an important new feature - data verification for preferred ArNS names. When preferred ArNS names are set, the bundles containing the data they point to will be locally unbundled (verifying data item signatures), and the data root for the bundle will be compared to the data root in the Arweave chain (establishing that the data is on Arweave). To enable this feature, set your preferred ArNS names, turn on unbundling by setting ANS104_DOWNLOAD_WORKERS and ANS104_UNBUNDLE_WORKERS both to 1, and set your ANS104_INDEX_FILTER to a filter that will match the data items for your preferred names. If you don't know the filter, use {"always": true}, but be aware this will index the entire bundle for the IDs related to your preferred names.Note: this release contains migrations to data.db. If your node appears unresponsive please check core service logs to determine whether migrations are running and wait for them to finish.Added Added prioritized data verification system for preferred ArNS names, focusing computational resources on high-priority content while enabling flexible root transaction discovery through GraphQL fallback support.Added verification retry prioritization system with tracking of retry counts, priority levels, and attempt timestamps to ensure bundles do not get stuck retrying forever.Added improved observer functionality with best-of-2 observations and higher compression for more reliable network monitoring.Added MAX_VERIFICATION_RETRIES environment variable (default: 5) to limit verification retry attempts and prevent infinite loops for consistently failing data items.Added retry logic with exponential backoff for GraphQL queries to handle rate limiting (429) and server errors with improved resilience when querying trusted gateways for root bundle IDs.Changed Updated dependencies: replaced deprecated express-prometheus-middleware with the actively maintained express-prom-bundle library and updated prom-client to v15.1.3 for better compatibility and security.Updated Linux setup documentation to use modern package installation methods, replacing apt-key yarn installation with npm global install and updating Node.js/nvm versions.Improved route metrics normalization with explicit whitelist function for better granularity and proper handling of dynamic segments.Fixed Fixed docker-compose configuration to use correct NODE_MAX_OLD_SPACE_SIZE environment variable name.Fixed production TypeScript build configuration to exclude correct "test" directory path.Fixed Parquet exporter to properly handle data item block_transaction_index exports, preventing NULL value issues.Fixed bundles system to copy root_parent_offset when flushing data items to maintain data integrity.Fixed ClickHouse auto-import script to handle Parquet export not_started status properly.Fixed docker-compose ClickHouse configuration to not pass conflicting PARQUET_PATH environment variable to container scripts.Fixed verification process for data items that have not been unbundled by adding queue bundle support and removing bundle join constraint to ensure proper verification of data items without indexed root parents.[Release 36] - 2025-05-27 This is a recommended but not essential upgrade. The most important changes are the preferred ArNS caching feature for improved performance on frequently accessed content and the observer's 80% failure threshold to prevent invalid reports during network issues.Added Added preferred ArNS caching functionality that allows configuring lists of ArNS names to be cached longer via PREFERRED_ARNS_NAMES and PREFERRED_ARNS_BASE_NAMES environment variables. When configured, these names will be cleaned from the filesystem cache after PREFERRED_ARNS_CONTIGUOUS_DATA_CACHE_CLEANUP_THRESHOLD instead of the standard cleanup threshold (CONTIGUOUS_DATA_CACHE_CLEANUP_THRESHOLD). This is accomplished by maintaining an MRU (Most Recently Used) list of ArNS names in the contiguous metadata cache. When filesystem cleanup runs, it checks this list to determine which cleanup threshold to apply. This feature enables gateway operators to ensure popular or important ArNS names remain cached longer, improving performance for frequently accessed content.Added ArNS headers to responses: X-ArNS-Name, X-ArNS-Basename, and X-ArNS-Record to help identify which ArNS names were used in the resolution.Changed Updated observer to prevent report submission when failure rate exceeds 80%. This threshold helps guard against both poorly operated observers and widespread network issues. In the case of a widespread network issue, the assumption is that most gateway operators are well intentioned and will work together to troubleshoot and restore both observations and network stability, rather than submitting reports that would penalize functioning gateways.Updated default trusted gateway in docker-compose Envoy configuration to ar-io.net for improved robustness and alignment with core service configuration.Improved range request performance by passing ranges directly to getData implementations rather than streaming all data and extracting ranges.Fixed Fixed missing cache headers (X-Cache and other data headers) in range request responses to ensure consistent cache header behavior across all request types.Fixed async streaming for multipart range requests by using async iteration instead of synchronous reads, preventing potential data loss.Fixed ArNS resolution to properly exclude www subdomain from resolution logic.Fixed test reliability issues by properly awaiting stream completion before making assertions.Fixed chunk broadcasting to not await peer broadcasts, as they are best-effort operations.[Release 35] - 2025-05-19 This is a low upgrade priority release. It contains a small caching improvement and routing fix. Upgrading to help test it is appreciated but not essential.Changed Adjusted filesystem data expiration to be based on last request times rather than file access times which may be inaccurate.Adjusted CORS headers to include content-* headers.Fixed Fixed regex used to expose /api-docs when an apex ArNS name is set.[Release 34] - 2025-05-05 Given the resilience provided by adding a second trusted gateway URL, it is recommended that everyone upgrade to this release.Added Added peer list endpoints for retrieving information about Arweave peers and ar.io gateway peers.Added ar-io.net as a secondary trusted gateway to increase data retrieval resilience by eliminating a single point of failure.Added circuit breaker for Arweave peer chunk posting.Changed Created directories for DuckDB and Parquet to help avoid permission issues by the directories being created by containers.Fixed Fixed GraphQL ClickHouse error when returning block ID and timestamp.Fixed the tx-chunks-data-source to throw a proper error (resulting in a 404) when the first chunk is missing rather than streaming a partial response.[Release 33] - 2025-05-05 Added Added a [Parquet and ClickHouse usage guide]. Using ArDrive as an example, it provides step by step instructions about how to bulk load Parquet and configure continuous ingest of bundled data items into ClickHouse. This allows the ar-io-node to support performant GraphQL queries on larger data sets and facilitates sharing indexing work across gateways via distribution of Parquet files.Added support for configurable ArNS 404 pages using either:ARNS_NOT_FOUND_TX_ID: Transaction ID for custom 404 content ARNS_NOT_FOUND_ARNS_NAME: ArNS name to resolve for 404 content Added experimental /chunk/ GET route for serving chunk data by absolute offset either the local cache.Added support for AWS_SESSION_TOKEN in the S3 client configuration.Expanded ArNS OTEL tracing to improve resolution behavior observability.Added support for setting a ClickHouse username and password via the CLICKHOUSE_USERNAME and CLICKHOUSE_PASSWORD environment variable. When using ClickHouse, CLICKHOUSE_PASSWORD should always be set. However, CLICKHOUSE_USERNAME can be left unset. The username default will be used in that case.Added support for configuring the port used to connect to ClickHouse via the CLICKHOUSE_PORT environment variable.Changed Disabled ClickHouse import timing logging by default. It can be enabled via environment variable - DEBUG when running the service standalone or CLICKHOUSE_DEBUG when using Docker Compose Upgraded to ClickHouse 25.4.Fixed Ensure .env is read in clickhouse-import script.[Release 32] - 2025-04-22 Changed Reenabled parallel ArNS resolution with removal of misplaced global limit. Refer to release 30 notes for more details on configuration and rationale.Added a timeout for the last ArNS resolver in ARNS_RESOLVER_PRIORITY_ORDER. It defaults to 30 seconds and is configurable using ARNS_COMPOSITE_LAST_RESOLVER_TIMEOUT_MS. This helps prevent promise build up if the last resolver stalls.Fixed Fixed apex ArNS name handling when a subdomain is present in ARNS_ROOT_HOST.Fixed a case where fork recovery could stall due to early flushing of unstable chain data.Restored observer logs by removing unintentional default log level override in docker-compose.yaml.[Release 31] - 2025-04-11 Changed Improved peer TX header fetching by fetching from a wider range of peers and up/down weighting peers based on success/failure.Fixed Rolled back parallel ArNS resolution changes that were causing ArNS resolution to slow down over time.[Release 30] - 2025-04-04 Added Added support for filtering Winston logs with a new LOG_FILTER environment variable.Example filter: {"attributes":{"class":"ArweaveCompositeClient"}} to only show logs from that class.Use CORE_LOG_FILTER environment variable when running with docker-compose.Added parallel ArNS resolution capability.Configured via ARNS_MAX_CONCURRENT_RESOLUTIONS (default: 1).This foundation enables future enhancements to ArNS resolution and should generally not be adjusted at present.Changed Improved ClickHouse auto-import script with better error handling and continuous operation through errors.Reduced maximum header request rate per second to trusted node to load on community gateways.Optimized single owner and recipient queries on ClickHouse with specialized sorted tables.Used ID sorted ClickHouse table for ID queries to improve performance.Fixed Fixed data alignment in Parquet file name height boundaries to ensure consistent import boundaries.Removed trailing slashes from AO URLs to prevent issues when passing them to the SDK.Only prune SQLite data when ClickHouse import succeeds to prevent data loss during exports.[Release 29] - 2025-03-21 Changed Temporarily default to trusted gateway ArNS resolution to reduce CU load as much possible. On-demand CU resolution is still available as a fallback and the order can be modified by setting ARNS_RESOLVER_PRIORITY_ORDER.Remove duplicate network process call in on-demand resolver.Don't wait for network process debounces in the on-demand resolver.Slow network process dry runs no longer block fallback to next resolver.Added Added support for separate CUs URLs for the network and ANT processes via the NETWORK_AO_CU_URL and ANT_AO_CU_URL process URLs respectively. If either is missing the AO_CU_URL is used instead with a fallback to the SDK default URL if AO_CU_URL is also unspecified.Added CU URLs to on-demand ArNS resolver logs.Added circuit breakers for AR.IO network process CU dry runs. By default they use a 1 minute timeout and open after 30% failure over a 10 minute window and reset after 20 minutes.Fixed Owners in GraphQL results are now correctly retrieved from data based on offsets when using ClickHouse.[Release 28] - 2025-03-17 Changed Raised name not found name list refresh interval to 2 minutes to reduce load on CUs. This increases the maximum amount of time a user may wait for a new name to be available. Future releases will introduce other changes to mitigate this delay.Adjusted composite ArNS resolver to never timeout resolutions from the last ArNS resolver in the resolution list.Added Added support for serving a given ID or ArNS name from the apex domain of a gateway. If using an ID, set the APEX_TX_ID environment variable. If using an ArNS name, set the APEX_ARNS_NAME environment variable.Added BUNDLE_REPAIR_UPDATE_TIMESTAMPS_INTERVAL_SECONDS, BUNDLE_REPAIR_BACKFILL_INTERVAL_SECONDS, and BUNDLE_REPAIR_FILTER_REPROCESS_INTERVAL_SECONDS environment variables to control the interval for retrying failed bundles, backfilling bundle records, and reprocessing bundles after a filter change. Note: the latter two are rarely used. Queuing bundles for reprocessing via the /ar-io/admin/queue-bundle endpoint is usually preferable to automatic reprocessing as it is faster and offers more control over the reprocessing behavior.Fixed Signatures in GraphQL results are now correctly retrieved from data based on offsets when using ClickHouse.Adjusted exported Parquet file names to align with expectations of ClickHouse import script.Ensured that bundle indexing status is properly reset when bundles are manually queued after an unbundling filter change has been made.[Release 27] - 2025-02-20 Changed Set process IDs for mainnet.Increase default AO CU WASM memory limit to 17179869184 to support mainnet
process.[Release 26] - 2025-02-13 Added Added a per resolver timeout in the composite ArNS resolver. When the
composite resolver attempts resolution it is applied to each resolution
attempt. It is configurable via the ARNS_COMPOSITE_RESOLVER_TIMEOUT_MS and
defaults to 3 seconds in order to allow a fallback attempt before the default
observer timeout of 5 seconds.Added a TURBO_UPLOAD_SERVICE_URL environment variable to support
configuration of the bundler used by the observer (TurboSDK defaults are
used if not set).Added a REPORT_DATA_SINK environment variable that enables switching the
method used to post observer reports. With the default, turbo, it sends
data items via a Turbo compatible bundler. Switching it to arweave will
post base layer transactions directly to Arweave instead.Added a /ar-io/admin/bundle-status/ endpoint that returns the counters
and timestamps from the bundles row in data.db. This can be used for
monitoring unbundling progress and scripting (e.g., to skip requeuing already
queued bundles).Added more complete documentation for filters.Changed Use arweave.net as the default GraphQL URL for AO CUs since most gateways
will not have a complete local AO data item index.Use a default timeout of 5 seconds when refreshing Arweave peers to prevent
stalled peer refreshes.Cache selected gateway peer weights for the amount of time specified by the GATEWAY_PEERS_WEIGHTS_CACHE_DURATION_MS environment variable with a default
of 5 seconds to avoid expensive peer weight recomputation on each request.Chunk broadcasts to primary nodes occur in parallel with a concurrency limit
defaulting to 2 and configurable via the CHUNK_POST_CONCURRENCY_LIMIT environment variable.Added circuit breakers for primary chunk node POSTs to avoid overwhelming
chunk nodes when they are slow to respond.Fixed Properly cleanup timeout and event listener when terminating the data
root computation worker.Count chunk broadcast exceptions as errors in the arweave_chunk_broadcast_total metric.[Release 25] - 2025-02-07 Added Added support for indexing and querying ECDSA signed Arweave transactions.Expanded the OpenAPI specification to cover the entire gateway API and
commonly used Arweave node routes.ArNS undername record count limits are now enforced. Undernames are sorted
based on their ANT configured priority with a fallback to name comparisons
when priorities conflict or are left unspecified. Enforcement is enabled by
default but can be disabled by setting the ARNS_RESOLVER_ENFORCE_UNDERNAME_LIMIT to false.Changed Renamed the ario-peer data source to ar-io-peers for consistency and
clarity. ario-peer will continue to work for backwards compatibility but is
considered deprecated.Use AR.IO gateway peers from the ar.io gateway address registry (GAR) as the
last fallback for fetching data when responding to client data requests. This
has the benefit of making the network more resilient to trusted gateway
disruptions, but it can also result in nodes serving data from less trusted
sources if it is not found in the trusted gateway. This can be disabled by
using a custom ON_DEMAND_RETRIEVAL_ORDER that does not include ar-io-peers.Arweave data chunk requests are sent to the trusted node first with a
fallback to Arweave peers when chunks are unavailable on the trusted node.
This provides good performance by default with a fallback in case there are
issues retrieving chunks from the trusted node.Increased the observer socket timeout to 5 seconds to accommodate initial
slow responses for uncached ArNS resolutions.Disabled writing base layer Arweave signatures to the SQLite DB by default to
save disk space. When signatures are required to satisfy GraphQL requests,
they are retrieved from headers on the trusted node.Fixed Updated dependencies to address security issues.Improved reliability of failed bundle indexing retries.Fixed failure to compute data roots for verification for base layer data
larger than 2GiB.Fixed observer healthcheck by correcting node.js path in healthcheck script.[Release 24] - 2025-02-03 Added Added a ARNS_ANT_STATE_CACHE_HIT_REFRESH_WINDOW_SECONDS environment
variable that determines the number of seconds before the end of the TTL at
which to start attempting to refresh the ANT state.Added a TRUSTED_GATEWAYS_REQUEST_TIMEOUT_MS environment that defaults to
10,000 and sets the number of milliseconds to wait before timing out request
to trusted gateways.Added BUNDLE_REPAIR_RETRY_INTERVAL_SECONDS and BUNDLE_REPAIR_RETRY_BATCH_SIZE environment variables to control the time
between queuing batches of bundle retries and the number of data items
retrieved when constructing batches of bundles to retry.Added support for configuring the ar.io SDK log level via the AR_IO_SDK_LOG_LEVEL environment variable.Added a request_chunk_total Prometheus counter with status, source (a
URL) and source_type (trusted or peer) labels to track success/failure
of chunk retrieval in the Arweave network per source.Added a get_chunk_total Prometheus metric to count chunk retrieval
success/failure per chunk.Added arns_cache_hit_total and arns_cache_miss_total Prometheus counters
to track ArNS cache hits and misses for individual names respectively.Added arns_name_cache_hit_total and arns_name_cache_miss_total Prometheus
counters to track ArNS name list cache hits and misses
respectively.Added a arns_resolution_duration_ms Prometheus metric that tracks summary
statistics for the amount of time it takes to resolve ArNS names.Changed In addition to the trusted node, the Arweave network is now searched for
chunks by default. All chunks retrieved are verified against data roots
indexed from a trusted Arweave node to ensure their validity.Default to a 24 hour cache TTL for the ArNS name cache. Record TTLs still
override this, but in cases where resolution via AO CU is slow or fails, the
cache will be used. In the case of slow resolution, CU based resolution will
proceed in the background and update the cache upon completion.Switched to the ioredis library for better TLS support.Updated minor dependency minor versions (more dependencies will be updated in
the next release).Bundles imports will no longer be re-attempted for bundles that have already
been fully unbundled using the current filters if they are matched or
manually queued again.Replaced references docker-compose in the docs with the more modern docker compose.Fixed Ensure duplicate data item IDs are ignored when comparing counts to determine
if a bundle has been fully unbundled.Fixed worker threads failing to shut down properly when the main processped.Ensure bundle import attempt counts are incremented when bundles are skipped
to avoid repeatedly attempting to import skipped bundles.Use observe that correctly ensure failing gateways are penalized in the AR.IO
AO process.[Release 23] - 2025-01-13 Added Added FS_CLEANUP_WORKER_BATCH_SIZE,FS_CLEANUP_WORKER_BATCHDURATION, and FS_CLEANUP_WORKER_RESTARTDURATION environment variables to allow
configuration of number of contiguous data files cleaned up per batch, the between each batch, and the before restarting the entire cleanup
process again.Added data_items_unbundled_total Prometheus metric that counts the total
number of data items unbundled, including those that did not match the
unbundling filter.Added a parent_type label that can be one of transaction or data_item to data item indexing metrics.Added a files_cleaned_total total Prometheus metric to enable monitoring of
contiguous data cleanup.Added support for specifying the admin API via a file specified by the ADMIN_API_KEY_FILE environment variable.Added experimental support for posting chunks in a non-blocking way to
secondary nodes specified via a comma separate list in the SECONDARY_CHUNK_POST_URLS environment variable.Changed Renamed the parent_type lable to contiguous_data_type on bundle metrics
to more accurately reflect the meaning of the label.Reduced the maximum time to refresh the ArNS name list to 10 seconds to
minimize delays in ArNS availability after a new name is registered.Changed /ar-io/admin/queue-bundle to wait for bundles rows to be written
to the DB before responding to ensure that errors that occur due to DB
contention are not silently ignored.Data items are now flushed even when block indexing is ped. This allows
for indexing batches of data items using the admin API with block indexing
disabled.Adjust services in docker-compose to use unless-ped as their restart
policy. This guards against missing restarts in the case where service
containers exit with a success status even when they shouldn't.Fixed Added missing created_at field in blocked_names table.Fixed broken ArNS undername resolution.[Release 22] - 2024-12-18 Added Added the ability to block and unblock ArNS names (e.g., to comply with hosting provider TOS). To block a name, POST { "name": "" } to /ar-io/admin/block-name. To unblock a name, POST { "name": "" } to /ar-io/admin/unblock-name.Changed Return an HTTP 429 response to POSTs to /ar-io/admin/queue-bundle when the bundle data import queue is full so that scripts queuing bundles can wait rather than overflowing it.Fixed Adjust ArNS length limit from <= 48 to <= 51 to match the limit enforced by the AO process.[Release 21] - 2024-12-05 Added Added a ClickHouse auto-import service. When enabled, it calls the Parquet export API, imports the exported Parquet into ClickHouse, moves the Parquet files to an imported subdirectory, and deletes data items in SQLite up to where the Parquet export ended. To use it, run Docker Compose with the clickhouse profile, set the CLICKHOUSE_URL to http://clickhouse:8123, and ensure you have set an ADMIN_KEY. Using this configuration, the core service will also combine results from ClickHouse and SQLite when querying transaction data via GraphQL. Note: if you have a large number of data items in SQLite, the first export and subsequent delete may take an extended period. Also, this functionality is considered experimental. We expect there are still bugs to be found in it and we may make breaking changes to the ClickHouse schema in the future. If you choose to use it in production (not yet recommended), we suggest backing up copies of the Parquet files found in data/parquet/imported so that they can be reimported if anything goes wrong or future changes require it.Added a background data verification process that will attempt to recompute data roots for bundles and compare them to data roots indexed from Arweave nodes. When the data roots match, all descendant data items will be marked as verified. This enables verification of data initially retrieived from sources, like other gateways, that serve contiguous data instead of verifiable chunks. Data verification can be enabled by setting the ENABLE_BACKGROUND_DATA_VERIFICATION environment variable to true. The interval between attempts to verify batches of bundles is configurable using the BACKGROUND_DATA_VERIFICATION_INTERVAL_SECONDS environment variable.Added a CHUNK_POST_MIN_SUCCESS_COUNT environment variable to configure how many Arweave nodes must accept a chunk before a chunk broadcast is considered successful.Added arweave_chunk_post_total and arweave_chunk_broadcast_total Prometheus metrics to respectively track the number of successful chunk POSTs to Arweave nodes and the number of chunks successfully broadcast.When resolving ArNS names, the entire list of names is now cached instead of individually checking whether each name exists. This reduces the load on AO CUs since the entire list can be reused across multiple requests for different names. Note: due to the default 5 minute interval between name list refreshes, newly registered may now take longer to resolver after initial registration. We intend to make further caching refinements to address this in the future.Added support for multiple prioritized trusted gateways configurable by setting the TRUSTED_GATEWAYS_URLS environment variable to a JSON value containing a mapping of gateway hosts to priorities. Data requests are sent to other gateways in ascending priority order. If multiple gateways share the same priority, all the gateways with the same priority are tried in a random order before continuing on to the next priority.Added support for caching contiguous data in S3. It is enabled by default when the AWS_S3_CONTIGUOUS_DATA_BUCKET and AWS_S3_CONTIGUOUS_DATA_PREFIX environment variables are set.Changed trusted-gateway was changed to trusted-gateways in ON_DEMAND_RETRIEVAL_ORDER and BACKGROUND_RETRIEVAL_ORDER.Renamed the S3 contiguous environment variables - AWS_S3_BUCKET to AWS_S3_CONTIGUOUS_DATA_BUCKET and AWS_S3_PREFIX to AWS_S3_CONTIGUOUS_DATA_PREFIX.[Release 20] - 2024-11-15 Added Exposed the core service chunk POST endpoint via Envoy. It accepts a Arweave data chunk and broadcasts it to either the comma separated list of URLs specified by the CHUNK_POST_URLs environment variable or, if none are specified, the /chunk path on URL specified by the TRUST_GATEWAY_URL environment variable.Added a X-AR-IO-Root-Transaction-Id HTTP header to data responses containing the root base layer transaction ID for the ID in question if it's been indexed.Added a X-AR-IO-Data-Item-Data-Offset HTTP header containing the offset of the data item relative to the root bundle base layer transaction for it. In conjunction with X-AR-IO-Root-Transaction-Id, it enables retrieving data for data item IDs from base layer data using first a HEAD request to retrieve the root ID and data offset followed by a range request into the root bundle. This greatly increases the likelihood of retriving data item data by ID since only an index into the base layer and Arweave chunk availability is needed for this access method to succeed.Added an experimental ClickHouse service to docker-compose.yaml (available via the clickhouse profile). This will be used as a supplemental GraphQL DB in upcoming releases.Added a data item indexing healthcheck that can be enabled by setting the RUN_AUTOHEAL environment variable to true. When enabled, it will restart the core service if no data items have been indexed since the value specified by the MAX_EXPECTED_DATA_ITEM_INDEXING_INTERVAL_SECONDS environment variable.[Release 19] - 2024-10-21 Fixed Adjusted data item flushing to use the bundle DB worker instead of the core DB worker to prevent write contention and failed flushes under heavy unbundling load.Added Added X-AR-IO-Digest, X-AR-IO-Stable, X-AR-IO-Verified, and ETag headers. X-AR-IO-Digest contains a base64 URL encoded representation of the SHA-256 hash of the data item data. It may be empty if the gateway has not previously cached the data locally. X-AR-IO-Stable contains either true or false depending on whether the associated Arweave transaction is more than 18 blocks old or not. X-AR-IO-Verified contains either true if the gateway has verified the data root of the L1 transaction or the L1 root parent of the data item or false if it has not. ETag contains the same value a X-AR-IO-Digest and is used to improve HTTP caching efficiency.Added support for using a different data source for on-demand and background data retrieval. Background data retrieval is used when unbundling. The background retrieval data source order is configurable using the BACKGROUND_RETRIEVAL_ORDER environment variable and defaults to chunks,s3,trusted-gateway,tx-data. Priority is given to chunk retrieval since chunks are verifiable.Added an /ar-io/admin/export-parquet/status to support monitoring of in-progress Parquet export status.Added sqlite_in_flight_ops Prometheus metric with worker (core, bundles, data, or moderation) and role (read or write) labels to support monitoring the number of in-flight DB operations.Added experimental Grafana and Prometheus based observability stack. See the "Monitoring and Observability" section of the README for more details.Changed Bundle data is now retrieved as chunks from Arweave nodes by default so that data roots can be compared against the chain (see entry about background retrieval above).Changed observer configuration to use 8 instead of 5 chosen names. These are combined with 2 names prescribed from the contract for a total of 10 names observed each epoch to provide increased ArNS observation coverage.Verification status is set on data items when unbundling a parent that has already been verified.[Release 18] - 2024-10-01 Fixed Improved performance of data attributes query that was preventing data.db WAL flushing.Added Added WAL sqlite_wal_checkpoint_pages Prometheus metric to help monitor WAL flushing.Added a POST /ar-io/admin/export-parquet endpoint that can be used to export the contents of the SQLite3 core and bundle DBs as Parquet. To trigger an export, POST JSON containing outputDir, startHeight, endHeight, and maxFileRows keys. The resulting Parquet files can then be queried directly using DuckDB or loaded into another system (e.g. ClickHouse). Scripts will be provided to help automate the latter in a future release.Added ARNS_RESOLVER_OVERRIDE_TTL_SECONDS that can be used to force ArNS names to refresh before their TTLs expire.Added a GET /ar-io/resolver/:name endpoint that returns an ArNS resolution for the given name.Changed Removed ArNS resolver service in favor of integrated resolver. If a standalone resolver is still desired, the core service can be run with the START_WRITERS environment variable set to false. This will disable indexing while preserving resolver functionality.Deduplicated writes to data.db to improve performance and reduce WAL growth rate.[Release 17] - 2024-09-09 Notes This release includes a LONG RUNNING MIGRATION. Your node may appear unresponsive while it is running. It is best to wait for it to complete. If it fails or is interrupted, removing your SQLite DBs (in data/sqlite by default) should resolve the issue, provided you are willing to lose your GraphQL index and let your node rebuild it.Fixed Use the correct environment variable to populate WEBHOOK_BLOCK_FILTER in docker-compose.yaml.Don't cache data regions retrieved to satisfy range requests to avoid unnecessary storage overhead and prevent inserting invalid ID to hash mappings into the data DB.Added Added a new ClickHouse based DB backend. It can be used in combination with the SQLite DB backend to enable batch loading of historical data from Parquet. It also opens up the possibility of higher DB performance and scalability. In its current state it should be considered a technology preview. It won't be useful to most users until we either provide Parquet files to load into it or automate flushing of the SQLite DB to it (both are planned in future release). It is not intended to be standalone solution. It supports bulk loading and efficient GraphQL querying of transactions and data items, but it relies on SQLite (or potentially another OLTP in the future) to index recent data. These limitations allow greatly simplified schema and query construction. Querying the new ClickHouse DB for transaction and data items via GraphQL is enabled by setting the CLICKHOUSE_URL environment variable.Added the ability to skip storing transaction signatures in the DB by setting WRITE_TRANSACTION_DB_SIGNATURES to false. Missing signatures are fetched from the trusted Arweave node when needed for GraphQL results.Added a Redis backed signature cache to support retrieving optimistically indexed data item signatures in GraphQL queries when writing data items signatures to the DB has been disabled.Added on-demand and composite ArNS resolvers. The on-demand resolver fetches results directly from an AO CU. The composite resolver attempts resolution in the order specified by the ARNS_RESOLVER_PRIORITY_ORDER environment variable (defaults to on-demand,gateway).Added a queue_length Prometheus metric to fasciliate monitoring queues and inform future optimizations Added SQLite WAL cleanup worker to help manage the size of the data.db-wal file. Future improvements to data.db usage are also planned to further improve WAL management.Changed Handle data requests by ID on ArNS sites. This enables ArNS sites to use relative links to data by ID.Replaced ARNS_RESOLVER_TYPE with ARNS_RESOLVER_PRIORITY_ORDER (defaults to on-demand,gateway).Introduced unbundling back pressure. When either data item data or GraphQL indexing queue depths are more than the value specified by the MAX_DATA_ITEM_QUEUE_SIZE environment variable (defaults to 100000), unbundling is d until the queues length falls bellow that threshold. This prevents the gateway from running out of memory when the unbundling rate exceeds the indexing rate while avoiding wasteful bundle reprocessing.Prioritized optimistic data item indexing by inserting optimistic data items at the front of the indexing queues.Prioritized nested bundle indexing by inserting nested bundles at the front of the unbundling queue.[Release 16] - 2024-08-09 Fixed Fixed promise leak caused by missing await when saving data items to the DB.Modified ArNS middleware to not attempt resolution when receiving requests for a different hostname than the one specified by ARNS_ROOT_HOST.Added Added support for returning Content-Encoding HTTP headers based on user specified Content-Encoding tags.Added isNestedBundle filter enables that matches any nested bundle when indexing. This enables composite unbundling filters that match a set of L1 tags and bundles nested under them.Added ability to skip writing ANS-104 signatures to the DB and load them based on offsets from the data instead. This significantly reduces the size of the bundles DB. It can be enabled by setting the WRITE_ANS104_DATA_ITEM_DB_SIGNATURES environment variable to false.Added data_item_data_indexed_total Prometheus counter to count data items with data attributes indexed.Changed Queue data attributes writes when serving data rather than writing them syncronously.Reduced the default data indexer count to 1 to lessen the load on the data DB.Switched a number of overly verbose info logs to debug level.Removed docker-compose on-failure restart limits to ensure that services restart no matter how many times they fail.Modified the data_items_indexed_total Prometheus counter to count data items indexed for GraphQL querying instead of data attributes.Increased aggressiveness of contiguous data cleanup. It now s 5 seconds instead of 10 seconds per batch and runs every 4 hours instead of every 24 hours.[Release 15] - 2024-07-19 Fixed Fixed query error that was preventing bundles from being marked as fully imported in the database.Added Adjusted data item indexing to record data item signature types in the DB. This helps distinguish between signatures using different key formats, and will enable querying by signature type in the future.Adjusted data item indexing to record offsets for data items within bundles and signatures and owners within data items. In the future this will allow us to avoid saving owners and signatures in the DB and thus considerably reduce the size of the bundles DB.Added ARNS_CACHE_TTL_MS environment variable to control the TTL of ARNS cache entries (defaults to 1 hour).Added support for multiple ranges in a single HTTP range request.Added experimental chunk POST endpoint that broadcasts chunks to the comma-separate list of URLS in the CHUNK_BROADCAST_URLS environment variable. It is available at /chunk on the internal gateway service port (4000 by default) but is not yet exposed through Envoy.Added support for running an AO CU adjacent to the gateway (see README.md for details).Added X-ArNS-Process-Id to ArNS resolved name headers.Added a set of AO_... environment variables for specifying which AO URLs should be used (see docker-compose.yaml for the complete list). The AO_CU_URL is of particular use since the core and resolver services only perform AO reads and only the CU is needed for reads.Changed Split the monolithic docker-compose.yaml into docker-compose.yaml, docker-compose.bundler.yaml, and docker-compose.ao.yaml (see README for details).Replaced references to 'docker-compose' with 'docker compose' in the docs since the former is mostly deprecated.Reduce max fork depth from 50 to 18 inline to reflect Arweave 2.7.2 protocol changes.Increased the aggressiveness of bundle reprocessing by reducing reprocessing interval from 10 minutes to 5 minutes and raising reprocessing batch size from 100 to 1000.Use a patched version of Litestream to work around insufficient S3 multipart upload size in the upstream version.[Release 14] - 2024-06-26 Fixed Correctly handle manifest index after paths.[Release 13] - 2024-06-24 Added Added support for optimistically reading data items uploaded using the integrated Turbo bundler via the LocalStack S3 interface.Added X-AR-IO-Origin-Node-Release header to outbound data requests.Added hops, origin, and originNodeRelease query params to outbound data requests.Added support for fallback in v0.2 manifests that is used if no path in the manifest is matched.Changed Updated Observer to read prescribed names from and write observations to the ar.io AO network process.Updated Resolver to read from the ar.io AO network process.Fixed Modified optimistic indexing of data items to use a null parent_id when inserting into the DB instead of a placeholder value. This prevents unexpected non-null bundledIn values in GraphQL results for optimistically indexed data items.Modified GraphQl query logic to require an ID for single block GraphQL queries. Previously queries missing an ID were returning an internal SQLite error. This represents a small departure from arweave.net's query logic which returns the latest block for these queries. We recommend querying blocks instead of block in cases where the latest block is desired.Adjusted Observer health check to reflect port change to 5050.Security Modified docker-compose.yaml to only expose Redis, PostgreSQL, and LocalStack ports internally. This protects gateways that neglect to deploy behind a firewall, reverse proxy, or load balancer.[Release 12] - 2024-06-05 Added Added /ar-io/admin/queue-data-item endpoint for queuing data item headers for indexing before the bundles containing them are processed. This allows trusted bundlers to make their data items quickly available to be queried via GraphQL without having to wait for bundle data submission or unbundling.Added experimental support for retrieving contiguous data from S3. See AWS_* environment variables documentation for configuration details. In conjuction with a local Turbo bundler this allows optimistic bundle (but not yet data item) retrieval.Add experimental support for fetching data from gateway peers. It can be enabled by adding ario-peer to ON_DEMAND_RETRIEVAL_ORDER. Note: do not expect this work reliably yet! This functionality is in active development and will be improved in future releases.Add import_attempt_count to bundle records to enable future bundle import retry optimizations.Changed Removed version from docker-compose.yaml to avoid warnings with recent versions of docker-compose.Switched default observer port from 5000 to 5050 to avoid conflict on OS X. Since Envoy is used to provide external access to the observer API this should have no user visible effect.[Release 11] - 2024-05-21 Added Added arweave_tx_fetch_total Prometheus metric to track counts of transaction headers fetched from the trusted node and Arweave network peers.Changed Revert to using unnamed bind mounts due to cross platform issues with named s.[Release 10] - 2024-05-20 Added Added experimental support for streaming SQLite backups to S3 (and compatible services) using Litestream. Start the service using the docker-compose "litestream" profile to use it, and see the AR_IO_SQLITE_BACKUP_* environment variables documentation for further details.Added /ar-io/admin/queue-bundle endpoint for queueing bundles for import for import before they're in the mempool. In the future this will enable optimistic indexing when combined with a local trusted bundler.Added support for triggering webhooks when blocks are imported matching the filter specified by the WEBHOOK_BLOCK_FILTER environment variable.Added experimental support for indexing transactions and related data items from the mempool. Enable it by setting ENABLE_MEMPOOL_WATCHER to 'true'.Made on-demand data caching circuit breakers configurable via the GET_DATA_CIRCUIT_BREAKER_TIMEOUT_MS environment variable. This allows gateway operators to decide how much latency they will tolerate when serving data in exchange for more complete data indexing and caching.Rename cache header from X-Cached to X-Cache to mimic typical CDN practices.Add X-AR-IO-Hops and X-AR-IO-Origin headers in preparation for future peer-to-peer functionality.Upgrade to Node.js v20 and switch to native test runner.[Release 9] - 2024-04-10 Added Added experimental Farcaster Frames support, enabling simple Arweave based Frames with button navigation. Transaction and data item data is now served under /local/farcaster/frame/. /local is used as a prefix to indicate this functionality is both experimental and local to a particular gateway rather than part of the global gateway API. Both GET and POST requests are supported.Added an experimental local ArNS resolver. When enabled it removes dependence on arweave.net for ArNS resolution! Enable it by setting RUN_RESOLVER=TRUE, TRUSTED_ARNS_RESOLVER_TYPE=resolver, and TRUSTED_ARNS_RESOLVER_URL=http://resolver:6000 in your .env file.Added an X-Cached header to data responses to indicate when data is served from the local cache rather than being retrieved from an external source. This is helpful for interfacing with external systems, debugging, and end-to-end testing.Save hashes for unbundled data items during indexing. This enables reduction in data storage via hash based deduplication as well as more efficient peer-to-peer data retrieval in the future.[Release 8] - 2024-03-14 Added Added GraphQL SQL query debug logging to support trouble-shooting and performance optimization.Added support for indexing data items (not GraphQL querying) based solely on tag name. (example use case: indexing all IPFS CID tagged data items).Changes Observer data sampling now uses randomized ranges to generate content hashes.Reference gateway ArNS resolutions are now cached to improve report generation performance.Contract interactions are now tested before posting using dryWrite to avoid submitting interactions that would fail./ar-io/observer/info now reports INVALID for wallets that fail to load.Fixed Fix data caching failure caused by incorrect method name in getData circuit breakers.Fix healthcheck when ARNS_ROOT_HOST includes a subdomain.[Release 7] - 2024 - 02 - 14 Added Add support for notifying other services of transactions and data items using webhooks (see README for details).Add support for filter negation (particularly useful for excluding large bundles from indexint).Improve unbundling throughput by decoupling data fetching from unbundling.Add Envoy and core service ARM builds.Changed Improve resouce cleanup and shutdown behavior.Don't save Redis data to disk by default to help prevent memory issues on startup for small gateways.Reduce the amount of data sampled from large files by the observer.Ensure block poa2 field is not chached to reduce memory consumption.[Release 6] - 2024-01-29 Fixed Update observer to improve reliability of contract state synchronization and evaluation.[Release 5] - 2024-01-25 Added Added transaction offset indexing to support future data retrieval capabilities.Enabled IPv6 support in Envoy config.Added ability to configure observer report generation interval via the REPORT_GENERATION_INTERVAL_MS environmental variable. (Intended primarily for development and testing) Changed Updated observer to properly handle FQDN conflicts.Renamed most created_at columns to index to indexed_at for consistency and clarity.Fixed Updated LMDB version to remove Buffer workaround and fix occasional block cache errors.[Release 4] - 2024-01-11 Added Added circuit breakers around data index access to reduce impact of DB access contention under heavy requests loads.Added support for configuring data source priority via the ON_DEMAND_RETRIEVAL_ORDER environment variable.Updated observer to a version that retrieves epoch start and duration from contract state.Changed Set the Redis max memory eviction policy to allkeys-lru.Reduced default Redis max memory from 2GB to 256MB.Improved predictability and performance of GraphQL queries.Eliminated unbundling worker threads when filters are configured to skip indexing ANS-104 bundles.Reduced the default number of ANS-104 worker threads from 2 to 1 when unbundling is enabled to conserve memory.Increased nodejs max old space size to 8GB when ANS-104 workers > 1.Fixed Adjusted paths for chunks indexed by data root to include the full data root.[Release 3] - 2023-12-05 Added Support range requests (PR 61, PR 64) Note: serving multiple ranges in a single request is not yet supported.Release number in /ar-io/info response.Redis header cache implementation (PR 62).New default header cache (replaces old FS cache).LMDB header cache implementation (PR 60).Intended for use in development only.Enable by setting CHAIN_CACHE_TYPE=lmdb.Filesystem header cache cleanup worker (PR 68).Enabled by default to cleanup old filesystem cache now that Redis is the new default.Support for parallel ANS-104 unbundling (PR 65).Changed Used pinned container images tags for releases.Default to Redis header cache when running via docker-compose.Default to LMDB header cache when running via yarn start.Fixed Correct GraphQL pagination for transactions with duplicate tags.

---

# 27. ARIO Node Release Notes - ARIO Docs

Document Number: 27
Source: https://docs.ar.io/gateways/release-notes#
Words: 8187
Quality Score: 0.505
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

AR.IO Release Notes Overview Welcome to the documentation page for the AR.IO gateway release notes. Here, you will find detailed information about each version of the AR.IO gateway, including the enhancements, bug fixes, and any other changes introduced in every release. This page serves as a comprehensive resource to keep you informed about the latest developments and updates in the AR.IO gateway. For those interested in exploring the source code, each release's code is readily accessible at our GitHub repository: AR.IO gateway change logs. Stay updated with the continuous improvements and advancements in the AR.IO gateway by referring to this page for all release-related information.[Release 43] - 2025-07-21 This is a recommended release that enables data verification by default for data items linked to ArNS names, improves chunk broadcasting efficiency, and adds automatic chunk data cache cleanup.Added Added automatic chunk data cache cleanup functionality with configurable retention period. Chunks are now automatically removed after 4 hours by default (configurable via CHUNK_DATA_CACHE_CLEANUP_THRESHOLD). The cleanup can be disabled by setting ENABLE_CHUNK_DATA_CACHE_CLEANUP=false. This helps manage disk space usage while maintaining cache performance benefits.Added demand-driven opt-out background verification for ArNS data. When ArNS names are requested, the system now proactively verifies the underlying data asynchronously in the background by unbundling verified chunk data retrieved directly from Arweave nodes. This ensures ArNS-served content is prioritized for verification, improving data integrity guarantees for frequently accessed named content.Changed Simplified chunk data storage by removing the dual-storage approach (by-hash and by-dataroot with symlinks). Chunks are now stored directly by data root only, reducing complexity and improving performance.Revamped chunk broadcasting architecture from 3-tier system to unified peer-based approach. Chunk broadcasting now uses individual fastq queues per peer with configurable concurrency and queue depth protection. Added support for preferred chunk POST peers via PREFERRED_CHUNK_POST_URLS environment variable. Configuration defaults have been optimized: CHUNK_POST_PEER_CONCURRENCY now defaults to match CHUNK_POST_MIN_SUCCESS_COUNT (3) to avoid over-broadcasting, and CHUNK_POST_PER_NODE_CONCURRENCY defaults to match CHUNK_POST_QUEUE_DEPTH_THRESHOLD (10) for consistent per-node load management. This change improves broadcast reliability and performance while simplifying the codebase by removing circuit breakers and tier-based logic.Modified DataVerificationWorker to ensure data item IDs (not just root IDs) have their retry count incremented, preventing IDs from being stuck without retry attempts. This improves the reliability of the data verification process.Fixed Fixed experiment bash Parquet export script generating filenames with count_star() instead of actual row counts for blocks and tags files. The script now correctly uses the -noheader flag when retrieving counts for filename generation.Fixed missing directory existence checks in FsCleanupWorker to prevent errors when attempting to scan non-existent directories during filesystem cleanup operations.[Release 42] - 2025-07-14 This is an optional release that improves peer request traceability, adds HyperBEAM URL support, and includes draft AI-generated technical documentation.Added Added support for optional HyperBEAM URL configuration via AO_ANT_HYPERBEAM_URL environment variable. In the future this allows ANT processes to use HyperBEAM nodes for caching and serving state, reducing pressure on compute units for simple read requests.Added AI-generated technical documentation covering AR.IO gateway architecture, data retrieval, Arweave connectivity, ArNS name resolution system, centralization analysis, and database architecture. These guides in docs/drafts/ are generally correct but should not be considered authoritative.Added origin and release information to query string parameters in outbound requests to both peer gateways and trusted gateways. Data requests now include ar-io-hops, ar-io-origin, ar-io-origin-release, ar-io-arns-record, and ar-io-arns-basename as query parameters, improving network observability and request tracing across the entire gateway network.Changed Implemented X-AR-IO header initialization for outbound peer requests while removing x-ar-io-origin and x-ar-io-origin-node-release headers from responses. This change maintains necessary header functionality for peer communication while reducing unnecessary header overhead in responses.Updated @ar.io/sdk dependency to support optional HyperBEAM URL functionality.[Release 41] - 2025-06-30 Added Added preferred chunk GET node URLs configuration via PREFERRED_CHUNK_GET_NODE_URLS environment variable to enable chunk-specific peer prioritization. Preferred URLs receive a weight of 100 for prioritization and the system selects 10 peers per attempt by default.Added hash validation for peer data fetching by including X-AR-IO-Expected-Digest header in peer requests when hash is available, validating peer responses against expected hash, and immediately rejecting mismatched data.Added DOCKER_NETWORK_NAME environment variable to configure the Docker network name used by Docker Compose.Added draft guide for running a community gateway.Added draft data verification architecture document.Changed Removed trusted node fallback for chunk retrieval. Chunks are now retrieved exclusively from peers, with the retry count increased from 3 to 50 to ensure reliability without the trusted node fallback.Fixed Fixed inverted logic preventing symlink creation in FsChunkDataStore.Fixed Content-Length header for range requests and 304 responses, properly setting header for single and multipart range requests and removing entity headers from 304 Not Modified responses per RFC 7232.Fixed MaxListenersExceeded warnings by adding setMaxListeners to read-through data cache.Fixed potential memory leaks in read-through data cache by using once instead of on for error and end event listeners.[Release 40] - 2025-06-23 This is an optional release that primarily improves caching when data is fetched from peers.Added Added experimental flush-to-stable script for manual database maintenance. This script allows operators to manually flush stable chain and data item tables, mirroring the logic of StandaloneSqliteDatabase.flushStableDataItems. WARNING: This script is experimental and directly modifies database contents. Use with caution and ensure proper backups before running.Changed Replaced yesql with custom SQL loader that handles comments better, improving SQL file parsing and maintenance.Switched to SPDX license headers to reduce LLM token usage, making the codebase more efficient for AI-assisted development.Improved untrusted data handling and hash validation in cache operations. The cache now allows caching when a hash is available for validation even for untrusted data sources, but only finalizes the cache when the computed hash matches a known trusted hash. This prevents cache poisoning while still allowing data caching from untrusted sources when the data can be validated.[Release 39] - 2025-06-17 This release enhances observability and reliability with new cache metrics, improved data verification capabilities, and automatic failover between chain data sources. The addition of ArNS-aware headers enables better data prioritization across the gateway network. This is a recommended but not urgent upgrade.Added Added filesystem cache metrics with cycle-based tracking. Two new Prometheus metrics track cache utilization: cache_objects_total (number of objects in cache) and cache_size_bytes (total cache size in bytes). Both metrics include store_type and data_type labels to differentiate between cache types (e.g., headers, contiguous_data). Metrics are updated after each complete cache scan cycle, providing accurate visibility into filesystem cache usage.Added X-AR-IO-Data-Id header to all data responses. This header shows the actual data ID being served, whether from a direct ID request or manifest path resolution, providing transparency about the content being delivered.Added automatic data item indexing when data verification is enabled. When ENABLE_BACKGROUND_DATA_VERIFICATION is set to true, the system now automatically enables data item indexing (ANS104_UNBUNDLE_FILTER) with an always: true filter if no filter is explicitly configured. This ensures bundles are unbundled to verify that data items are actually contained in the bundle associated with the Arweave transaction's data root.Added ArNS headers to outbound gateway requests to enable data prioritization. The generateRequestAttributes function now includes ArNS context headers (X-ArNS-Name, X-ArNS-Basename, X-ArNS-Record) in requests to other gateways and Arweave nodes, allowing downstream gateways to effectively prioritize ArNS data requests.Added configurable Docker Compose host port environment variables (CORE_PORT, ENVOY_PORT, CLICKHOUSE_PORT, CLICKHOUSE_PORT_2, CLICKHOUSE_PORT_3, OBSERVER_PORT) to allow flexible port mapping while maintaining container-internal port compatibility and security.Added Envoy aggregate cluster configuration for automatic failover between primary and fallback chain data sources. The primary cluster (default: arweave.net:443) uses passive outlier detection while the fallback cluster (default: peers.arweave.xyz:1984) uses active health checks. This enables zero-downtime failover between HTTPS and HTTP endpoints with configurable FALLBACK_NODE_HOST and FALLBACK_NODE_PORT environment variables.Changed Streamlined background data retrieval to reduce reliance on centralized sources. The default BACKGROUND_RETRIEVAL_ORDER now only includes chunks,s3, removing trusted-gateways and tx-data from the default configuration. This prioritizes verifiable chunk data and S3 storage for background operations like unbundling.Removed ar-io.net from default trusted gateways list and removed TRUSTED_GATEWAY_URL default value to reduce load on ar-io.net now that P2P data retrieval is re-enabled. Existing deployments with TRUSTED_GATEWAY_URL explicitly set will continue to work for backwards compatibility.[Release 38] - 2025-06-09 This release focuses on data integrity and security improvements, introducing trusted data verification and enhanced header information for data requests. Upgrading to this release is recommended but not urgent.Added Added X-AR-IO-Trusted header to indicate data source trustworthiness in responses. This header helps clients understand whether data comes from a trusted source and works alongside the existing X-AR-IO-Verified header to provide data integrity information. The system now filters peer data by requiring peers to indicate their content is either verified or trusted, protecting against misconfigured peers that may inadvertently serve unintended content (e.g., provider default landing pages) instead of actual Arweave data.Added If-None-Match header support for HTTP conditional requests enabling better client-side caching efficiency. When clients send an If-None-Match header that matches the ETag, the gateway returns a 304 Not Modified response with an empty body, reducing bandwidth usage and improving performance.Added digest and hash headers for data HEAD requests to enable client-side data integrity verification.Added EC2 IMDS (instance-profile) credential support for S3 data access, improving AWS authentication in cloud environments.Added trusted data flag to prevent caching of data from untrusted sources, ensuring only verified and reliable content is stored locally while still allowing serving of untrusted data when necessary.Changed Re-enabled ar-io-peers as fallback data source in configuration for improved data availability.Updated trusted node configuration to use arweave.net as the default trusted node URL.Updated ETag header format to use properly quoted strings (e.g., "hash" instead of hash) following HTTP/1.1 specification standards for improved compatibility with caching proxies and clients.[Release 37] - 2025-06-03 This is a recommended release due to the included observer robustness improvements. It also adds an important new feature - data verification for preferred ArNS names. When preferred ArNS names are set, the bundles containing the data they point to will be locally unbundled (verifying data item signatures), and the data root for the bundle will be compared to the data root in the Arweave chain (establishing that the data is on Arweave). To enable this feature, set your preferred ArNS names, turn on unbundling by setting ANS104_DOWNLOAD_WORKERS and ANS104_UNBUNDLE_WORKERS both to 1, and set your ANS104_INDEX_FILTER to a filter that will match the data items for your preferred names. If you don't know the filter, use {"always": true}, but be aware this will index the entire bundle for the IDs related to your preferred names.Note: this release contains migrations to data.db. If your node appears unresponsive please check core service logs to determine whether migrations are running and wait for them to finish.Added Added prioritized data verification system for preferred ArNS names, focusing computational resources on high-priority content while enabling flexible root transaction discovery through GraphQL fallback support.Added verification retry prioritization system with tracking of retry counts, priority levels, and attempt timestamps to ensure bundles do not get stuck retrying forever.Added improved observer functionality with best-of-2 observations and higher compression for more reliable network monitoring.Added MAX_VERIFICATION_RETRIES environment variable (default: 5) to limit verification retry attempts and prevent infinite loops for consistently failing data items.Added retry logic with exponential backoff for GraphQL queries to handle rate limiting (429) and server errors with improved resilience when querying trusted gateways for root bundle IDs.Changed Updated dependencies: replaced deprecated express-prometheus-middleware with the actively maintained express-prom-bundle library and updated prom-client to v15.1.3 for better compatibility and security.Updated Linux setup documentation to use modern package installation methods, replacing apt-key yarn installation with npm global install and updating Node.js/nvm versions.Improved route metrics normalization with explicit whitelist function for better granularity and proper handling of dynamic segments.Fixed Fixed docker-compose configuration to use correct NODE_MAX_OLD_SPACE_SIZE environment variable name.Fixed production TypeScript build configuration to exclude correct "test" directory path.Fixed Parquet exporter to properly handle data item block_transaction_index exports, preventing NULL value issues.Fixed bundles system to copy root_parent_offset when flushing data items to maintain data integrity.Fixed ClickHouse auto-import script to handle Parquet export not_started status properly.Fixed docker-compose ClickHouse configuration to not pass conflicting PARQUET_PATH environment variable to container scripts.Fixed verification process for data items that have not been unbundled by adding queue bundle support and removing bundle join constraint to ensure proper verification of data items without indexed root parents.[Release 36] - 2025-05-27 This is a recommended but not essential upgrade. The most important changes are the preferred ArNS caching feature for improved performance on frequently accessed content and the observer's 80% failure threshold to prevent invalid reports during network issues.Added Added preferred ArNS caching functionality that allows configuring lists of ArNS names to be cached longer via PREFERRED_ARNS_NAMES and PREFERRED_ARNS_BASE_NAMES environment variables. When configured, these names will be cleaned from the filesystem cache after PREFERRED_ARNS_CONTIGUOUS_DATA_CACHE_CLEANUP_THRESHOLD instead of the standard cleanup threshold (CONTIGUOUS_DATA_CACHE_CLEANUP_THRESHOLD). This is accomplished by maintaining an MRU (Most Recently Used) list of ArNS names in the contiguous metadata cache. When filesystem cleanup runs, it checks this list to determine which cleanup threshold to apply. This feature enables gateway operators to ensure popular or important ArNS names remain cached longer, improving performance for frequently accessed content.Added ArNS headers to responses: X-ArNS-Name, X-ArNS-Basename, and X-ArNS-Record to help identify which ArNS names were used in the resolution.Changed Updated observer to prevent report submission when failure rate exceeds 80%. This threshold helps guard against both poorly operated observers and widespread network issues. In the case of a widespread network issue, the assumption is that most gateway operators are well intentioned and will work together to troubleshoot and restore both observations and network stability, rather than submitting reports that would penalize functioning gateways.Updated default trusted gateway in docker-compose Envoy configuration to ar-io.net for improved robustness and alignment with core service configuration.Improved range request performance by passing ranges directly to getData implementations rather than streaming all data and extracting ranges.Fixed Fixed missing cache headers (X-Cache and other data headers) in range request responses to ensure consistent cache header behavior across all request types.Fixed async streaming for multipart range requests by using async iteration instead of synchronous reads, preventing potential data loss.Fixed ArNS resolution to properly exclude www subdomain from resolution logic.Fixed test reliability issues by properly awaiting stream completion before making assertions.Fixed chunk broadcasting to not await peer broadcasts, as they are best-effort operations.[Release 35] - 2025-05-19 This is a low upgrade priority release. It contains a small caching improvement and routing fix. Upgrading to help test it is appreciated but not essential.Changed Adjusted filesystem data expiration to be based on last request times rather than file access times which may be inaccurate.Adjusted CORS headers to include content-* headers.Fixed Fixed regex used to expose /api-docs when an apex ArNS name is set.[Release 34] - 2025-05-05 Given the resilience provided by adding a second trusted gateway URL, it is recommended that everyone upgrade to this release.Added Added peer list endpoints for retrieving information about Arweave peers and ar.io gateway peers.Added ar-io.net as a secondary trusted gateway to increase data retrieval resilience by eliminating a single point of failure.Added circuit breaker for Arweave peer chunk posting.Changed Created directories for DuckDB and Parquet to help avoid permission issues by the directories being created by containers.Fixed Fixed GraphQL ClickHouse error when returning block ID and timestamp.Fixed the tx-chunks-data-source to throw a proper error (resulting in a 404) when the first chunk is missing rather than streaming a partial response.[Release 33] - 2025-05-05 Added Added a [Parquet and ClickHouse usage guide]. Using ArDrive as an example, it provides step by step instructions about how to bulk load Parquet and configure continuous ingest of bundled data items into ClickHouse. This allows the ar-io-node to support performant GraphQL queries on larger data sets and facilitates sharing indexing work across gateways via distribution of Parquet files.Added support for configurable ArNS 404 pages using either:ARNS_NOT_FOUND_TX_ID: Transaction ID for custom 404 content ARNS_NOT_FOUND_ARNS_NAME: ArNS name to resolve for 404 content Added experimental /chunk/ GET route for serving chunk data by absolute offset either the local cache.Added support for AWS_SESSION_TOKEN in the S3 client configuration.Expanded ArNS OTEL tracing to improve resolution behavior observability.Added support for setting a ClickHouse username and password via the CLICKHOUSE_USERNAME and CLICKHOUSE_PASSWORD environment variable. When using ClickHouse, CLICKHOUSE_PASSWORD should always be set. However, CLICKHOUSE_USERNAME can be left unset. The username default will be used in that case.Added support for configuring the port used to connect to ClickHouse via the CLICKHOUSE_PORT environment variable.Changed Disabled ClickHouse import timing logging by default. It can be enabled via environment variable - DEBUG when running the service standalone or CLICKHOUSE_DEBUG when using Docker Compose Upgraded to ClickHouse 25.4.Fixed Ensure .env is read in clickhouse-import script.[Release 32] - 2025-04-22 Changed Reenabled parallel ArNS resolution with removal of misplaced global limit. Refer to release 30 notes for more details on configuration and rationale.Added a timeout for the last ArNS resolver in ARNS_RESOLVER_PRIORITY_ORDER. It defaults to 30 seconds and is configurable using ARNS_COMPOSITE_LAST_RESOLVER_TIMEOUT_MS. This helps prevent promise build up if the last resolver stalls.Fixed Fixed apex ArNS name handling when a subdomain is present in ARNS_ROOT_HOST.Fixed a case where fork recovery could stall due to early flushing of unstable chain data.Restored observer logs by removing unintentional default log level override in docker-compose.yaml.[Release 31] - 2025-04-11 Changed Improved peer TX header fetching by fetching from a wider range of peers and up/down weighting peers based on success/failure.Fixed Rolled back parallel ArNS resolution changes that were causing ArNS resolution to slow down over time.[Release 30] - 2025-04-04 Added Added support for filtering Winston logs with a new LOG_FILTER environment variable.Example filter: {"attributes":{"class":"ArweaveCompositeClient"}} to only show logs from that class.Use CORE_LOG_FILTER environment variable when running with docker-compose.Added parallel ArNS resolution capability.Configured via ARNS_MAX_CONCURRENT_RESOLUTIONS (default: 1).This foundation enables future enhancements to ArNS resolution and should generally not be adjusted at present.Changed Improved ClickHouse auto-import script with better error handling and continuous operation through errors.Reduced maximum header request rate per second to trusted node to load on community gateways.Optimized single owner and recipient queries on ClickHouse with specialized sorted tables.Used ID sorted ClickHouse table for ID queries to improve performance.Fixed Fixed data alignment in Parquet file name height boundaries to ensure consistent import boundaries.Removed trailing slashes from AO URLs to prevent issues when passing them to the SDK.Only prune SQLite data when ClickHouse import succeeds to prevent data loss during exports.[Release 29] - 2025-03-21 Changed Temporarily default to trusted gateway ArNS resolution to reduce CU load as much possible. On-demand CU resolution is still available as a fallback and the order can be modified by setting ARNS_RESOLVER_PRIORITY_ORDER.Remove duplicate network process call in on-demand resolver.Don't wait for network process debounces in the on-demand resolver.Slow network process dry runs no longer block fallback to next resolver.Added Added support for separate CUs URLs for the network and ANT processes via the NETWORK_AO_CU_URL and ANT_AO_CU_URL process URLs respectively. If either is missing the AO_CU_URL is used instead with a fallback to the SDK default URL if AO_CU_URL is also unspecified.Added CU URLs to on-demand ArNS resolver logs.Added circuit breakers for AR.IO network process CU dry runs. By default they use a 1 minute timeout and open after 30% failure over a 10 minute window and reset after 20 minutes.Fixed Owners in GraphQL results are now correctly retrieved from data based on offsets when using ClickHouse.[Release 28] - 2025-03-17 Changed Raised name not found name list refresh interval to 2 minutes to reduce load on CUs. This increases the maximum amount of time a user may wait for a new name to be available. Future releases will introduce other changes to mitigate this delay.Adjusted composite ArNS resolver to never timeout resolutions from the last ArNS resolver in the resolution list.Added Added support for serving a given ID or ArNS name from the apex domain of a gateway. If using an ID, set the APEX_TX_ID environment variable. If using an ArNS name, set the APEX_ARNS_NAME environment variable.Added BUNDLE_REPAIR_UPDATE_TIMESTAMPS_INTERVAL_SECONDS, BUNDLE_REPAIR_BACKFILL_INTERVAL_SECONDS, and BUNDLE_REPAIR_FILTER_REPROCESS_INTERVAL_SECONDS environment variables to control the interval for retrying failed bundles, backfilling bundle records, and reprocessing bundles after a filter change. Note: the latter two are rarely used. Queuing bundles for reprocessing via the /ar-io/admin/queue-bundle endpoint is usually preferable to automatic reprocessing as it is faster and offers more control over the reprocessing behavior.Fixed Signatures in GraphQL results are now correctly retrieved from data based on offsets when using ClickHouse.Adjusted exported Parquet file names to align with expectations of ClickHouse import script.Ensured that bundle indexing status is properly reset when bundles are manually queued after an unbundling filter change has been made.[Release 27] - 2025-02-20 Changed Set process IDs for mainnet.Increase default AO CU WASM memory limit to 17179869184 to support mainnet
process.[Release 26] - 2025-02-13 Added Added a per resolver timeout in the composite ArNS resolver. When the
composite resolver attempts resolution it is applied to each resolution
attempt. It is configurable via the ARNS_COMPOSITE_RESOLVER_TIMEOUT_MS and
defaults to 3 seconds in order to allow a fallback attempt before the default
observer timeout of 5 seconds.Added a TURBO_UPLOAD_SERVICE_URL environment variable to support
configuration of the bundler used by the observer (TurboSDK defaults are
used if not set).Added a REPORT_DATA_SINK environment variable that enables switching the
method used to post observer reports. With the default, turbo, it sends
data items via a Turbo compatible bundler. Switching it to arweave will
post base layer transactions directly to Arweave instead.Added a /ar-io/admin/bundle-status/ endpoint that returns the counters
and timestamps from the bundles row in data.db. This can be used for
monitoring unbundling progress and scripting (e.g., to skip requeuing already
queued bundles).Added more complete documentation for filters.Changed Use arweave.net as the default GraphQL URL for AO CUs since most gateways
will not have a complete local AO data item index.Use a default timeout of 5 seconds when refreshing Arweave peers to prevent
stalled peer refreshes.Cache selected gateway peer weights for the amount of time specified by the GATEWAY_PEERS_WEIGHTS_CACHE_DURATION_MS environment variable with a default
of 5 seconds to avoid expensive peer weight recomputation on each request.Chunk broadcasts to primary nodes occur in parallel with a concurrency limit
defaulting to 2 and configurable via the CHUNK_POST_CONCURRENCY_LIMIT environment variable.Added circuit breakers for primary chunk node POSTs to avoid overwhelming
chunk nodes when they are slow to respond.Fixed Properly cleanup timeout and event listener when terminating the data
root computation worker.Count chunk broadcast exceptions as errors in the arweave_chunk_broadcast_total metric.[Release 25] - 2025-02-07 Added Added support for indexing and querying ECDSA signed Arweave transactions.Expanded the OpenAPI specification to cover the entire gateway API and
commonly used Arweave node routes.ArNS undername record count limits are now enforced. Undernames are sorted
based on their ANT configured priority with a fallback to name comparisons
when priorities conflict or are left unspecified. Enforcement is enabled by
default but can be disabled by setting the ARNS_RESOLVER_ENFORCE_UNDERNAME_LIMIT to false.Changed Renamed the ario-peer data source to ar-io-peers for consistency and
clarity. ario-peer will continue to work for backwards compatibility but is
considered deprecated.Use AR.IO gateway peers from the ar.io gateway address registry (GAR) as the
last fallback for fetching data when responding to client data requests. This
has the benefit of making the network more resilient to trusted gateway
disruptions, but it can also result in nodes serving data from less trusted
sources if it is not found in the trusted gateway. This can be disabled by
using a custom ON_DEMAND_RETRIEVAL_ORDER that does not include ar-io-peers.Arweave data chunk requests are sent to the trusted node first with a
fallback to Arweave peers when chunks are unavailable on the trusted node.
This provides good performance by default with a fallback in case there are
issues retrieving chunks from the trusted node.Increased the observer socket timeout to 5 seconds to accommodate initial
slow responses for uncached ArNS resolutions.Disabled writing base layer Arweave signatures to the SQLite DB by default to
save disk space. When signatures are required to satisfy GraphQL requests,
they are retrieved from headers on the trusted node.Fixed Updated dependencies to address security issues.Improved reliability of failed bundle indexing retries.Fixed failure to compute data roots for verification for base layer data
larger than 2GiB.Fixed observer healthcheck by correcting node.js path in healthcheck script.[Release 24] - 2025-02-03 Added Added a ARNS_ANT_STATE_CACHE_HIT_REFRESH_WINDOW_SECONDS environment
variable that determines the number of seconds before the end of the TTL at
which to start attempting to refresh the ANT state.Added a TRUSTED_GATEWAYS_REQUEST_TIMEOUT_MS environment that defaults to
10,000 and sets the number of milliseconds to wait before timing out request
to trusted gateways.Added BUNDLE_REPAIR_RETRY_INTERVAL_SECONDS and BUNDLE_REPAIR_RETRY_BATCH_SIZE environment variables to control the time
between queuing batches of bundle retries and the number of data items
retrieved when constructing batches of bundles to retry.Added support for configuring the ar.io SDK log level via the AR_IO_SDK_LOG_LEVEL environment variable.Added a request_chunk_total Prometheus counter with status, source (a
URL) and source_type (trusted or peer) labels to track success/failure
of chunk retrieval in the Arweave network per source.Added a get_chunk_total Prometheus metric to count chunk retrieval
success/failure per chunk.Added arns_cache_hit_total and arns_cache_miss_total Prometheus counters
to track ArNS cache hits and misses for individual names respectively.Added arns_name_cache_hit_total and arns_name_cache_miss_total Prometheus
counters to track ArNS name list cache hits and misses
respectively.Added a arns_resolution_duration_ms Prometheus metric that tracks summary
statistics for the amount of time it takes to resolve ArNS names.Changed In addition to the trusted node, the Arweave network is now searched for
chunks by default. All chunks retrieved are verified against data roots
indexed from a trusted Arweave node to ensure their validity.Default to a 24 hour cache TTL for the ArNS name cache. Record TTLs still
override this, but in cases where resolution via AO CU is slow or fails, the
cache will be used. In the case of slow resolution, CU based resolution will
proceed in the background and update the cache upon completion.Switched to the ioredis library for better TLS support.Updated minor dependency minor versions (more dependencies will be updated in
the next release).Bundles imports will no longer be re-attempted for bundles that have already
been fully unbundled using the current filters if they are matched or
manually queued again.Replaced references docker-compose in the docs with the more modern docker compose.Fixed Ensure duplicate data item IDs are ignored when comparing counts to determine
if a bundle has been fully unbundled.Fixed worker threads failing to shut down properly when the main processped.Ensure bundle import attempt counts are incremented when bundles are skipped
to avoid repeatedly attempting to import skipped bundles.Use observe that correctly ensure failing gateways are penalized in the AR.IO
AO process.[Release 23] - 2025-01-13 Added Added FS_CLEANUP_WORKER_BATCH_SIZE,FS_CLEANUP_WORKER_BATCHDURATION, and FS_CLEANUP_WORKER_RESTARTDURATION environment variables to allow
configuration of number of contiguous data files cleaned up per batch, the between each batch, and the before restarting the entire cleanup
process again.Added data_items_unbundled_total Prometheus metric that counts the total
number of data items unbundled, including those that did not match the
unbundling filter.Added a parent_type label that can be one of transaction or data_item to data item indexing metrics.Added a files_cleaned_total total Prometheus metric to enable monitoring of
contiguous data cleanup.Added support for specifying the admin API via a file specified by the ADMIN_API_KEY_FILE environment variable.Added experimental support for posting chunks in a non-blocking way to
secondary nodes specified via a comma separate list in the SECONDARY_CHUNK_POST_URLS environment variable.Changed Renamed the parent_type lable to contiguous_data_type on bundle metrics
to more accurately reflect the meaning of the label.Reduced the maximum time to refresh the ArNS name list to 10 seconds to
minimize delays in ArNS availability after a new name is registered.Changed /ar-io/admin/queue-bundle to wait for bundles rows to be written
to the DB before responding to ensure that errors that occur due to DB
contention are not silently ignored.Data items are now flushed even when block indexing is ped. This allows
for indexing batches of data items using the admin API with block indexing
disabled.Adjust services in docker-compose to use unless-ped as their restart
policy. This guards against missing restarts in the case where service
containers exit with a success status even when they shouldn't.Fixed Added missing created_at field in blocked_names table.Fixed broken ArNS undername resolution.[Release 22] - 2024-12-18 Added Added the ability to block and unblock ArNS names (e.g., to comply with hosting provider TOS). To block a name, POST { "name": "" } to /ar-io/admin/block-name. To unblock a name, POST { "name": "" } to /ar-io/admin/unblock-name.Changed Return an HTTP 429 response to POSTs to /ar-io/admin/queue-bundle when the bundle data import queue is full so that scripts queuing bundles can wait rather than overflowing it.Fixed Adjust ArNS length limit from <= 48 to <= 51 to match the limit enforced by the AO process.[Release 21] - 2024-12-05 Added Added a ClickHouse auto-import service. When enabled, it calls the Parquet export API, imports the exported Parquet into ClickHouse, moves the Parquet files to an imported subdirectory, and deletes data items in SQLite up to where the Parquet export ended. To use it, run Docker Compose with the clickhouse profile, set the CLICKHOUSE_URL to http://clickhouse:8123, and ensure you have set an ADMIN_KEY. Using this configuration, the core service will also combine results from ClickHouse and SQLite when querying transaction data via GraphQL. Note: if you have a large number of data items in SQLite, the first export and subsequent delete may take an extended period. Also, this functionality is considered experimental. We expect there are still bugs to be found in it and we may make breaking changes to the ClickHouse schema in the future. If you choose to use it in production (not yet recommended), we suggest backing up copies of the Parquet files found in data/parquet/imported so that they can be reimported if anything goes wrong or future changes require it.Added a background data verification process that will attempt to recompute data roots for bundles and compare them to data roots indexed from Arweave nodes. When the data roots match, all descendant data items will be marked as verified. This enables verification of data initially retrieived from sources, like other gateways, that serve contiguous data instead of verifiable chunks. Data verification can be enabled by setting the ENABLE_BACKGROUND_DATA_VERIFICATION environment variable to true. The interval between attempts to verify batches of bundles is configurable using the BACKGROUND_DATA_VERIFICATION_INTERVAL_SECONDS environment variable.Added a CHUNK_POST_MIN_SUCCESS_COUNT environment variable to configure how many Arweave nodes must accept a chunk before a chunk broadcast is considered successful.Added arweave_chunk_post_total and arweave_chunk_broadcast_total Prometheus metrics to respectively track the number of successful chunk POSTs to Arweave nodes and the number of chunks successfully broadcast.When resolving ArNS names, the entire list of names is now cached instead of individually checking whether each name exists. This reduces the load on AO CUs since the entire list can be reused across multiple requests for different names. Note: due to the default 5 minute interval between name list refreshes, newly registered may now take longer to resolver after initial registration. We intend to make further caching refinements to address this in the future.Added support for multiple prioritized trusted gateways configurable by setting the TRUSTED_GATEWAYS_URLS environment variable to a JSON value containing a mapping of gateway hosts to priorities. Data requests are sent to other gateways in ascending priority order. If multiple gateways share the same priority, all the gateways with the same priority are tried in a random order before continuing on to the next priority.Added support for caching contiguous data in S3. It is enabled by default when the AWS_S3_CONTIGUOUS_DATA_BUCKET and AWS_S3_CONTIGUOUS_DATA_PREFIX environment variables are set.Changed trusted-gateway was changed to trusted-gateways in ON_DEMAND_RETRIEVAL_ORDER and BACKGROUND_RETRIEVAL_ORDER.Renamed the S3 contiguous environment variables - AWS_S3_BUCKET to AWS_S3_CONTIGUOUS_DATA_BUCKET and AWS_S3_PREFIX to AWS_S3_CONTIGUOUS_DATA_PREFIX.[Release 20] - 2024-11-15 Added Exposed the core service chunk POST endpoint via Envoy. It accepts a Arweave data chunk and broadcasts it to either the comma separated list of URLs specified by the CHUNK_POST_URLs environment variable or, if none are specified, the /chunk path on URL specified by the TRUST_GATEWAY_URL environment variable.Added a X-AR-IO-Root-Transaction-Id HTTP header to data responses containing the root base layer transaction ID for the ID in question if it's been indexed.Added a X-AR-IO-Data-Item-Data-Offset HTTP header containing the offset of the data item relative to the root bundle base layer transaction for it. In conjunction with X-AR-IO-Root-Transaction-Id, it enables retrieving data for data item IDs from base layer data using first a HEAD request to retrieve the root ID and data offset followed by a range request into the root bundle. This greatly increases the likelihood of retriving data item data by ID since only an index into the base layer and Arweave chunk availability is needed for this access method to succeed.Added an experimental ClickHouse service to docker-compose.yaml (available via the clickhouse profile). This will be used as a supplemental GraphQL DB in upcoming releases.Added a data item indexing healthcheck that can be enabled by setting the RUN_AUTOHEAL environment variable to true. When enabled, it will restart the core service if no data items have been indexed since the value specified by the MAX_EXPECTED_DATA_ITEM_INDEXING_INTERVAL_SECONDS environment variable.[Release 19] - 2024-10-21 Fixed Adjusted data item flushing to use the bundle DB worker instead of the core DB worker to prevent write contention and failed flushes under heavy unbundling load.Added Added X-AR-IO-Digest, X-AR-IO-Stable, X-AR-IO-Verified, and ETag headers. X-AR-IO-Digest contains a base64 URL encoded representation of the SHA-256 hash of the data item data. It may be empty if the gateway has not previously cached the data locally. X-AR-IO-Stable contains either true or false depending on whether the associated Arweave transaction is more than 18 blocks old or not. X-AR-IO-Verified contains either true if the gateway has verified the data root of the L1 transaction or the L1 root parent of the data item or false if it has not. ETag contains the same value a X-AR-IO-Digest and is used to improve HTTP caching efficiency.Added support for using a different data source for on-demand and background data retrieval. Background data retrieval is used when unbundling. The background retrieval data source order is configurable using the BACKGROUND_RETRIEVAL_ORDER environment variable and defaults to chunks,s3,trusted-gateway,tx-data. Priority is given to chunk retrieval since chunks are verifiable.Added an /ar-io/admin/export-parquet/status to support monitoring of in-progress Parquet export status.Added sqlite_in_flight_ops Prometheus metric with worker (core, bundles, data, or moderation) and role (read or write) labels to support monitoring the number of in-flight DB operations.Added experimental Grafana and Prometheus based observability stack. See the "Monitoring and Observability" section of the README for more details.Changed Bundle data is now retrieved as chunks from Arweave nodes by default so that data roots can be compared against the chain (see entry about background retrieval above).Changed observer configuration to use 8 instead of 5 chosen names. These are combined with 2 names prescribed from the contract for a total of 10 names observed each epoch to provide increased ArNS observation coverage.Verification status is set on data items when unbundling a parent that has already been verified.[Release 18] - 2024-10-01 Fixed Improved performance of data attributes query that was preventing data.db WAL flushing.Added Added WAL sqlite_wal_checkpoint_pages Prometheus metric to help monitor WAL flushing.Added a POST /ar-io/admin/export-parquet endpoint that can be used to export the contents of the SQLite3 core and bundle DBs as Parquet. To trigger an export, POST JSON containing outputDir, startHeight, endHeight, and maxFileRows keys. The resulting Parquet files can then be queried directly using DuckDB or loaded into another system (e.g. ClickHouse). Scripts will be provided to help automate the latter in a future release.Added ARNS_RESOLVER_OVERRIDE_TTL_SECONDS that can be used to force ArNS names to refresh before their TTLs expire.Added a GET /ar-io/resolver/:name endpoint that returns an ArNS resolution for the given name.Changed Removed ArNS resolver service in favor of integrated resolver. If a standalone resolver is still desired, the core service can be run with the START_WRITERS environment variable set to false. This will disable indexing while preserving resolver functionality.Deduplicated writes to data.db to improve performance and reduce WAL growth rate.[Release 17] - 2024-09-09 Notes This release includes a LONG RUNNING MIGRATION. Your node may appear unresponsive while it is running. It is best to wait for it to complete. If it fails or is interrupted, removing your SQLite DBs (in data/sqlite by default) should resolve the issue, provided you are willing to lose your GraphQL index and let your node rebuild it.Fixed Use the correct environment variable to populate WEBHOOK_BLOCK_FILTER in docker-compose.yaml.Don't cache data regions retrieved to satisfy range requests to avoid unnecessary storage overhead and prevent inserting invalid ID to hash mappings into the data DB.Added Added a new ClickHouse based DB backend. It can be used in combination with the SQLite DB backend to enable batch loading of historical data from Parquet. It also opens up the possibility of higher DB performance and scalability. In its current state it should be considered a technology preview. It won't be useful to most users until we either provide Parquet files to load into it or automate flushing of the SQLite DB to it (both are planned in future release). It is not intended to be standalone solution. It supports bulk loading and efficient GraphQL querying of transactions and data items, but it relies on SQLite (or potentially another OLTP in the future) to index recent data. These limitations allow greatly simplified schema and query construction. Querying the new ClickHouse DB for transaction and data items via GraphQL is enabled by setting the CLICKHOUSE_URL environment variable.Added the ability to skip storing transaction signatures in the DB by setting WRITE_TRANSACTION_DB_SIGNATURES to false. Missing signatures are fetched from the trusted Arweave node when needed for GraphQL results.Added a Redis backed signature cache to support retrieving optimistically indexed data item signatures in GraphQL queries when writing data items signatures to the DB has been disabled.Added on-demand and composite ArNS resolvers. The on-demand resolver fetches results directly from an AO CU. The composite resolver attempts resolution in the order specified by the ARNS_RESOLVER_PRIORITY_ORDER environment variable (defaults to on-demand,gateway).Added a queue_length Prometheus metric to fasciliate monitoring queues and inform future optimizations Added SQLite WAL cleanup worker to help manage the size of the data.db-wal file. Future improvements to data.db usage are also planned to further improve WAL management.Changed Handle data requests by ID on ArNS sites. This enables ArNS sites to use relative links to data by ID.Replaced ARNS_RESOLVER_TYPE with ARNS_RESOLVER_PRIORITY_ORDER (defaults to on-demand,gateway).Introduced unbundling back pressure. When either data item data or GraphQL indexing queue depths are more than the value specified by the MAX_DATA_ITEM_QUEUE_SIZE environment variable (defaults to 100000), unbundling is d until the queues length falls bellow that threshold. This prevents the gateway from running out of memory when the unbundling rate exceeds the indexing rate while avoiding wasteful bundle reprocessing.Prioritized optimistic data item indexing by inserting optimistic data items at the front of the indexing queues.Prioritized nested bundle indexing by inserting nested bundles at the front of the unbundling queue.[Release 16] - 2024-08-09 Fixed Fixed promise leak caused by missing await when saving data items to the DB.Modified ArNS middleware to not attempt resolution when receiving requests for a different hostname than the one specified by ARNS_ROOT_HOST.Added Added support for returning Content-Encoding HTTP headers based on user specified Content-Encoding tags.Added isNestedBundle filter enables that matches any nested bundle when indexing. This enables composite unbundling filters that match a set of L1 tags and bundles nested under them.Added ability to skip writing ANS-104 signatures to the DB and load them based on offsets from the data instead. This significantly reduces the size of the bundles DB. It can be enabled by setting the WRITE_ANS104_DATA_ITEM_DB_SIGNATURES environment variable to false.Added data_item_data_indexed_total Prometheus counter to count data items with data attributes indexed.Changed Queue data attributes writes when serving data rather than writing them syncronously.Reduced the default data indexer count to 1 to lessen the load on the data DB.Switched a number of overly verbose info logs to debug level.Removed docker-compose on-failure restart limits to ensure that services restart no matter how many times they fail.Modified the data_items_indexed_total Prometheus counter to count data items indexed for GraphQL querying instead of data attributes.Increased aggressiveness of contiguous data cleanup. It now s 5 seconds instead of 10 seconds per batch and runs every 4 hours instead of every 24 hours.[Release 15] - 2024-07-19 Fixed Fixed query error that was preventing bundles from being marked as fully imported in the database.Added Adjusted data item indexing to record data item signature types in the DB. This helps distinguish between signatures using different key formats, and will enable querying by signature type in the future.Adjusted data item indexing to record offsets for data items within bundles and signatures and owners within data items. In the future this will allow us to avoid saving owners and signatures in the DB and thus considerably reduce the size of the bundles DB.Added ARNS_CACHE_TTL_MS environment variable to control the TTL of ARNS cache entries (defaults to 1 hour).Added support for multiple ranges in a single HTTP range request.Added experimental chunk POST endpoint that broadcasts chunks to the comma-separate list of URLS in the CHUNK_BROADCAST_URLS environment variable. It is available at /chunk on the internal gateway service port (4000 by default) but is not yet exposed through Envoy.Added support for running an AO CU adjacent to the gateway (see README.md for details).Added X-ArNS-Process-Id to ArNS resolved name headers.Added a set of AO_... environment variables for specifying which AO URLs should be used (see docker-compose.yaml for the complete list). The AO_CU_URL is of particular use since the core and resolver services only perform AO reads and only the CU is needed for reads.Changed Split the monolithic docker-compose.yaml into docker-compose.yaml, docker-compose.bundler.yaml, and docker-compose.ao.yaml (see README for details).Replaced references to 'docker-compose' with 'docker compose' in the docs since the former is mostly deprecated.Reduce max fork depth from 50 to 18 inline to reflect Arweave 2.7.2 protocol changes.Increased the aggressiveness of bundle reprocessing by reducing reprocessing interval from 10 minutes to 5 minutes and raising reprocessing batch size from 100 to 1000.Use a patched version of Litestream to work around insufficient S3 multipart upload size in the upstream version.[Release 14] - 2024-06-26 Fixed Correctly handle manifest index after paths.[Release 13] - 2024-06-24 Added Added support for optimistically reading data items uploaded using the integrated Turbo bundler via the LocalStack S3 interface.Added X-AR-IO-Origin-Node-Release header to outbound data requests.Added hops, origin, and originNodeRelease query params to outbound data requests.Added support for fallback in v0.2 manifests that is used if no path in the manifest is matched.Changed Updated Observer to read prescribed names from and write observations to the ar.io AO network process.Updated Resolver to read from the ar.io AO network process.Fixed Modified optimistic indexing of data items to use a null parent_id when inserting into the DB instead of a placeholder value. This prevents unexpected non-null bundledIn values in GraphQL results for optimistically indexed data items.Modified GraphQl query logic to require an ID for single block GraphQL queries. Previously queries missing an ID were returning an internal SQLite error. This represents a small departure from arweave.net's query logic which returns the latest block for these queries. We recommend querying blocks instead of block in cases where the latest block is desired.Adjusted Observer health check to reflect port change to 5050.Security Modified docker-compose.yaml to only expose Redis, PostgreSQL, and LocalStack ports internally. This protects gateways that neglect to deploy behind a firewall, reverse proxy, or load balancer.[Release 12] - 2024-06-05 Added Added /ar-io/admin/queue-data-item endpoint for queuing data item headers for indexing before the bundles containing them are processed. This allows trusted bundlers to make their data items quickly available to be queried via GraphQL without having to wait for bundle data submission or unbundling.Added experimental support for retrieving contiguous data from S3. See AWS_* environment variables documentation for configuration details. In conjuction with a local Turbo bundler this allows optimistic bundle (but not yet data item) retrieval.Add experimental support for fetching data from gateway peers. It can be enabled by adding ario-peer to ON_DEMAND_RETRIEVAL_ORDER. Note: do not expect this work reliably yet! This functionality is in active development and will be improved in future releases.Add import_attempt_count to bundle records to enable future bundle import retry optimizations.Changed Removed version from docker-compose.yaml to avoid warnings with recent versions of docker-compose.Switched default observer port from 5000 to 5050 to avoid conflict on OS X. Since Envoy is used to provide external access to the observer API this should have no user visible effect.[Release 11] - 2024-05-21 Added Added arweave_tx_fetch_total Prometheus metric to track counts of transaction headers fetched from the trusted node and Arweave network peers.Changed Revert to using unnamed bind mounts due to cross platform issues with named s.[Release 10] - 2024-05-20 Added Added experimental support for streaming SQLite backups to S3 (and compatible services) using Litestream. Start the service using the docker-compose "litestream" profile to use it, and see the AR_IO_SQLITE_BACKUP_* environment variables documentation for further details.Added /ar-io/admin/queue-bundle endpoint for queueing bundles for import for import before they're in the mempool. In the future this will enable optimistic indexing when combined with a local trusted bundler.Added support for triggering webhooks when blocks are imported matching the filter specified by the WEBHOOK_BLOCK_FILTER environment variable.Added experimental support for indexing transactions and related data items from the mempool. Enable it by setting ENABLE_MEMPOOL_WATCHER to 'true'.Made on-demand data caching circuit breakers configurable via the GET_DATA_CIRCUIT_BREAKER_TIMEOUT_MS environment variable. This allows gateway operators to decide how much latency they will tolerate when serving data in exchange for more complete data indexing and caching.Rename cache header from X-Cached to X-Cache to mimic typical CDN practices.Add X-AR-IO-Hops and X-AR-IO-Origin headers in preparation for future peer-to-peer functionality.Upgrade to Node.js v20 and switch to native test runner.[Release 9] - 2024-04-10 Added Added experimental Farcaster Frames support, enabling simple Arweave based Frames with button navigation. Transaction and data item data is now served under /local/farcaster/frame/. /local is used as a prefix to indicate this functionality is both experimental and local to a particular gateway rather than part of the global gateway API. Both GET and POST requests are supported.Added an experimental local ArNS resolver. When enabled it removes dependence on arweave.net for ArNS resolution! Enable it by setting RUN_RESOLVER=TRUE, TRUSTED_ARNS_RESOLVER_TYPE=resolver, and TRUSTED_ARNS_RESOLVER_URL=http://resolver:6000 in your .env file.Added an X-Cached header to data responses to indicate when data is served from the local cache rather than being retrieved from an external source. This is helpful for interfacing with external systems, debugging, and end-to-end testing.Save hashes for unbundled data items during indexing. This enables reduction in data storage via hash based deduplication as well as more efficient peer-to-peer data retrieval in the future.[Release 8] - 2024-03-14 Added Added GraphQL SQL query debug logging to support trouble-shooting and performance optimization.Added support for indexing data items (not GraphQL querying) based solely on tag name. (example use case: indexing all IPFS CID tagged data items).Changes Observer data sampling now uses randomized ranges to generate content hashes.Reference gateway ArNS resolutions are now cached to improve report generation performance.Contract interactions are now tested before posting using dryWrite to avoid submitting interactions that would fail./ar-io/observer/info now reports INVALID for wallets that fail to load.Fixed Fix data caching failure caused by incorrect method name in getData circuit breakers.Fix healthcheck when ARNS_ROOT_HOST includes a subdomain.[Release 7] - 2024 - 02 - 14 Added Add support for notifying other services of transactions and data items using webhooks (see README for details).Add support for filter negation (particularly useful for excluding large bundles from indexint).Improve unbundling throughput by decoupling data fetching from unbundling.Add Envoy and core service ARM builds.Changed Improve resouce cleanup and shutdown behavior.Don't save Redis data to disk by default to help prevent memory issues on startup for small gateways.Reduce the amount of data sampled from large files by the observer.Ensure block poa2 field is not chached to reduce memory consumption.[Release 6] - 2024-01-29 Fixed Update observer to improve reliability of contract state synchronization and evaluation.[Release 5] - 2024-01-25 Added Added transaction offset indexing to support future data retrieval capabilities.Enabled IPv6 support in Envoy config.Added ability to configure observer report generation interval via the REPORT_GENERATION_INTERVAL_MS environmental variable. (Intended primarily for development and testing) Changed Updated observer to properly handle FQDN conflicts.Renamed most created_at columns to index to indexed_at for consistency and clarity.Fixed Updated LMDB version to remove Buffer workaround and fix occasional block cache errors.[Release 4] - 2024-01-11 Added Added circuit breakers around data index access to reduce impact of DB access contention under heavy requests loads.Added support for configuring data source priority via the ON_DEMAND_RETRIEVAL_ORDER environment variable.Updated observer to a version that retrieves epoch start and duration from contract state.Changed Set the Redis max memory eviction policy to allkeys-lru.Reduced default Redis max memory from 2GB to 256MB.Improved predictability and performance of GraphQL queries.Eliminated unbundling worker threads when filters are configured to skip indexing ANS-104 bundles.Reduced the default number of ANS-104 worker threads from 2 to 1 when unbundling is enabled to conserve memory.Increased nodejs max old space size to 8GB when ANS-104 workers > 1.Fixed Adjusted paths for chunks indexed by data root to include the full data root.[Release 3] - 2023-12-05 Added Support range requests (PR 61, PR 64) Note: serving multiple ranges in a single request is not yet supported.Release number in /ar-io/info response.Redis header cache implementation (PR 62).New default header cache (replaces old FS cache).LMDB header cache implementation (PR 60).Intended for use in development only.Enable by setting CHAIN_CACHE_TYPE=lmdb.Filesystem header cache cleanup worker (PR 68).Enabled by default to cleanup old filesystem cache now that Redis is the new default.Support for parallel ANS-104 unbundling (PR 65).Changed Used pinned container images tags for releases.Default to Redis header cache when running via docker-compose.Default to LMDB header cache when running via yarn start.Fixed Correct GraphQL pagination for transactions with duplicate tags.

---

# 28. Introduction - ARIO Docs

Document Number: 28
Source: https://docs.ar.io/introduction
Words: 591
Quality Score: 0.505
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

TL;DR AR.IO seeks to create a decentralized and incentivized cloud network aimed at attracting more gateways to the Arweave network therefore making the permanent web more accessible to all.
At the core of AR.IO's incentivization mechanism is the ARIO Token, a utility token used for joining the network, payments, gateway accountability, and protocol incentives.
The network features modular and composable gateway infrastructure in addition to the Arweave Name System (ArNS) – a system for assigning friendly domain names to permanent data.What is AR.IO AR.IO is the world's first permanent cloud network, providing the infrastructure to ensure data, applications, and digital identities are timeless, tamper-proof, and universally accessible.
Built on the foundation of the Arweave storage network, AR.IO forms a global ecosystem of gateways, protocols, and services that connect users to the permaweb – a web where information is permanent and free from centralized control.The AR.IO Network is an open, distributed, and ownerless system, supported by operators, developers, and end-users from around the world.
It's decentralized nodes, known as AR.IO Gateways, act as "Permanent Cloud Service Providers" delivering the critical services needed to read, write, index and query data stored on the permaweb.
These gateways provide a unified, resilient interface between users and the permaweb, featuring a permanent domain name system and seamless, location-independent access to permanent storage and applications.Gateways operate using standardized protocols to maintain consistency across the network.
They also engage in an observation and reporting protocol to monitor performance and ensure accountability, helping to maintain a healthy and reliable ecosystem.The AR.IO Network is powered by a utility token, ARIO, which drives the network's functionality and accessibility.
ARIO serves as a currency for services such as the Arweave Name System (ArNS), staking to join the network as a gateway operator, delegated staking, and as rewards for contributing to the network's performance and reliability.Together, these elements form the backbone of a permanent cloud network designed to preserve data and expand the possibilities of the web.Why AR.IO?Arweave (a Layer 1 blockchain network) offers scalable and permanent onchain data storage in a sustainable manner.
It does this by incentivizing miner nodes through a tokenomic endowment model which ensures data is globally stored and replicated for hundreds of years without the need for continual payment or maintenance by its uploader.However, the Arweave protocol does not incorporate all the needs of modern applications like data indexing, querying, retrieval, and other vital services.
Consequently, over the past few years, infrastructure services have been independently developed and deployed to meet the demands of the permaweb at scale.
Users and apps have come to rely on these gateway utilities, but they are closed source, have complex codebases, and are expensive to operate.Arweave does not offer any tokenomic incentives to offset the expenses associated with operating a gateway, which has led to the community's reliance on a single centrally controlled gateway subsidized for the betterment of the network: arweave.net.
While arweave.net currently caches and indexes the entire weave with a high quality of service, it is a single bottleneck and point of failure for the whole ecosystem.AR.IO seeks to reduce the barriers of entry and attract more gateway operators to the permaweb with the goal of further enhancing its overall health, resiliency, and functionality through decentralized mechanisms that are as trustless as possible.The solution will be applied in two directions:By reducing gateway overhead costs with open source, efficient, modular networked architecture.By creating an economic incentive layer with the ARIO Token.The overall goal of this white paper is to present the framework for a healthy and sustainable decentralized gateway network.

---

# 29. Parquet and ClickHouse Usage Guide - ARIO Docs

Document Number: 29
Source: https://docs.ar.io/gateways/parquet
Words: 1476
Quality Score: 0.502
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Overview AR.IO gateway Release 33 introduces a new configuration option for using Parquet files and ClickHouse to improve performance and scalability of your AR.IO gateway for large datasets.This guide will walk you through the process of setting up ClickHouse with your AR.IO gateway, and importing Parquet files to bootstrap your ClickHouse database.What is Parquet?Apache Parquet is a columnar storage file format designed for efficient data storage and retrieval. Unlike row-based storage formats like SQLite, Parquet organizes data by column rather than by row, which provides several advantages for analytical workloads:Efficient compression: Similar data is stored together, leading to better compression ratios Columnar access: You can read only the columns you need, reducing I/O operations Predicate pushdown: Filter operations can be pushed down to the storage layer, improving query performance Current Integration with AR.IO Gateways In the current AR.IO gateway implementation, Parquet and ClickHouse run alongside SQLite rather than replacing it. This parallel architecture allows each database to handle what it does best:SQLite continues to handle transaction writes and updates ClickHouse with Parquet files is optimized for fast query performance, especially with large datasets The gateway continues to operate with SQLite just as it always has, maintaining all of its normal functionality. Periodically, the gateway will export batches of data from SQLite to Parquet files, which are then imported into ClickHouse. This batch-oriented approach is much more efficient than attempting to synchronize the databases in real-time, as it leverages Parquet's strength in handling large, immutable data sets.Note that despite Parquet's efficient compression, gateways may not see significant disk space reduction in all cases. While bundled transaction data is exported to Parquet, L1 data remains in SQLite. Without substantial unbundling and indexing filters, minimal data gets exported to Parquet, limiting potential storage savings.With ClickHouse integration enabled, GraphQL queries are primarily routed to ClickHouse, leveraging its superior performance for large datasets. This significantly improves response times while maintaining SQLite's reliability for transaction processing.Parquet vs. SQLite in AR.IO Gateways While SQLite is excellent for transactional workloads and small to medium datasets, it faces challenges with very large datasets:Benefits for Gateway Operators Implementing Parquet and ClickHouse alongside SQLite in your AR.IO gateway offers several key advantages:Dramatically improved query performance for GraphQL endpoints, especially for large result sets Reduced storage requirements through efficient columnar compression Better scalability for growing datasets Faster bootstrapping of new gateways through Parquet file imports Reduced load on SQLite by offloading query operations to ClickHouse The primary focus of the Parquet/ClickHouse integration is the significant speed improvement for querying large datasets. Gateway operators managing significant s of data will notice substantial performance gains when using this configuration.Storage Considerations While Parquet files offer more efficient compression for the data they contain, it's important to understand the storage impact:Bundled transaction data is exported to Parquet and removed from SQLite, potentially saving space L1 data remains in SQLite regardless of Parquet configuration Space savings are highly dependent on your unbundling filters - without substantial unbundling configurations, minimal data gets exported to Parquet The more data you unbundle and export to Parquet, the greater the potential storage efficiency For gateway operators, this means proper filter configuration is crucial to realize storage benefits. The primary advantage remains significantly improved query performance for large datasets, with potential space savings as a secondary benefit depending on your specific configuration.The following sections will guide you through setting up ClickHouse with your AR.IO gateway, exporting data from SQLite to Parquet, and importing Parquet files to bootstrap your ClickHouse database.Note The below instructions are designed to be used in a linux environment. Windows and MacOS users must modify the instructions to use the appropriate package manager/ command syntax for their platform.Unless otherwise specified, all commands should be run from the root directory of the gateway.Installing ClickHouse ClickHouse is a powerful, open-source analytical database that excels at handling large datasets and complex queries. It is the tool used by the gateway to integrate with the Parquet format. To integrate ClickHouse with your AR.IO gateway, follow these steps:It is recommended to use official pre-compiled deb packages for Debian or Ubuntu. Run these commands to install packages:This will verify the installation package from official sources and enable installation via apt-get.This will perform the actual installation of the ClickHouse server and client.During installation, you will be prompted to set a password for the default user. This is required to connect to the ClickHouse server.Advanced users may also choose to create a designated user account in clickhouse for the gateway to use, but the default gateway configuration will assume the default user.Configure Gateway to use ClickHouse Because the gateway will be accessing ClickHouse, host address andthe password for the selected user must be provided. This is done via the CLICKHOUSE_PASSWORD environment variable.Update your.env file with the following:If you set a specific user account for the gateway to use, you can set the CLICKHOUSE_USER environment variable to the username.CLICKHOUSE_USER= If omitted, the gateway will use the default user.Additionally, The Parquet file provided below contains an unbundled data set that includes all data items uploaded via an ArDrive product, including Turbo. Because of this, it is recommended to include unbundling filters that match, or expand, this configuration.ANS104_UNBUNDLE_FILTER='{ "and": [ { "not": { "or": [ { "tags": [ { "name": "Bundler-App-Name", "value": "Warp" } ] }, { "tags": [ { "name": "Bundler-App-Name", "value": "Redstone" } ] }, { "tags": [ { "name": "Bundler-App-Name", "value": "KYVE" } ] }, { "tags": [ { "name": "Bundler-App-Name", "value": "AO" } ] }, { "attributes": { "owner_address": "-OXcT1sVRSA5eGwt2k6Yuz8-3e3g9WJi5uSE99CWqsBs" } }, { "attributes": { "owner_address": "ZE0N-8P9gXkhtK-07PQu9d8me5tGDxa_i4Mee5RzVYg" } }, { "attributes": { "owner_address": "6DTqSgzXVErOuLhaP0fmAjqF4yzXkvth58asTxP3pNw" } } ] } }, { "tags": [ { "name": "App-Name", "valueStartsWith": "ArDrive" } ] } ] }'
ANS104_INDEX_FILTER='{ "tags": [ { "name": "App-Name", "value": "ArDrive-App" } ] }' Lastly, you must have a gateway admin password set. This is used for the periodic export of data from SQLite to Parquet.ADMIN_API_KEY= Once the.env file is updated, restart the gateway to apply the changes.A Parquet archive file is available for download from ar://JVmsuD2EmFkhitzWN71oi9woADE4WUfvrbBYgremCBM. This file contains an unbundled data set that includes all data items uploaded via an ArDrive product, current to April 23, 2025, and compressed using tar.gz.To download the file, run the following command:or visit the url https://arweave.net/JVmsuD2EmFkhitzWN71oi9woADE4WUfvrbBYgremCBM and download the file manually.Note If downloaded manually, it will download as a binary file named JVmsuD2EmFkhitzWN71oi9woADE4WUfvrbBYgremCBM. This is normal and must be converted to a tar.gz file by renaming it to 2025-04-23-ardrive-ans104-parquet.tar.gz.It should also be placed in the root directory of the gateway.The downloaded file will be approximately 3.5GB in size.Extracting and Importing the Parquet File With the parquet file downloaded and placed in the root directory of the gateway, you can extract the file and import it into ClickHouse.This will extract the file into a directory named 2025-04-23-ardrive-ans104-parquet, and take a while to complete.Next, if you do not already have a data/parquet directory, you must create it. Release 33 does not have this directory by default, but future Releases will. You can create the directory by using the following command:or by starting the gateway ClickHouse container with the following command:Note Depending on your system configurations, allowing the gateway to create the directory may result in the directory being created with incorrect permissions. If this is the case, you can remove the restrictions by running the following command:With the directory created, you can now move the extracted parquet files into it.When this is complete, you can run the import script to import the parquet files into ClickHouse.If you haven't done so already, start the ClickHouse container with the following command:Then run the import script with the following command:./scripts/clickhouse-import This process will take several minutes, and will output the progress of the import.Verifying Successful Import To verify that the import was successful, run the following commands:Being sure to replace with the password you set for the selected ClickHouse user.This should return a count of the number of unique transactions in the parquet file, which is 32712311.You can also verify that the data is being served by the gateway's GraphQL endpoint by ensuring the gateway is not proxying its GraphQL queries (Make sure GRAPHQL_HOST is not set) and running the following command:Starting and ping the Gateway with ClickHouse The gateway ClickHouse container is run as a "profile" in the main docker compose file. That means you must specify the profile when starting or ping the gateway if you want to include the ClickHouse container in the commands.To start the gateway with the ClickHouse profile, run the following command:This will start all of the containers normally covered by the docker compose up command, but will also start the ClickHouse container.To the gateway with the ClickHouse profile, run the following command:This will all of the containers normally covered by the docker compose down command, but will also the ClickHouse container.To start or only the ClickHouse container, you can use the following commands:and

---

# 30. Observation and Incentives - ARIO Docs

Document Number: 30
Source: https://docs.ar.io/gateways/observer
Words: 1721
Quality Score: 0.501
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Observation and Incentives (OIP) Overview The Observation and Incentive Protocol is designed to maintain and enhance the operational integrity of gateways on the AR.IO Network.
It achieves this through a combination of incentivizing gateways for good performance and tasking those gateways to fulfill the role of "observers".
The protocol is intentionally simple and adaptable, employing a smart contract-based method for onchain “voting” to assess peer performance while being flexible on how that performance is measured.
This setup permits gateway and observer nodes to experiment and evolve best practices for performance evaluation, all while operating within the bounds of the network's immutable smart contract, thus eliminating the need for frequent contract updates (forks).In this protocol, observers evaluate their gateway peers' performance to resolve ArNS names.
Their aim is to ensure each gateway in the network accurately resolves a subset of names and assigning a pass / fail score based on their findings.A key component of the protocol is its reward mechanism.
This system is predicated on gateway performance and compliance with observation duties.
Gateways that excel are tagged as "Functional Gateways" and earn rewards, while those that do not meet the criteria, “Deficient Gateways” risk facing penalties – namely, the lack of rewards.Funds for incentive rewards are derived from the protocol balance, which consists of ARIO tokens initially allocated at network genesis as well as those collected from ArNS asset purchases.
Every epoch, this balance is utilized to distribute rewards to qualifying gateways and observers based on certain performance metrics.Observation Protocol The Observation protocol is organized around daily epochs, periods of time that are broken into an observation reporting and tallying phase.
The protocol is followed across each epoch, promoting consistent healthy network activity that can form pro-social behaviors and react to malicious circumstances.Onchain Reports The to-be-evaluated ArNS names include a set of two (2) names randomly determined by the protocol, known as “prescribed names”, which are common across all observers within the epoch, as well as a set of eight (8) “chosen names” picked at the discretion of each individual observer.
“Prescribed names” are assigned to act as a common denominator / baseline while “chosen names” allow each observer to evaluate names that may be important to their operation.Observers shall upload their completed reports (in JSON format) to the Arweave network as an onchain audit trail.
In addition, observers shall submit an interaction to the AR.IO smart contract detailing each gateway that they observed to have “failed” their assessments.
These “votes” are tallied and used to determine the reward distribution.Selection of Observers The observer selection process commences at the beginning of each epoch and employs a random-weighted selection method.
By combining random selection with weighted criteria like stake, tenure, and past rewards, the process aims to ensure both fairness and acknowledgment of consistent performance.
This method allows for a systematic yet randomized approach to selecting gateways for observation tasks.Criteria for Selection Up to fifty (50) gateways can be chosen as observers per epoch.
If the GAR is below that amount, then every gateway is designated as an observer for that epoch.
If there are greater than 50, then randomized selection shall be utilized.The weighted selection criteria will consider the following for each gateway:Stake Weight (SW): This factor considers how financially committed a gateway is to the network. It is the ratio of the total amount of ARIO tokens staked by the gateway (plus any delegated stake) relative to the network minimum and is expressed as:SW = (Gateway Stake + Delegated Stake) / (Minimum Network Join Stake) Tenure Weight (TW): This factor considers how long a gateway has been part of the network, with a maximum value capped at four (4). This means that the maximum value is achieved after 2-years of participation in the network. It is calculated as:TW = (Gateway Network Tenure) / (6-months) Gateway Performance Ratio Weight (GPRW): This factor is a proxy for a gateway’s performance at resolving ArNS names. The weight represents the ratio of epochs in which a gateway received rewards for correctly resolving names relative to their total time on the network. To prevent division by zero conditions, it is calculated as:GPRW = (1 + Passed Epochs) / (1 + Participated Epochs) Observer Performance Ratio Weight (OPRW): This factor is a proxy for a gateway’s performance at fulfilling observation duties. The weight reflects the ratio of epochs in which a gateway, as an observer, successfully submitted observation reports relative to their total periods of service as an observer. To prevent division by zero conditions thus unfairly harming a newly joined gateway, it is calculated as:OPRW = (1 + Submitted Epochs) / (1 + Selected Epochs) Weight Calculation and Normalization For each gateway, a composite weight (CW) is computed, combining the Stake Weight, Tenure Weight, Gateway Performance Ratio Weight, and Observer Performance Ratio Weight.The formula used is:CW = SW x TW x GPRW x OPRW These weights are then normalized across the network to create a continuous range, allowing for proportional random selection based on the weighted scores.
The normalized composite weight (N_CW) for each gateway indicates its likelihood of being chosen as an observer and is calculated by dividing the gateway's CW by the sum of all CWs.
Any gateway with a composite weight equal to zero shall be ineligible for selection as an observer during the associated epoch.Random Selection Process The selection of observers is randomized within the framework of these weights.
A set of unique random numbers is generated with entropy within the total range of normalized weights.
For each random number, the gateway whose normalized weight range encompasses this number is selected.
This system ensures that while gateways with higher weights are more likely to be chosen, all gateways maintain a non-zero chance of selection, preserving both fairness and meritocracy in the observer assignment process.
The current epoch’s selected / prescribed observers as well as prescribed ArNS names to be evaluated shall be saved in the contract state at the beginning of the epoch to ensure that any activities during that epoch do not affect the selection of observers or awards distribution.Performance Evaluation Consider the following classifications:Functional or Passed Gateways: are gateways that meet or surpass the network’s performance and quality standards.Deficient or Failed Gateways: are gateways that fall short of the network's performance expectations.Functional or Submitted Observers: are selected observers who diligently perform their duties and submit observation reports and contract interactions.Deficient or Failed Observers: are selected observers who do not fulfill their duty of submitting observation reports and contract interactions.At the end of an epoch, the smart contract will assess the results from the observers and determine a pass / fail score for each gateway:If greater than or equal to 50% of submitted observer contract interactions indicate a PASS score, then that gateway is considered Functional and eligible for gateway rewards.Else, if greater than 50% of submitted observer contract interactions indicate a FAIL score, then that gateway is considered Deficient and ineligible for gateway rewards.These results will determine how reward distributions are made for that epoch.
Rewards shall be distributed after forty (40) minutes (approx. twenty (20) Arweave blocks) in the following epoch have elapsed.
This delay ensures that all observation contract interactions are safely confirmed by the Arweave network without risk of “forking out” prior to the evaluation and reward distribution process.Reward Distribution Each epoch, a portion of the protocol balance is earmarked for distribution as rewards.
This value shall begin at 0.1% per epoch for the first year of operation, then linearly decline down to and stabilize at 0.05% over the following 6 months.
From this allocation, two distinct reward categories are derived:Base Gateway Reward (BGR): This is the portion of the reward allocated to each Functional Gateway within the network and is calculated as:BGR = [Epoch Reward Allocation x 90% / Total Gateways in the Network] Base Observer Reward (BOR): Observers, due to their additional responsibilities, have a separate reward calculated as:BOR = [Epoch Reward Allocation x 10% / Total Selected Observers for the Epoch] Distribution Based on Performance The reward distribution is contingent on the performance classifications derived from the Performance Evaluation:Functional Gateways: Gateways that meet the performance criteria receive the Base Gateway Reward.Deficient Gateways: Gateways falling short in performance do not receive any gateway rewards.Functional Observers: Observers that fulfilled their duty receive the Base Observer Reward.Deficient Observers: Observers failing to meet their responsibilities do not receive observer rewards. Furthermore, if they are also Functional Gateways, their gateway reward is reduced by 25% for that epoch as a consequence for not performing their observation duty.Gateways shall be given the option to have their reward tokens “auto-staked” to their existing stake or sent to their wallet as unlocked tokens. The default setting shall be “auto-staked”.Distribution to Delegates The protocol will automatically distribute a Functional Gateway’s shared rewards with its delegates.
The distribution will consider the gateway’s total reward for the period (including observation rewards), the gateway’s “Delegate Reward Share Ratio”, and each delegate’s stake proportional to the total delegation.
Each individual delegate reward is calculated as:Unlike gateways, token reward distributions to delegated stakers will only be “auto-staked” in that they will be automatically added to the delegate’s existing stake associated with the rewarded gateway.
The delegated staker is then free to withdraw their staked rewards at any time (subject to withdrawal delays).Undistributed Rewards In cases where rewards are not distributed, either due to the inactivity or deficiency of gateways or observers, the allocated tokens shall remain in the protocol balance and carry forward to the next epoch.
This mechanism is in place to discourage observers from frivolously marking their peers as offline in hopes of attaining a higher portion of the reward pool.
Note that if a gateway (and its delegates) leaves the network or a delegate fully withdraws stake from a gateway, they become ineligible to receive rewards within the corresponding epoch and the earmarked rewards will not be distributed.Handling Deficient Gateways To maintain network efficiency and reduce contract state bloat, gateways that are marked as deficient, and thus fail to receive rewards,
for thirty (30) consecutive epochs will automatically trigger a “Network Leave” action and be subjesct to the associated stake withdrawal durations for both gateway stake and any delegated stake.
In addition, the gateway shall have its minimum network-join stake slashed by 100%. The slashed stake shall be immediately sent to the protocol balance.

---

# 31. ARIO Docs

Document Number: 31
Source: https://docs.ar.io/wayfinder/core/gateway-providers/local-storage
Words: 142
Quality Score: 0.500
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

LocalStorageGatewaysProvider The LocalStorageGatewaysProvider is a gateway provider that caches gateway lists in the browser's localStorage. This allows gateway data to persist across page reloads and browser sessions, making it ideal for web applications that require fast access to gateway information without repeated network requests. The provider automatically manages cache expiration based on a configurable TTL (time-to-live), ensuring that gateway data remains fresh while minimizing network usage. Use this provider when you want persistent, client-side caching of gateway lists in browser environments.Note: If you are building a React-based application, consider using @ar.io/wayfinder-react for seamless integration with React components, hooks, and context providers. This package is designed to work hand-in-hand with gateway providers like LocalStorageGatewaysProvider for optimal developer experience.Basic Usage Configuration Options Related Documentation Gateway Providers Overview: Compare all gateway providers NetworkGatewaysProvider: Dynamic network discovery StaticGatewaysProvider: Static gateway configuration Wayfinder Configuration: Main wayfinder setup

---

# 32. ARIO Docs

Document Number: 32
Source: https://docs.ar.io/gateways/bundler
Words: 808
Quality Score: 0.499
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Bundler Overview A Turbo ANS-104 data item bundler can be run alongside an AR.IO gateway. This allows gateways the ability to accept data items to be submit to the Arweave blockweave.The bundler service can be easily run inside Docker in the same way that the gateway is. It utilizes a separate docker compose file for configuration and deployment, which also allows for the use of a separate file for environmental variables specific to the bundler service. Additionally, the separation allows operators to spin their bundler service up or down at any time without affecting their core gateway service. Despite the use of separate docker compose files, the bundler service shares a docker network with the AR.IO gateway, and so is able to directly interact with the gateway service and data.Getting Started NOTE: The bundler service relies on GraphQL indexing of recently bundled and uploaded data to manage its pipeline operations. The AR.IO gateway should have its indexes synced up to Arweave's current block height before starting the bundler's service stack.Environmental Variables Environmental variables must be provided for the bundler to function and integrate properly with an existing AR.IO gateway. The gateway repository provides a .env.bundler.example file that can be renamed to .env.bundler and used as a starting point. It contains the following:BUNDLER_ARWEAVE_WALLET must be the entire jwk of an Arweave wallet's keyfile, stringified. All uploads of bundled data items to Arweave will be signed and paid for by this wallet, so it must maintain a balance of AR tokens sufficient to handle the uploads.BUNDLER_ARWEAVE_ADDRESS must be the normalized public address for the provided Arweave wallet.APP_NAME is a GraphQL tag that will be added to uploaded bundles.The remaining lines in the .env.bundler.example file control settings that allow the bundler service to share data with the AR.IO gateway. Data sharing of contiguous data between a bundler and a gateway allows the gateway to serve optimistically cached data without waiting for it to fully settle on chain.Managing Bundler Access By default, the bundler will only accept data items uploaded by data item signers whose normalized wallet addresses are in the ALLOW_LISTED_ADDRESSES list. This is an additional environmental variable that can be added to your .env.bundler file, and must be a comma separated list of normalized public wallet addresses for wallets that should be allowed to bundle and upload data through your gateway.ALLOW_LISTED_ADDRESSES=, The following permissioning configurations schemes are also possible:Indexing Bundlers submit data to the Arweave network as an ANS-104 data item bundle. This means it is several transactions wrapped into one. A gateway will need to unbundle these transactions in order to index them. A gateway should include the following ANS-104 filters in order to unbundle and index transactions from a particular bundler:$BUNDLER_ARWEAVE_ADDRESS should be replaced with the normalized public wallet address associated with the bundler.NOTE: The above filters must be placed in the .env file for the core gateway service, not the bundler.Gateways handle data item indexing asynchronously. This means they establish a queue of items to index, and work on processing the queue in the background while the gateway continues with its normal operations. If a gateway has broad indexing filters, there can be some latency in indexing data items from the bundler while the gateway works through its queue.Optimistic Indexing Gateway operators control access to their optimistic data item indexing API via an admin key that must be supplied by all bundling clients in order for their requests to be accepted. This key should be made available in the environment configuration files for BOTH the core gateway, and the bundler, and should be provided as AR_IO_ADMIN_KEY:NOTE: If a gateway is started without providing the admin key, a random string will be generated to protect the gateway's admin endpoints. This can be reset by restarting the gateway with the admin key provided in the .env file.Starting and ping the Bundler Starting The bundler service is designed to run in conjunction with an AR.IO gateway, and so relies on the ar-io-network network created in Docker when the core gateway services are spun up. It is possible to spin up the bundler while the core services are down, but the network must exist in Docker.To start the bundler, specify the env and docker-compose files being used in a docker compose up command:The -d flag runs the command in "detached" mode, so it will run in the background without requiring the terminal to remain active.ping To spin the bundler service down, specify the docker-compose file in a docker compose down command:logs While the bundler service is running in detached mode, logs can be checked by specifying the docker-compose file in a docker compose logs command:-f runs the command in "follow" mode, so the terminal will continue to watch and dis new logs.--tail= defines the number of logs to dis that existed prior to running the command. 0 diss only new logs.

---

# 33. Importing SQLite Database Snapshots - ARIO Docs

Document Number: 33
Source: https://docs.ar.io/gateways/snapshots
Words: 483
Quality Score: 0.498
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Overview One of the challenges of running an AR.IO Gateway is the initial synchronization time as your gateway builds its local index of the Arweave network. This process can take days or even weeks, depending on your hardware and the amount of data you want to index. To accelerate this process, you can import a pre-synchronized SQLite database snapshot that contains transaction and data item records already indexed.This guide will walk you through the process of importing a database snapshot into your AR.IO Gateway.Note The below instructions are designed to be used in a linux environment. Windows and MacOS users must modify the instructions to use the appropriate package manager/ command syntax for their platform.Unless otherwise specified, all commands should be run from the root directory of the gateway.Obtaining a Database Snapshot SQLite database snapshots are very large and not easy to incrementally update. For these reasons, AR.IO is distributing them using BitTorrent. These snapshots can be downloaded using any preferred torrenting client, and below is instructions on doing so using transmission-cli from a terminal.This will download a snapshot, current to April 23, 2025, of an unbundled data set that includes all data items uploaded via an ArDrive product, including Turbo. The file will be named 2025-04-23-sqlite.tar.gz and be approximately 42.8Gb in size.Note While continuing to seed the torrent after download is not required, it is highly recommended to help ensure the continued availability of the snapshot for others, as well as the integrity of the data. Seeding this file should not cause any issues with your internet service provider.This is a compressed tarball, so it will need to be extracted before it can be used.Extracting the Database Snapshot Once the file has downloaded, you can extract it using the following command, be sure to replace the filename with the actual filename of the snapshot you are using, if not using the example above.This will extract the file into a directory matching the filename, minus the .tar.gz extension.Importing the Database Snapshot Once you have an extracted database snapshot, you can import it into your AR.IO gateway by replacing the existing SQLite database files. Follow the instructions below to do so.IMPORTANT Importing a database snapshot will delete your existing database and replace it with the snapshot you are importing. your AR.IO gateway.(Optional) Backup your existing SQLite database files.Delete the existing SQLite database files.Move the snapshot files into the data/sqlite directory.Be sure to replace 2025-04-23-sqlite with the actual directory name of the extracted snapshot you are using.Start your AR.IO gateway.Verifying the Import The simplest way to verify the import is to check the gateway logs to see what block number is being imported. The 2025-04-23 snapshot was taken at block 1645229, so the gateway will start importing blocks after this height if the snapshot was imported successfully.You can also use the Grafana Sidecar to view the last block imported in a more human readable format.

---

# 34. Arlink Deploy - ARIO Docs

Document Number: 34
Source: https://docs.ar.io/build/guides/arlink
Words: 462
Quality Score: 0.496
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Overview Arlink is a third party tool that allows you to permanently deploy and manage web apps on the permaweb with ease.How it works Users can link their Github or Protocol.land repositories to their Arlink account through the Arlink dashboard. When a new project or build is deployed,
Arlink will take the repository, build it, and upload the build folder to Arweave.Arlink also allows users to connect their project to an ArNS name they own, or an undername of the ArNS name ar://arlink.Dashboard After connecting your wallet to the Arlink web app using the button at the top right, you will be taken to your dashboard. This page will dis any deployments associated with your wallet, and includes a "+ New Deployment" button
in order to start the process of deploying a new project. New Deployment After clicking on the new deployment button, you will be prompted to import a repository from either Github or Protocol.land. Authorize Github If this is your first time importing from Github, you will be prompted to authorize Arlink to access your Github repositories. You can authorize all repositories, or limit authorization to any number of specific ones. Select Repository Once authorization is approved, select which repository and branch you want to deploy. Define Build and Output Steps Once you select what you want to deploy, you need to specify how the project needs to be built to get it ready. Arlink prompts for five inputs:Project Name: This is the name of your project.Install Command: The command for installing dependencies for your project. Usually npm install or yarn install Build Command: This is the command to run your build script. Usually npm run build or yarn build Sub Directory: If the front end for your project lives in a sub directory of your selected repository, you can specify that here.Output Directory: This is the path to the build folder being deployed. This will be different depending on the framework your project uses. Select ArNS The last thing to do is select an ArNS name to deploy your project to. If you own your own name, you can connect to it here with the "Use existing ArNS" toggle. Otherwise, you can select an undername of the ArNS name arlink to deploy to.
Duplicate undernames cannot exist, so you can only select an undername that is not already being used. Logs Once you select your ArNS name and click "Deploy", your project will be deployed. Logs from the build and deploy process will be dised so you can monitor for errors. Updates To deploy a new build of your project, select it from the dashboard. The project page gives you the option to update any settings or configurations, and has a "Deploy Latest" button which will redeploy your project.

---

# 35. Arlink Deploy - ARIO Docs

Document Number: 35
Source: https://docs.ar.io/guides/arlink
Words: 462
Quality Score: 0.496
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Overview Arlink is a third party tool that allows you to permanently deploy and manage web apps on the permaweb with ease.How it works Users can link their Github or Protocol.land repositories to their Arlink account through the Arlink dashboard. When a new project or build is deployed,
Arlink will take the repository, build it, and upload the build folder to Arweave.Arlink also allows users to connect their project to an ArNS name they own, or an undername of the ArNS name ar://arlink.Dashboard After connecting your wallet to the Arlink web app using the button at the top right, you will be taken to your dashboard. This page will dis any deployments associated with your wallet, and includes a "+ New Deployment" button
in order to start the process of deploying a new project. New Deployment After clicking on the new deployment button, you will be prompted to import a repository from either Github or Protocol.land. Authorize Github If this is your first time importing from Github, you will be prompted to authorize Arlink to access your Github repositories. You can authorize all repositories, or limit authorization to any number of specific ones. Select Repository Once authorization is approved, select which repository and branch you want to deploy. Define Build and Output Steps Once you select what you want to deploy, you need to specify how the project needs to be built to get it ready. Arlink prompts for five inputs:Project Name: This is the name of your project.Install Command: The command for installing dependencies for your project. Usually npm install or yarn install Build Command: This is the command to run your build script. Usually npm run build or yarn build Sub Directory: If the front end for your project lives in a sub directory of your selected repository, you can specify that here.Output Directory: This is the path to the build folder being deployed. This will be different depending on the framework your project uses. Select ArNS The last thing to do is select an ArNS name to deploy your project to. If you own your own name, you can connect to it here with the "Use existing ArNS" toggle. Otherwise, you can select an undername of the ArNS name arlink to deploy to.
Duplicate undernames cannot exist, so you can only select an undername that is not already being used. Logs Once you select your ArNS name and click "Deploy", your project will be deployed. Logs from the build and deploy process will be dised so you can monitor for errors. Updates To deploy a new build of your project, select it from the dashboard. The project page gives you the option to update any settings or configurations, and has a "Deploy Latest" button which will redeploy your project.

---

# 36. ARIO Network Testnet - ARIO Docs

Document Number: 36
Source: https://docs.ar.io/guides/testnet
Words: 885
Quality Score: 0.496
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Testnet The AR.IO Network Testnet allows developers to test their applications and workflows using ARIO Network features such as ArNS Names before deploying to the mainnet. The ARIO Network Testnet offers a faucet for requesting testnet ARIO tokens (tARIO). The initial version of testnet only supports registering and resolving temporary ArNS names; however, enhancements such as temporary data uploads will be added in the future. We welcome feedback for improvements and other feature requests.Faucet Browser UI The ARIO Network Testnet Faucet is a service that allows developers to request testnet ARIO tokens (tARIO). It can be accessed in a browser by visiting ar://faucet.This is the recommended way to use the faucet. To use it:Select Testnet from the network dropdown Enter your wallet address Enter the an amount of tARIO tokens (max 10000) Complete the captcha challenge Click the "Request Tokens" button Onece complete, tARIO tokens will automatically be sent to your wallet Using Testnet Using the testnet is similar to using the mainnet, with a few key differences:Using the ARIO SDK When using the ARIO SDK, to interact with the AR.IO testnet - you can create your ARIO instance in one of two ways;Using the ARIO.tesntet() API By default, this instance will leverage cu.ardrive.io for process evaluation and the recommended way to interact with testnet.Using process with ARIO_TESTNET_PROCESS_ID By default, this instance will leverage community CUs managed by forward.Note: ANTs are network-agnostic, so no additional configuration is needed when working with them.Once configured, all SDK methods will operate on testnet instead of mainnet. For more details on configuration, see the ARIO Configuration documentation.Accessing ArNS Names To access ArNS names on testnet in a browser, you must use a gateway that is configured to operate on testnet instead of mainnet.The gateway ar-io.dev is configured to operate on the ARIO Network Testnet.Using arns.app with Testnet arns.app is the primary graphical dApp for purchasing and managing ArNS names. To configure arns.app to operate on testnet:Click the Connect button in the top right corner to connect your wallet After connecting, click on your user profile button (which replaces the Connect button) Go to Settings Click on ArNS Registry Settings On the right side of the screen, you'll see three buttons: Devnet, Testnet, and Mainnet Click on Testnet to switch the app to operate on the testnet The app will now operate on testnet, allowing you to purchase and manage ArNS names using testnet tokens.Running your own Gateway with testnet In addition to ar-io.dev - you can also elect to run your own ARIO gateway that resolves names against testnet. To do so, you need to setup your gateway by following the steps in the Linux Setup Guide or the Windows Setup Guide.Once running, modify the .env to point ARIO testnet process id.Once set, restart your gateway and navigate to /ar-io/info - you should see agYcCFJtrMG6cqMuZfskIkFTGvUPddICmtQSBIoPdiA as the process id. Your gateway will now resolve arns names stored on the ARIO tesntet process.Restrictions Testnet has a few primary purposes: to mimic mainnet functionality as close as possible, to provide a testing bed for upcoming network upgrades, and to provide a ground for users and developers to experiment. It is NOT intended for production purposes and should not be used as such.
Test ARIO (tARIO) tokens are just that - test tokens. They have no external value, may break, and have no guarantee of continued support. tARIO tokens have no relation to mainnet $ARIO and are not a proxy for any rewards. There is no supply cap on tARIO tokens.
While advanced notice will be provided whenever possible, testnet may go offline for maintenance. Likewise, test token balances and test ArNS names may be reset/nullified at any point to clean up the contract state or prepare for an upgrade.Advanced Integrating AR.IO Testnet in your client-side applications If you'd like to incorporate the AR.IO faucet into your application, you can programmatically retrieve access tokens - which allow your application to request testnet tokens for your users.To integrate:import { ARIO, ARIOToken } from '@ar.io/sdk'
// setup testnet client;
const testnet = ARIO.testnet()
// request the captcha URL for the token, which will require a human to solve
const captchaURL = await testnet.faucet.captchaURL()
// open the captcha URL in a browser;
const captchaWindow = window.open(
captchaUrl.captchaUrl,
'_blank',
'width=600,height=600',
)
// The captcha URL includes a window.parent.postMessage event that is used to send the auth token to the parent window.
// You can store the auth token in localStorage and use it to claim tokens for the duration of the auth token's expiration (default 1 hour).
window.parent.addEventListener('message', async (event) => {
if (event.data.type === 'ario-jwt-success') {
localStorage.setItem('ario-jwt', event.data.token)
localStorage.setItem('ario-jwt-expires-at', event.data.expiresAt)
// close our captcha window
captchaWindow?.close()
// claim the tokens using the JWT token,
const res = await testnet.faucet
.claimWithAuthToken({
authToken: event.data.token,
recipient: await window.arweaveWallet.getActiveAddress(),
quantity: new ARIOToken(100).toMARIO().valueOf(), // 100 ARIO
})
.then((res) => {
alert('Successfully claimed 100 ARIO tokens! Transaction ID: ' + res.id)
})
.catch((err) => {
alert(`Failed to claim tokens: ${err}`)
})
}
})
// you can re-use the JWT for up to 1 hour, allowing you to request tokens for multiple wallets without having to satisfy the catpcha multiple times
if (
localStorage.getItem('ario-jwt-expires-at') &&
Date.now() < parseInt(localStorage.getItem('ario-jwt-expires-at') ?? '0')
) {
const res = await testnet.faucet.claimWithAuthToken({
authToken: localStorage.getItem('ario-jwt') ?? '',
recipient: await window.arweaveWallet.getActiveAddress(),
quantity: new ARIOToken(100).toMARIO().valueOf(), // 100 ARIO
})
}

---

# 37. ARIO Docs

Document Number: 37
Source: https://docs.ar.io/ar-io-sdk
Words: 422
Quality Score: 0.495
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

AR.IO SDK Overview The AR.IO SDK provides functionality for interacting with the AR.IO ecosystem of services and protocols. This includes, the AR.IO Network, gateways, the ARIO token, and ArNS domains. The AR.IO SDK is available for both NodeJS and web environments.AR.IO Network The AR.IO Network is the AO smart contract process that controls all child services and protocols.The AR.IO SDK supports read operations to access various details about the current or historical state of the network. It also provides write operations for managing features such as the Gateway Address Registry and ARIO token.Gateways AR.IO gateways are open source nodes that index and serve Arweave transaction headers and data items. Gateway operators may join their gateway to the Gateway Address Registry (GAR), which makes the gateway discoverable using the AR.IO SDK. The gateway information is stored in the AR.IO AO contract as a JSON object with the following attributes:{
"operatorStake": "number", // The amount of ARIO tokens staked by the operator, 50,000 minimum
"totalDelegatedStake": "number", // Total amount of ARIO tokens staked to the gateway by wallets other than the operator
"vaults": "object", // Details of tokens vaults (locked tokens) associated with the gateway (object)
"delegates": "object", // Details of non-operator wallets who staked ARIO tokens on the gateway (object)
"startTimestamp": "number (unix)", // Unix timestamp indicating start time
"stats": "object", // Statistical information related to gateway performance (object)
"settings": "object", // Configuration settings (object)
"status": "string (e.g., joined)", // The current status of the operator
"observerAddress": "string" // The public wallet address of the observer for the gateway
} The ar.io SDK supports write operations for gateway management, including joining, leaving, and updating settings. It also provides read operations for discovering gateways in the GAR and retrieving details about specific gateways.ARIO Token ARIO is an AO token that powers the ar.io Network and and its suite of permaweb applications. It is used to join the GAR, as payment for services like ArNS, as incentives for participation in the ar.io Network, and more.The ar.io SDK supports read and write operations for getting token information and balances, or transferring tokens.ArNS The Arweave Name System (ArNS) is a protocol which allows for assigning friendly names to Arweave transactions or data items. Powered by Arweave Name Tokens (ANTs), AO tokens that manage settings for individual ArNS domains, ArNS enables easy interaction with data stored on Arweave.The ar.io SDK supports read and write operations for managing ArNS domains, including retrieving domain information, leasing, purchasing, and extending leases. Additionally, it allows direct read and write access to ANTs.

---

# 38. joinNetwork - ARIO Docs

Document Number: 38
Source: https://docs.ar.io/ar-io-sdk/ario/gateways/join-network
Words: 200
Quality Score: 0.495
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

joinNetwork is a method on the ARIO class that joins a gateway to the ar.io network using its associated wallet.joinNetwork requires authentication.Parameters Example joinNetwork const fs = require("fs");
const { ARIO, ArweaveSigner, ARIOToken } = require("@ar.io/sdk");
async function main() {
const jwk = JSON.parse(fs.readFileSync("KeyFile.json"));
const ario = ARIO.init({
signer: new ArweaveSigner(jwk),
});
const { id: txId } = await ario.joinNetwork(
{
qty: new ARIOToken(10_000).toMARIO(), // minimum operator stake allowed
autoStake: true, // auto-stake operator rewards to the gateway
allowDelegatedStaking: true, // allows delegated staking
minDelegatedStake: new ARIOToken(100).toMARIO(), // minimum delegated stake allowed
delegateRewardShareRatio: 10, // percentage of rewards to share with delegates (e.g. 10%)
label: 'john smith', // min 1, max 64 characters
note: 'The example gateway', // max 256 characters
properties: 'FH1aVetOoulPGqgYukj0VE0wIhDy90WiQoV3U2PeY44', // Arweave transaction ID containing additional properties of the Gateway
observerWallet: '0VE0wIhDy90WiQoV3U2PeY44FH1aVetOoulPGqgYukj', // wallet address of the observer, must match OBSERVER_WALLET on the observer
fqdn: 'example.com', // fully qualified domain name - note: you must own the domain and set the OBSERVER_WALLET on your gateway to match `observerWallet`
port: 443, // port number
protocol: 'https', // only 'https' is supported
},
// optional additional tags
{ tags: [{ name: 'App-Name', value: 'My-Awesome-App' }] },
);
}
main();

---

# 39. ARIO Docs

Document Number: 39
Source: https://docs.ar.io/ar-io-sdk/ario/arns/get-arns-returned-name
Words: 34
Quality Score: 0.494
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

getArNSReturnedName getArNSReturnedName is a method on the ARIO class that retrieves information about an ArNS name that has been returned to the protocol, including its auction settings and timing details.getArNSReturnedName does not require authentication.

---

# 40. Arweave Name System (ArNS) - ARIO Docs

Document Number: 40
Source: https://docs.ar.io/arns
Words: 1711
Quality Score: 0.493
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Overview Arweave URLs and transaction IDs are long, difficult to remember, and occasionally miscategorized as spam.
The Arweave Name System (ArNS) aims to resolve these problems in a decentralized manner.
ArNS is a censorship-resistant naming system stored on Arweave, powered by ARIO tokens, enabled through AR.IO gateway domains, and used to connect friendly domain names to permaweb apps, web pages, data, and identities.It's an open, permissionless, domain name registrar that doesn’t rely on a single TLD.This system works similarly to traditional DNS services, where users can purchase a name in a registry and DNS Name servers resolve these names to IP addresses.
The system shall be flexible and allow users to purchase names permanently or lease them for a defined duration based on their use case.
With ArNS, the registry is stored permanently on Arweave via AO, making it immutable and globally resilient.
This also means that apps and infrastructure cannot just read the latest state of the registry but can also check any point in time in the past, creating a “Wayback Machine” of permanent data.Users can register a name, like ardrive, within the ArNS Registry.
Before owning a name, they must create an Arweave Name Token (ANT), an AO Computer based token and open-source protocol used by ArNS to track the ownership and control over the name.
ANTs allow the owner to set a mutable pointer to any type of permaweb data, like a page, app or file, via its Arweave transaction ID.Each AR.IO gateway acts as an ArNS Name resolver.
They will fetch the latest state of both the ArNS Registry and its associated ANTs from an AO compute unit (CU) and serve this information rapidly for apps and users.
AR.IO gateways will also resolve that name as one of their own subdomains, e.g., https://ardrive.arweave.net and proxy all requests to the associated Arweave transaction ID.
This means that ANTs work across all AR.IO gateways that support them: https://ardrive.ar-io.dev, https://ardrive.g8way.io/, etc.Users can easily reference these friendly names in their browsers, and other applications and infrastructure can build rich solutions on top of these ArNS primitives.Name Registration There are two different types of name registrations that can be utilized based upon the needs of the user:Lease: a name may be leased on a yearly basis. A leased name can have its lease extended or renewed but only up to a maximum active lease of five (5) years at any time.Permanent (permabuy): a name may be purchased for an indefinite duration.Registering a name requires spending ARIO tokens corresponding to the name’s character length and purchase type.Name Registry The ArNS Registry is a list of all registered names and their associated ANT Process IDs. Key rules embedded within the smart contract include:Genesis Prices: Set within the contract as starting conditions.Dynamic Pricing: Varies based on name length, purchase type (lease vs buy), lease duration, and current Demand Factor.Name Records: Include a pointer to the Arweave Name Token process identifier, lease end time (if applicable), and undername allocation.Reassignment: Name registrations can be reassigned from one ANT to another.Lease Extension: Anyone with available ARIO Tokens can extend any name’s active lease.Lease to Permanent Buy: Anyone with available ARIO Tokens can convert a name’s lease to a permanent buy.Undername Capacity: Additional undername capacity can be purchased for any actively registered name. There is no cap on the maximum amount of undernames that a top-level ArNS name can have associated with it.Name Removal: Name records can only be removed from the registry if a lease expires, or a permanent name is returned to the protocol.Name Validation Rules All names registered shall meet the following criteria:Valid names include only numbers 0-9, characters a-z and dashes.Dashes cannot be leading or trailing characters.Dashes cannot be used in single character domains.1 character minimum, 51 characters maximum.Shall not be an invalid name predesignated to prevent unintentional use/abuse such as www.Lease Expirations When a lease term ends, there is a grace period of two (2) weeks where the lease can be renewed before it fully expires.
If this grace period elapses, the name is considered expired and returns to the protocol for public registration. Once expired, a name’s associated undername registrations and capacity also expire.A recently expired name’s registration shall be priced subject to the “Returned Name Premium” mechanics detailed below.Lease to Permabuy Conversions An actively leased name may be converted to a permanent registration. The price for this conversion shall be treated as if it were a new permanent name purchase.This functionality allows users to transition from leasing to permanent ownership based on changing needs and available resources.
It generates additional protocol revenue through conversion fees, contributing to the ecosystem's financial health and reward system.
Additionally, by maintaining fair value for name conversions, it ensures prices reflect current market conditions, promoting a balanced and fair environment.Permanent Name Return Users have the option to “return” their permanently registered names back to the protocol.
This process allows users to relinquish their ownership, returning the name to the protocol for public re-registration. Only the Owner of a name can initiate a name return.When a permanent name is returned, the name is subject to a "Returned Name Premium”, similar to expired leases.
A key difference is that if the name is repurchased during the premium window, the proceeds are split between the returning owner and the protocol balance.Primary Names The Arweave Name System (ArNS) supports the designation of a "Primary Name" for users, simplifying how Arweave addresses are dised across applications.
A Primary Name is a user-friendly alias that replaces complex wallet addresses, making interactions and profiles easier to manage and identify.Users can set one of their owned ArNS names as their Primary Name, subject to a small fee. This allows applications to use a single, human-readable identifier for a wallet, improving user experience across the network.Arweave Name Token (ANT) To establish ownership of a record in the ArNS Registry, each record contains both a friendly name and a reference to an Arweave Name Token, ANT.
Name Tokens are unique AO Computer based tokens / processes that give their owners the ability to update the Arweave Transaction IDs that their associated friendly names point to.The ANT smart contract process is a standardized contract that implements the specific Arweave Name Process specification required by AR.IO gateways who resolve ArNS names and their Arweave Transaction IDs.
It also contains other basic functionality to establish ownership and the ability to transfer ownership and update the Arweave Transaction ID.Name Tokens have an owner, who can transfer the token and control its modifiable settings.
These settings include modifying the address resolution time to live (ttl) for each name contained in the ANT, and other settings like the ANT Name, Ticker, and an ANT Controller.
The controller can only manage the ANT and set and update records, name, and the ticker, but cannot transfer the ANT.
Note that ANTs are initially created in accordance with network standards by an end user who then has to ability to transfer its ownership or assign a controller as they see fit.Owners of names should ensure their ANT supports evolve ability if future modifications are desired. Loss of a private key for a permanently purchased name can result in the name being "bricked”.Secondary markets could be created by ecosystem partners that facilitate the trading of Name Tokens.
Additionally, tertiary markets could be created that support the leasing of these friendly names to other users.
Such markets, if any, would be created by third parties unrelated to and outside of the scope of this paper or control of the Foundation.The table below indicates some of the possible interactions with the ArNS registry, corresponding ANTs, and who can perform them:ANT Interactions Under_names ANT owners and controllers can configure multiple subdomains for their registered ArNS name known as “under_names” or more easily written “undernames”.
These undernames are assigned individually at the time of registration or can be added on to any registered name at any time.Under_names use an underscore “_” in place of a more typically used dot “.“ to separate the subdomain from the main ArNS domain.Addressing Variable Market Conditions The future market landscape is unpredictable, and the AR.IO Network smart contract is designed to be immutable, operating without governance or manual intervention.
Using a pricing oracle to fix name prices relative to a stable currency is not viable due to the infancy of available solutions and reliance on external dependencies.
To address these challenges, ArNS is self-contained and adaptive, with name prices reflecting network activity and market conditions over time.To achieve this, ArNS incorporates:A dynamic pricing model that adjusts fees using a "Demand Factor" based on ArNS purchase activity.A Returned Name Premium (RNP) system that applies a timed, descending multiplier to registration prices for names that have recently expired or been returned to the protocol.This approach ensures that name valuations adapt to market conditions within the constraints of an immutable, maintenance-free smart contract framework.Dynamic Pricing Model ArNS employs an adaptive pricing model to balance market demand with pricing fairness for name registration within the network.
This model integrates static and dynamic elements, adjusting prices based on name length and purchase options like leasing, permanent acquisition, and undername amounts.
A key element is the Demand Factor (DF), which dynamically adjusts prices according to network activity and revenue trends, ensuring prices reflect market conditions while remaining accessible and affordable.A detailed description of the variables and formulas used for dynamic pricing can be found in the Appendix.Returned Name Premiums (RNP) ArNS applies a Returned Name Premium (RNP) to names that re-enter the market after expiration or permanent return.
This premium starts at a maximum value and decreases linearly over a predefined window, ensuring fair and transparent pricing for re-registered names.The RNP multiplier is applied to the registration price of both permanently purchased and leased names.Gateway Operator ArNS Discount Gateway operators who demonstrate consistent, healthy participation in the network are eligible for a 20% discount on certain ArNS interactions.To qualify:The gateway must maintain a “Gateway Performance Ratio Weight” (GPRW) of 0.85 or higher.The gateway must have a “Tenure Weight” (TW) of 0.5 or greater, indicating at least a 3-month prior commitment to the network.A gateway marked as “Leaving” shall not be eligible for this discount.Eligible ArNS Discounted Interactions:Purchasing a name Extending a lease Upgrading a lease to permabuy Increasing undernames capacity

---

# 41. ARIO Docs

Document Number: 41
Source: https://docs.ar.io/ar-io-sdk/ario/arns/get-arns-returned-names
Words: 49
Quality Score: 0.490
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

getArNSReturnedNames getArNSReturnedNames is a method on the ARIO class that retrieves all currently active returned ArNS names, with support for pagination and custom sorting. Pagination is handled using a cursor system, where the cursor is the name from the last record of the previous request.getArNSReturnedNames does not require authentication.

---

# 42. ARIO Docs

Document Number: 42
Source: https://docs.ar.io/ar-io-sdk/ario/gateways/redelegate-stake
Words: 107
Quality Score: 0.490
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

redelegateStake redelegateStake is a method on the ARIO class that moves staked tokens from one gateway to another. A vault ID can be optionally included to redelegate from an existing withdrawal vault. The redelegation fee is calculated based on the fee rate and the stake amount. Users receive one free redelegation every seven epochs. Each additional redelegation increases the fee by 10%, up to a maximum of 60%.For example: If 1000 mARIO is redelegated with a 10% fee rate, the fee will be 100 mARIO. This results in 900 mARIO being redelegated to the new gateway and 100 mARIO being returned to the protocol balance.redelegateStake requires authentication.

---

# 43. ARIO Docs

Document Number: 43
Source: https://docs.ar.io/ar-io-sdk/ario/gateways/get-allowed-delegates
Words: 39
Quality Score: 0.488
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

getAllowedDelegates getAllowedDelegates is a method on the ARIO class that retrieves all allowed delegates for a specific gateway address. The cursor parameter is used for pagination and represents the last address from the previous request.getAllowedDelegates does not require authentication.

---

# 44. Join the Gateway Network - ARIO Docs

Document Number: 44
Source: https://docs.ar.io/gateways/join-network
Words: 468
Quality Score: 0.487
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Join the AR.IO Network Prerequisites Must have a fully functional AR.IO gateway.This includes the ability to resolve ArNS subdomains.Follow installation instructions for windows or linux and get help from the ar.io community.Gateway must be associated with an Arweave Wallet.Learn about creating Arweave wallets here Arweave wallet must be funded with enough ARIO tokens to meet the minimum stake for gateway operators.Joining Via Network Portal The simplest method for joining a new gateway to the Gateway Address Registry (GAR) is to use the Network Portal.The Network portal has a prominent "Start your own gateway" button That will open a form where configurations can be set for your gateway in the network. Start Your Gateway Start Gateway Form Start Gateway Form The form is used to set basic configurations for a gateway when joining the network. It contains the following fields:Label: This is a friendly name for a gateway. It can be a maximum of 64 characters.Address: This is the fully qualified domain name of the gateway. That is, the standard web address used to access the gateway. i.e. arweave.net. The form prefills the https:// protocol prefix, and www should not be included. Gateways DO support using subdomains as their address, so long as the gateway is properly configured.Observer Wallet: This is the public wallet address of the wallet used for the gateway's observer. By default, the primary gateway wallet address is filled in this space; however, a different wallet may be utilized if desired for operational reasons.Properties ID: This is an Arweave Transaction Id for a JSON object that contains additional details about the gateway. The gateway network has not yet incorporated these properties into standard gateway participation, and so the space may safely be left as the default value. The contents of the default properties Id can be viewed here Stake: This is the amount of ARIO tokens to be staked to the gateway. It must be at least the network minimum.Delegated Stake: This toggle enables or disables delegated staking on a gateway. This may be changed later.Minimum Delegated Stake: This is the minimum number of ARIO tokens that a delegate must stake in order to stake to a gateway. The network minimum is 10 ARIO.Reward Share Ratio: The percentage of gateway rewards that will be distributed to delegated stakers.Note: A description of the gateway. It can be a maximum of 256 characters.Once all required fields of the form are completed, the "Confirm" button will become available. Clicking this will prompt a signature from the connected Arweave wallet in order to complete the joining process.Joining Programmatically Joining the network can also be completed programmatically through the AR.IO SDK. This is done using the join-network method on the ARIO class.The method must be called after authenticating the ARIO class using the wallet to be associated with the new gateway.

---

# 45. Staking - ARIO Docs

Document Number: 45
Source: https://docs.ar.io/staking
Words: 534
Quality Score: 0.484
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Overview Staking tokens within the AR.IO Network serves a dual primary purpose: it signifies a public commitment by gateway operators and qualifies them and their delegates for reward distributions.In the AR.IO ecosystem, "staking" refers to the process of locking a specified amount of ARIO tokens into a protocol-controlled vault.
This act signifies an opportunity cost for the staker, acting both as a motivator and a public pledge to uphold the network's collective interests.
Once staked, tokens remain locked until the staker initiates an 'unstake / withdraw' action or reaches the end of the vault’s lock period.It is important to note that the ARIO Token is non-inflationary, distinguishing the AR.IO Network's staking mechanism from yield-generation tools found in other protocols.
Staking in this context is about eligibility for potential rewards rather than direct token yield.
By staking tokens, gateway operators (and their delegates) demonstrate their commitment to the network, thereby gaining eligibility for protocol-driven rewards and access to the network’s shared resources.Gateway Staking A gateway operator must stake tokens to join their gateway to the network, which not only makes them eligible for protocol rewards but also promotes network reliability.
This staking requirement reassures users and developers of the gateway's commitment to the network’s objectives, and gateways that adhere to or surpass network performance standards become eligible for these rewards.
Gateway operators may increase their stake above the minimum, known as excess stake. A gateway’s total stake is impacted the following epoch once excess stake is added or removed.To promote participation from a wider audience, the network shall allow anyone with available ARIO tokens to partake in delegated staking.
In this, users can choose to take part in the risk and rewards of gateway operations by staking their tokens with an active gateway (or multiple gateways) through an act known as delegating.
By delegating tokens to a gateway, a user increases the overall stake of that gateway.
A delegated staker proxies their stake to gateways and therefore entrusts gateway operators to utilize that stake in maintaining a quality of service befitting the permaweb.Stake Redelegation This feature enables existing stakers to reallocate their staked tokens between gateways, known as redelegation.
Both delegated stakers and gateway operators with excess stake (stake above the minimum network-join requirement) can take advantage of this feature.
Redelegation is intended to offer users flexibility and the ability to respond to changing network conditions.Staked tokens generally have restricted liquidity to maintain a healthy degree of stability in the network.
However, an exception to these restrictions allows delegated stakers to use their staked tokens for specific ArNS -related services.
By leveraging their staking rewards, delegates can further engage with ArNS, strengthening the name system’s utilization and impact across the network.Expedited Withdrawal Fees Gateway operators and delegated stakers can shorten the standard withdrawal delay period after initiating a withdrawal (or being placed into an automatic withdrawal by protocol mechanisms); this action is subject to a dynamic fee.
At any point during the delay, users can choose to expedite access to their pending withdrawal tokens by paying a fee to the protocol balance, calculated based on how much sooner they want to receive their funds.
Once triggered, the tokens are returned immediately to the user’s wallet.

---

# 46. getTokenCost - ARIO Docs

Document Number: 46
Source: https://docs.ar.io/ar-io-sdk/ario/arns/get-token-cost
Words: 71
Quality Score: 0.484
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

getTokenCost is a method on the ARIO class that calculates the cost in mARIO tokens for various ArNS operations such as buying records, extending leases, increasing undername limits, upgrading to permabuy, and requesting primary names.getTokenCost does not require authentication.Parameters The getTokenCost method accepts different parameter sets depending on the intent (the specific action you want to check the cost for). Each intent requires a different combination of parameters as outlined below:

---

# 47. ARIO Docs

Document Number: 47
Source: https://docs.ar.io/ar-io-sdk/ario/gateways/get-redelegation-fee
Words: 45
Quality Score: 0.482
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

getRedelegationFee getRedelegationFee is a method on the ARIO class that retrieves the redelegation fee rate as a percentage for a specific address. The fee rate ranges from 0% to 60% based on the number of redelegations since the last fee reset.getRedelegationFee does not require authentication.

---

# 48. Register an IP Asset on Arweave - ARIO Docs

Document Number: 48
Source: https://docs.ar.io/guides/story
Words: 1932
Quality Score: 0.481
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Registering Story Protocol IP Assets with Arweave Metadata using Turbo Utilize the speed and reliability of ArDrive Turbo to store metadata for Story Protocol IP Assets permanently on Arweave.Story Protocol enables the registration and management of intellectual property (IP) on-chain. A crucial part of this process involves linking metadata to your IP Assets. While various storage solutions exist, Arweave offers permanent, decentralized storage, making it an ideal choice for valuable IP metadata.This guide demonstrates how to use the ArDrive Turbo SDK to efficiently upload IP Asset metadata to Arweave and register it with the Story Protocol TypeScript SDK.Prerequisites Before you begin, ensure you have the following:Node.js: Version 18 or later. Download from nodejs.org.npm/pnpm/yarn: A compatible package manager.Arweave Wallet: A wallet.json file. Generate one using tools like the Wander browser extension. Keep this file secure and do not commit it to version control.Turbo Credits: Your Arweave wallet must be funded with Turbo credits to pay for uploads. Top up at https://turbo-topup.com.Story Protocol Account: An Ethereum-compatible private key (WALLET_PRIVATE_KEY) and an RPC Provider URL (RPC_PROVIDER_URL) for the desired Story Protocol network (e.g., Aeneid testnet) stored in a .env file.TypeScript Environment: You'll need to execute TypeScript code, so make sure you have ts-node installed globally (npm install -g ts-node) or as a dev dependency.Setup 1. Install Dependencies First, set up a new project directory and install the necessary SDKs:Then install the required dependencies:2. Project Setup Create the following files in your project:.env file (in the project root):Place your Arweave wallet.json file in the project root.Create a tsconfig.json file in the project root:3. Initialize SDK Clients Create a configuration file to set up and export both the Turbo and Story clients:import { TurboFactory, TurboAuthenticatedClient } from "@ardrive/turbo-sdk";
import { StoryClient, StoryConfig } from "@story-protocol/core-sdk";
import { http } from "viem";
import { Account, privateKeyToAccount, Address } from "viem/accounts";
import fs from 'fs';
import path from 'path';
import 'dotenv/config';
// --- Environment Variable Loading ---
const privateKeyEnv = process.env.WALLET_PRIVATE_KEY;
const rpcProviderUrlEnv = process.env.RPC_PROVIDER_URL;
const walletPath = path.resolve(process.cwd(), 'wallet.json'); // Assumes wallet.json is in the project root
// --- Validations ---
if (!privateKeyEnv) {
throw new Error("WALLET_PRIVATE_KEY is not set in the .env file");
}
if (!rpcProviderUrlEnv) {
throw new Error("RPC_PROVIDER_URL is not set in the .env file");
}
if (!fs.existsSync(walletPath)) {
throw new Error(`Arweave wallet file not found at ${walletPath}. Please ensure wallet.json exists in the project root.`);
}
// --- ArDrive Turbo Client Setup ---
function parseWallet(filePath: string): any {
try {
const walletData = fs.readFileSync(filePath, 'utf8');
return JSON.parse(walletData);
} catch (error) {
console.error(`Error reading or parsing wallet file at ${filePath}:`, error);
throw new Error(`Failed to load Arweave wallet. Ensure ${filePath} exists and is valid JSON.`);
}
}
const arweaveWallet = parseWallet(walletPath);
export const turboClient: TurboAuthenticatedClient = TurboFactory.authenticated({
privateKey: arweaveWallet,
});
console.log("ArDrive Turbo Client initialized.");
// --- Story Protocol Client Setup ---
const storyPrivateKey: Address = `0x${privateKeyEnv}`;
const storyAccount: Account = privateKeyToAccount(storyPrivateKey);
const storyConfig: StoryConfig = {
account: storyAccount,
transport: http(rpcProviderUrlEnv),
chainId: "aeneid", // Adjust chainId if necessary
};
export const storyClient = StoryClient.newClient(storyConfig);
console.log("Story Client initialized.");Make sure to create the utils directory first:Now, let's create a script to register an IP asset. This involves three steps:Define metadata for the IP itself and the NFT representing ownership Upload metadata to Arweave using Turbo Register the IP on Story Protocol Create the following script file:import { storyClient, turboClient } from "./utils/clients";
import { createHash } from "crypto";
import { Address } from "viem";
import type { UploadResult } from "@ardrive/turbo-sdk";
// Helper function to upload JSON to Arweave via Turbo
async function uploadJSONToArweave(jsonData: any, description: string): Promise {
const dataBuffer = Buffer.from(JSON.stringify(jsonData));
console.log(`Uploading ${description} (${dataBuffer.byteLength} bytes) to Arweave via Turbo...`);
const tags = [
{ name: "Content-Type", value: "application/json" },
{ name: "App-Name", value: "ArDrive-Story-Tutorial" } // Example tag
];
try {
// Use Turbo to upload the file buffer
const result = await turboClient.uploadFile(dataBuffer, { tags });
console.log(`${description} uploaded successfully: Transaction ID ${result.id}`);
return result;
} catch (error) {
console.error(`Error uploading ${description} to Arweave:`, error);
throw new Error(`Arweave upload failed for ${description}.`);
}
}
async function register() {
// --- Step 1: Define IP Metadata ---
const ipMetadata = {
title: "My Arweave-Powered IP",
description: "An example IP asset with metadata stored permanently on Arweave via Turbo.",
// Add other required fields like image, creators, etc.
// Example creator:
creators: [
{ name: "Your Name/Org", address: storyClient.account.address, contributionPercent: 100 },
],
};
console.log("IP Metadata defined.");
const nftMetadata = {
name: "Ownership NFT for My Arweave IP",
description: "This NFT represents ownership of the IP Asset whose metadata is on Arweave.",
// Add other fields like image
};
console.log("NFT Metadata defined.");
// --- Step 2: Upload Metadata to Arweave ---
const ipUploadResult = await uploadJSONToArweave(ipMetadata, "IP Metadata");
const nftUploadResult = await uploadJSONToArweave(nftMetadata, "NFT Metadata");
// Use arweave.net URLs instead of ar:// protocol
const ipMetadataArweaveURI = `https://arweave.net/${ipUploadResult.id}`;
const nftMetadataArweaveURI = `https://arweave.net/${nftUploadResult.id}`;
console.log(`IP Metadata Arweave URI: ${ipMetadataArweaveURI}`);
console.log(`NFT Metadata Arweave URI: ${nftMetadataArweaveURI}`);
// Calculate metadata hashes (required by Story Protocol)
const ipMetadataHash = `0x${createHash("sha256")
.update(JSON.stringify(ipMetadata))
.digest("hex")}`;
const nftMetadataHash = `0x${createHash("sha256")
.update(JSON.stringify(nftMetadata))
.digest("hex")}`;
console.log(`IP Metadata Hash: ${ipMetadataHash}`);
console.log(`NFT Metadata Hash: ${nftMetadataHash}`);
// --- Step 3: Register IP on Story Protocol ---
console.log("Registering IP Asset on Story Protocol...");
// Choose an SPG NFT contract (Story Protocol Governed NFT)
// Use a public testnet one or create your own (see Story docs)
const spgNftContract: Address = "0xc32A8a0FF3beDDDa58393d022aF433e78739FAbc"; // Aeneid testnet example
try {
const response = await storyClient.ipAsset.mintAndRegisterIp({
spgNftContract: spgNftContract,
ipMetadata: {
ipMetadataURI: ipMetadataArweaveURI, // URI pointing to Arweave
ipMetadataHash: ipMetadataHash as Address, // Content hash
nftMetadataURI: nftMetadataArweaveURI, // URI pointing to Arweave
nftMetadataHash: nftMetadataHash as Address // Content hash
},
txOptions: { waitForTransaction: true }, // Wait for confirmation
});
console.log(
`Successfully registered IP Asset!`
);
console.log(` Transaction Hash: ${response.txHash}`);
console.log(` IP ID: ${response.ipId}`);
console.log(` Story Explorer Link: https://aeneid.explorer.story.foundation/ipa/${response.ipId}`); // Adjust explorer link for different networks
console.log(` IP Metadata (Arweave): ${ipMetadataArweaveURI}`);
console.log(` NFT Metadata (Arweave): ${nftMetadataArweaveURI}`);
} catch (error) {
console.error("Error registering IP Asset on Story Protocol:", error);
}
}
// Execute the register function
register().catch(console.error);Run the Registration Script To execute the script and register your IP Asset:This will:Upload your IP metadata to Arweave permanently Upload your NFT metadata to Arweave permanently Register an IP Asset on Story Protocol pointing to these Arweave URLs Once an IP Asset is registered, you can attach license terms and allow others to mint license tokens. Create a new script for this:import { storyClient } from "./utils/clients";
import { Address } from "viem";
// Assume these values are known for the IP Asset you want to license
const LICENSOR_IP_ID: Address = "0x..."; // Replace with the actual IP ID of the asset
const LICENSE_TERMS_ID: string = "..."; // Replace with the specific terms ID attached to the IP Asset
const RECEIVER_ADDRESS: Address = "0x..."; // Address to receive the license token(s)
async function mintLicense() {
console.log(`Minting license token(s) for IP ID ${LICENSOR_IP_ID} under terms ${LICENSE_TERMS_ID}...`);
try {
const response = await storyClient.license.mintLicenseTokens({
licenseTermsId: LICENSE_TERMS_ID,
licensorIpId: LICENSOR_IP_ID,
receiver: RECEIVER_ADDRESS,
amount: 1, // Number of license tokens to mint
// Optional parameters:
// maxMintingFee: BigInt(0), // Set if the terms have a fee; 0 disables check if no fee expected
// maxRevenueShare: 100, // Default check for revenue share percentage
txOptions: { waitForTransaction: true },
});
console.log(
`Successfully minted license token(s)!`
);
console.log(` Transaction Hash: ${response.txHash}`);
console.log(` License Token ID(s): ${response.licenseTokenIds}`);
} catch (error) {
console.error("Error minting license token(s):", error);
}
}
// Execute the function (after updating the constants above)
// mintLicense().catch(console.error);Before running this script:Replace LICENSOR_IP_ID with the actual IP ID obtained from your registration Replace LICENSE_TERMS_ID with the ID of license terms attached to that IP Replace RECEIVER_ADDRESS with the address to receive the license token Uncomment the function call at the bottom Then run:Finally, let's create a script to register a derivative work based on an existing IP, also using Arweave for metadata storage:import { storyClient, turboClient } from "./utils/clients";
import { createHash } from "crypto";
import { Address } from "viem";
import type { UploadResult } from "@ardrive/turbo-sdk";
import { DerivativeData } from "@story-protocol/core-sdk";
// Helper function to upload JSON to Arweave via Turbo (same as in registerIpWithArweave.ts)
async function uploadJSONToArweave(jsonData: any, description: string): Promise {
const dataBuffer = Buffer.from(JSON.stringify(jsonData));
console.log(`Uploading ${description} (${dataBuffer.byteLength} bytes) to Arweave via Turbo...`);
const tags = [
{ name: "Content-Type", value: "application/json" },
{ name: "App-Name", value: "ArDrive-Story-Tutorial" }
];
try {
const result = await turboClient.uploadFile(dataBuffer, { tags });
console.log(`${description} uploaded successfully: Transaction ID ${result.id}`);
return result;
} catch (error) {
console.error(`Error uploading ${description} to Arweave:`, error);
throw new Error(`Arweave upload failed for ${description}.`);
}
}
// --- Information about the Parent IP and License ---
const PARENT_IP_ID: Address = "0x..."; // Replace with the actual Parent IP ID
const LICENSE_TERMS_ID: string = "..."; // Replace with the License Terms ID to derive under
async function registerDerivative() {
// --- Step 1: Define Derivative Metadata ---
const derivativeIpMetadata = {
title: "My Derivative Work (Arweave Metadata)",
description: "A remix/adaptation based on a parent IP, metadata on Arweave.",
// Add other required fields (image, creators matching the derivative creator, etc.)
};
const derivativeNftMetadata = {
name: "Ownership NFT for My Derivative Work",
description: "NFT for the derivative IP, metadata on Arweave.",
// Add other fields
};
// --- Step 2: Upload Derivative Metadata to Arweave ---
console.log("Uploading derivative metadata to Arweave via Turbo...");
const derivIpUploadResult = await uploadJSONToArweave(derivativeIpMetadata, "Derivative IP Metadata");
const derivNftUploadResult = await uploadJSONToArweave(derivativeNftMetadata, "Derivative NFT Metadata");
// Use arweave.net URLs instead of ar:// protocol
const derivIpMetadataArweaveURI = `https://arweave.net/${derivIpUploadResult.id}`;
const derivNftMetadataArweaveURI = `https://arweave.net/${derivNftUploadResult.id}`;
const derivIpMetadataHash = `0x${createHash("sha256")
.update(JSON.stringify(derivativeIpMetadata))
.digest("hex")}`;
const derivNftMetadataHash = `0x${createHash("sha256")
.update(JSON.stringify(derivativeNftMetadata))
.digest("hex")}`;
console.log(`Derivative IP Metadata Arweave URI: ${derivIpMetadataArweaveURI}`);
console.log(`Derivative NFT Metadata Arweave URI: ${derivNftMetadataArweaveURI}`);
// --- Step 3: Register Derivative on Story Protocol ---
// Prepare Derivative Data for Story Protocol
const derivData: DerivativeData = {
parentIpIds: [PARENT_IP_ID],
licenseTermsIds: [LICENSE_TERMS_ID],
};
console.log("Registering Derivative IP Asset on Story Protocol...");
// Use the same SPG NFT contract or your own
const spgNftContract: Address = "0xc32A8a0FF3beDDDa58393d022aF433e78739FAbc"; // Aeneid testnet example
try {
const response = await storyClient.ipAsset.mintAndRegisterIpAndMakeDerivative({
spgNftContract: spgNftContract,
derivData: derivData, // Link to parent IP and license terms
ipMetadata: { // Metadata for the *new* derivative IP
ipMetadataURI: derivIpMetadataArweaveURI, // Arweave URI
ipMetadataHash: derivIpMetadataHash as Address, // Content hash
nftMetadataURI: derivNftMetadataArweaveURI, // Arweave URI
nftMetadataHash: derivNftMetadataHash as Address // Content hash
},
txOptions: { waitForTransaction: true },
});
console.log(
`Successfully registered Derivative IP Asset!`
);
console.log(` Transaction Hash: ${response.txHash}`);
console.log(` Derivative IP ID: ${response.ipId}`);
console.log(` Derivative Token ID: ${response.tokenId}`);
console.log(` Story Explorer Link: https://aeneid.explorer.story.foundation/ipa/${response.ipId}`);
console.log(` Derivative Metadata (Arweave): ${derivIpMetadataArweaveURI}`);
} catch (error) {
console.error("Error registering derivative IP Asset on Story Protocol:", error);
}
}
// Before running this script:
// 1. Replace PARENT_IP_ID with a real IP ID you have access to
// 2. Replace LICENSE_TERMS_ID with the actual license terms ID
// Then uncomment the line below to execute
// registerDerivative().catch(console.error);Before running this script:Replace PARENT_IP_ID with the actual parent IP ID Replace LICENSE_TERMS_ID with the license terms ID that permits derivatives Uncomment the function execution at the bottom Run:Conclusion By leveraging the ArDrive Turbo SDK, you can seamlessly integrate permanent Arweave storage into your Story Protocol workflow. Uploading metadata with Turbo ensures fast, reliable, and cost-effective data persistence for your valuable IP Assets, whether they are root IPs or complex derivatives with licensing relationships.This tutorial demonstrated a complete workflow:Setting up a project structure with all required dependencies Creating a utility module for client initialization Registering original IP Assets with metadata stored on Arweave Minting license tokens for IP Assets Creating and registering derivative works For further details on Story Protocol concepts like licensing, derivatives, or specific SDK functions, refer to the Story Protocol Documentation.

---

# 49. ARIO Docs

Document Number: 49
Source: https://docs.ar.io/wayfinder
Words: 351
Quality Score: 0.480
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Wayfinder Wayfinder is a client-side routing and verification protocol that provides decentralized, cryptographically verified access to data stored on Arweave via the AR.IO Network. It automatically selects optimal gateways and ensures data integrity for seamless permaweb experiences.What is Wayfinder?Wayfinder solves the challenge of reliable data access on the permaweb by:Intelligent Routing: Automatically selects the best gateway for each request based on performance, availability, and user preferences Data Verification: Cryptographically verifies data integrity to ensure you're getting authentic, unmodified content Decentralized Access: Eliminates single points of failure by distributing requests across multiple AR.IO gateways Seamless Integration: Works behind the scenes to provide fast, reliable access without requiring users to understand the underlying infrastructure Who is Wayfinder For?Builders People who build dApps on the permaweb Wayfinder enables developers to build robust decentralized applications with:Reliable Data Access: Never worry about gateway downtime or slow responses Built-in Verification: Ensure data integrity without implementing complex verification logic Developer-Friendly APIs: Simple JavaScript/TypeScript libraries and React components Performance Monitoring: Built-in telemetry to track and optimize application performance Flexible Configuration: Choose routing strategies and verification methods that fit your use case Browsers People who browse the permaweb Wayfinder provides end users with:Fast Loading: Automatically routes to the fastest available gateway for optimal performance Reliable Access: Seamlessly switches between gateways if one becomes unavailable Data Integrity: Verifies that content hasn't been tampered with or corrupted Transparent Operation: Works invisibly in the background without requiring user interaction No Tokens Required: Access permaweb content without needing AR tokens or wallet connections Operators People who operate AR.IO gateways Wayfinder helps gateway operators by:Performance Insights: Provides telemetry data to help optimize gateway performance Network Participation: Enables gateways to participate in the decentralized routing ecosystem Load Distribution: Intelligently distributes traffic based on gateway capabilities and performance Quality Monitoring: Tracks gateway reliability and performance metrics Network Health: Contributes to overall AR.IO network resilience and performance Available Packages @ar.io/wayfinder-core: Core JavaScript/TypeScript library for any web application @ar.io/wayfinder-react: React components, hooks, and providers for React applications Getting Started Ready to integrate Wayfinder into your project? Check out our Getting Started Guide for installation instructions and basic configuration examples.

---

# 50. ARIO Docs

Document Number: 50
Source: https://docs.ar.io/wayfinder/core/gateway-providers/network
Words: 96
Quality Score: 0.479
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

NetworkGatewaysProvider Overview The NetworkGatewaysProvider discovers AR.IO gateways from the AR.IO Network using the AR.IO SDK. It provides dynamic access to the full network of verified gateways, making it the recommended choice for production applications.Important To avoid rate limits and improve performance, consider wrapping NetworkGatewaysProvider with SimpleCacheGatewaysProvider (for Node.js/server environments) or LocalStorageGatewaysProvider (for browser environments). This enables caching of gateway lists and reduces unnecessary network requests.Basic Usage Configuration Options NetworkGatewaysProviderOptions Related Documentation Gateway Providers Overview: Compare all gateway providers StaticGatewaysProvider: Static gateway configuration SimpleCacheGatewaysProvider: Caching wrapper Wayfinder Configuration: Main wayfinder setup Routing Strategies: How gateways are selected

---

# 51. Content Moderation - ARIO Docs

Document Number: 51
Source: https://docs.ar.io/gateways/moderation
Words: 543
Quality Score: 0.479
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Overview Arweave is a network designed for permanent storage of data. It is a practical impossibility for data to be wholly removed from the network once it has been uploaded.The AR.IO Network has adopted Arweave's voluntary content moderation model, whereby every participant of the network has the autonomy to decide which content they want to (or can legally) store, serve, and see. Each gateway operating on the network has the right and ability to blocklist any content, ArNS name, or address that is deemed in violation of its content policies or is non-compliant with local regulations.NOTE Overly restrictive content policies may impact a gateway's likelihood of
receiving protocol rewards.Gateway operators may set content to be blocked by their gateway by submitting a Put request to their gateway defining the content to be blocked. This requires that the ADMIN_API_KEY environmental variable to be set in order to authenticate the moderation request.The simplest method for submitting moderation requests to a gateway is to use curl in a terminal.Authentication Moderation requests must contain the gateway's ADMIN_API_KEY in the request Header, as Authorization: Bearer.For example, if a gateway's ADMIN_API_KEY is set to secret, any request must contain Authorization: Bearer secret in the Header.Block Data Specific data items can be blocked by a gateway operator by submitting a Put request containing a json object with three keys:id: The Arweave transaction Id of the data item to be blocked.notes: Any note the gateway operator wants to leave him/herself as to the reason the content is blocked.source: A note as to where the content was identified as requiring moderation. i.e. a public block list.Requests to block data must be submitted to the gateway's /ar-io/admin/block-data endpoint.Unblock Data At this time, blocked data items can only be unblocked by manually deleting the corresponding row from the data/sqlite/moderation.db database.
The Arweave transaction Id of the blocked data item is stored in the database as raw bytes, which sqlite3 accepts as a BLOB (Binary Large OBject), and so cannot be accessed easily using the original transaction Id, which is a base64url.
Sqlite3 is able to interact with a hexadecimal representation of the BLOB, by using a BLOB literal. To do so, wrap a hexadecimal representation of the Arweave transaction Id in single quotes, and prepend an X i.e. X'de5cb181b804bea352bc9ad35f627b09f472721503e4a0a51618552f24cf3424'.Where possible, consider using the notes or source values to identify rows for deletion rather than the id.Block ArNS Name ArNS names can be blocked so that a gateway will refuse to serve their associated content even if the name holder updates the Arweave transaction Id that the name points at.This is done via an authenticated PUT request to the endpoint /ar-io/admin/block-name containing a json object with three keys:name: The ArNS name to be blocked.notes: Any note the gateway operator wants to leave him/herself as to the reason the content is blocked.source: A note as to where the content was identified as requiring moderation. i.e. a public block list.Undernames For moderation purposes, each undername of an ArNS name is treated as a separate name and must be moderated separately.Unblock ArNS Name Gateway operators can unblock ArNS names that were previously blocked.This is done via an authenticated PUT request to the endpoint /ar-io/admin/unblock-name containing a json object with a single key:name: The ArNS name to be unblocked

---

# 52. ARIO Docs

Document Number: 52
Source: https://docs.ar.io/wayfinder/core
Words: 298
Quality Score: 0.478
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Wayfinder The @ar.io/wayfinder-core library provides intelligent gateway routing and data verification for accessing Arweave data through the AR.IO network. It's the foundational package that powers all other Wayfinder tools.What is Wayfinder?Wayfinder Core is a JavaScript/TypeScript library that:Intelligently Routes Requests: Automatically selects the best AR.IO gateway for each request Verifies Data Integrity: Cryptographically verifies that data hasn't been tampered with Handles Failures Gracefully: Automatically retries with different gateways when requests fail Provides Observability: Emits events and telemetry for monitoring and debugging Works Everywhere: Compatible with browsers, Node.js, and edge environments Installation Basic Configuration Advanced Configuration With Routing Strategy With Data Verification Full Configuration Example import {
Wayfinder,
NetworkGatewaysProvider,
FastestPingRoutingStrategy,
HashVerificationStrategy,
} from '@ar.io/wayfinder-core'
import { ARIO } from '@ar.io/sdk'
const wayfinder = new Wayfinder({
// Gateway discovery
gatewaysProvider: new NetworkGatewaysProvider({
ario: ARIO.mainnet(),
limit: 10,
sortBy: 'operatorStake',
}),
// Routing configuration
routingSettings: {
strategy: new FastestPingRoutingStrategy({
timeoutMs: 500,
cacheResultsMs: 30000,
}),
events: {
onRoutingSucceeded: (event) => {
console.log('Selected gateway:', event.selectedGateway)
},
onRoutingFailed: (error) => {
console.error('Routing failed:', error.message)
},
},
},
// Data verification
verificationSettings: {
enabled: true,
strategy: new HashVerificationStrategy({
trustedGateways: ['https://arweave.net'],
}),
strict: false,
events: {
onVerificationSucceeded: (event) => {
console.log('Verification passed:', event.txId)
},
onVerificationFailed: (error) => {
console.warn('Verification failed:', error.message)
},
},
},
// Telemetry (optional)
telemetrySettings: {
enabled: true,
serviceName: 'my-application',
clientName: 'my-app',
clientVersion: '1.0.0',
sampleRate: 0.1,
},
// Custom logger (optional)
logger: {
debug: (message, ...args) =>
console.debug(`[WAYFINDER] ${message}`, ...args),
info: (message, ...args) => console.info(`[WAYFINDER] ${message}`, ...args),
warn: (message, ...args) => console.warn(`[WAYFINDER] ${message}`, ...args),
error: (message, ...args) =>
console.error(`[WAYFINDER] ${message}`, ...args),
},
}) request(): How to fetch Arweave data using Wayfinder resolveUrl(): Use dynamic URLs for transaction IDs, ArNS names, etc.Gateway Providers: Understand gateway discovery options Routing Strategies: Explore different routing algorithms Verification Strategies: Learn about data integrity verification Telemetry: Set up monitoring and observability

---

# 53. ARIO Docs

Document Number: 53
Source: https://docs.ar.io/ar-io-sdk/ants/release-name
Words: 71
Quality Score: 0.478
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

releaseName releaseName is a method on the ANT class that releases an ArNS name from the ANT, making it available for auction on the ARIO contract. The name must be permanently owned by the releasing wallet. Upon successful auction, 50% of the winning bid will be distributed to the ANT owner at the time of release. If there are no bids, the name becomes available for anyone to register.releaseName requires authentication.

---

# 54. Gateway Architecture - ARIO Docs

Document Number: 54
Source: https://docs.ar.io/gateways
Words: 650
Quality Score: 0.477
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Overview Gateways are the workhorses of the AR.IO Network.
Their primary role is to act as a bridge between the Arweave network and the outside world.
This means that a gateway's main task is to make it easier for users to interact with the Arweave network by simplifying the technical processes of writing, reading, and discovering data on the blockweave in a trust-minimized fashion.Gateway functions The functions of an AR.IO gateway are broken down into the following categories:Writing data involves:Proxying base layer transaction headers to one or more healthy and active Arweave nodes (miners) to facilitate inclusion in the mempools of as many nodes as possible.Proxying chunks for base layer Arweave transactions to Arweave nodes to help facilitate storage and replication of the chunks on the blockweave.Receiving and bundling so-called bundled data items (e.g., ANS-104 spec) as base layer transactions.Reading involves retrieving:Transaction headers for a base layer Arweave transaction.Individual data chunks for a base layer Arweave transaction.Blocks from the blockweave.Storage pricing rates for data from the Arweave node network.Contiguous streams of chunks representing an entire base layer transaction.Bundled data items (e.g., ANS-104).Wallet information (e.g., token balance).Discovering data involves:Facilitating efficient, structured queries for base layer transactions, bundled data items, and wallet data by:examining incoming streams of data (i.e., directly ingested transactions and data items, blocks emitted by the chain, etc.).managing index data in a database or analogous data store.Parsing and executing user queries.Facilitating friendly-path routing via Arweave manifest indexing.Including other benefits and capabilities such as:Facilitating friendly-subdomain-name routing to Arweave transactions via a direct integration with the Arweave Name System (ArNS).Providing the modularity and configurability necessary for operating extensible gateways that can be deployed at small or large scales to meet the needs of specific applications, use cases, communities, or business models.Providing pluggable means for consuming telemetry data for internal and external monitoring and alerting.Facilitating configurable content moderation policies.Providing connectivity to a decentralized network of other AR.IO gateways, enabling data sharing and other shared workloads.AR.IO Gateway Benefits AR.IO gateways provide many new benefits and capabilities beyond general Arweave gateways:Providing the modularity and configurability necessary for operating extensible gateways that can be deployed at small or large scales to meet the needs of specific applications, use cases, communities, or business models.Providing pluggable means for consuming telemetry data for internal and external monitoring and alerting.Facilitating friendly-subdomain-name routing to Arweave transactions via a direct integration with the Arweave Name System (ArNS).Facilitating configurable content moderation policies.Providing connectivity to a decentralized network of other AR.IO gateways, enabling data sharing and other shared workloads.Gateway Modularity A design principle of AR.IO gateways is that their core components should be interchangeable with compatible implementations.The core services in the gateway are written in Typescript, with flexible interfaces to the various subsystems and databases. This allows operators to customize their gateway to meet their specific requirements. Gateway services can be turned on or off depending on the operator's needs. For example, an operator might choose to have their gateway serve data, but not actively index Layer 2 bundled data. This flexibility also allows operators to utilize the technologies that are appropriate for the scale and environments in which they operate.For example, small scale operators might want to use low-overhead relational databases to power their indexing while larger scale operators might opt to use cloud-native, horizontally scalable databases. Analogous examples for storage and caching exist as well.ARNS Indexing and Routing The Arweave Name System’s (ArNS) state is managed by the ARIO token’s smart contract. AR.IO gateways shall perform the following minimum functions relative to ArNS:Actively track state changes in the contract.Maintain up-to-date indexes for routing configurations based on the state of the ARIO contract as well as the states of the Arweave Name Token (ANT) contracts to which each name is affiliated.Manage the expiration of stale records.Facilitate ArNS routing based on the subdomains specified on incoming requests where appropriate.Provide a custom HTTP response header for ArNS requests indicating the corresponding Arweave transaction ID.

---

# 55. upgradeRecord - ARIO Docs

Document Number: 55
Source: https://docs.ar.io/ar-io-sdk/ario/arns/upgrade-record
Words: 76
Quality Score: 0.476
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

upgradeRecord is a method on the ARIO class that upgrades an existing ArNS record from a lease to a permanent ownership (permabuy). This allows converting a leased name to permanent ownership.upgradeRecord requires authentication.Parameters Parameter Type Description Optional name string The ArNS name to upgrade to permanent ownership false fundFrom string The source of funds: 'balance', 'stakes', 'any', or 'turbo' true tags array An array of GQL tag objects to attach to the transfer AO message true

---

# 56. setUndernameRecord - ARIO Docs

Document Number: 56
Source: https://docs.ar.io/ar-io-sdk/ants/set-undername-record
Words: 120
Quality Score: 0.476
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

setUndernameRecord is a method on the ANT class that creates or updates an undername record for the ANT. An undername is a prefix that is joined to the base name with an underscore (e.g., dapp_ardrive.ar.io).setUndernameRecord requires authentication.Parameters TTL Time-To-Live (TTL) determines how often gateways should check the ANT for updates to the corresponding record. You can have different TTLs for different records within an ANT, depending on their use case. A record that is updated frequently should have a lower
value to facilitate serving current data, while a record that is updated less
often should have a higher value to allow cached data to be served more
quickly.TTL must be between 60 seconds (1 minute) and 86400 seconds (1 day).

---

# 57. ANT Configuration - ARIO Docs

Document Number: 57
Source: https://docs.ar.io/ar-io-sdk/ants/configuration
Words: 98
Quality Score: 0.475
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

init init is a factory function that creates a read-only or writable client. By providing a signer, additional write APIs that require signing (like setRecord and transfer) become available. By default, a read-only client is returned and no write APIs are available.Parameters ← Swipe to see more → Parameter Type Description Optional processId String The AO process ID of the ANT to connect to.false process AOProcess A pre-configured AOProcess instance used to initialize the ANT class true signer ContractSigner An optional signer instance, used to enable write operations on the
blockchain true ← Swipe to see more →

---

# 58. getGatewayVaults - ARIO Docs

Document Number: 58
Source: https://docs.ar.io/ar-io-sdk/ario/gateways/get-gateway-vaults
Words: 27
Quality Score: 0.474
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

getGatewayVaults is a method on the ARIO class that retrieves all vault information for a specific gateway, including delegated stakes and pending withdrawals.getGatewayVaults does not require authentication.

---

# 59. setBaseNameRecord - ARIO Docs

Document Number: 59
Source: https://docs.ar.io/ar-io-sdk/ants/set-base-name-record
Words: 116
Quality Score: 0.474
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

setBaseNameRecord is a method on the ANT class that adds or updates the base name record for the ANT. This record defines the top-level name of the ANT (e.g., ardrive.ar.io).setBaseNameRecord requires authentication.Parameters TTL Time-To-Live (TTL) determines how often gateways should check the ANT for an update to the corresponding record. You can have different TTLs for different records within an ANT, depending on their use case. A record that is updated frequently should have a lower
value to facilitate serving current data, while a record that is updated less
often should have a higher value to allow cached data to be served more
quickly.TTL must be between 60 seconds (1 minute) and 86400 seconds (1 day).

---

# 60. ARIO Docs

Document Number: 60
Source: https://docs.ar.io/ar-io-sdk/ario/gateways/get-gateway-delegates
Words: 42
Quality Score: 0.473
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

getGatewayDelegates getGatewayDelegates is a method on the ARIO class that retrieves all delegates for a specific gateway. Results are paginated and sorted by the specified criteria. The cursor parameter represents the last delegate address from the previous request.getGatewayDelegates does not require authentication.

---

# 61. getDemandFactorSettings - ARIO Docs

Document Number: 61
Source: https://docs.ar.io/ar-io-sdk/ario/arns/get-demand-factor-settings
Words: 40
Quality Score: 0.473
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

getDemandFactorSettings is a method on the ARIO class that retrieves the configuration settings for the demand factor algorithm, which dynamically adjusts ArNS registration costs based on network demand.getDemandFactorSettings does not require authentication.Parameters The getDemandFactorSettings method does not accept any parameters.

---

# 62. ARIO Docs

Document Number: 62
Source: https://docs.ar.io/ar-io-sdk/ario/arns/get-demand-factor
Words: 52
Quality Score: 0.471
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

getDemandFactor getDemandFactor is a method on the ARIO class that retrieves the current network demand factor. This factor is a dynamic multiplier that adjusts the cost of ArNS interactions based on network demand - higher demand results in higher costs, and vice versa.getDemandFactor does not require authentication.Parameters getDemandFactor does not accept parameters.

---

# 63. getRecords - ARIO Docs

Document Number: 63
Source: https://docs.ar.io/ar-io-sdk/ants/get-records
Words: 38
Quality Score: 0.469
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

getRecords is a method on the ANT class that retrieves all the records stored in the ANT process, including both base name records and undername records.getRecords does not require authentication.Parameters The getRecords method does not accept any parameters.

---

# 64. ARIO Docs

Document Number: 64
Source: https://docs.ar.io/wayfinder/core/gateway-providers
Words: 70
Quality Score: 0.468
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Gateway Providers Overview Gateway providers are responsible for discovering and managing AR.IO gateways that Wayfinder can use to access Arweave data. They abstract the complexity of gateway discovery and provide a consistent interface for routing strategies to select optimal gateways.Provider Comparison Related NetworkGatewaysProvider: Network-based gateway discovery StaticGatewaysProvider: Static gateway configuration SimpleCacheGatewaysProvider: Caching wrapper for providers Routing Strategies: How gateways are selected for requests Wayfinder Configuration: Main wayfinder setup and usage

---

# 65. setRecord - ARIO Docs

Document Number: 65
Source: https://docs.ar.io/ar-io-sdk/ants/set-record
Words: 206
Quality Score: 0.467
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Deprecated This method is deprecated. Please use setBaseNameRecord for top-level names
or setUndernameRecord for undernames instead. See the setBaseNameRecord and setUndernameRecord documentation for
more details.setRecord is a method on the ANT class that sets or updates a record in the ANT process. Records map names to Arweave transaction IDs with optional TTL settings.setRecord requires authentication.Parameters ← Swipe to see more → Parameter Type Description Optional undername string The undername name for the record (use "@" for the root domain) false transactionId string The Arweave transaction ID to point the record to false ttlSeconds number Time-to-live in seconds for the record cache true tags array An array of GQL tag objects to attach to the AO message true ← Swipe to see more → TTL Time-To-Live (TTL) determines how often gateways should check the ANT for updates to the corresponding record. You can have different TTLs for different records within an ANT, depending on their use case. A record that is updated frequently should have a lower
value to facilitate serving current data, while a record that is updated less
often should have a higher value to allow cached data to be served more
quickly.TTL must be between 60 seconds (1 minute) and 86400 seconds (1 day).

---

# 66. getRegistrationFees - ARIO Docs

Document Number: 66
Source: https://docs.ar.io/ar-io-sdk/ario/arns/get-registration-fees
Words: 37
Quality Score: 0.467
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

getRegistrationFees is a method on the ARIO class that retrieves the current registration fee structure for ArNS names, including base fees and any applicable multipliers.getRegistrationFees does not require authentication.Parameters The getRegistrationFees method does not accept any parameters.

---

# 67. The ARIO Token - ARIO Docs

Document Number: 67
Source: https://docs.ar.io/token
Words: 250
Quality Score: 0.467
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Overview ARIO is the multifunction AO Computer based token that powers the AR.IO Network and its suite of permanent cloud applications. The ARIO Token uses include:Gateway Participation: Gateway operators must stake ARIO tokens to join and actively participate in the network.Eligibility for Protocol Rewards: Both individuals who stake tokens as gateway operators and those who delegate tokens to a gateway are positioned to receive protocol rewards.ArNS Name Purchases: Acquiring friendly names through the Arweave Name System (ArNS) requires ARIO tokens. These transactions directly contribute to the protocol, with the proceeds being redistributed through the Observation and Incentive Protocol.Universal Currency: Within the AR.IO ecosystem, ARIO tokens serve as a versatile currency, enabling network participants to make purchases and exchange value.Moreover, ARIO tokens a crucial role in driving ecosystem growth, fueling incentive programs, investments, bounties, and grants designed for active participants.Adding ARIO Token to Wander To view your ARIO token balance in Wander, formerly ArConnect, follow these steps to add the token to your wallet:Open your Wander wallet (available on both desktop and mobile) Access Settings:Mobile: Click the 3 vertical dots in the top right, then select "Settings" Desktop: Click the hamburger menu icon in the top left Select "Tokens" Click "Import Token" For Desktop users: Ensure "Token Type" is set to "ao Token" Enter the AO process ID:qNvAoz0TgcH7DMg8BCVn8jF32QH5L6T29VjHxhHqqGE The token ticker "ARIO" and name "AR.IO Network" will appear automatically Click "Import Asset" to complete the process Once imported, you'll be able to view your total ARIO balance in your Wander wallet.

---

# 68. Gateway Troubleshooting  FAQ - ARIO Docs

Document Number: 68
Source: https://docs.ar.io/gateways/troubleshooting
Words: 2165
Quality Score: 0.467
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Welcome to the unified troubleshooting and FAQ resource for AR.IO Gateway operators. Use the quick lookup table below for fast answers, or browse the detailed sections for in-depth guidance.Quick Lookup Below is a quick summary of what you should check when troubleshooting your gateway. Find more detailed information in the sections below.← Swipe to see more → Issue What to Check My release number is wrong Pull the latest github updates and make sure you are on the main branch Gateway appears offline on Viewblock or ar://gateways Probably fine, but verify that your gateway is still running.'/ar-io/observer/reports/current' just says "report pending" Normal behavior, wait for the report to complete.Observer error "Cannot read properties of undefined" Normal behavior, Observer is checking for data not implemented yet.Observing my gateway shows failures Check AR_IO_WALLET and ARNS_ROOT_HOST settings.Updated.env settings not reflected on gateway Rebuild your gateway after editing.env file.Out of disk space error Check for inode exhaustion and delete files if necessary.Can't load ArNS names Check ARNS_ROOT_HOST setting in.env file, and DNS records."Your connection is not private" error Generate or renew SSL certificates.404/Nginx error when accessing domain Check Nginx settings and restart Nginx if necessary.502 error from Nginx Check for errors in your gateway.Trouble generating SSL certificates Ensure TXT records have propagated and follow certbot instructions.← Swipe to see more → General Troubleshooting My Gateway Seems to be Running but...My release number doesn't match the latest version, or includes "-pre" If your release number when you go to /ar-io/info is lower than the current release, you simply need to upgrade your gateway in order to reach the latest release.If your release number includes the suffix "-pre" it means you are running your gateway from the development branch of the github repository, instead of the main branch. The development branch is used for staging work that the engineering team is in the middle of. Because of this, it can be much less stable than the main branch used for production and can cause significant issues.Ensure that you are running the latest release, from the main branch, by running the below commands in your terminal:If this doesn't resolve the issue, you can also try a more extreme method of clearing out the incorrect docker images:It appears offline on Viewblock or ar://gateways Viewblock and ar://gateways use a very simple ping method for determining if a gateway is "up". There are plenty of reasons why this ping may fail while the gateway is running perfectly, so showing as down is not cause for concern. Just verify that your gateway is still running, and wait. Your gateway will show as up again soon.< gateway >/ar-io/observer/reports/current just says "report pending" This is normal. Your Observer is working to generate a report and that report will be dised once it is complete.My Observer is showing me the error "error: Error reading interaction: Cannot read properties of undefined" This is not an issue with your observer. The short explanation is that your Observer is looking for tasks assigned to it by the AR.IO network contract, but there isnt anything there. You can safely ignore this error message.Observing my gateway shows failures When observing a gateway, there are two main pass/fail tests. "Ownership" and "ArNS Assessment" Ownership: This tests to see if the value set in your gateway AR_IO_WALLET value (in.env) matches the wallet used to join the AR.IO Network. If they don't match, update the value in your.env file and restart your gateway.ArNS Assessment: This tests to see if a gateway is able to resolve ArNS names correctly. The first thing you should check is if you have the ARNS_ROOT_HOST value set in your.env file. If not, set the value and restart your gateway. If this value is set, check to make sure you have current DNS records and SSL certificates for wildcard subdomains on your gateway.I updated my.env settings, but nothing changed on my gateway Once you edit your.env file, you need to "rebuild" your gateway for the changes to take effect. As of release 3, every time you start your gateway with docker-compose it is automatically rebuilt. So all you need to do is shut your gateway down and restart it.I am getting an out of disk space error, but I still have open storage space on my computer The most likely cause of this is inode exhaustion. Test this by running the command:If one of the lines in the output says 100%, you have run out of inodes and so your filesystem is not capable of creating new files, even if you have available space. The solution is to delete files from your data folder in order to free up inodes.This was a common issue prior to release #3, when Redis caching was introduced to reduce the number of small files created. If you are using an older version of the gateway, consider upgrading to mitigate the risk of inode exhaustion.I can't load ArNS names The first thing you should check if your gateway is not resolving ArNS names is that you have ARNS_ROOT_HOST set in your.env file. If not, set it to your domain name used for the gateway. For example, ARNS_ROOT_HOST=arweave.dev.Once this value is set, restart your gateway for the changes to take effect.If that doesn't resolve the issue, check your dns records. You need to have a wildcard subdomain ( *.< your-domain > ) set with your domain registrar so that ArNS names will actually point at your gateway. You can set this record, and generate an SSL certificate for it, in the same way you set the records for your primary domain.When I try to access my gateway in a browser I get a "Your connection is not private" error This error message means that your SSL certificates have expired. You need to renew your certificates by running the same certbot command you used when you initially started your gateway:Certbot SSL certificates expire after 90 days, and you will need to rerun this command to renew every time. If you provide an email address, you will receive an email letting you know when it is time to renew.I set my gateway up, but when I go to my domain I get a 404/Nginx error If you navigate to your domain and see a 404 error from Nginx (the reverse proxy server used in the setup guide) it means that your domain is correctly pointed at the machine running your gateway, but you have not properly configured your Nginx settings (or your gateway is not running).The Set up Networking section of the setup guide has detailed instructions on configuring your Nginx server. If all else fails, try restarting Nginx, that usually clears any issues with the server clinging to old configurations.When I visit my domain I see a 502 error from Nginx A 502 error from Nginx means that Nginx is working correctly, but it is receiving an error from your gateway when it tries to forward traffic.I am having trouble generating my SSL certificates When using the manual certbot command provided in the setup guide:You need to be sure that you are waiting after creating your TXT records for them to completely propagate. You can check propagation using a tool like dnschecker.org.If you continue to have issues, you can check the official certbot instructions guide.My gateway was working, but it just ped Visit your gateway in a browser and see if your SSL certs are expired. This is the most common issue causing sudden s in proper operation.I updated my SSL certs, but it still shows as bad in a browser Try restarting nginx, it sometimes has trouble looking at the new certs without a restart.My gateway won't resolve ArNS names Make sure ARNS_ROOT_HOST is properly set in your .env file. Updating this requires restarting your gateway.Make sure you have a DNS record set for *.. Since ArNS names are served as subdomains, you need to make sure all subdomains are pointed at your gateway.If your gateway is attempting to resolve the name, but times out, it's most likely a CU issue.I see an error in my logs, but everything appears to be working AR.IO gateways are very robust, they can handle temporary errors gracefully and not affect normal operation. You should only be concerned if the error is consistent or it is causing your gateway to not function properly.I was selected as an observer, but my logs say a report was not saved Observers generate and submit their reports at specific times throughout the epoch. This is to ensure a healthy network throughout the entire epoch, not just at the start.Your observer wallet must match the observer wallet associated with your gateway in the AR.IO contract. You can check this by navigating to your gateway in ar://gateways.I see an error in my logs that says . is not in the cert's altnames: DNS: This failure means that the observer's SSL certificate does not match the gateway's domain name. This is almost always an issue with the gateway's SSL certificate. This most likely occurred because the gateway's operator did not update the gateway's SSL certificate when the gateway's domain name was changed. Obtaining a new SSL certificate and updating the gateway's reverse proxy configuration to use the new certificate is the only solution to this issue.write EPROTO :error::SSL routines:ssl3_read_bytes:tlsv1 unrecognized name::SSL alert number 112 This failure almost always means that the gateway operator did not properly obtain SSL certificates for the gateway's wildcard subdomain. Obtaining a new SSL certificate and updating the gateway's reverse proxy configuration to use the new certificate is the only solution to this issue. FAQ Why was my reward different this epoch?Show answer Gateway protocol rewards are calculated as 0.1% of the protocol balance (0.05% after August 2025) split between all gateways in the network. A change in the protocol balance or the number of gateways in the network between epochs will result in the reward for an individual gateway changing.The Observer rewards are separate from protocol rewards, and if your gateway is selected as an observer for an epoch, assuming it performs its duties well, it will receive additional rewards I have a high stake on my gateway, why am I not an observer?Show answer The observer selection process uses a weighted random selection method that considers multiple factors beyond just stake:Stake Weight (SW): Ratio of your total staked ARIO tokens (including delegated stake) to the network minimum Tenure Weight (TW): How long your gateway has been part of the network (capped at 4 after 2 years) Gateway Performance Ratio Weight (GPRW): Ratio of epochs where you correctly resolved names vs total participation Observer Performance Ratio Weight (OPRW): Ratio of epochs where you successfully submitted reports vs total observer periods A composite weight (CW) is calculated as: CW = SW × TW × GPRW × OPRW Up to 50 gateways are chosen as observers per epoch. If there are more than 50 gateways, selection is randomized based on these normalized weights. Even with a high stake, other factors like performance and tenure affect your chances of being selected.I withdrew my stake, but now I have less Show answer There is a 90 day locking period when withdrawing stake, either from delegated stake or operator stake on your gateway. This locking period can be skipped, for a fee. The fee starts at 50% of the withdrawal amount, and goes down over time. If you selected instant withdrawal, you paid the fee to skip the locking period.Why Can't I withdraw my stake?Show answer The minimum operator stake for gateways (10,000 ARIO) cannot be instantly withdrawn, it is subject to the full 90 day locking period, and withdrawal can only be started by removing your gateway from the network.I would like to move my node to a new server - how?Show answer If possible, leave your original server running while you prepare the new one Set up the new server following the same steps you used to set up the original server This includes setting up SSL certificates for the new server You must use the same gateway wallet when setting up the new server The observer wallet may be changed at any point, but requires extra steps. It is recommended you use the original observer wallet as well Once the new server is set up, change your DNS A records to point at the new server After your DNS records are set and you have verified your gateway is operating correctly, shut down the original server No changes need to be made in the network contract or on ar://gateways Can I change my nodes FQDN?Show answer Yes Configure your new domain to point at your gateway, including setting up SSL certificates Update your NGINX (or other reverse proxy) server to recognize the new domain. This usually requires a restart of NGINX Update the ARNS_ROOT_HOST variable in your .env and restart the gateway Using ar://gateways, update your gateway settings to change the FQDN in the contract Your gateway is now using the new domain name for normal operation.

---

# 69. getState - ARIO Docs

Document Number: 69
Source: https://docs.ar.io/ar-io-sdk/ants/get-state
Words: 36
Quality Score: 0.465
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

getState is a method on the ANT class that retrieves the complete state of the ANT process, including all records, balances, controllers, and metadata.getState does not require authentication.Parameters The getState method does not accept any parameters.

---

# 70. Glossary - ARIO Docs

Document Number: 70
Source: https://docs.ar.io/glossary
Words: 1405
Quality Score: 0.465
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Many novel terms and acronyms are used by the Arweave ecosystem as well as some new ones introduced by AR.IO. The list below is intended to serve as a non-exhaustive reference of those terms. For a comprehensive glossary of permaweb-specific terminology, check out the permaweb glossary section:AO Computer (AO):The AO Computer is an actor-oriented machine on the Arweave network, creating a unified computing environment across diverse nodes. It supports many parallel processes through an open message-passing layer, linking independent processes into a cohesive system, similar to how websites are interconnected via hyperlinks.Arweave Name System (ArNS):a decentralized and censorship-resistant naming system enabled by AR.IO gateways which connects friendly names to permaweb applications, pages, data or identities.Arweave Name Token (ANT), "Name Token":A an AO Computer based token, that is connected to each registered ArNS Name. Each ANT gives the owner the ability to update the subdomains and Arweave Transaction IDs used by the registered name as well as transfer ownership and other functions.Arweave Network Standards (ANS):Drafts and finalized standards for data formats, tag formats, data protocols, custom gateway features and anything that is built on top the Arweave Network. Specific standards are denoted by an associated number, e.g., ANS-###.Base Layer Transaction:refers to one of up to 1,000 transactions that make up a single Arweave block. A base layer transaction may contain bundled data items.Bundle, bundling:an Arweave concept introduced in ANS-104 that allows for a way of writing multiple independent data transactions into one base layer transaction. Bundled transactions contain multiple independent transactions, called data items, wrapped into one larger transaction. This offers two major network benefits:A scaling solution for increasing the throughput of uploads to the Arweave network,Allows delegation of payment for an upload to a third party, while maintaining the identity and signature of the person who created the upload, without them needing to have a wallet with funds.Bundled Data Item (BDI):A data item / transaction nested within an ANS-104 bundled transaction.Bundler:A third-party service and gateway feature that bundles data files on a user's behalf.Chunk:A chunk is a unit of data that is stored on the Arweave network. It represents a piece of a larger file that has been split into smaller, manageable segments for efficient storage and retrieval.Decentralized, decentralization, etc:A nonbinary, many axis scale enabling a system or platform to be: permissionless, trustless, verifiable, transparent, open-source, composable, resilient, and censorship resistant. Ultimately, something that is decentralized is not prone to single points of failure or influence.Epoch:a specific duration (e.g., one day) during which network activities and evaluations are conducted. It serves as a key time frame for processes such as observation duties, performance assessments, and reward distributions within the network's protocols.Gateway:A node operating on the Arweave network that provides services for reading from, writing to, and indexing the data stored on the permaweb. Sometimes referred to as "permaweb nodes".Gateway Address Registry (GAR):a decentralized directory maintained in the AR.IO smart contract. It serves as the authoritative list of all registered gateways on the AR.IO Network. The registry provides detailed metadata about each gateway to facilitate discovery, health monitoring, and data sharing among apps, users and other infrastructure. The GAR is designed to be easily queryable, sortable, and filterable by end users and clients, allowing for tailored selections based on various criteria to meet specific use cases.Indexing:The act of organizing transaction data tags into queryable databases.Layer 2 Infrastructure:Layer 2 refers to the technology / infrastructure stack built "above" a base layer. In this use, the AR.IO Network would be considered Layer 2 infrastructure to the base Arweave protocol.Manifest (aka Path Manifest, Arweave Manifest):Special "aggregate" files uploaded to Arweave that map user-definable sub-paths with other Arweave transaction IDs. This allows users to create logical groups of content, for example a directory of related files, or the files and assets that make up a web page or application. Instead of having to manually collate these assets, manifests group them together so that an entire website or app can be launched from a single manifest file. Gateways can interpret this structure, so that users can then reference individual transactions by their file name and/or path.Mempool:Short for "memory pool," is a component of Arweave mining nodes that temporarily stores valid transactions that have been broadcasted to the network but have not yet been added to a block.Message:An interaction with an AO Process, including action and tags. Every interaction with AO takes the form of a message.Miner (aka Arweave Node):A node operating on the Arweave network responsible for data storage and recall.Native Address:The way public addresses are commonly (or by spec) represented in their native blockchain. Arweave keys are 43 character base64url representations of the public key, while Ethereum keys use a different hashing algorithm and start with 0x etc.Normalized Address:43 character base64url representation of the sha256 hash of a public key. Public keys for other chains can be normalized by this representation.Observer:A gateway selected to evaluate the performance of peer gateways in resolving ArNS names. Observers assess and report on the operational efficacy of other gateways.Optimistic Indexing:Indexing transaction or data item headers before the associated L1 transaction has been accepted and confirmed in a chain block.Owner:Generally, the public key of the signer.Owner Address:The normalized address of the owner Period:Refers to a predefined time span (e.g., a day) that serves as a cycle for network activities such as dynamic pricing. It is a fundamental unit of time for operational and protocol processes within the network.Permanent Cloud Network:A decentralized network that securely stores, distributes, and serves data and applications in a timeless, tamper-proof, and universally accessible way. Unlike traditional clouds, it ensures data permanence and user sovereignty by eliminating reliance on centralized providers and creating a resilient, censorship-resistant infrastructure.Permaweb:The permaweb is the permanent and decentralized web of files and applications built on top of Arweave.Process:Process: A decentralized computation unit in the AO framework, enabling scalable, parallel execution via message-passing. Each process maintains its own state, interacts asynchronously, and is permanently stored on Arweave for transparency and immutability.Process ID (PID):Every process in AO is assigned a unique immutable identifier code.Protocol Balance:The primary sink and source of ARIO tokens circulating through the AR.IO Network. This balance is akin to a central vault or wallet programmatically encoded into the network's smart contract from which ArNS revenue is accumulated and incentive rewards are distributed.Protocol Rewards:ARIO Token incentive rewards distributed by the protocol to the network's eligible users and gateway operators.Public Key:The publicly known keys for a signer (wallet). Public keys are different byte lengths depending on the signer type (e.g. Arweave vs. Ethereum (ECDSA), vs Solana, etc.) Seeding:Refers to the act of propagating new data throughout the network. Miner nodes seed Arweave base layer transaction data to other miners, while gateways ensure that the transactions they receive reach the Arweave nodes. Both gateways and Arweave nodes seed base layer transactions and data chunks.Staking (of tokens):Refers to the process of locking ARIO tokens into a protocol-facilitated vault, temporarily removing them from circulation until unlocked. This action represents an opportunity cost for the gateway operator and serves as a motivator to prioritize the network's collective interests.Stake Redelegation:The process by which stakers move their delegated tokens from one gateway to another.Stake Redemption:A feature allowing stakers to use their staked tokens for ArNS-related activities, such as purchasing names, extending leases, or increasing undername capacity.Transaction ID (txID):Every transaction and data file uploaded to Arweave is assigned a unique identifier code known as the Transaction ID. These txID's can be referenced by users to easily locate and retrieve files.Trust-minimization:Relates to enacting network security by minimizing the number of entities and the degree to which they must be trusted to achieve reliable network interactions. A network with trust-minimizing mechanisms means that it has reduced exposure to undesirable third-party actions and built-in incentives to reward good behavior while punishing bad behavior.Vault:Token vaults are protocol level mechanisms used to contain staked tokens over time. Each vault contains a starting timestamp, ending timestamp (if applicable), along with a balance of tokens.Wayfinder Protocol:The Wayfinder protocol provides applications with a pattern for dynamically switching / routing between network gateways. It also allows for abstraction of top level domain names from Arweave data and verifies the responses from AR.IO Gateways. It forms the basis of the ar:// schema, so users can seamlessly access ArNS names, Arweave base layer transactions, and bundled data items without the user providing a top-level domain.Permaweb Glossary For a more comprehensive glossary of terms used in the permaweb, try the Permaweb Glossary. Or use it below:

---

# 71. getInfo - ARIO Docs

Document Number: 71
Source: https://docs.ar.io/ar-io-sdk/ants/get-info
Words: 35
Quality Score: 0.463
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

getInfo is a method on the ANT class that retrieves general information about the ANT process, including name, ticker, denomination, and other metadata.getInfo does not require authentication.Parameters The getInfo method does not accept any parameters.

---

# 72. getArNSRecord - ARIO Docs

Document Number: 72
Source: https://docs.ar.io/ar-io-sdk/ario/arns/get-arns-record
Words: 34
Quality Score: 0.461
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

getArNSRecord is a method on the ARIO class that retrieves the details of a specific ArNS record by its name. This includes lease information, type, process ID, and other metadata.getArNSRecord does not require authentication.

---

# 73. ARIO Docs

Document Number: 73
Source: https://docs.ar.io/ar-io-sdk/ants/remove-primary-names
Words: 33
Quality Score: 0.460
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

removePrimaryNames removePrimaryNames is a method on the ANT class that removes specified primary names from the ANT process. This affects any primary names associated with base names controlled by this ANT.removePrimaryNames requires authentication.

---

# 74. ARIO Docs

Document Number: 74
Source: https://docs.ar.io/ar-io-sdk/ants/reassign-name
Words: 33
Quality Score: 0.460
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

reassignName reassignName is a method on the ANT class that transfers ownership of an ArNS name to a new ANT. This operation can only be performed by the current ANT owner.reassignName requires authentication.

---

# 75. ARIO Docs

Document Number: 75
Source: https://docs.ar.io/ar-io-sdk/ario/gateways/instant-withdrawal
Words: 33
Quality Score: 0.460
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

instantWithdrawal instantWithdrawal is a method on the ARIO class that instantly withdraws funds from an existing vault on a gateway. If no gatewayAddress is provided, the signer's address will be used.instantWithdrawal requires authentication.

---

# 76. ARIO Docs

Document Number: 76
Source: https://docs.ar.io/wayfinder/core/gateway-providers/simple-cache
Words: 76
Quality Score: 0.457
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

SimpleCacheGatewaysProvider Overview The SimpleCacheGatewaysProvider holds the resulting gateways in memory for the provided TTL, making it ideal for Node environments. This helps avoid rate-limits and unnecessary network requests to the underlying gateways provider.Important SimpleCacheGatewaysProvider is ideal for Node.js/server environments. For browser-based web applications, use LocalStorageGatewaysProvider instead to persist gateway lists across sessions.Basic Usage Configuration Options Related Documentation Gateway Providers: Compare all gateway providers NetworkGatewaysProvider: Dynamic network discovery StaticGatewaysProvider: Static gateway configuration Wayfinder Configuration: Main wayfinder setup

---

# 77. getBalance - ARIO Docs

Document Number: 77
Source: https://docs.ar.io/ar-io-sdk/ants/get-balance
Words: 46
Quality Score: 0.456
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

getBalance is a method on the ANT class that retrieves the token balance for a specific wallet address within the ANT process.getBalance does not require authentication.Parameters Parameter Type Description Optional address string - WalletAddress The wallet address to retrieve the balance for false Examples Output 1

---

# 78. Gateway ArNS Resolution - ARIO Docs

Document Number: 78
Source: https://docs.ar.io/gateways/arns-resolution
Words: 624
Quality Score: 0.455
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

ArNS Resolution Overview One of the core functions of the AR.IO network gateway is to serve ArNS (Arweave Name System) records. Each ArNS name is assigned a specific "time to live" (TTL) value,
which determines how often gateways should check for updates to the Arweave Transaction ID that the name points to.
This TTL works similarly to a , which controls how often updates are checked for traditional websites. As a result, there may be a delay between when an ArNS record is updated and when users see the updated information in their browser.Effective with gateway Release 23, new features have been implemented on AR.IO gateways to optimize the resolution of ArNS records. These include an option for
gateway operators to override the ArNS TTL, and set their own schedule for checking ArNS names for updates.Initial Caching When a gateway starts up, it will attempt to fetch the records of all ArNS names in order to create a local cache. Previously, this cache was stored in memory. After Release 23, this cache is saved to persistent storage
so that the gateway's ArNS cache will survive restarting the gateway. This prevents delays in resolving ArNS names immediately after a gateway starts up. This cache is saved to the directory data/arns.Cache Refreshing When a new ArNS name is purchased on arns.app (or programmatically using the AR.IO SDK), gateways need to update their local cache to include this new name.
Previously, gateway operators could not control how or when their gateway refreshed its cache. As a result, new names would often take several hours to resolve. With Release 23, once a new name is purchased and
requested from a gateway, the gateway will check if it was already aware of the name's existence. If not, it will refresh its cache to include the records for the new name, allowing immediate resolution.Gateway operators can specify how often their gateway should refresh its cache when it fails to find an ArNS name that has been requested by setting the ARNS_NAME_LIST_CACHE_MISS_REFRESH_INTERVAL_SECONDS value in their .env file.
The default value for this environmental variable is 10 seconds.
Similarly, they can prompt their gateway to refresh their cache of ArNS names when a name is requested and successfully found in the local cache by setting the ARNS_NAME_LIST_CACHE_HIT_REFRESH_INTERVAL_SECONDS, which defaults to 1 hour.Both of these variables can be set to a number, which represents the number of seconds the gateway should wait before refreshing its cache when a name is requested that is, or is not, already in its local cache.Gateway TTL Override Every ArNS record is set with a TTL specified by the name owner. Gateway operators can set the ARNS_RESOLVER_OVERRIDE_TTL_SECONDS variable in their .env file to override this TTL,
and define for themselves how often the gateway should check for updated records. A shorter TTL value will result in more frequent outgoing requests to the ANT that controls the ArNS name, which can result in slower serving of the name data to users, while a longer TTL allows for faster serving of cached data, which may be out of date.TTL Override is disabled by default, and should be set to the number of seconds the gateway should use as its TTL when resolving names.If a gateway operator chooses to override the TTL set by ArNS owners, they must carefully weigh the trade-offs and decide on the balance between performance speed and record currency that best aligns with their priorities and use case.Note that the gateway TTL override does not override what is set in the cache
headers for the name, it only overrides that TTL on the internal cache of the
gateway (meaning the gateway will fetch is more frequently if it wants, but
always respects the TTL when serving it)

---

# 79. ARIO Docs

Document Number: 79
Source: https://docs.ar.io/ar-io-sdk/ario/gateways/leave-network
Words: 51
Quality Score: 0.455
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

leaveNetwork leaveNetwork is a method on the ARIO class that sets a gateway's status to leaving on the ar.io network. The gateway's operator and delegate stakes are vaulted and will be returned after the leave period. The gateway will be removed from the network once the leave period ends.leaveNetwork requires authentication.

---

# 80. ARIO Docs

Document Number: 80
Source: https://docs.ar.io/ar-io-sdk/ario/gateways/increase-operator-stake
Words: 30
Quality Score: 0.454
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

increaseOperatorStake increaseOperatorStake is a method on the ARIO class that increases the caller's operator stake. This method must be executed with a wallet registered as a gateway operator.increaseOperatorStake requires authentication.

---

# 81. ARIO Docs

Document Number: 81
Source: https://docs.ar.io/ar-io-sdk/ario/gateways/decrease-operator-stake
Words: 30
Quality Score: 0.454
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

decreaseOperatorStake decreaseOperatorStake is a method on the ARIO class that decreases the caller's operator stake. This method must be executed with a wallet registered as a gateway operator.decreaseOperatorStake requires authentication.

---

# 82. Getting Started - ARIO Docs

Document Number: 82
Source: https://docs.ar.io/ar-io-sdk/getting-started
Words: 120
Quality Score: 0.454
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Prerequisites node >= v18.0.0 npm or yarn Installation Quick Start The following examples demonstrate how to use the AR.IO SDK to retrieve a list of active gateways from the Gateway Address Registry (GAR) across different environments.Node Web Polyfills Polyfills are not provided by default for bundled web projects (Vite, ESBuild,
Webpack, Rollup, etc.). Depending on your apps bundler configuration and
plugins, you will need to provide polyfills for various imports including
crypto, process and buffer. Refer to examples/webpack and examples/vite for examples. For other project configurations, refer to your bundler's
documentation for more information on how to provide the necessary polyfills.Output The output for obtaining a list of gateways, regardless of the environment used, will follow the structure outlined below:

---

# 83. getBalances - ARIO Docs

Document Number: 83
Source: https://docs.ar.io/ar-io-sdk/ants/get-balances
Words: 29
Quality Score: 0.452
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

getBalances is a method on the ANT class that retrieves all token balances within the ANT process.getBalances does not require authentication.Parameters The getBalances method does not accept any parameters.

---

# 84. removeRecord - ARIO Docs

Document Number: 84
Source: https://docs.ar.io/ar-io-sdk/ants/remove-record
Words: 33
Quality Score: 0.451
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Deprecated This method is deprecated. Please use removeUndernameRecord instead. See the removeUndernameRecord documentation
for more details.removeRecord is a method on the ANT class that removes a record from the ANT process.removeRecord requires authentication.

---

# 85. getArNSReservedNames - ARIO Docs

Document Number: 85
Source: https://docs.ar.io/ar-io-sdk/ario/arns/get-arns-reserved-names
Words: 94
Quality Score: 0.451
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

getArNSReservedNames is a method on the ARIO class that retrieves all reserved ArNS names, with support for pagination and custom sorting. Reserved names are names that are protected and cannot be registered by users.getArNSReservedNames does not require authentication.Parameters Parameter Type Description Optional Default cursor string The name to use as the starting point for the next page of results true None limit number The maximum number of records to return (max: 1000) true 100 sortBy string The property to sort results by true name sortOrder string The sort direction ('desc' or 'asc') true asc

---

# 86. getArNSReservedName - ARIO Docs

Document Number: 86
Source: https://docs.ar.io/ar-io-sdk/ario/arns/get-arns-reserved-name
Words: 43
Quality Score: 0.450
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

getArNSReservedName is a method on the ARIO class that retrieves details about a specific reserved ArNS name, including its target and any expiration information.getArNSReservedName does not require authentication.Parameters Parameter Type Description Optional name string The reserved ArNS name to retrieve information for false

---

# 87. removeUndernameRecord - ARIO Docs

Document Number: 87
Source: https://docs.ar.io/ar-io-sdk/ants/remove-undername-record
Words: 28
Quality Score: 0.450
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

removeUndernameRecord is a method on the ANT class that removes a specified undername record from the ANT process. Once removed, the undername will no longer resolve.removeUndernameRecord requires authentication.

---

# 88. ARIO Configuration - ARIO Docs

Document Number: 88
Source: https://docs.ar.io/ar-io-sdk/ario/configuration
Words: 96
Quality Score: 0.450
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

init init is a factory function that creates a read-only or writable client. By providing a signer, additional write APIs that require signing (like buyRecord and transfer) become available. By default, a read-only client is returned and no write APIs are available.Parameters ← Swipe to see more → Parameter Type Description Optional process AOProcess A pre-configured AOProcess instance used to initialize the ARIO class true processId string The process ID of the AO process true signer ContractSigner An optional signer instance, used to enable write operations on the
blockchain true ← Swipe to see more →

---

# 89. Managing Primary Names - ARIO Docs

Document Number: 89
Source: https://docs.ar.io/guides/primary-names
Words: 716
Quality Score: 0.447
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Overview Primary names allow users to set a user-friendly alias for their Arweave wallet address, simplifying how addresses are dised across applications. This process involves interaction between two separate smart contracts:The AR.IO Contract - which manages the primary name registry and requests The ANT Contract - which controls the specific ArNS name and must approve any primary name requests The process requires two steps because these are separate contracts:First, a request must be submitted to the AR.IO contract to set a specific ArNS name as the primary name for a wallet Then, the ANT owner must approve this request, confirming that this wallet can use the name as its primary identifier This two-step verification ensures that both the wallet owner and the ANT owner have authorized the connection.Think of this like setting a username on a social platform - where the
platform (AR.IO contract) maintains the registry of usernames, and the name
owner (ANT) must approve who can claim their name as an identifier. Setting a Primary Name with arns.app arns.app is the official ArNS portal from AR.IO. It allows you to manage your ArNS names and set primary names for your wallet addresses.To set a primary name using arns.app, connect your wallet and navigate to the ArNS name management page. Simply locate the ArNS name you want to set as primary and click the star icon at the right of the entry. You will then be prompted to accept the cost of setting the name, and the location of the funds to pay for the transaction. Once the transaction is confirmed, you will be prompted to sign the transaction with your connected wallet. When this is completed, the name will be set as primary for your wallet address, and apps that support primary names will dis the name instead of the wallet address. Setting a Primary Name With the AR.IO SDK The process of setting a primary name using the AR.IO SDK involves two steps: requesting and approval. This two-step process ensures proper authorization from both the wallet owner and the ANT owner.Requesting a Primary Name When requesting a primary name, you're asking to use an ArNS name as the identifier for your wallet address. This requires:The ArNS name to exist Your wallet to submit the request using the requestPrimaryName method The ANT owner's approval Check Primary Name Requests The getPrimaryNameRequest method allows you to verify if a primary name request exists and its status. Use this to:Verify if your request is pending Check if someone has requested to use your ANT's name Build UI flows around the request/approval process Approving a Primary Name Request The ANT owner must approve any requests to use their name as a primary name using the approvePrimaryNameRequest method. This gives ANT owners control over how their names are used as identifiers.Querying Primary Names The AR.IO SDK provides several methods to query primary names, each serving different use cases:Get a Single Primary Name Use getPrimaryName when you need to find the primary name for a specific wallet address. This is particularly useful in applications where you want to dis a user-friendly identifier instead of their wallet address.Common use cases:Dising a user's primary name in a profile or dashboard Showing who authored a piece of content Making transaction histories more readable List All Primary Names Use getPrimaryNames when fetching all primary names. This is useful when you need to:Build a directory of users Create search functionality Dis multiple users in a more readable format Map multiple wallet addresses to their friendly names at once The method supports pagination through a cursor-based system, where the cursor is the last name from your previous request.The response includes:items: Array of primary names for the current page cursor: The last name from the current request, used for getting the next page hasMore: Boolean indicating if there are more results available totalItems: Total number of primary names matching your query Best Practices Always verify ownership of both the ArNS name and ANT before attempting to set a primary name Check if a primary name request already exists before submitting a new one Consider implementing error handling for cases where the name or ANT doesn't exist When dising primary names in your application, always have a fallback to show the wallet address if no primary name exists

---

# 90. Data Root Verification Strategy - ARIO Docs

Document Number: 90
Source: https://docs.ar.io/wayfinder/core/verification-strategies/data-root-verification
Words: 196
Quality Score: 0.445
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

DataRootVerificationStrategy Overview The DataRootVerificationStrategy provides the highest level of data integrity verification by validating data using Arweave's Merkle tree proofs. This strategy ensures maximum security by verifying that the data matches the cryptographic data root stored in the transaction, providing mathematical proof of data integrity.Important DataRootVerificationStrategy requires that the trusted gateway has the relevant
transaction data indexed locally. Gateways cannot proxy out verification
requests to other sources, as this would compromise the security and
reliability of the verification process. If a gateway doesn't have the
required data indexed, verification will fail.How It Works Compute Data Root: Chunk the received content and build a Merkle tree Calculate Root Hash: Compute the root hash of the Merkle tree Fetch Trusted Root: Get the data root from trusted gateways via /tx/{txId}/data_root Compare Roots: Verify the calculated root matches the trusted data root Result: Pass or fail based on data root validation Warning ANS-104 Data Items Not Supported: This strategy currently only works with regular Arweave transactions, not ANS-104 bundled data items. If you attempt to verify an ANS-104 data item, it will throw an error.Basic Usage Related Hash Verification: Learn about fast integrity checking Signature Verification: Understand authenticity validation

---

# 91. ARIO Node Filtering System - ARIO Docs

Document Number: 91
Source: https://docs.ar.io/gateways/filters
Words: 541
Quality Score: 0.444
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

The AR.IO Node filtering system provides a flexible way to match and filter items based on various criteria. The system is built around JSON-based filter definitions that can be combined to create both simple and complex matching patterns.Unbundling and Indexing Filters When processing bundles, the AR.IO Node applies two filters obtained from environment variables:The ANS104_UNBUNDLE_FILTER determines which base layer transactions and data items, in the case of bundles nested in other bundles, are processed, and the ANS104_INDEX_FILTER determines which data items within the processed bundles are indexed for querying.Webhook Filters There are also two filters available that are used to trigger webhooks. When a transaction is processed that matches one of the webhook filters, the gateway will send a webhook to the specified WEBHOOK_TARGET_SERVERS urls containing the transaction data.The WEBHOOK_INDEX_FILTER is used to trigger a webhook when a transaction is indexed. The WEBHOOK_BLOCK_FILTER is used to trigger a webhook when a block is processed.Important Notes All tag names and values are base64url-decoded before matching Owner addresses are automatically converted from owner public keys Empty or undefined filters default to "never match" Tag matching requires all specified tags to match Attribute matching requires all specified attributes to match The filter system supports nested logical operations to any depth, allowing for very precise control over what data gets processed All these filters can be used in various contexts within the AR.IO Node, such as configuring webhook triggers, controlling ANS-104 bundle processing, or setting up data indexing rules. The filtering system is designed to be intuitive yet powerful, allowing for precise control over which items get processed while maintaining readable and maintainable filter definitions.Filter Construction.env formatting While the filters below are dised on multiple lines for readability, they must be stored in the .env file as a single line for proper processing.Basic Filters The simplest filters you can use "always" and "never" filters. The "never" filter is the default behavior and will match nothing, while the "always" filter matches everything.Tag Filters Tag filters allow you to match items based on their tags in three different ways. You can match exact tag values, check for the presence of a tag regardless of its value, or match tags whose values start with specific text. All tag values are automatically base64url-decoded before matching.Attribute Filters Attribute filtering allows you to match items based on their metadata properties. The system automatically handles owner public key to address conversion, making it easy to filter by owner address. You can combine multiple attributes in a single filter:Nested Bundle Filter The isNestedBundle filter is a specialized filter that checks whether a data item is part of a nested bundle structure. It's particularly useful when you need to identify or process data items in bundles that are contained within other bundles. The filter checks for the presence of a parent_id field in the item.Note: When processing nested bundles, be sure to include filters that match the nested bundles in both ANS104_UNBUNDLE_FILTER and ANS104_INDEX_FILTER. The bundle data items (nested bundles) need to be indexed to be matched by the unbundle filter.Complex Filters Using Logical Operators For more complex scenarios, the system provides logical operators (AND, OR, NOT) that can be combined to create sophisticated filtering patterns. These operators can be nested to any depth:

---

# 92. ARIO Docs

Document Number: 92
Source: https://docs.ar.io/wayfinder/core/gateway-providers/static
Words: 66
Quality Score: 0.443
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

StaticGatewaysProvider Overview The StaticGatewaysProvider uses a predefined list of gateway URLs, making it ideal for development, testing, or when you need to use specific trusted gateways. It provides fast, predictable gateway discovery without network calls.Basic Usage Configuration Options StaticGatewaysProviderOptions Related Documentation Gateway Providers Overview: Compare all gateway providers NetworkGatewaysProvider: Dynamic network discovery SimpleCacheGatewaysProvider: Caching wrapper Wayfinder Configuration: Main wayfinder setup Routing Strategies: How gateways are selected

---

# 93. Normalized Addresses - ARIO Docs

Document Number: 93
Source: https://docs.ar.io/concepts/normalized-addresses
Words: 618
Quality Score: 0.442
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Overview Different blockchains use different formats for the public keys of wallets, and the native addresses for those wallets. In most cases, when a system in the Arweave ecosystem needs to dis the wallet address of a wallet from a different blockchain, for instance in the Owner.address value of an AO process spawned by an ETH wallet, that address will be normalized into the format recognized by Arweave. Specifically, a 43 character base64url representation of the sha256 hash of the public key. This is done to prevent potential errors by systems in the Arweave ecosystem that expect these values to be a certain size and conform to a specific format.Essentially, normalized addresses are a way to represent public keys and wallet addresses from other blockchains in a way that is familiar to systems in the Arweave ecosystem.A tool for easily obtaining a normalized addresses from public keys can be found at ar://normalize-my-key At A Glance Public Keys and Addresses Crypto wallets consist of two separate components. The public keys, which are public knowledge and can be seen by anyone, and the private keys, which only the owner of a wallet should have access to. Crypto wallet addresses are derived from the public key.Encoded Public Keys It is important to note that all crypto wallet public and private keys are
binary data. The values provided below for Arweave and Ethereum/Polygon public
keys are base64url and hex encoded representations of that binary data
respectively.Arweave The public key for an Arweave wallet is the n field of the JWK json file.0jkGWDFYI3DHEWaXhZitjTg67T-enQwXs50lTDrMhy2qb619_91drv_50J5PwrOYJiMmYhiEA5ojMvrrAFY-Dm1bJbJfVBU1kIsPho2tFcXnbSOa2_1bovAys0ckJU07wkbmIUpzp3trdxYReB4jayMMOXWw9B8xS0v81zFmK3IbCtL9N6WNTMONOSMATHFQrGqtDhDUqKyIsQZCBPFvfGykRWaLWzbtAUrApprqG9hfExQzppNsw0gsftNSHZ1emC5tC2fuib6FhQw9TE2ge9tUjEZNALcVZvopTtTX0H2gEfnRJ48UNeV3SKggjXcoPVeivmqXuPBGncXWWq1pHR-Xs4zSLA5Mgcw_tQJc4FIER0i7hUlZXoc991ZHyOvAC-GlHWzQwvrlY11oD38pB47NkHN2WVPtUCAtyYQe5TE6Xznd9kPgqqvVUkV0s0suh5vINGoiPEnMjyhYEN7eOmJRIJ_A87IJesbdPRV4ZzBsqPbd02RG3ZuVpc3gI1xKvwH1WS05XI8eWK-BbvB3oxB7WjaQTWcfBWhMEULiwx-SucuyAzPAw3i6Wjtq61TcL9SdWhmOf9_yo-Np052tj7MQ66nmgdOH_MEKYjAdFypxTsRQoSLbv28HEcSjwx8u3pY0q0gKMK_5X2XKJrp2i2GB_fVgbcpH9YsgrYxh1Q8 The public wallet address for that wallet is 9ODOd-_ZT9oWoRMVmmD4G5f9Z6MjvYxO3Nen-T5OXvU, this is obtained by decoding the public key from base64url to normalize padding, sha256 hashing the result, and then base64url encoding that.Ethereum/Polygon The public key for an EVM wallet (Ethereum, Polygon/Matic) is derived from its private key, using the Elliptic Curve Digital Signature Algorithm, or ECDSA.0xb5d96e5533334a630af9d50b226011d44b9879c3165ffee0601bb0bac621e0047c302d4b72e4b1ca145043940c53093021825726cacdbf1d0a0e8ff2e70a4037 The public wallet address is 0x084af408C8E492aC52dc0Ec76514A7deF8D5F03f, this is obtained by removing the first byte from the public key, Keccak-256 hashing the remainder, taking the the last 20 bytes (40 hexadecimal characters) and prepending 0x to it.Solana A Solana wallet is an array of 64 bytes. The first 32 bytes are the private key, and the last 32 bytes are the public key. Below is the public key portion of a Solana wallet:[172, 175, 23, 95, 23, 124, 38, 171, 25, 20, 245, 213, 59, 9, 18, 89, 46, 70, 135, 84, 137, 205, 251, 95, 8, 226, 233, 46, 78, 34, 212, 86] The public wallet address for this wallet is Cd5yb4mvbuQyyJgAkriFZbWQivh2zM68KGZX8Ksn1L85, this is derived by base58 encoding the public key bytes.Normalizing Addresses As shown in the above examples, the format of public keys, and the resulting derived wallet addresses, vary widely between blockchains. Arweave manages this by applying the same derivation methods that Arweave uses for its own wallets to the public keys from other chains.Ethereum/Polygon The leading 0x and uncompressed flag 04 (if present) is removed from the public key of an EVM wallet, and then the remainder is base64url encoded to obtain the Arweave normalized public key. Continuing with the same public key in the above example, the normalized public key would be:2W5VMzNKYwr51QsiYBHUS5h5wxZf_uBgG7C6xiHgBHwwLUty5LHKFFBDlAxTCTAhglcmys2_HQoOj_LnCkA3 This value is what is used as the GraphQL tag owner value for data items being uploaded to Arweave using an EVM wallet. The normalized address is then derived from this value by sha256 hashing it, and then base64url encoding the result:5JtuS4yOFtUX2Rg3UU7AgBaUqh4s8wyyNTZk9UrzI-Q Solana The normalized public key for Solana wallets are derived similarly. The 32 byte public key is base64url encoded:rK8XXxd8JqsZFPXVOwkSWS5Gh1SJzftfCOLpLk4i1FY Again, this value is used for the GraphQl tag owner when uploading data. It can then be sha256 hashed, and base64url encoded again to derive the normalized address:K8kpPM1RID8ZM2sjF5mYy0rP4gXSRDbrwPUd9Qths64

---

# 94. ARIO Docs

Document Number: 94
Source: https://docs.ar.io/ar-io-sdk/ario/gateways/update-gateway-settings
Words: 198
Quality Score: 0.441
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

updateGatewaySettings updateGatewaySettings is a method on the ARIO class that writes new gateway settings to the caller's gateway configuration.updateGatewaySettings requires authentication.Parameters ← Swipe to see more → Parameter Type Description Optional autoStake boolean If true, automatically stakes gateway rewards.true allowDelegatedStaking boolean If true, allows third parties to delegate stake to the gateway.true minDelegatedStake number Minimum number of tokens, in mARIO that can be delegated to the
gateway.true delegateRewardShareRatio number Percentage of gateway rewards to share with delegates. e.g. 10% true label string Friendly name for gateway, min 1 character, max 64 characters.true note string A note to be associated with gateway, max 256 characters.true properties string - ArweaveTxId ArweaveTxId to properties object containing additional gateway
configuration details.true observerWallet string - WalletAddress Public wallet address for wallet used to upload network observations.true fqdn string Fully qualified domain name, must be valid domain owned by gateway
operator.true port number Port number to use when accessing gateway, generally 443 (https) true protocol string - "http" || "https" Protocol to use when accessing gateway, only "https" is supported for
network participation.true tags array An array of GQL tag objects to attach to the joinNetwork AO message.true ← Swipe to see more →

---

# 95. ARIO Docs

Document Number: 95
Source: https://docs.ar.io/ar-io-sdk/ario/arns/extend-lease
Words: 115
Quality Score: 0.439
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

extendLease extendLease is a method on the ARIO class that extends the lease duration of a registered ArNS domain. The extension period can be 1-5 years, depending on the domain's grace period status. Note that permanently registered domains cannot have their leases extended.extendLease requires authentication.Parameters ← Swipe to see more → Parameter Type Description Optional name string The ArNS name for which to extend the lease false years number The number of years to extend the lease by (1-5 years) false fundFrom string The source of funds: 'balance', 'stakes', 'any', or 'turbo' true tags array An array of GQL tag objects to attach to the transfer AO message true ← Swipe to see more →

---

# 96. addController - ARIO Docs

Document Number: 96
Source: https://docs.ar.io/ar-io-sdk/ants/add-controller
Words: 83
Quality Score: 0.435
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

addController is a method on the ANT class that adds a new controller to the ANT's list of approved controllers. Controllers have permissions to set records and modify the ANT process's ticker and name.addController requires authentication.Parameters ← Swipe to see more → Parameter Type Description Optional controller string - WalletAddress The public wallet address of the controller to be added false tags array An array of GQL tag objects to attach to the transfer AO message true ← Swipe to see more →

---

# 97. Optimizing Data Handling in ARIO Gateway - ARIO Docs

Document Number: 97
Source: https://docs.ar.io/gateways/optimize-data
Words: 968
Quality Score: 0.432
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

The AR.IO Gateway provides powerful tools for optimizing how you access and serve specific types of data. By configuring filters and worker settings, you can focus your gateway on efficiently handling the data that matters most to your use case, ensuring quick and reliable access to relevant information.Understanding the Filtering System The AR.IO Gateway uses two filters to control how ANS104 data items are processed:ANS104_UNBUNDLE_FILTER: Controls which bundles are processed and unbundled ANS104_INDEX_FILTER: Controls which data items from unbundled bundles are stored in the database for querying These filters are configured through environment variables:By default, the gateway processes no bundles and indexes no data items. This allows you to selectively enable processing for the specific data types you need.For a detailed explanation of how to construct these filters, see our Filtering System documentation.Key Environment Variables Several environment variables control how your gateway processes data:Data Item Flushing The gateway uses a two-stage storage system for indexed data items:Temporary Storage: Newly indexed data items are first stored in a temporary table Stable Storage: Data items are periodically "flushed" from temporary to stable storage This process is controlled by two environment variables:DATA_ITEM_FLUSH_COUNT_THRESHOLD: Number of items to queue before flushing (default: 1000) MAX_FLUSH_INTERVAL_SECONDS: Maximum time between flushes (default: 600 seconds) The gateway will flush data items when either:The number of items in temporary storage reaches the threshold The time since the last flush exceeds the interval This batching approach helps optimize database performance by reducing the number of write operations.GraphQL Configuration The GRAPHQL_HOST setting determines how your gateway handles GraphQL queries. You have two options:Using arweave.net (Recommended for new gateways) Proxies queries to a gateway with a complete index of the blockweave Provides immediate access to all historical data No need to wait for local indexing May introduce additional latency from proxying Local-only Queries (Unset GRAPHQL_HOST) Responds to queries using only locally indexed data Faster response times for indexed data Requires complete local indexing (can take weeks for L1 transactions) No proxying overhead Only returns data that matches your indexing filters Note: Even with GRAPHQL_HOST set to arweave.net, your gateway will still maintain its own index based on your filters. This allows for quick access to frequently requested data while ensuring availability of all historical data.Common Use Cases Optimizing for Specific Data Types By configuring your filters and workers appropriately, you can optimize your gateway for different types of data:High- Data: Configure workers to handle large amounts of data efficiently Specific Applications: Filter for particular app names or content types Filter Examples The AR.IO Gateway uses two distinct filters to control how ANS104 bundle data is processed:ANS104_UNBUNDLE_FILTER: Determines which bundles (including nested bundles) are unbundled ANS104_INDEX_FILTER: Determines which data items within a bundle have their data indexed Here are some practical examples of how to configure these filters for specific use cases:Specific Application Data This configuration demonstrates how to focus your gateway on data from a specific application. In this example, we show how to process and index all ArDrive-related transactions, but you can adapt this pattern for any application, using the App-Name tag. This approach is perfect for:Building application-specific services Creating application data archives Running application-focused analytics Supporting application infrastructure Reducing processing overhead by focusing only on relevant data In this example, the index filter uses the ArFS tag to only index ArFS-compliant data, which is a specific aspect of ArDrive applications. Index filters can be adjusted for any application's needs - the App-Name tag is particularly useful here, as data items within a bundle can have a different App-Name than the bundle that contains them.Personal Data Gateway This configuration is designed for users who want to run a personal gateway that only processes their own ArDrive data. It:Excludes common specific use case bundlers to reduce unnecessary processing Only indexes data owned by your wallet address Includes all ArDrive and Turbo app data Perfect for personal data management Personal Data Gateway All ArDrive Bundles (Excluding Common Bundlers) This configuration is useful for gateways that want to process ArDrive data while avoiding common bundlers. It's ideal for:Reducing processing overhead by excluding known bundlers Maintaining a clean dataset focused on direct ArDrive transactions Optimizing storage and processing resources Supporting ArDrive infrastructure with reduced resource requirements All ArDrive Bundles (Excluding Common Bundlers) Important Filter Considerations When configuring your filters, keep these points in mind:The unbundle filter determines which bundles are processed and unbundled The index filter determines which data items from unbundled bundles are indexed in the database When filtering by owner addresses, use the modulus of the Arweave public address in the unbundle filter Common Bundler Exclusions When configuring filters, you may want to exclude data from common bundlers:Bundler Addresses:Irys Node 1: -OXcT1sVRSA5eGwt2k6Yuz8-3e3g9WJi5uSE99CWqsBs Irys Node 2: ZE0N-8P9gXkhtK-07PQu9d8me5tGDxa_i4Mee5RzVYg Irys Node 3: 6DTqSgzXVErOuLhaP0fmAjqF4yzXkvth58asTxP3pNw Bundler App Names:Warp Redstone Kyve AO ArDrive Best Practices Start Small: Begin with conservative worker counts and adjust based on system performance Monitor Resources: Watch system memory and CPU usage when adjusting worker counts Reprocess Bundles with New Filters: Use FILTER_CHANGE_REPROCESS to reprocess bundles after changing filters Regular Maintenance: Enable background verification and cleanup features Performance Considerations When optimizing your gateway, consider these factors:System Resources: Worker counts should be balanced against available CPU cores and memory Storage Space: Indexing filters affect database size and query performance Network Bandwidth: Unbundling workers can generate significant network traffic Query Performance: More indexed data means larger databases but better query capabilities Review the Filtering System documentation for detailed filter syntax Check your system resources to determine optimal worker counts Start with basic filters and gradually refine based on your needs Monitor system performance and adjust settings as needed Optimization Strategy Focus on configuring your gateway to efficiently handle the specific data types you need. The default state processes no data, so you can selectively enable processing for your use case without worrying about unnecessary resource usage.

---

# 98. transfer - ARIO Docs

Document Number: 98
Source: https://docs.ar.io/ar-io-sdk/ants/transfer
Words: 65
Quality Score: 0.430
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

transfer is a method on the ANT class that transfers ownership of the ANT process to another wallet address.transfer requires authentication.Parameters ← Swipe to see more → Parameter Type Description Optional target string - WalletAddress The wallet address to transfer ownership to false tags array An array of GQL tag objects to attach to the transfer AO message true ← Swipe to see more →

---

# 99. getCostDetails - ARIO Docs

Document Number: 99
Source: https://docs.ar.io/ar-io-sdk/ario/arns/get-cost-details
Words: 148
Quality Score: 0.429
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

getCostDetails is a method on the ARIO class that calculates detailed cost information for a specific interaction (such as buying an ArNS record). The method determines costs based on the interaction type, the payer's address, and the funding source (balance, stake, or any available funds).getCostDetails does not require authentication.Parameters ← Swipe to see more → Parameter Type Description Optional intent string The type of interaction to calculate costs for (e.g., 'Buy-Record') false fromAddress string - WalletAddress The Arweave address that will be charged for the interaction false fundFrom string The source of funds: 'balance', 'stakes', or 'any' false name string The ArNS name for the interaction (for Buy-Record operations) conditional type string The type of purchase: 'lease' or 'permabuy' (for Buy-Record operations) conditional years number Number of years (for lease-based operations) conditional quantity number Quantity for operations like increasing undername limits conditional ← Swipe to see more →

---

# 100. setKeywords - ARIO Docs

Document Number: 100
Source: https://docs.ar.io/ar-io-sdk/ants/set-keywords
Words: 66
Quality Score: 0.428
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

setKeywords is a method on the ANT class that updates the list of keywords associated with the ANT process.setKeywords requires authentication.Parameters ← Swipe to see more → Parameter Type Description Optional keywords array An array of keywords to associate with the ANT process false tags array An array of GQL tag objects to attach to the transfer AO message true ← Swipe to see more →

---

# 101. Signature Verification Strategy - ARIO Docs

Document Number: 101
Source: https://docs.ar.io/wayfinder/core/verification-strategies/signature-verification
Words: 148
Quality Score: 0.427
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

SignatureVerificationStrategy Overview The SignatureVerificationStrategy validates Arweave transaction signatures to ensure data authenticity and ownership. This strategy provides cryptographic proof that the data was created by the claimed wallet address and hasn't been tampered with since signing.Important SignatureVerificationStrategy requires that the trusted gateway has the relevant
transaction data indexed locally. Gateways cannot proxy out verification
requests to other sources, as this would compromise the security and
reliability of the verification process. If a gateway doesn't have the
required data indexed, verification will fail.How It Works Fetch Metadata: Retrieve transaction metadata from trusted gateways Reconstruct Signature Data: Build the signature data using the received content Verify Signature: Validate the signature matches the claimed owner's public key Check Ownership: Confirm the transaction was signed by the claimed wallet Result: Pass or fail based on signature validation Basic Usage Related Hash Verification: Learn about fast integrity checking Signature Verification: Understand authenticity validation

---

# 102. approvePrimaryNameRequest - ARIO Docs

Document Number: 102
Source: https://docs.ar.io/ar-io-sdk/ants/approve-primary-name-request
Words: 85
Quality Score: 0.423
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

approvePrimaryNameRequest is a method on the ANT class that approves a primary name request for a given name or address.approvePrimaryNameRequest requires authentication.Parameters ← Swipe to see more → Parameter Type Description Optional name string ArNS name to approve as primary name.false address string - WalletAddress Public wallet address that made the primary name request being approved.false ioProcessId string Process Id of the ARIO contract.false tags array An array of GQL tag objects to attach to the transfer AO message.true ← Swipe to see more →

---

# 103. ARIO Gateway Environment Variables - ARIO Docs

Document Number: 103
Source: https://docs.ar.io/gateways/env
Words: 1250
Quality Score: 0.416
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Environmental Variables Overview The AR.IO Gateway allows configuration customization through environmental variables. These variables dictate the gateway's behavior, from block synchronization settings to log formatting. Detailed below is a table enumerating all available environmental variables, their respective types, default values, and a brief description. Note that certain variables, such as SANDBOX_PROTOCOL, rely on others (e.g., ARNS_ROOT_HOST) to function effectively. Ensure proper understanding of these dependencies when configuring.Variables ← Swipe to see more → ENV Name Type Default Value Description GRAPHQL_HOST String arweave.net Host for GraphQL queries. You may use any available gateway that
supports GQL queries. If omitted, your node can support GQL queries on
locally indexed transactions, but only L1 transactions are indexed by
default.GRAPHQL_PORT Number 443 Port for GraphQL queries. Used in conjunction with GRAPHQL_HOST to set
up the proxy for GQL queries.START_HEIGHT Number or "Infinity" 0 Starting block height for node synchronization (0 = start from genesis
block) _HEIGHT Number or "Infinity" "Infinity" block height for node synchronization (Infinity = keep syncing
until ped) TRUSTED_NODE_URL String " https://arweave.net " Arweave node to use for fetching data TRUSTED_GATEWAY_URL String " https://arweave.net " Arweave node to use for proxying reqeusts TRUSTED_GATEWAYS_URLS String TRUSTED_GATEWAY_URL A JSON map of gateways and priority TRUSTED_GATEWAYS_REQUEST_TIMEOUT_MS String "10000" Request timeout in milliseconds for trusted gateways TRUSTED_ARNS_GATEWAY_URL String "https:// NAME.arweave.dev" ArNS gateway WEIGHTED_PEERS_TEMPERATURE_DELTA Number 0.1 Any positive number above 0, best to keep 1 or less. Used to determine
the sensitivity of which the probability of failing or succeeding peers
decreases or increases.INSTANCE_ID String "" Adds an "INSTANCE_ID" field to output logs LOG_FORMAT String "simple" Sets the format of output logs, accepts "simple" and "json" SKIP_CACHE Boolean false If true, skips the local cache and always fetches headers from the node PORT Number 4000 AR.IO node exposed port number SIMULATED_REQUEST_FAILURE_RATE Number 0 Number from 0 to 1, representing the probability of a request failing AR_IO_WALLET String "" Arweave wallet address used for staking and rewards ADMIN_API_KEY String Generated API key used for admin API requests (if not set, it is generated and
logged into the console) ADMIN_API_KEY_FILE String Generated Alternative way to set the API key used for admin API requests via
filepath, it takes precedence over ADMIN_API_KEY if defined BACKFILL_BUNDLE_RECORDS Boolean false If true, AR.IO node will start indexing missing bundles FILTER_CHANGE_REPROCESS Boolean false If true, all indexed bundles will be reprocessed with the new filters
(you can use this when you change the filters) ON_DEMAND_RETRIEVAL_ORDER String s3,trusted-gateways,chunks,tx-data Data source retrieval order for on-demand data requests BACKGROUND_RETRIEVAL_ORDER String chunks,s3,trusted-gateways,chunks,tx-data Data source retrieval order for background data requests (i.e.,
unbundling) ANS104_UNBUNDLE_FILTER String {"never": true} Only bundles compliant with this filter will be unbundled ANS104_INDEX_FILTER String {"never": true} Only bundles compliant with this filter will be indexed ANS104_DOWNLOAD_WORKERS String 5 Sets the number of ANS-104 bundles to attempt to download in parallel ANS104_UNBUNDLE_WORKERS Number 0, or 1 if filters are set Sets the number of workers used to handle unbundling DATA_ITEM_FLUSH_COUNT_THRESHOLD Number 1000 Sets the number of new data items indexed before flushing to stable data
items MAX_FLUSH_INTERVAL_SECONDS Number 600 Sets the maximum time interval in seconds before flushing to stable data
items WRITE_ANS104_DATA_ITEM_DB_SIGNATURES Boolean false If true, the data item signatures will be written to the database WRITE_TRANSACTION_DB_SIGNATURES Boolean true If true, the transactions signatures will be written to the database ENABLE_DATA_DB_WAL_CLEANUP Boolean false If true, the data database WAL cleanup worker will be enabled ENABLE_BACKGROUND_DATA_VERIFICATION Boolean false If true, unverified data will be verified in background MAX_DATA_ITEM_QUEUE_SIZE Number 100000 Sets the maximum number of data items to queue for indexing before
skipping indexing new data items ARNS_ROOT_HOST String undefined Domain name for ArNS host SANDBOX_PROTOCOL String undefined Protocol setting in process of creating sandbox domains in ArNS
(ARNS_ROOT_HOST needs to be set for this env to have any effect) accepts
"http" or "https" START_WRITERS Boolean true If true, start indexing blocks, tx, ANS104 bundles RUN_OBSERVER Boolean true If true, run observer (ARIO processes), requires WALLET env var to be
set WALLET String N/A Wallet jwk file path for observer ario process LMDB_BLOCK_STORE_COMPRESSION String "gzip" Accepts 'gzip', 'brotli', or 'none'. Compresses new blocks with
specified algorithm before storing them in the local header store. Note:
Changing this after blocks have been stored locally will require re-sync
or remove local data to apply new compression setting to previously
stored blocks.LMDB_BUNDLE_STORE_COMPRESSION String "gzip" Accepts 'gzip', 'brotli', or 'none'. Compresses new bundles with
specified algorithm before storing them in the local bundle store. Note:
Changing this after bundles have been stored locally will require
re-indexing to apply new compression setting to previously stored
bundles.LMDB_DATA_ITEM_STORE_COMPRESSION String "gzip" Accepts 'gzip', 'brotli', or 'none'. Compresses new data items with
specified algorithm before storing them in the local data item store.
Note: Changing this after data items have been stored locally will
require re-indexing to apply new compression setting to previously
stored data items.LMDB_TX_STORE_COMPRESSION String "gzip" Accepts 'gzip', 'brotli', or 'none'. Compresses new transactions with
specified algorithm before storing them in the local transaction store.
Note: Changing this after transactions have been stored locally will
require re-sync or remove local data to apply new compression setting to
previously stored transactions.LMDB_DATA_STORE_COMPRESSION String "gzip" Accepts 'gzip', 'brotli', or 'none'. Compresses new data with specified
algorithm before storing them in the local data store. Note: Changing
this after data has been stored locally will require re-sync or remove
local data to apply new compression setting to previously stored data.CONTIGUOUS_DATA_CACHE_CLEANUP_THRESHOLD Number 1000 Sets the number of contiguous data items to cache before cleaning up ENABLE_FS_HEADER_CACHE_CLEANUP Boolean true If true, enable header cache cleanup for the fs cache (this will prune
headers that are older than HEADER_CACHE_CLEANUP_THRESHOLD) HEADER_CACHE_CLEANUP_THRESHOLD Number 2000 Sets the height threshold for which to clean up headers CHUNK_DATA_CACHE_CLEANUP_THRESHOLD Number 250000 Sets the number of chunks to cache before cleaning up MANIFEST_CACHE_CLEANUP_THRESHOLD Number 250000 Sets the number of data items to cache before cleaning up manifest cache ANS104_DATA_INDEX_CACHE_CLEANUP_THRESHOLD Number 50000 Sets the number of data items to cache before cleaning up ANS-104 data
index cache REDIS_CACHE_URL String undefined Redis cache URL for external caching of data items, chunks, and tx
headers REDIS_CACHE_TTL_SECONDS Number 3600 TTL in seconds for Redis cache entries AWS_S3_BUCKET String undefined AWS S3 bucket to save/retrieve block files AWS_REGION String us-east-1 AWS S3 bucket region AWS_ENDPOINT String " https://s3.amazonaws.com " AWS S3 bucket endpoint AWS_ACCESS_KEY_ID String undefined AWS S3 bucket access key AWS_SECRET_ACCESS_KEY String undefined AWS S3 secret key MIN_CONFIRMATIONS Number 10 Minimum number of confirmations needed for a transaction to be returned
by the /tx endpoint INDEX_BLOCKS Boolean true If true, the gateway will index blocks as they're synced INDEX_TX Boolean true If true, the gateway will index transactions as they're synced INDEX_DATA_ITEMS Boolean true If true, the gateway will index data items as they're synced INDEX_TX_OFFSET_LISTS Boolean true If true, the gateway will index the chunks of block data and transaction
data offsets ENABLE_MEMPOOL_WATCHER Boolean false If true, the gateway will watch the mempool for new transactions and
save the txs headers ENABLE_WEBHOOKS Boolean false If true, allows the gateway to act as a client and execute webhooks when
local state changes WEBHOOK_TARGET_SERVERS String "" Comma separated list of target webhook servers (URLs) WEBHOOK_INDEX_FILTER String {"never": true} Webhook events are emitted only if incoming transactions satisfy the
specified filter WEBHOOK_BLOCK_FILTER String {"never": true} Block webhook events are emitted only if incoming block satisfies the
specified filter PROMETHEUS_METRICS_ENABLED Boolean false If true, the gateway will expose Prometheus compatible metrics via the
/metrics endpoint NODE_ENV String development Node.js environment setting LOG_LEVEL String info Log verbosity level ← Swipe to see more →

---

# 104. ARIO Docs

Document Number: 104
Source: https://docs.ar.io/ar-io-sdk/ario/arns/increase-undername-limit
Words: 114
Quality Score: 0.407
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

increaseUndernameLimit increaseUndernameLimit is a method on the ARIO class that increases the number of undernames an ArNS domain can support. Each domain starts with a default limit of 10 undernames and can be increased up to a maximum of 10,000 undernames.increaseUndernameLimit requires authentication.Parameters ← Swipe to see more → Parameter Type Description Optional name string The ArNS name to increase the undername limit for false increaseCount number The number of additional undername slots to purchase (up to 10,000
total) false fundFrom string The source of funds: 'balance', 'stakes', 'any', or 'turbo' true tags array An array of GQL tag objects to attach to the transfer AO message true ← Swipe to see more →

---

# 105. ARIO SDK Release Notes - ARIO Docs

Document Number: 105
Source: https://docs.ar.io/ar-io-sdk/release-notes
Words: 5988
Quality Score: 0.406
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

AR.IO SDK Changelog Overview Welcome to the documentation page for the AR.IO SDK release notes. Here, you will find detailed information about each version of the AR.IO SDK, including the enhancements, bug fixes, and any other changes introduced in every release. This page serves as a comprehensive resource to keep you informed about the latest developments and updates in the AR.IO SDK. For those interested in exploring the source code, each release's code is readily accessible at our GitHub repository: AR.IO SDK change logs. Stay updated with the continuous improvements and advancements in the AR.IO SDK by referring to this page for all release-related information.3.9.1 (2025-03-31) Bug Fixes ario: throw errors if fail to find epoch data (b1bb024) cli: update other vault APIs (0916e96) cli: update types and errors in cli (4b5aebd) io: do not return undefined for any API (ce6a077) 3.9.0 (2025-03-27) Bug Fixes ao: update retry logic on send, include more verbose messaging (70e6678) comments: cleanup (7444be3) exports: move types/browser exports above import/require (280d8bd) gql: add fallback to go to CU for epoch distribution data (12be216) logging: log errors more verbosely on read fails (c9fab18) messaging: only retry messaging if no id was received (9cbffef) options: add write options to addVersion (95ccef0) PE-7802: add logo to SpawnAntState type and options (c7adfca) send: add comment on not retrying on send (692938a) send: log on max attempts in send as well (2399d23) versions: export versions class (6368c44) Features versions: add ANT version class (c9ec5c5) versions: add versioning handlers to ant registry (c681909) 3.8.4 (2025-03-12) Bug Fixes types: add vault controller as optional to vault (f26bdb3) 3.8.3 (2025-03-05) Bug Fixes add missing maxDelegateRewardSharePct field from AoGatewayRegistrySettings (87942ad) schema: remove viem and use string for AOAddressSchema (090c799) schemas: update ant schema to accept eth support (7bc7df4) tests: update unit test to check loosely on eth address (b8e202b) 3.8.2 (2025-02-25) Bug Fixes missing break for happy path through send (e55ecc1) modify retry logic for send to only retry on exceptions from ao.message or ao.result (229df6b) modify retry logic to only occur on dryrun exceptions (c578893) protect against if retries is 0 (6aa1b58) 3.8.1 (2025-02-21) Bug Fixes mainnet: default to the mainnet process ID (a96713c) [3.8.0] (2025-02-20) View changes on Github Features mainnet: update constant to the mainnet process ID (4a11840) [3.7.1] (2025-02-19) View changes on Github Bug Fixes types: overload getEpoch to provide correct types on specific param requests (bafce74) 3.7.1-alpha.1 (2025-02-18) Bug Fixes types: overload getEpoch to provide correct types on specific param requests (bafce74) [3.7.0] (2025-02-17) View changes on GitHub Bug Fixes types: fix epoch settings type (a306baa) Features distributions: init paginated distributions cli command PE-7641 (8810ec6) distributions: init paginated getEligibleDistributions PE-7641 (9ba192f) distributions: remove eligible rewards from get epoch return PE-7641 (4437eaa) read commands: add commands epoch-settings, demand-factor-settings, read-action (821b6f6) [3.7.0-alpha.1] (2025-02-17) View changes on GitHub Features distributions: init paginated distributions cli command PE-7641 (8810ec6) distributions: init paginated getEligibleDistributions PE-7641 (9ba192f) distributions: remove eligible rewards from get epoch return PE-7641 (4437eaa) read commands: add commands epoch-settings, demand-factor-settings, read-action (821b6f6) [3.6.2-alpha.1] (2025-02-17) View changes on GitHub Bug Fixes types: fix epoch settings type (a306baa) [3.6.1] (2025-02-17) View changes on GitHub Bug Fixes types: correct types for demand factor and gateway settings, update tests (583ffeb) [3.6.0] (2025-02-17) View changes on GitHub Bug Fixes ant ids: update module and lua source ids to ant 15 (b8d6c96) deps: bump aoconnect sdk (3896ee8) ids: bump module and lua source ids to ant 16 (cf6d0de) page size: set page size to 1000 on fetch all records util (5fa802e) request name: add fund from tag on request primary name api (be362ad) Features ant: add sorting to ANT records responses by default (4e74825) [3.5.3] (2025-02-12) View changes on GitHub Bug Fixes arns: use buy-name buy default for getCostDetails (d71f402) [3.5.2] (2025-02-12) View changes on GitHub Bug Fixes arns: use buy-name when fetching token cost by default (5585b4d) [3.5.1] (2025-02-09) View changes on GitHub Bug Fixes gql: use goldsky by default for fetching gql data (57f4948) zod: fix zod enforcement (08d5168) [3.5.0] (2025-02-06) View changes on GitHub Bug Fixes ant: add priority as an attribute on ANTs (f0c6758) ant: update types and add index for easy enforcement (3dd6df5) ant: use deterministic sort with no locale comparison (7f2e067) evolve: use fetch for data instead of arweave (6deb91c) module ids: update ant lua and module id (97e0628) Features arns stats: include arns stats type on epoch PE-7562 (f92ee91) [3.4.1] (2025-02-03) View changes on GitHub Bug Fixes epochs: getPrescribedObservers and getPrescribedNames should get data from GQL/arweave vs. the contract (d8fa25d) gar: mark old fields as deprecated, add new ones (18ca1b4) [3.4.0] (2025-01-31) View changes on GitHub Bug Fixes ant: add setUndername and setBasename apis (ce4abfe) Features ant apis: add commands for new methods (931e621) revokable vaults: init revokeVault and vaultedTransfer commands and methods PE-7514 (6ca44a1) vault apis: assert lock length in range PE-7541 (3585643) vault apis: init write methods+commands for create/extend/increase vault PE-7541 (b2e3cab) [3.3.1] (2025-01-29) View changes on GitHub Bug Fixes ant: bumps ids (8eb2e38) ants: module bump _wSmbjfSlX3dZNcqE8JqKmj-DKum9uQ_jB08LwOKCyw (8d442e0) ant: update ANT ids (9f37e76) boot: add boot loader logic to ant spawn util (f00ab47) lua: update lua code id (76822a2) tags: remove extra tags from spawn util (f308b84) [3.3.0] (2025-01-24) View changes on GitHub Bug Fixes ants: tag with ao authority (f08af65) ao: add ao client for ants in emitter (489c040) arconnect: use signDataItem method, signature is deprecated (11e2378) arweave: use defaultArweave when fetching data (acf3e02) error handling: trim escape codes from thrown error PE-7417 (6dcf641) error handling: use a consolidated regexp for msg.Error and msg.Tags.Error PE-7417 (770a81e) gql: add retries when fetching epoch distribution data from arweave (42c1534) ids: add module and code ids (7474ccd) import: use import from file (f8fe7b4) logs: add processId to read error logs, include stack trace (51b7e38) module id: update ant module id (9e122af) pagination: allow nested keys in sortBy pagination params utility type PE-7428 (8ae8d88) spawn: spawn ANTs with a custom ANT module instead of aos module (2359b5b) test: double test timeout (4a52b81) ts: add root dir (e33eba5) types: simplify types for init functions, cleanup contructors (2197d99) types: simplify types for init functions, cleanup contructors (cd0afa6) Features add writeAction sdk/cli command for utility PE-7417 (1953504) get all delegates: init getAllDelegates type/handler PE-7221 (b015582) get all delegates: init list-all-delegates command PE-7221 (a632563) get all vaults: init command PE-7220 (e74a6e4) get all vaults: init type and ARIO method PE-7220 (e8f5a74) io: fetch historical epoch data from gql (b627d55) [3.2.0] (2025-01-13) View changes on GitHub Bug Fixes ant: add getLogo api (eddc3a8) ario: use standardize tags for registration fees and cost details (3f5fdbe) io: remove new APIs (d916ab6) types: add Buy-Name to supported intent types (b5a6d01) Features ario: add new APIs to ario class, update ant removePrimaryNames tags (61e0ee8) cost-details: include returnedNameDetails when they exist on cost-details PE-7371 (9edfb79) [3.1.0] (2025-01-02) View changes on GitHub Bug Fixes don't get old arweave block timestamps on read actions (1792ee8) don't return null when stringified null is found in message data on ao.read (c5873e6) eth signer: use a unique anchor in ans-104 headers (8cd5587) format process errors to be more user friendly PE-7327 (3449e32) io: fix AoEpochData type, add prescribedNames (1ba3588) tags: prune out empty tags (de0ec83) types: fix funding plan vaults type (1cea7db) types: revert prescribedObserver type (ca60f6f) Features cost-details: init cli command get-cost-details PE-7114 (674626e) cost-details: init new cost method for exposing fundingPlan and discounts PE-7114 (c6910c8) fund-from: add Fund-From tag to eligible methods/commands PE-7291 (4d47270) primary names: add processID to read APIs PE-7307 (e01e6ce) remove usage of Tags.Timestamp in favor of computing epoch indexes PE-7338 (ee1bea0) [3.0.0] (2024-12-10) View changes on GitHub Bug Fixes ar.io cli: use global program from cli.ts scope for ar.io command PE-5854 (3e83298) expose instant param for decreaseOperatorStake function arg type (2fd1f5d) lua id: change lua id (d4907db) remove un-used import (5db9ac0) spawn-ant: use a valid default ttlSeconds (aea4aa7) use Keywords for setKeywords (19ab3ad) [3.0.0] (2024-12-10) View changes on GitHub Bug Fixes ar.io cli: use global program from cli.ts scope for ar.io command PE-5854 (3e83298) expose instant param for decreaseOperatorStake function arg type (2fd1f5d) lua id: change lua id (d4907db) remove un-used import (5db9ac0) spawn-ant: use a valid default ttlSeconds (aea4aa7) use Keywords for setKeywords (19ab3ad) Features ar-io cli: init balance command and CLI setup (94c630b) ar-io cli: init join-network command (fc9dc07) ar.io cli: add --cu-url global parameter PE-5854 (2346f5b) ar.io cli: enable confirmation prompts on each write action PE-5854 (9ac88bb) ar.io cli: include --tags input in write actions PE-5854 (4b9d03e) ar.io cli: init buy/upgrade/extend-record, inc-undernames, sub-auc-bid, req-prim-name PE-5854 (5eb3df2) ar.io cli: init decrease-delegate-stake instant/cancel-withdraw commands PE-5854 (f0e7b9e) ar.io cli: init epoch read commands PE-5854 (61e0fc3) ar.io cli: init get token cost and auction prices PE-5854 (867807d) ar.io cli: init get-delegations, get-arns-record, list-arns-records commands PE-5854 (d7cbde3) ar.io cli: init get-gateway-delegates and get-gateways commands PE-5854 (35a33ef) ar.io cli: init get-vault and get-gateway commands (d262243) ar.io cli: init increase/decrease-operator-stake commands PE-5854 (1312860) ar.io cli: init info command (c721374) ar.io cli: init leave-network, delegate-stake PE-5854 (40ebe06) ar.io cli: init pagination from CLI layer PE-5854 (f52ce1f) ar.io cli: init read/write ANT commands PE-5854 (392a9ef) ar.io cli: init redelegate-stake PE-5854 (7bf4a8e) ar.io cli: init save-observations PE-5854 (f80bb8c) ar.io cli: init spawn-ant and get-ant-state PE-5854 (119c765) ar.io cli: init token-supply command (b58d782) ar.io cli: init transfer command (5553584) ar.io cli: init update-gateway-settings PE-5854 (7a6aa4b) ar.io cli: stringify outputs for command line compatibility (3c04cac) ARIO token: change all IO references to ARIO (4f8135d) ARIO token: update all IO references to ARIO (8fb2188) returned names: remove/replace auction APIs in favor returned names (2c9826f) BREAKING CHANGES ARIO token: All exported IO and IOToken are now repleced with ARIO and ARIOToken respectively PE-7225 [2.6.0] (2024-12-05) View changes on GitHub Bug Fixes lua id: bump lua id for ANT 9 (9e8e7e8) use Keywords for setKeywords (99cccd4) Features get demand factor settings: init new IO method PE-6894 (ad2eb36) init get gateway registry settings PE-6895 (bb7b6b4) [2.5.5] (2024-11-28) View changes on GitHub Bug Fixes io: update gateway delegates api, add to README (65aa6a8) [2.5.4] (2024-11-28) View changes on GitHub Bug Fixes primary: support primary name in token cost API (b4edf47) [2.5.3] (2024-11-27) View changes on GitHub Bug Fixes ant lua id: update ant lua id (54ff68b) ant: update write handler types removes evolve handler name (d9f5de4) handler names: add primary name handlers (5192c09) [2.5.2] (2024-11-25) View changes on GitHub Bug Fixes io: fix tag for requestPrimaryName API (bdaeaaf) io: updated types and fixed apis for primary name requests (a297628) [2.5.1] (2024-11-22) View changes on GitHub Bug Fixes primary names: update type for getPrimaryNameRequest (bdd3a9f) [2.5.0] (2024-11-22) View changes on GitHub Bug Fixes ant: revert breaking change on records for ANT (58db878) arns: update reserved names to pagaination api (dacf0c5) cjs: remove ant validation from cjs test (50b8290) errors: we should be checking the result.Error as well as tags (7ffe131) eslint: remove unnecessary rule config (03a0552) getHandlers: remove redundant check (b0c9548) handlers: update handler name list (251695e) id and test: add test for old ant and add lua source id for new code (77601b2) io: add getDelegations to AoIORead (7c30c9b) io: use helper for computing timestamp (ffe6ff3) lint: ignore underscore vars (2c84d3d) lint: update lint rule for ignore args (136e44a) lint: update linter to allow nullable string (b985139) lua id: rollback lua id (89b8392) primary: add additional ANT handlers for primary names (c98b136) readme: make api headers h4 (395f7fb) readme: update readme with new apis on ant class (bce76d2) readme: use real outputs in example (1529f79) setLogo: call param txId instead of logo (cda5e1d) source id: name the source id tags the same on evolve and spawn (058c829) spawn: add lua source id to spawn (8850ed2) test: remove old test for validate (14a77dc) tests: add test for old ant (0489cb6) tests: add unit tests for util and move parsing of records to uitl (2d08c9a) tests: update ANT in tests to use v8 ant (1eff8a9) types: modify AoDelegation type (18bb755) types: restructure type construction (2ef04db) validation util: remove validation util (d803e59) validator: add comments and reformat into a more clear loop for creating the validation config (ea3e70c) vaults: add API for gateway vaults (923b2cd) Features delegations: add getter for staked and vaulted delegations PE-7093 (7182942) delegations: add SDK function to retrieve an address's delegations PE-7093 (07c9107) getRecords: update getRecords to return as flat array of objects (b9808c1) io: add getAllowedDelegates to IO (7d143e0) PE-6910: support primary name APIs (6ace606) PE-6910: support primary name APIs (82a5b44) redelegate stake: init IO methods PE-7159 (7539dd2) setLogo: add set logo api to ant class (c5812b1) util: move validation util to ant class (cad7149) validation util: simplify validation util (cd57929) validations: add write validation util (69fc131) [2.4.0] (2024-11-12) View changes on GitHub Bug Fixes ant: add reassignName to ant implementation (9e705a9) auctions: fix submitAuctionApi to accept type and years (6780a80) auctions: update auction APIs and types (5fd2ccc) auctions: update read APIs to fetch auctions, use vite example dis active auction (32001c2) auctions: update types and add intervalMs (bc21200) corrected AoVaultData field to be startTimestamp (b9888bf) delegates: fixes type (ae7be5c) emitter: do non strict checks on state in arns emitter (6566a3c) emitter: provide strictness in constuctor (060df05) exports: add exports to barrel file (fec094e) exports: dont export http stuff) (d6369aa) io: consolidate instantGatewayWithdrawal and instantGatewayWithdrawal to just instantWithdrawal, update `cancelWithdrawal (ea9f3eb) io: include address in delegate type for gateway (46ef1a7) lint: add lint fix and missing bracket (72446aa) PE-7080: add apis for fetching paginated delegates (e3d4af2) schema: add strict mode to ANT with default to false (4864abf) schemas: add passthrough on schema checks for ants (9cb2776) schemas: add zod schemas and tests (feba587) schema: specify HandlerNames instead of Handlers (44cc472) schemas: update ant schema and tests (f3284ed) schema: update handlers schema (6ec52e4) strict: allow for passing in strict mode on apis (e147220) tag: small tweak to instant tag (663de6f) test: correct params for get record (f999c49) tests: add esm tests and remove redundant cjs tests (95244ea) tests: add js path on imports (db1520a) tests: simplify strict check on test (62c9140) types: add back delegates for AoGateway (d337a74) types: update types to match contract (cb7d2b4) types: use generic on PageParms for sortBy, update delegate types (7a1abc4) util: create schema parsing util to pretty format errors (367537a) validations: add zod schema validations on ant returns (163c2f1) withdrawls: update API for cancelling withdrawls to allow delegate and operator withdrawls (5cb680a) Features ant: adds set-keywords and set-description methods for ants) (3b260a2) ant: support releasing of name of ANTs (16363e8) arns: add upgradeRecord API (9c1726d) auctions: add auctions api to IO classes (974897b) delegates: add instant delegate withdrawal for a fee (4b4cb8f) getVault: init IO method PE-7081 (0e3cde2) paginated vaults: init SDK paginated vaults PE-7081 (6d079f9) paginated vaults: use flat array over nested vaults PE-7081 (e17cfb7) [2.3.2] (2024-10-16) View changes on GitHub Bug Fixes io: add getDemandFactor api (feab461) io: update getTokenSupply to type that returns full breakdown of tokens (e790055) types: add totalEligibleGateways to AoEpochDistributionData type (9a35d39) types: update gateways to include services (a3fe5b4) [2.3.1] (2024-10-09) View changes on GitHub Bug Fixes use AoEpochObservationData type to match what is coming back from contract (684abf3) [2.3.0] (2024-10-08) View changes on GitHub Bug Fixes ao: check messages is not empty to avoid .length error when evaluating outputs of dryrun (a7b4953) logs: enable logging in spawn and evolve utils (08ce71a) luaID: update lua id to latest for ant source code (9c13dd3) main: merge main back to alpha, release hotfixes on alpha (9299427) types: add source code tx id to ant state type (8949f04) types: fix types on ant (3bdb3a6) types: remove restricted type (b1fac75) types: update type and tests (877b03f) types: update types (883ffb3) Features delegates: add cancel delegate withdrawal method (a3827dc) io: add api for querying get registration fees handler to AoIORead class (7b3909f) [2.2.5] (2024-09-26) View changes on GitHub Bug Fixes ant: allow sending tags on ant write interactions (99c24f8) [2.2.4] (2024-09-26) View changes on GitHub Bug Fixes types: update getInfo types on IO (7a0d20d) [2.2.3] (2024-09-25) View changes on GitHub Bug Fixes types: update type and tests (877b03f) [2.2.2] (2024-09-23) View changes on GitHub Bug Fixes deps: update arbundles to @dha-team/arbundles (c41e4e4) [2.2.1] (2024-09-16) View changes on GitHub Bug Fixes types: correct totalEpochCount for gateway stats (f82fed8) [2.2.0] (2024-08-30) View changes on GitHub Bug Fixes logger: permit logger as argument for typeguard util and default it (45df626) register: update spawn ant to register at end of spawn (4320c80) signer: add typeguard util for aoSigner (0d7f210) signing: add aosigner to contract signer (3b0495a) tests: dont send messages to ao in e2e tests (e7108da) tests: reconfigure test structure (1872a26) tests: use test-wallet fixture in tests instead of generating anew each time (27a5dc2) typeguard: return true or false in typeguard and log the error (4b851c5) types: update types for epoch distributions (5aedf50) util: use ANTRegistry class for registering ant on spawn instead of aoconnect (350112d) Features ant id: update lua ant id to latest (968c30e) util: add AoAntState typeguard util (c6f457f) [2.1.0] (2024-08-07) View changes on GitHub Bug Fixes actions: ignore engines in action (7f6f87d) ant lua id: update to version Flwio4Lr08g6s6uim6lEJNnVGD9ylvz0_aafvpiL8FI (8cbd564) ant: remove data from ant object, none of our ant methods require data attributes (0f267c1) ao: update AoProcess to only support string | undefined (584aee1) arns: update event emitter to provide more events and logs while loading arns records (8775896) constants: do not set env var for ant registry (9e61cc7) deps: move arconnect to dev deps (34f07d2) emiter: use a set to filter out duplicate (7887af9) emitter: add page size param for emitter to increase amount of records per page to 50k (b6f2157) errors: use any type on error (f14ed5a) events: use arns name space for events (1d67dfe) evolve: call eval twice to ensure evolve txid is set (a6261e5) evolve: dont double eval (a2a9121) evolve: fixed evolve somehow (b06503b) example: dont spawn in example (d1d5147) example: remove unused arweave instance (d0035c0) format: fix linting issues in format (b72dc1f) gateway stats: update gateway stat types (a59b166) io: add api that returns the total token supply (261c85c) io: no longer add data to save observations (c017b52) lint: fix lint errors and warnings (e532f4e) lua id: set new lua id in constants (e4c3aaf) naming: name AoSigner property aoSigner (4604524) records: update arns emitter to use ant registry (e55a67b) signer: describe signing function as signer vs aoSigner in case of signer type changes (3b23f80) signer: move createAoSigner to be a util (7f7a0e6) signer: pass in signing function instead of signer class (cba16e3) signer: use AoSigner type as return type (8e95edd) spawn: update spawn to use ant registry id in the tags (28dae7f) tests: check the return of ACL on ant tests more granularly (350bab1) tests: update e2e tests to only read from ant registry (a61e0bf) tests: update web test to use ANT registry in app (38ca913) tests: use const for unchanging test vars (9f965e1) test: update browser test with data test id and render checks (93741cb) test: use a known wallet adddress in tests (9dac280) todo: remove completed todo comment (c868522) types: add gateway weights to AoGateway (e725198) types: check info on evolve util first (a44cca1) types: remove deprecated types (c674876) types: update AoGateway to include weights (5368668) types: update type name to what contract returns (99edbad) use custom event names to avoid overlap (5b919ac) utils: revert new util (c959c81) utils: update util to use ant registry (b2223d4) Features ant registry: add ant registry class (2056674) evolve: add evolve util (47bfe20) signing: add window arweave wallet to available signing options (7596aec) [2.0.2] (2024-07-12) View changes on GitHub Bug Fixes types: update gateway settings type to only support observerAddress (13e073b) [2.0.1] (2024-07-11) View changes on GitHub Bug Fixes logger: fixes the console logger to respect the log level provided by web clients (99d7993) [2.0.0] (2024-07-11) View changes on GitHub Bug Fixes arweave: use default arweave in IO (21d25b9) deps: replace bunyan or console depending on the client environment (9d940aa) log: allow log level configuration for clients (9cb0981) log: replace bunyan with winston to ensure browser compatibility (80b38e0) Features io: add paginated gateway support for larger state objects (e.g. balances, records, and gateways) (b23efa8) util: add utility for fetching all records (8df2aac) io: add leaveNetwork API (54222ce) BREAKING CHANGES deps: removes all smartweave implementations using warp-sdk. The result is an only AO compatible ANT and IO network contracts. Some utilities are preserved due to their usefulness.imports: modifies web named exports to provide esm and cjs exports instead of minified bundle. The web bundle was causing issues in bundled projects, and polyfills are no longer provided by default. Refer to the README for specifications on how to use the SDK for a web project.[1.2.2] (2024-07-11) View changes on GitHub Bug Fixes api: ensure timestamps are always in miliseconds (93b162f) [1.2.1] (2024-07-04) View changes on GitHub Bug Fixes io: default the IO process to use testnet (61bca5c) [1.2.0] (2024-07-03) View changes on GitHub Bug Fixes ant: add event emitter util for fetching ants (ee5287b) ant: fix read api and update types (977e0e3) ant: handle when no data is returned (1de6610) ants: separate out interfaces (60fd593) ant: update apis to implement interface (9c54db0) ant: update interface to expect undername instead of name for ant records (416cb3d) ao ant: add handler for get state (fd20aa7) ao reads: safely parse json (1ff5410) ao: add AR-IO-SDK tag to process interaction (e5b5603) ao: add default timestamp to getTokenCost (36fed1b) ao: add getPrescribedNames for epoch api (747fad2) ao: add retries to read interactions (67d59e2) ao: fix tag for join network, update observation response (556f5d5) ao: prune tags on joinNetwork (31978f9) ao read: fix interface to have ant getState api (4e95bbd) aos: update aos module id and lua id (e19139e) ao: support connection config params in AO (3e6a246) ao: support tags for all write interactions (67f8da9) ao: update APIs for ao interface to be more descriptive (f07ac36) ao: update epoch interfaces to support various inputs (ddc4c10) ao: update send on process to use proper signer and evalute result (4e2f65d) ao: update stake interface (427e8ba) ao: use types and connect config in ao process to wrap connect from ao (05b07cf) buy: require processId on buyRecord (cc5859f) deps: add eventemitter3 dep (1d50cd1) deps: use p-limit-lit to avoid jest issues (05e0673) emitter: add a end and some console logs in the example (bc4e6b8) emmiter: rename and move throttle to be variable powered (f9cf40d) epochs: fix epoch default timestamp (ffb9df7) events: return process ids on end of fetching (15e3f44) handlers: update handler names (720b178) io: add buyRecord API (30d5e74) io: add epoch-settings api and tests (56555ea) io: add init to provide custom process (8811016) io: separate out io/ao contract interfaces (d96fa59) io: update arns interactions on registry contract (9befe2a) pLimit: add pLimit for util to avoid ao throttling (5b13560) readds incorrectly removed descriptions (c77217a) revert purchasetype tag (2dc08df) spawn: add option state contractTxID to track where init state is from (1745766) tags: make remaining tags ans-116 compliant (d034c8c) tags: use updated ans-116 tag format for actions (261b788) timeout: increase timeout period on arns emitter (b5ddb5f) type: default to unknown return type for json (0bddce0) types: add ao ant state type (02dbacd) types: update some types for arns names and contract state (2d23241) updates to use IO class and process terminology (ec45d66) util: initial implementation of get ant process for wallet (885fa31) Features ant: add balance APIs to ant interface (ec67440) ant: add utility for fetchint ant modules owned by wallet (01f7ec9) ants: support ANT apis in SDK (b187aeb) ao utils: add spawn ant util (d02566e) ao: experiment with initial implementation of ao contract (6118cea) getInfo io: add getInfo method to io class (4ef25ec) IO: implement io/ao classes that call process apis (aab8967) [1.1.1] (2024-06-06) View changes on GitHub Bug Fixes api: default evaluation options on getArNSReservedNames api (0a1f22e) [1.1.0] (2024-06-03) View changes on GitHub Bug Fixes api: make evaluation options optional on the interface (9e5a1c0) api: remove unused variable for epochBlockHeight (98c5ebc) arweave: default to arweave.net (84c9653) axios: add back axios-retry (9aae4de) errors: throw AbortError on signal aborted (63bd395) getContracts: only implement util for now (6b29c2f) gql query: don't abstract the data protocol query (f0b8f77) imports: import type from base route warp-contracts (bf99a85) init: allow signer to be undefined and if so return readable (b6a05e2) init: fix type for init to allow undefined signer (0a64ea9) init: remove unnecessary destructuring (81af1af) interface: remove epochBlockHeight from interface (b646f08) types:remove DataItem from WriteInteractionResult (eadb1a1) types: use gql node interface for dataProtocolTransaction (79cebd9) warp: ensure contract init on read interactions (bc3d1b8) Features getContracts: add get contracts on network specific providers like WarpContract (603d36e) gql util: add smartweave gql utils (5ea3aab) write: add tags support to write interactions on warp-contract and saveObservations (46eb4c9) [1.0.8] (2024-05-29) View changes on GitHub Bug Fixes api: add getPriceForInteration api to ario contract (3b8083c) bundle: minify web bundle (9266676) api: use function map for method name (439ec1f) reserved: add reserved arns name get methods (ad203ef) signer: check if method is property of signer before using (c52783c) signer: modify signer to assume the signer type based on public key being undefined (b775c96) test: add dockerfile for running tests in certain node environments (86cf2ad) [1.0.7] (2024-05-23) View changes on GitHub Bug Fixes contract: add extendLease and increaseUndernameSupport apis (1b13b5e) types: fix the AtLeastOne type (ffd0869) deps: force arweavve to 1.15.1 (2448598) contract: make params required - properties and note (89db674) types: update tests and use overwrite type to allow mIOtoken for certain paramaters (badcece) api: change to increaseUndernameLimit (9b72c1e) docs: update ario apis (4af0862) tests: update extend test util to include a test domain (e959b7c) token: add mIO and IO token classes to exports (f47f7d5) types: add delegated gateway type (c877496) types: export the token types (dfc83ae) types: remove visible types (6ab1fc3) types: update Gateway delegates type to use the new GatewayDelegate (ac7e924) warp: bump warp version (db7344d) [1.0.6] (2024-05-07) View changes on GitHub Bug Fixes warp: bump warp to fix AbortError issue on warp imports for web (c9a5613) [1.0.5] (2024-05-02) View changes on GitHub Bug Fixes cjs: provide path alias for warp in cjs export (7f9bf9a) logger: replace winston with bunyan (0488f75) util: add FQDN regex that matches ArNS contract (e6d7396) utils: manally conver from b64 to b64url to avoid web polyfill issues (766035c) utils: use base64 for fromB64url util (42302ef) warp-contract: correctly throw error in write interaction (c2368dd) [1.0.4] (2024-04-30) View changes on GitHub Bug Fixes ario: update joinNetwork to accept observerWallet param (6a32dd1) [1.0.3] (2024-04-26) View changes on GitHub Bug Fixes signer: set owner before signing data (0b558f5) [1.0.2] (2024-04-25) View changes on GitHub Bug Fixes arweave: default to the arweave node import to avoid issues with browser environments (fc8c26e) cacheurl: use default cache url in warpcontract (a676a3c) init: cleanup init overload methods and tests (fa328d2) lint: address lint issue in ArIOWriteable (4a3ee89) tsconfig: modify some tsconfig settings to get isolated configs for web/cjs/esm (46b7acc) typeguards: make type guards accept unknowns (7f285bb) types: use generic types and modify the requirements for init functions (9350f78) utils: add writeInteraction types and update base64url logic (4f5476b) [1.0.1] (2024-04-23) View changes on GitHub Bug Fixes docs: improve README docs interface documentation for ArIO clients (b0da48c) [1.0.0] (2024-04-23) Bug Fixes actions: bump node setup action (4eb49cd) actions: freeze lockfile (dba7313) contract add cache config in ario constructor (1f3c0ba) ant: add ant contract to exports (a2ff57b) ant: add signer to ant test (4581b8d) ant: default evaluation options for ant apis that do not take an… (#25) (0c8b55d) ant: default evaluation options for ant apis that do not take another parameter (7c59033) ant: default evaluation options for apis that do not require them (72b57d5) ant: fix API for getRecords (c714aa3) apis: remove epoch from distributions and observations (7b2d279) arbundle version: pin version (35ffab6) arbundles: update arbundles import (f02d83f) ario: add cache config in ario constructor (#11) (ecb279d) ario: formatting (c61570a) ario: make state provider nullable and default to remote arns-service provider (fa1cb72) ario: re-add contract default config (2296cc3) ario: remove unused cache property (7f2d02e) build: add setImmediate polyfill for web only (ad36776) build: remove redundant exported type (134319b) cache: remove cache folder (2ac9427) cacheURL: update ario cache url setting pattern to use custom url appropriately (c76e67d) cache: validate arweave id before setting it (5ba1175) casing: revert to lower case casing (b5da0ab) comments: make class logger private, remove comments (7483246) connect: add init static function on ario class to create interaction classes (765f39c) contract configuration: return cache url as well (b4a7bc3) contract functions: correct contract function names (ad9bc56) contracts: add configuration view method and update types (4fae4a2) contracts: remove write method and type from remote contract (740d8b8) contracttxid: make contractTxID require in remote state cache instance (dc82d21) contracttxid: make contractTxID required in remote state cache instance (#10) (bf651bb) ctrl flow: remove else from control flow (4b3c4c2) deps: pin arweave (d39391c) deps: remove axios-retry, will implement later (0218e95) deps: remove extra crypto-browserify (9b42898) deps: remove warp-contracts-deploy from deps (9d4f9fa) docs: remove docs folder (47e8403) drywrite: throw on bad drywrite and continue if successful (5052c0a) eslintignore: remove old file names (415c163) eslint: remove eslint comments and use this signer (32530eb) esm: add polyfills for crypto (dd8fbfe) esm: add polyfills for crypto (#27) (553822c) example web: update ario instatiation (77c6842) example: escape quotes in packagejson for example package json (fb47de0) example: simplify example and remove unused method on remote cache (81637f8) examples: update comments and fix package.json (db7140b) examples: update examples to use devnet (cc037ac) examples: update examples with records methods, and balance methods (a2d2a02) exports: add arweavesigner and arconnectsigner to exports, clean up docs (c7860ed) exports: update exports in indices (f794437) exports: update package exports to have index in src folder (2cce9e3) files: clean git cache of duplicate casing (e9eaa2d) filters: punt filters (1c23cb3) fixture: add type to arns state fixture (5bcac32) formating: format (3f30f77) gar write: fix types and flow on gar write (f5e7774) gateway: update gateway settings to support autostake (82c6840) generics: use named generic (4b647f0) gitignore: remove cache from gitignore (2867abc) git: test fix with file casing issue (c3611ee) headers: use source-version for header (2b26d88) http: add headers sdk headers to http config (94810ed) husky: add commit hooks (885ce68) imports: update to use indexed imports from warp (1242568) indentation: fix indentation in examples (a266731) interface: removed filters and added base records types (849834d) interface: rename interface to ContractCache (2a0a765) jest: remove extra config (014fbde) lint: disable no-any warning certain types (de5f108) lint: formatting (21224e2) logger, errors, http: Updated to axios and axios-retry, added winston logger, more extensive custom error objects (b944f4d) logger: remove unused logger property (9501d1d) logs: removing debug logs (f025171) mixin: filter private methods in mixin util (beb8610) naming: change epoch to epochStartHeight (908971c) naming: rename getRecord[s] to getArNSRecord[s] (bd3d4bc) overloads: only accept warp contract as a contract config for ariowritable (e3c97e9) polyfills: rollback polyfill on logger (0cdb2f0) postinstall: remove husky postinstall script (c74a135) readme: add grammar and example recs (ecc07f7) readme: condense quick start (b35e5bd) readme: refactor api list to header tags (817d99b) readme: update ant header (77235ce) readme: update ANT usage description (70c8520) readme: update joinNetwork docs (9fcf440) readme: update quick start (a60d96a) readme: update readme with default provider example (68a5a16) readme: update readme with examples (d9ee23e) record records: update key to use result instead of record (90314db) records: remove contractTxId filter remove lodash shrink readme (50669e1) records: use state endpoint to fetch records (2f02c53) recs: modify the interfaces for contracts and implement with warp and remote service (#13) (56ebb08) release: remove release assets entirely (9d5a1b3) release: update github release config to publish packages to github (5534d9d) remote: getState not properly setting evalTo in http requests (55745c1) safety: update type safety checks (32eebbc) setimmediate: make set immediate a build dependency as it is required by the node winston (9292eaa) signer: check that contract is connected before trying to write (d352e9c) signer: check that contract is connected before trying to write (#29) (536a116) signer: fix signer in WarpContracts - update tests (ea9448f) signer: fix signer in WarpContracts - update tests (#32) (16d69d8) signer: remove jwk use, ignore web example for now (bc7e577) signer: remove signer, will do in other pr (d02276d) signer: remove use of JWK, simplify constructor (#22) (d2ef573) signer: update ANT to have signer (c7f8eee) structure: update cache provider folder to be named caches (844c1aa) structure: use snake case for file and folder names (37f27d3) test warp-contract: use beforeAll to read env vars (95cc019) tests: add test cases as a const (8458185) tests: add test for custom arIO client config (0e6142b) tests: change control flow pattern to.catch instead of trycatch (883de51) tests: dont make blockHeight or sortKey undefined but rather evalTo (f76a201) tests: instantiate new ant to connect in tests (9869415) tests: remove dryWrite from writeInteraction, update tests (bc1becc) tests: remove fixture and use live service for tests (30d3e8c) tests: test 404 response (590dea6) tests: update ario test (4208bd0) tests: update client instantiation test to check read vs write clients (059653c) tests: update docker compose params (a71befd) tests: update gateways test (1fcb3e6) tests: update stubs in tests (e4bbc6e) tests: update test to match jest syntax (553bdbb) tests: update tests for named prop expectation (4ea04a7) tests: update tests to use younger contract, add evalParams config (ae890c8) tests: update tests with constants and update types (1bdcfeb) tests: update tests with new name (2cd1b5c) tests: update with new names on methods (619c193) tests: use angela for testing (10f30fe) tests: use http not https in tests (fddba1e) tests: use process vars as priority url (faab4f3) test: update test to use ArweaveTransactionID class (f6c4f8b) tsconfig, names: reverted tsconfig to nodenext resolution, changed naming convention on provider, removed extraeneous error classes, rolled back axios-retry to match our tsconfig settings (d412d44) tyeps: set types to objects rather than top level params for easier readability (edfd77b) type: rename all type implementations (5959045) types and tests: update evalTo to allow undefined sortKey and block and test that (a59f05c) types: add @ to records (53601c1) types: make props nullable on certain read apis (f8ff552) types: remove any type (5c80242) types: remove any types (d8d910b) types: remove ArweaveTransactionID type for now (3adf53b) types: remove unnecesssary empty defaults (7d14edb) types: rename signer to ContractSigner (87d6c90) types: require atleast one param to update gateway settings (857ebdc) types: update interaction type to only use read for now (2c02e90) types: update tests, readme, and types (e9985dd) types: use partial write type (fa6a638) types: use string instead of any (014a262) validate id: make validator a private method (dce4a94) validity util: isBlockheight check more strict (2b28675) warp contract: added test for getting state after connecting with warp (060ee2c) warp-contract: provide logger - update isTransaction flow ctrl - use typed props (5f6e0a1) warp-contracts: bump warp to 1.4.38 - fixed warp exports (af4a20b) winston: move the winston polyfill - this will prevent any esm based web projects from getting polyfill issues (c8b7998) write: add dry run - sync state - abortSignal - update interface (970bdef) write: update utils - change error flow - update arweave constructor props (0a81c92) write: update write methods on warp (9c0540b) yarn: update lockfile (fd5e0ee) Features ant: add ANT read interface (c941c96) ant: create ant contract class for interacting with ant contracts (6eb7ef5) ants: add readable-writable framework to the ant client and implement write methods (3019f53) ario contract: add distributions and observation apis (21e38d1) arioContract: update ArIO interface and ArIOContract interface (5d87e2e) auctions: add auctions apis (faf08c5) contract: add distribution, observations apis, update readme and examples (0208317) contract: create new contract classes that impelement both warp and remote cache for ant contract and ar-io contracts (855da2d) first issue: setup examples, readme, and initial gateways provider (5a9e232) gar methods: add gar write methods to the ario client (e01b08b) inital providers: scaffold initial providers (4949514) io transfer: add transfer api to ario writable client (0d37623) observerations: add saveObservations write interaction (8dd977c) observers: add API for fetching prescribed observers (a18e130) observers: add API for fetching prescribed observers (#17) (17ce6de) PE-5742: add records api to arns remote cache (#8) (c46cd39) PE-5751: add blockheight and sortkey eval filters (#12) (832a1ad) PE-5758: add signer to ario class (#20) (1b82077) PE-5759: observations and distributions apis (#16) (dded361) PE-5773: add auctions read apis (#18) (e0c6fca) PE-5800: add epoch apis (48ee4ba) PE-5800: epoch apis (#15) (70563b1) PE-5825: ANT read interface (#19) (6a0c477) records: add records api to arns remote cache (1b7f54f) signer: add arweave signer to ario class (7e08097) write: add write interface and base implementation on warp-contract (6dfc969)

---

# 106. ARIO Docs

Document Number: 106
Source: https://docs.ar.io/ar-io-sdk/ants/remove-controller
Words: 24
Quality Score: 0.405
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

removeController removeController is a method on the ANT class that removes a specified wallet address from the ANT's list of approved controllers.removeController requires authentication.

---

# 107. getGateway - ARIO Docs

Document Number: 107
Source: https://docs.ar.io/ar-io-sdk/ario/gateways/get-gateway
Words: 24
Quality Score: 0.405
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

getGateway is a method on the ARIO class that retrieves detailed information about a specific gateway using its wallet address.getGateway does not require authentication.

---

# 108. getGateways - ARIO Docs

Document Number: 108
Source: https://docs.ar.io/ar-io-sdk/ario/gateways/get-gateways
Words: 87
Quality Score: 0.404
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

getGateways is a method on the ARIO class that retrieves all gateways with optional pagination and filtering support.getGateways does not require authentication.Parameters ← Swipe to see more → Parameter Type Description Optional Default cursor string The gateway address to use as the starting point for pagination true None limit number The maximum number of gateways to return (max: 1000) true 100 sortBy string The property to sort gateways by true startTimestamp sortOrder string The sort direction ('desc' or 'asc') true desc ← Swipe to see more →

---

# 109. ARIO Documentation

Document Number: 109
Source: https://docs.ar.io/
Words: 141
Quality Score: 0.404
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

🚀 Get Started Quickly: Explore Our Quick Start Guides → Welcome to the Permaweb Data in paradise. The AR.IO ecosystem is dedicated to cultivating products and protocols for sustaining access to digital permanence, making the permaweb available to everyone. Powered by the ARIO Token, this global network of Gateways connects users to permanently stored data, files, applications, and web pages on the Arweave decentralized storage network.Guides Run a Gateway Get your AR.IO Gateway up and running correctly and quickly.Read more Use ArNS Learn the process of purchasing and managing an ArNS name.Read more Deploy a dApp Learn how to easily deploy a website or application on the permaweb.Read more ANTs on Bazar In a few simple steps, learn how to make an ANT tradable on Bazar.Read more GraphQL Learn how to leverage GraphQL to efficiently fetch data via AR.IO gateways.Read more

---

# 110. ARIO Docs

Document Number: 110
Source: https://docs.ar.io/ar-io-sdk/ants/set-logo
Words: 33
Quality Score: 0.400
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

setLogo setLogo is a method on the ANT class that updates the logo of the ANT process. The logo must be specified as an Arweave transaction ID that contains an image.setLogo requires authentication.

---

# 111. ANTs on Bazar - ARIO Docs

Document Number: 111
Source: https://docs.ar.io/guides/ants-on-bazar
Words: 526
Quality Score: 0.399
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Trading ANTs on Bazar Overview Arweave Name Tokens are Atomic Asset Spec compliant AO tokens that manage records and permission for ArNS names. Because the ANT spec is compliant with the Atomic Asset Spec, they are tradable on Bazar, which is a decentralized market place for Atomic Assets on AO. There are a few simple steps that are required in order to make an ANT available on Bazar to be traded.Bazar relies on profiles for dising user information and tradable assets. Profiles are AO processes that contain user specified information like a name, a nickname, and images associated with the profile. Profiles also track assets held by the profile in order to provide their information to bazar.Create a Profile If you do not already have a profile associated with your wallet, you can easily create one on using the "Create your profile" button on bazar after connecting your wallet: You will be prompted to add, at a minimum, a name and handle (nickname) to associate with the profile. These values can be changed later. Click "Save" at the bottom to finish creation of your profile.Once your profile is created, you can get its ao process Id at any time by clicking on the user icon in Bazar, and then the "Copy profile address" button from the menu. Bazar profiles only track assets that are held in the profile process, not in a user wallet. In order for an ANT to be dised and transferred on Bazar, it must first be transferred into the Bazar profile. This can be done easily using arns.app in your manage page for a given name. Once an ANT is transferred into the profile process, it will automatically be detected and dised by Bazar. It can be transferred or sold just like any other atomic asset on the marketplace, with no additional steps required.Restore Controllers Optional This is an optional step that will enable updating an ANT's Target Id without transferring it back into your wallet. This step may be safely skipped without affecting the ANT's functionality or tradability on Bazar.Transferring an ANT to a new wallet or AO process resets all authorized controllers, or non-owner entities that are allowed to update some settings on the ArNS name. It does not reset the Target Id that the ArNS name is pointing to. If you want to be able to update the Target ID and undernames from your wallet using arns.app, you will need to set your wallet address as a controller for the ANT while it is in your profile. The easiest way to do this is using aos.If you have not used aos before, you can find installation instructions here Using aos, you can log directly into your profile process with the command:Be sure to replace with the process Id for your profile process, and /path/to/your/keyfile with the path to the keyfile for the wallet you created the profile with.Once you are logged in with aos, you can send a message to the ANT in your profile to set your wallet as a controller:Replace with the process Id of the ANT you transferred into your profile, and with your wallet address.

---

# 112. ANTs on Bazar - ARIO Docs

Document Number: 112
Source: https://docs.ar.io/learn/guides/ants-on-bazar
Words: 526
Quality Score: 0.399
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Trading ANTs on Bazar Overview Arweave Name Tokens are Atomic Asset Spec compliant AO tokens that manage records and permission for ArNS names. Because the ANT spec is compliant with the Atomic Asset Spec, they are tradable on Bazar, which is a decentralized market place for Atomic Assets on AO. There are a few simple steps that are required in order to make an ANT available on Bazar to be traded.Bazar relies on profiles for dising user information and tradable assets. Profiles are AO processes that contain user specified information like a name, a nickname, and images associated with the profile. Profiles also track assets held by the profile in order to provide their information to bazar.Create a Profile If you do not already have a profile associated with your wallet, you can easily create one on using the "Create your profile" button on bazar after connecting your wallet: You will be prompted to add, at a minimum, a name and handle (nickname) to associate with the profile. These values can be changed later. Click "Save" at the bottom to finish creation of your profile.Once your profile is created, you can get its ao process Id at any time by clicking on the user icon in Bazar, and then the "Copy profile address" button from the menu. Bazar profiles only track assets that are held in the profile process, not in a user wallet. In order for an ANT to be dised and transferred on Bazar, it must first be transferred into the Bazar profile. This can be done easily using arns.app in your manage page for a given name. Once an ANT is transferred into the profile process, it will automatically be detected and dised by Bazar. It can be transferred or sold just like any other atomic asset on the marketplace, with no additional steps required.Restore Controllers Optional This is an optional step that will enable updating an ANT's Target Id without transferring it back into your wallet. This step may be safely skipped without affecting the ANT's functionality or tradability on Bazar.Transferring an ANT to a new wallet or AO process resets all authorized controllers, or non-owner entities that are allowed to update some settings on the ArNS name. It does not reset the Target Id that the ArNS name is pointing to. If you want to be able to update the Target ID and undernames from your wallet using arns.app, you will need to set your wallet address as a controller for the ANT while it is in your profile. The easiest way to do this is using aos.If you have not used aos before, you can find installation instructions here Using aos, you can log directly into your profile process with the command:Be sure to replace with the process Id for your profile process, and /path/to/your/keyfile with the path to the keyfile for the wallet you created the profile with.Once you are logged in with aos, you can send a message to the ANT in your profile to set your wallet as a controller:Replace with the process Id of the ANT you transferred into your profile, and with your wallet address.

---

# 113. cancelWithdrawal - ARIO Docs

Document Number: 113
Source: https://docs.ar.io/ar-io-sdk/ario/gateways/cancel-withdrawal
Words: 82
Quality Score: 0.397
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

cancelWithdrawal is a method on the ARIO class that cancels a pending withdrawal for a gateway, returning the stake back to the delegated amount.cancelWithdrawal requires authentication.Parameters ← Swipe to see more → Parameter Type Description Optional gatewayAddress string - WalletAddress The wallet address of the gateway false vaultId string The ID of the vault containing the withdrawal to cancel false tags array An array of GQL tag objects to attach to the transfer AO message true ← Swipe to see more →

---

# 114. ARIO Docs

Document Number: 114
Source: https://docs.ar.io/ar-io-sdk/ario/gateways/increase-delegate-stake
Words: 21
Quality Score: 0.397
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

increaseDelegateStake increaseDelegateStake is a method on the ARIO class that increases the caller's delegated stake on the target gateway.increaseDelegateStake requires authentication.

---

# 115. ARIO Docs

Document Number: 115
Source: https://docs.ar.io/ar-io-sdk/ario/gateways/decrease-delegate-stake
Words: 21
Quality Score: 0.397
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

decreaseDelegateStake decreaseDelegateStake is a method on the ARIO class that decreases the caller's delegated stake on the target gateway.decreaseDelegateStake requires authentication.

---

# 116. getArNSRecords - ARIO Docs

Document Number: 116
Source: https://docs.ar.io/ar-io-sdk/ario/arns/get-arns-records
Words: 92
Quality Score: 0.395
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

getArNSRecords is a method on the ARIO class that retrieves all ArNS records with optional pagination and filtering support.getArNSRecords does not require authentication.Parameters ← Swipe to see more → Parameter Type Description Optional Default cursor string The ArNS name to use as the starting point for the next page of results true None limit number The maximum number of records to return (max: 1000) true 100 sortBy string The property to sort results by true startTimestamp sortOrder string The sort direction ('desc' or 'asc') true desc ← Swipe to see more →

---

# 117. ARIO Docs

Document Number: 117
Source: https://docs.ar.io/ar-io-sdk/ants/set-name
Words: 20
Quality Score: 0.394
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

setName setName is a method on the ANT class that updates the dis name of the ANT process.setName requires authentication.

---

# 118. ARIO Docs

Document Number: 118
Source: https://docs.ar.io/ar-io-sdk/ants/set-ticker
Words: 20
Quality Score: 0.394
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

setTicker setTicker is a method on the ANT class that updates the ticker symbol of the ANT process.setTicker requires authentication.

---

# 119. ARIO Docs

Document Number: 119
Source: https://docs.ar.io/ar-io-sdk/ants/set-description
Words: 20
Quality Score: 0.394
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

setDescription setDescription is a method on the ANT class that updates the descriptive text for the ANT process.setDescription requires authentication.

---

# 120. getHandlers - ARIO Docs

Document Number: 120
Source: https://docs.ar.io/ar-io-sdk/ants/get-handlers
Words: 28
Quality Score: 0.390
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

getHandlers is a method on the ANT class that retrieves the handlers supported by the ANT.getHandlers does not require authentication.Parameters The getHandlers method does not accept any parameters.

---

# 121. Verification Strategies - ARIO Docs

Document Number: 121
Source: https://docs.ar.io/wayfinder/core/verification-strategies
Words: 158
Quality Score: 0.386
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Overview Verification strategies in Wayfinder ensure data integrity and authenticity when fetching content from Arweave through AR.IO gateways. These strategies use cryptographic methods to verify that the data you receive matches what was originally stored on Arweave, protecting against tampering, corruption, or malicious gateways.Why Verification Matters Data Integrity: Ensures content hasn't been corrupted during transmission Security: Protects against malicious gateways serving fake data Trust: Provides cryptographic proof that data is authentic Compliance: Meets security requirements for sensitive applications Strategy Comparison Important Verification methods require that the gateway being used has the relevant
transaction data indexed locally. Gateways cannot proxy out verification
requests to other sources, as this would compromise the security and
reliability of the verification process. If a gateway doesn't have the
required data indexed, verification will fail.Related Hash Verification: Learn about fast integrity checking Signature Verification: Understand authenticity validation Data Root Verification: Explore maximum security verification Wayfinder Core: See how to configure verification in your application

---

# 122. Gateway Apex Domain Content Resolution - ARIO Docs

Document Number: 122
Source: https://docs.ar.io/gateways/apex
Words: 355
Quality Score: 0.374
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Overview Prior to gateway Release 28, the apex domain of a gateway would only dis information about the Arweave network. Release 28 introduced two new environment variables that allow a gateway to serve custom content from the apex domain:APEX_TX_ID: Set to serve content from a specific transaction ID APEX_ARNS_NAME: Set to serve content from an ArNS name These variables enable gateway operators to customize their gateway's apex domain with useful information, details about the operator or associated projects, or any other content they wish to share.Quick Start If you want to serve your project's dApp from the apex domain of your gateway:Upload your dApp to Arweave Assign your dApp's transaction Id to an ArNS name Set the environment variable:APEX_ARNS_NAME=your-ArNS-name Restart your gateway Your dApp will now be served from your gateway's apex domain Configuration Environment Variables You can configure your gateway to serve content from the apex domain by setting one of two environment variables:IMPORTANT You cannot set both variables simultaneously. Providing both variables will result in an error.Restart Requirements The gateway must be restarted after initially setting these environment variables If using APEX_ARNS_NAME, no restart is needed when the ArNS name points to a new transaction If using APEX_TX_ID, the gateway must be restarted when updating the transaction ID Use Cases Gateway operators can use this feature to:Dis information about their gateway service Share details about the operator or organization Showcase associated projects and services Share educational content about Arweave and the permaweb Dis any other content they wish to make available at their gateway's root domain Community Examples Several gateway operators have already implemented this feature to serve custom content from their apex domains:arnode.asia - Serves a custom landing page with information about their gateway service arlink.xyz - Serves the permaDapp for the Arlink project frostor.xyz / love4src.com - Serves information about the Memetic Block Software Guild and their projects vilenarios.com - Serves personalized portfolio/link tree information about the operator permagate.io - Serves personalized link tree information about the operator These examples demonstrate how gateway operators can leverage the apex domain feature to create a more personalized and informative experience for their users.

---

# 123. buyRecord - ARIO Docs

Document Number: 123
Source: https://docs.ar.io/ar-io-sdk/ario/arns/buy-record
Words: 111
Quality Score: 0.370
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

buyRecord is a method on the ARIO class that purchases a record in the ArNS registry for a specified name and duration.buyRecord requires authentication.Parameters ← Swipe to see more → Parameter Type Description Optional name string The ArNS name to purchase false years number The number of years to lease the name for (1-5) false processId string The ANT process ID to set for this name false type string The type of purchase: 'lease' or 'permabuy' true fundFrom string The source of funds: 'balance', 'stakes', 'any', or 'turbo' true tags array An array of GQL tag objects to attach to the transfer AO message true ← Swipe to see more →

---

# 124. StaticRoutingStrategy - ARIO Docs

Document Number: 124
Source: https://docs.ar.io/wayfinder/core/routing-strategies/static
Words: 110
Quality Score: 0.368
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Overview The StaticRoutingStrategy is the simplest routing strategy that always returns a single, pre-configured gateway URL. This strategy ignores any gateways provided by the GatewaysProvider and is useful for scenarios where you want to force all requests to use a specific gateway.How It Works The strategy always returns the configured gateway, ignoring any provided gateway lists:Configure Gateway: Set a single gateway URL during initialization Ignore Provided Gateways: Any gateways from providers are ignored Return Static Gateway: Always return the same configured gateway Log Warnings: Warn when provided gateways are ignored Configuration Basic Usage With Custom Gateway Parameters Related FastestPingRoutingStrategy: Network-based gateway discovery PreferredWithFallbackRoutingStrategy: Static gateway configuration RandomRoutingStrategy: Randomized gateway selection

---

# 125. Hash Verification Strategy - ARIO Docs

Document Number: 125
Source: https://docs.ar.io/wayfinder/core/verification-strategies/hash-verification
Words: 97
Quality Score: 0.367
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

HashVerificationStrategy Overview The HashVerificationStrategy verifies data integrity by comparing SHA-256 hashes of fetched data against trusted gateway digest headers. This strategy provides fast, cryptographically secure verification for high-throughput applications.How It Works Fetch Data: Retrieve content from the selected gateway Request Digest: Get the digest from trusted gateways via HTTP headers using HEAD/GET requests from a trusted gatweay Compute Hash: Calculate the SHA-256 hash of the received data Compare: Verify that both hashes match exactly Result: Pass or fail based on hash comparison Basic Usage Related Signature Verification: Understand authenticity validation Data Root Verification: Explore maximum security verification

---

# 126. ARIO Network Composition - ARIO Docs

Document Number: 126
Source: https://docs.ar.io/network-composition
Words: 265
Quality Score: 0.360
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Overview The permanent web, or "permaweb," is the collection of all webpages, applications, and files stored on the Arweave network and made accessible by the AR.IO permanent cloud.
These range from simple tools for viewing and managing data to sophisticated decentralized applications integrating immutable storage and smart contracts.For users and developers, the permaweb offers low-cost, maintenance-free, and permanent hosting for web apps, data, and pages – serving both traditional and emerging industries.Composition of the Permanent Cloud The AR.IO Network integrates decentralized protocols, services, and applications to power the permanent web alongside the traditional internet.
Foundational components like Arweave and AO are independently developed, while AR.IO introduces essential services and incentives that enable seamless interaction and accessibility. Diagram 1: The Permanent Cloud Network Major Components of the Permanent Cloud:Storage: Arweave At the foundation lies the Arweave protocol, providing decentralized, immutable data storage. This layer ensures data is preserved indefinitely with clear provenance records for long-term reliability.Compute: AO This layer comprises decentralized compute platforms, such as Arweave-native solutions like AO and other Layer 1 smart contract platforms like Ethereum.
These systems enable flexible, data-driven computation and smart contract execution, broadening the ecosystem's capabilities.Services: AR.IO Sitting atop the compute layer, the AR.IO Network provides essential services like data upload, retrieval, indexing, querying, and domain name resolution.
AR.IO gateways ensure the permanent web remains functional, accessible, and usable for developers, creators, and end users.Together, these layers form a cohesive ecosystem, combining data permanence, decentralized computation, and seamless cloud services.
Each layer strengthens the others, creating a resilient foundation for the permaweb while bridging the traditional and decentralized internet paradigms.

---

# 127. ARIO Docs

Document Number: 127
Source: https://docs.ar.io/wayfinder/core/routing-strategies/random
Words: 102
Quality Score: 0.355
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

RandomRoutingStrategy Overview The RandomRoutingStrategy selects gateways randomly from the available pool. This strategy provides simple load distribution without maintaining state or performing complex calculations, making it ideal for scenarios where unpredictability is desired or where simplicity is paramount.How It Works Receive Gateway List: Accept the list of available gateways Generate Random Index: Create a random number within the gateway list range Select Gateway: Choose the gateway at the random index Apply Filters: Optionally filter out unhealthy or blocked gateways Return Selection: Return the randomly selected gateway Basic Usage Parameters Related FastestPingRoutingStrategy: Network-based gateway discovery PreferredWithFallbackRoutingStrategy: Static gateway configuration RandomRoutingStrategy: Randomized gateway selection

---

# 128. Quick Start Guides - ARIO Docs

Document Number: 128
Source: https://docs.ar.io/guides
Words: 104
Quality Score: 0.352
Extraction Method: semantic_dom
Extraction Reason: found_content_in_main

Quick Start Guides
Deploy a dApp with ArlinkEasily deploy a web app with ArNS using Arlinkmake your ArNS name tradable on BazarHow to dis and trade your ArNS ANTs on BazarBuild a dApp using the ArNext frameworkBuild and deploy a dApp for dising and updating ArNS names using ArNextAutomate deployment using Permaweb DeployAutomate the deployment of your dApp to ArNS using Permaweb Deploy, ArNS, and GithubManaging UndernamesHow to programmatically manage ArNS undernames using the AR.IO SDKQuery data on Arweave using GraphQLSchema and best practices for constructing a GraphQL queryDeploy a dApp with ArDrive webHow to upload a dApp to the permaweb using ArDrive web

---

# 129. ARIO Smart Contract - ARIO Docs

Document Number: 129
Source: https://docs.ar.io/ario-contract
Words: 300
Quality Score: 0.347
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Overview The AR.IO smart contract encompasses all the functionality required to support the network's currency, utilities, and management.
Written in Lua and compiled to WASM64, it is deployed as a Process within AO, leveraging the decentralized infrastructure of Arweave for immutability and auditability.
This ensures that AR.IO's smart contract code is stored permanently, is easily verifiable by external auditors, and is transparent to the community.Protocol Balance The Protocol Balance is the primary sink and source of ARIO tokens circulating through the AR.IO Network.
This balance is akin to a central vault or wallet programmatically encoded into the network's smart contract from which ArNS revenue is accumulated and incentive rewards are distributed.This balance is stored like any other token balance in the AR.IO smart contract, using the contract's Process ID as the balance owner.
This balance is stored like any other token balance in the AR.IO smart contract, using the contract’s Process ID as the balance owner.
Should a user or organization desire, tokens can even be sent directly into this balance to support the reward protocol and ecosystem.Cross-Chain Signature Support AO leverages the flexibility of ANS-104 data items, which support multiple signature types from various blockchains. This includes signatures from Arweave, Ethereum, Solana, Cosmos, among others.This cross-chain signature support provides significant benefits to the AR.IO network:Interoperability: Cross-chain signatures enable seamless interactions across different blockchain ecosystems, allowing AR.IO to integrate with diverse apps and services without friction.Flexibility: Users can validate transactions with signatures from their preferred blockchain, making it easier for a broader range of participants to engage with AR.IO using familiar wallets and mechanisms.Security: Decentralized cryptographic standards across chains ensure that interactions on AR.IO remain secure and trusted, regardless of the blockchain used.By supporting cross-chain signatures, AR.IO enhances interoperability, flexibility, and security, empowering users and developers across multiple blockchain ecosystems.

---

# 130. ARIO Docs

Document Number: 130
Source: https://docs.ar.io/wayfinder/core/routing-strategies/fastest-ping
Words: 105
Quality Score: 0.347
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

FastestPingRoutingStrategy Overview The FastestPingRoutingStrategy selects the gateway with the lowest latency by performing HEAD requests to all available gateways and choosing the one that responds fastest. This strategy optimizes for performance by dynamically selecting the most responsive gateway for each request.How It Works Ping All Gateways: Send HEAD requests to all available gateways for the provided path and subdomain Measure Response Times: Records the time taken for each gateway to respond Select Fastest: Choose the gateway with the lowest response time Basic Usage Parameters Related PreferredWithFallbackRoutingStrategy: Static gateway configuration RoundRobinRoutingStrategy: Even distribution across gateways RandomRoutingStrategy: Randomized gateway selection StaticRoutingStrategy: Always use a single, fixed gateway

---

# 131. ARIO Docs

Document Number: 131
Source: https://docs.ar.io/wayfinder/core/routing-strategies/round-robin
Words: 116
Quality Score: 0.338
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

RoundRobinRoutingStrategy Overview The RoundRobinRoutingStrategy distributes requests evenly across all available gateways in a cyclical manner. Each gateway is selected in turn, ensuring fair load distribution and preventing any single gateway from being overwhelmed.How It Works Initialize Gateway List: Start with an ordered list of available gateways Track Current Position: Maintain a pointer to the current gateway in the rotation Select Next Gateway: Choose the next gateway in the sequence Cycle Through List: Return to the first gateway after reaching the end Handle Failures: Skip failed gateways and continue rotation Configuration Basic Usage With Weighted Rotation Parameters Related FastestPingRoutingStrategy: Network-based gateway discovery PreferredWithFallbackRoutingStrategy: Static gateway configuration RandomRoutingStrategy: Randomized gateway selection StaticRoutingStrategy: Always use a single, fixed gateway

---

# 132. ARIO Docs

Document Number: 132
Source: https://docs.ar.io/wayfinder/core/routing-strategies/preferred-with-fallback
Words: 117
Quality Score: 0.337
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

PreferredWithFallbackRoutingStrategy Overview The PreferredWithFallbackRoutingStrategy attempts to use a designated preferred gateway first, and only falls back to an alternative routing strategy if the preferred gateway fails or is unavailable. This strategy is ideal for applications with dedicated infrastructure or specific gateway requirements.How It Works Health Check: Performs a HEAD request to the preferred gateway with a 1000ms timeout Success: If the preferred gateway responds with a successful status, it's used Failure: If the preferred gateway fails or times out, the fallback strategy is used Logging: All attempts and failures are logged for monitoring Basic Usage Parameters Related FastestPingRoutingStrategy: Network-based gateway discovery RoundRobinRoutingStrategy: Even distribution across gateways RandomRoutingStrategy: Randomized gateway selection StaticRoutingStrategy: Always use a single, fixed gateway

---

# 133. Routing Strategies - ARIO Docs

Document Number: 133
Source: https://docs.ar.io/wayfinder/core/routing-strategies
Words: 52
Quality Score: 0.309
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Routing strategies determine how Wayfinder selects which AR.IO gateway to use for each request. Different strategies optimize for different goals like performance, reliability, or load distribution.Strategy Comparison Related FastestPingRoutingStrategy: Network-based gateway discovery PreferredWithFallbackRoutingStrategy: Static gateway configuration RoundRobinRoutingStrategy: Even distribution across gateways RandomRoutingStrategy: Randomized gateway selection StaticRoutingStrategy: Always use a single, fixed gateway
