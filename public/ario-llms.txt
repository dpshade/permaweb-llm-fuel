# Permaweb Documentation Collection

Generated on: 2025-10-13T12:16:57.242Z
Total documents: 99
Total words: 63774

## Table of Contents

### Included Documents

1. [Setting Apex Domain Content ARIO Documentation](https://docs.ar.io/build/run-a-gateway/manage/setting-apex-domain)
2. [Content Moderation ARIO Documentation](https://docs.ar.io/build/run-a-gateway/manage/content-moderation)
3. [Bundler ARIO Documentation](https://docs.ar.io/build/extensions/bundler)
4. [Turbo SDK ARIO Documentation](https://docs.ar.io/sdks/turbo-sdk)
5. [Storing DePIN Data on Arweave Using Turbo ARIO Documentation](https://docs.ar.io/build/guides/depin)
6. [ClickHouse Parquet ARIO Documentation](https://docs.ar.io/build/extensions/clickhouse)
7. [Crossmint NFT Minting App ARIO Documentation](https://docs.ar.io/build/guides/crossmint-nft-minting-app)
8. [Hosting Decentralized Websites ARIO Documentation](https://docs.ar.io/build/guides/hosting-decentralized-websites)
9. [Using Turbo SDK with Vanilla HTML ARIO Documentation](https://docs.ar.io/build/guides/using-turbo-in-a-browser/html)
10. [ArNS Undernames for Permasite Versioning ARIO Documentation](https://docs.ar.io/build/guides/arns-undernames-versioning)
11. [Advanced Uploading with Turbo ARIO Documentation](https://docs.ar.io/build/upload/advanced-uploading-with-turbo)
12. [Environment Variables ARIO Documentation](https://docs.ar.io/build/run-a-gateway/manage/environment-variables)
13. [AO Compute Unit (CU) ARIO Documentation](https://docs.ar.io/build/extensions/compute-unit)
14. [Importing SQLite Database Snapshots ARIO Documentation](https://docs.ar.io/build/run-a-gateway/manage/index-snapshots)
15. [Index Querying ARIO Documentation](https://docs.ar.io/apis/ar-io-node/index-querying)
16. [Wayfinder React ARIO Documentation](https://docs.ar.io/sdks/wayfinder/wayfinder-react)
17. [Wayfinder ARIO Documentation](https://docs.ar.io/build/access/wayfinder)
18. [Gateway Filters ARIO Documentation](https://docs.ar.io/build/run-a-gateway/manage/filters)
19. [Data Model ARIO Documentation](https://docs.ar.io/build/advanced/arfs/data-model)
20. [ARIO SDK ARIO Documentation](https://docs.ar.io/sdks/ar-io-sdk)
21. [Guides ARIO Documentation](https://docs.ar.io/build/guides)
22. [Arweave Name System (ArNS) ARIO Documentation](https://docs.ar.io/learn/arns)
23. [Working With Primary Names ARIO Documentation](https://docs.ar.io/build/guides/arns-primary-names)
24. [Find Data (via GraphQL) ARIO Documentation](https://docs.ar.io/build/access/find-data)
25. [Creating Drives ARIO Documentation](https://docs.ar.io/build/advanced/arfs/creating-drives)
26. [Join the Network ARIO Documentation](https://docs.ar.io/build/run-a-gateway/join-the-network)
27. [Access Data ARIO Documentation](https://docs.ar.io/build/access)
28. [Arweave Name Tokens (ANTs) ARIO Documentation](https://docs.ar.io/learn/arns/ants)
29. [Upgrading your Gateway ARIO Documentation](https://docs.ar.io/build/run-a-gateway/manage/upgrading-a-gateway)
30. [Run a Gateway ARIO Documentation](https://docs.ar.io/build/run-a-gateway)
31. [Fetch Data (via REST API) ARIO Documentation](https://docs.ar.io/build/access/fetch-data)
32. [Getting Started with Turbo ARIO Documentation](https://docs.ar.io/build/upload/bundling-services)
33. [Payments ARIO Documentation](https://docs.ar.io/apis/turbo/payment-service/payments)
34. [Logging ARIO Documentation](https://docs.ar.io/sdks/turbo-sdk/logging)
35. [Arweave Name System (ArNS) ARIO Documentation](https://docs.ar.io/build/access/arns)
36. [Entity Types ARIO Documentation](https://docs.ar.io/build/advanced/arfs/entity-types)
37. [Automating SSL Certificate Renewal ARIO Documentation](https://docs.ar.io/build/run-a-gateway/manage/ssl-certs)
38. [Reading Data ARIO Documentation](https://docs.ar.io/build/advanced/arfs/reading-data)
39. [Pricing Model ARIO Documentation](https://docs.ar.io/learn/arns/pricing-model)
40. [Wayfinder Protocol ARIO Documentation](https://docs.ar.io/learn/wayfinder)
41. [Tagging ARIO Documentation](https://docs.ar.io/build/upload/tagging)
42. [Get Started ARIO Documentation](https://docs.ar.io/build)
43. [Gateway ARIO Documentation](https://docs.ar.io/apis/ar-io-node/gateway)
44. [Events ARIO Documentation](https://docs.ar.io/sdks/turbo-sdk/events)
45. [Privacy Encryption ARIO Documentation](https://docs.ar.io/build/advanced/arfs/privacy)
46. [Upload Data ARIO Documentation](https://docs.ar.io/build/upload)
47. [Using Turbo SDK with Vite ARIO Documentation](https://docs.ar.io/build/guides/using-turbo-in-a-browser/vite)
48. [Pagination ARIO Documentation](https://docs.ar.io/sdks/ar-io-sdk/pagination)
49. [APIs Reference ARIO Documentation](https://docs.ar.io/apis)
50. [Manifests ARIO Documentation](https://docs.ar.io/build/upload/manifests)
51. [What is ARIO ARIO Documentation](https://docs.ar.io/learn/what-is-ario)
52. [Advanced ARIO Documentation](https://docs.ar.io/build/advanced)
53. [TurboAuthenticatedClient ARIO Documentation](https://docs.ar.io/sdks/turbo-sdk/turboauthenticatedclient)
54. [Data ARIO Documentation](https://docs.ar.io/apis/ar-io-node/data)
55. [Using Turbo SDK with Nextjs ARIO Documentation](https://docs.ar.io/build/guides/using-turbo-in-a-browser/nextjs)
56. [TurboFactory ARIO Documentation](https://docs.ar.io/sdks/turbo-sdk/turbofactory)
57. [Introduction ARIO Documentation](https://docs.ar.io/sdks)
58. [Using Turbo in a Browser ARIO Documentation](https://docs.ar.io/build/guides/using-turbo-in-a-browser)
59. [Staking ARIO Documentation](https://docs.ar.io/learn/token/staking)
60. [Manage your Gateway ARIO Documentation](https://docs.ar.io/build/run-a-gateway/manage)
61. [Token Conversion ARIO Documentation](https://docs.ar.io/sdks/ar-io-sdk/token-conversion)
62. [Paying for Uploads ARIO Documentation](https://docs.ar.io/build/upload/turbo-credits)
63. [What is Arweave ARIO Documentation](https://docs.ar.io/learn/what-is-arweave)
64. [ArNS Marketplace ARIO Documentation](https://docs.ar.io/build/guides/arns-marketplace)
65. [Static Methods ARIO Documentation](https://docs.ar.io/sdks/ar-io-sdk/static-methods)
66. [Turbo Credit Sharing ARIO Documentation](https://docs.ar.io/sdks/turbo-sdk/turbo-credit-sharing)
67. [Glossary ARIO Documentation](https://docs.ar.io/glossary)
68. [Logging ARIO Documentation](https://docs.ar.io/sdks/ar-io-sdk/logging)
69. [Upgrading Private Drives ARIO Documentation](https://docs.ar.io/build/advanced/arfs/upgrading-drives)
70. [Introduction ARIO Documentation](https://docs.ar.io/learn)
71. [Normalized Addresses ARIO Documentation](https://docs.ar.io/build/advanced/normalized-addresses)
72. [ARIO Gateway APIs ARIO Documentation](https://docs.ar.io/apis/ar-io-node)
73. [Troubleshooting ARIO Documentation](https://docs.ar.io/build/run-a-gateway/manage/troubleshooting)
74. [Distributions ARIO Documentation](https://docs.ar.io/learn/oip/reward-distribution)
75. [Balance ARIO Documentation](https://docs.ar.io/apis/turbo/payment-service/balance)
76. [ArFS Protocol ARIO Documentation](https://docs.ar.io/build/advanced/arfs)
77. [Encryption ARIO Documentation](https://docs.ar.io/build/upload/encryption)
78. [Data Verification ARIO Documentation](https://docs.ar.io/learn/gateways/data-verification)
79. [Observation Incentive Protocol ARIO Documentation](https://docs.ar.io/learn/oip)
80. [EthAReum Protocol ARIO Documentation](https://docs.ar.io/build/advanced/ethareum)
81. [Arweave Name System (ArNS) ARIO Documentation](https://docs.ar.io/sdks/ar-io-sdk/arweave-name-system-arns)
82. [Data Retrieval ARIO Documentation](https://docs.ar.io/learn/gateways/data-retrieval)
83. [Extensions Sidecars ARIO Documentation](https://docs.ar.io/build/extensions)
84. [Architecture ARIO Documentation](https://docs.ar.io/learn/gateways/architecture)
85. [Name Registration ARIO Documentation](https://docs.ar.io/learn/arns/name-registration)
86. [Add to Wander ARIO Documentation](https://docs.ar.io/learn/token/add-to-wander)
87. [Use Cases ARIO Documentation](https://docs.ar.io/learn/wayfinder/use-cases)
88. [Observer Selection ARIO Documentation](https://docs.ar.io/learn/oip/observer-selection)
89. [Deploy a dApp with ArDrive Web ARIO Documentation](https://docs.ar.io/build/guides/deploy-dapp-with-ardrive-web)
90. [What is the Permaweb ARIO Documentation](https://docs.ar.io/learn/permaweb)
91. [Gateway Registry ARIO Documentation](https://docs.ar.io/learn/gateways/gateway-registry)
92. [Architecture ARIO Documentation](https://docs.ar.io/learn/token/architecture)
93. [Get the Token ARIO Documentation](https://docs.ar.io/learn/token/get-the-token)
94. [Reporting ARIO Documentation](https://docs.ar.io/learn/oip/reporting)
95. [Performance and Weights ARIO Documentation](https://docs.ar.io/learn/oip/performance-evaluation)
96. [Turbo APIs ARIO Documentation](https://docs.ar.io/apis/turbo)
97. [Token ARIO Documentation](https://docs.ar.io/learn/token)
98. [What are Bundles ARIO Documentation](https://docs.ar.io/learn/ans-104-bundles)
99. [ARIO Gateways ARIO Documentation](https://docs.ar.io/learn/gateways)

---

# 1. Setting Apex Domain Content  ARIO Documentation

Document Number: 1
Source: https://docs.ar.io/build/run-a-gateway/manage/setting-apex-domain
Words: 1181
Quality Score: 0.737
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Run a Gateway Manage your Gateway Configure your AR.IO Gateway to serve custom content from the apex domain instead of the default Arweave network information. This allows you to customize your gateway's root domain with useful information, project details, or any content you wish to share.Overview Prior to gateway Release 28, the apex domain of a gateway would only dis information about the Arweave network. Release 28 introduced two new environment variables that allow a gateway to serve custom content from the apex domain:APEX_TX_ID: Set to serve content from a specific transaction ID APEX_ARNS_NAME: Set to serve content from an ArNS name These variables enable gateway operators to customize their gateway's apex domain with useful information, details about the operator or associated projects, or any other content they wish to share.Quick Start Choose Your Content Source Decide how you want to serve your content:Option 1: Direct Transaction ID Upload your content to Arweave Use the transaction ID directly Option 2: ArNS Name (Recommended) Upload your content to Arweave Assign your content's transaction ID to an ArNS name Use the ArNS name for easier management Upload Your Content Upload your dApp, website, or other content to Arweave using your preferred method:ArDrive - For simple file uploads Turbo - For application bundles Direct upload - For advanced users Configure Environment Variable Add one of these variables to your .env file:Restart Your Gateway Restart your gateway to apply the changes:docker compose down
docker compose up -d Verify Configuration Visit your gateway's apex domain to confirm the custom content is being served correctly.Configuration Methods Using Direct Transaction ID Upload Content Upload your content to Arweave and note the transaction ID:# Example: Upload using ArDrive CLI
ardrive upload-file --file-path ./my-website.html
# Note the returned transaction ID
# Example: abc123...def789 Set Environment Variable Add the transaction ID to your .env file:APEX_TX_ID=abc123...def789 Restart Gateway Restart your gateway to apply the configuration:docker compose down
docker compose up -d Update Content To update your content:Upload new content to Arweave Update APEX_TX_ID with the new transaction ID Restart your gateway Advantages:Direct control over content No additional ArNS setup required Simple for one-time content Disadvantages:Requires gateway restart for updates Less flexible for content management Using ArNS Name (Recommended) Upload Content Upload your content to Arweave:# Upload your website or dApp
ardrive upload-file --file-path ./my-dapp.html
# Note the transaction ID: xyz789...abc123 Register ArNS Name Register an ArNS name pointing to your content:Visit ArNS App Connect your wallet Choose your desired name (e.g., my-gateway-content) Set the transaction ID: xyz789...abc123 Pay the registration fee Configure Environment Variable Add the ArNS name to your .env file:APEX_ARNS_NAME=my-gateway-content Restart Gateway Restart your gateway to apply the configuration:docker compose down
docker compose up -d Update Content To update your content:Upload new content to Arweave Update the ArNS name to point to the new transaction ID No gateway restart required!Advantages:No restart required for content updates Easy content management Professional domain naming Can be updated independently Disadvantages:Requires ArNS setup Additional cost for ArNS registration Advanced Setup Options Custom Content Types Configure different types of content:Static Website:# Upload HTML/CSS/JS files
APEX_ARNS_NAME=my-gateway-website Single Page Application:# Upload SPA bundle
APEX_ARNS_NAME=my-dapp Documentation Site:# Upload documentation
APEX_ARNS_NAME=my-gateway-docs Content Management Workflow Implement a content management workflow:Development - Test content locally Upload - Deploy to Arweave Register - Create/update ArNS name Verify - Check content on gateway Monitor - Track performance and usage Use Cases and Examples Dis Gateway Service Information Perfect for showcasing your gateway service:Content Ideas:Gateway operator information Service capabilities and features Contact information Status and uptime statistics Network participation details Example Structure:

My AR.IO Gateway



# AR.IO Gateway Service
Reliable gateway infrastructure for the permanent web

- High availability
- Fast response times
- Global CDN

Contact: operator@example.com

Showcase Associated Projects Highlight your projects and services:Content Ideas:Project portfolio Service offerings Recent updates and news Links to other projects Integration examples Example Structure:

My Projects - AR.IO Gateway


# My Projects
Project Alpha
Description of project and its features
Visit Project
Project Beta
Another project description
Visit Project

Host Documentation Provide comprehensive documentation:Content Ideas:Gateway setup guides API documentation Integration tutorials Troubleshooting guides FAQ sections Example Structure:Real-World Examples Several gateway operators have implemented this feature:arweave.tech Serves a custom landing page with gateway service information Professional presentation of capabilities arlink.xyz Serves the permaDapp for the Arlink project Demonstrates integration with existing projects frostor.xyz / love4src.com Serves information about the Memetic Block Software Guild Showcases community and project information vilenarios.com Serves personalized portfolio/link tree information Personal branding and contact information permagate.io Serves personalized link tree information Professional operator presence Troubleshooting Fix Configuration Problems Check Environment Variables Verify your .env file configuration:# Check if variables are set correctly
grep -E "APEX_(TX_ID|ARNS_NAME)" .env
# Should show only one of:
# APEX_TX_ID=your-transaction-id
# APEX_ARNS_NAME=your-arns-name Verify Gateway Restart Ensure your gateway has been restarted after configuration changes:# Check if gateway is running
docker compose ps
# Restart if needed
docker compose down
docker compose up -d Check Gateway Logs Review logs for any error messages:docker compose logs ar-io-core | grep -i apex Resolve Content Issues Verify Content Accessibility Test if your content is accessible:# Test transaction ID directly
curl -I https://arweave.net/your-transaction-id
# Test ArNS name resolution
curl -I https://your-arns-name.arweave.net Test Content Rendering Verify content renders correctly in different browsers:Test in Chrome, Firefox, Safari Check mobile responsiveness Verify all links work correctly Test with different screen sizes Fix ArNS Problems Verify ArNS Resolution Check if your ArNS name resolves correctly:# Test ArNS resolution
nslookup your-arns-name.arweave.net
# Check if it points to the correct transaction
curl -s https://your-arns-name.arweave.net | head -10 Update ArNS Record If ArNS name points to wrong content:Go to ArNS App Find your ArNS name Update the transaction ID Wait for propagation (usually immediate) Check ArNS Status Verify ArNS name is active and not expired:Visit the ArNS app Check your name's status Ensure it's not expired Verify payment is up to date Best Practices Content Design Optimize for Performance Keep file sizes reasonable Use efficient HTML/CSS Optimize images and assets Minimize external dependencies Ensure Accessibility Use semantic HTML Include alt text for images Ensure good color contrast Test with screen readers Mobile Responsiveness Design for mobile-first Use responsive CSS Test on various devices Ensure touch-friendly interfaces Content Management Version Control Keep content in version control Document changes and updates Test changes before deployment Maintain backup copies Regular Updates Keep information current Update contact details Refresh project information Monitor for broken links Backup Strategy Backup content regularly Keep multiple copies Document restoration procedures Test backup recovery Next Steps Additional Resources ArNS Documentation - names and management Content Upload Guides - Best practices for uploading content to Arweave Gateway Configuration - Advanced gateway configuration options Community Examples - See how other operators use this feature Getting Help If you encounter issues:Check the troubleshooting section above Verify your configuration is correct Test content accessibility independently Consult the AR.IO Discord for community support How is this guide?Importing SQLite Database Snapshots Learn how to import SQLite database snapshots to quickly bootstrap your AR.IO Gateway and reduce synchronization time.Troubleshooting Comprehensive troubleshooting guide and FAQ for AR.IO Gateway operators, including common issues, failed epoch guidance, and frequently asked questions.

---

# 2. Content Moderation  ARIO Documentation

Document Number: 2
Source: https://docs.ar.io/build/run-a-gateway/manage/content-moderation
Words: 811
Quality Score: 0.700
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Run a Gateway Manage your Gateway Overview Arweave is a network designed for permanent storage of data. It is a practical impossibility for data to be wholly removed from the network once it has been uploaded.The AR.IO Network has adopted Arweave's voluntary content moderation model, whereby every participant of the network has the autonomy to decide which content they want to (or can legally) store, serve, and see. Each gateway operating on the network has the right and ability to blocklist any content, ArNS name, or address that is deemed in violation of its content policies or is non-compliant with local regulations.Gateway operators may set content to be blocked by their gateway by submitting a PUT request to their gateway defining the content to be blocked. This requires that the ADMIN_API_KEY environmental variable to be set in order to authenticate the moderation request.The simplest method for submitting moderation requests to a gateway is to use curl in a terminal.Quick Start Set Up Admin API Key Configure your admin API key in your .env file:# Set a secure admin API key
ADMIN_API_KEY=your_secure_admin_key_here Test API Access Verify your admin API key is working:# Test admin endpoint access
curl -H "Authorization: Bearer your_secure_admin_key_here" \
http://localhost:3000/ar-io/admin/debug Block Your First Content Block a specific transaction ID:curl -X 'PUT' \
'http://localhost:3000/ar-io/admin/block-data' \
-H 'accept: */*' \
-H 'Authorization: Bearer your_secure_admin_key_here' \
-H 'Content-Type: application/json' \
-d '{
"id": "3lyxgbgEvqNSvJrTX2J7CfRychUD5KClFhhVLyTPNCQ",
"notes": "Content violates our policies",
"source": "Manual Review"
}' Authentication Moderation requests must contain the gateway's ADMIN_API_KEY in the request Header, as Authorization: Bearer.For example, if a gateway's ADMIN_API_KEY is set to secret, any request must contain Authorization: Bearer secret in the Header.Block Data Specific data items can be blocked by a gateway operator by submitting a PUT request containing a json object with three keys:id: The Arweave transaction Id of the data item to be blocked.notes: Any note the gateway operator wants to leave him/herself as to the reason the content is blocked.source: A note as to where the content was identified as requiring moderation. i.e. a public block list.Requests to block data must be submitted to the gateway's /ar-io/admin/block-data endpoint.curl -X 'PUT' \
'http://localhost:3000/ar-io/admin/block-data' \
-H 'accept: */*' \
-H 'Authorization: Bearer secret' \
-H 'Content-Type: application/json' \
-d '{
"id": "3lyxgbgEvqNSvJrTX2J7CfRychUD5KClFhhVLyTPNCQ",
"notes": "This content is offensive",
"source": "Public Block list"
}' Unblock Data At this time, blocked data items can only be unblocked by manually deleting the corresponding row from the data/sqlite/moderation.db database.
The Arweave transaction Id of the blocked data item is stored in the database as raw bytes, which sqlite3 accepts as a BLOB (Binary Large OBject), and so cannot be accessed easily using the original transaction Id, which is a base64url.
Sqlite3 is able to interact with a hexadecimal representation of the BLOB, by using a BLOB literal. To do so, wrap a hexadecimal representation of the Arweave transaction Id in single quotes, and prepend an X i.e. X'de5cb181b804bea352bc9ad35f627b09f472721503e4a0a51618552f24cf3424'.Where possible, consider using the notes or source values to identify rows for deletion rather than the id.sqlite3 data/sqlite/moderation.db "DELETE FROM blocked_ids WHERE id=X'de5cb181b804bea352bc9ad35f627b09f472721503e4a0a51618552f24cf3424';"
# Note that the id in this command is a BLOB literal using the hexadecimal representation of the Arweave transaction Id, not the transaction Id in its normal base64url format sqlite3 data/sqlite/moderation.db "DELETE FROM blocked_ids WHERE block_source_id = (SELECT id FROM block_sources WHERE name='Public Block List');"
# This command uses a subquery to look up the id in block_sources where name='Public Block List'
# This command will unblock ALL data items marked with this source value Block ArNS Name ArNS names can be blocked so that a gateway will refuse to serve their associated content even if the name holder updates the Arweave transaction Id that the name points at.This is done via an authenticated PUT request to the endpoint /ar-io/admin/block-name containing a json object with three keys:name: The ArNS name to be blocked.notes: Any note the gateway operator wants to leave him/herself as to the reason the content is blocked.source: A note as to where the content was identified as requiring moderation. i.e. a public block list.curl -X 'PUT' \
'http://localhost:3000/ar-io/admin/block-name' \
-H 'accept: */*' \
-H 'Authorization: Bearer secret' \
-H 'Content-Type: application/json' \
-d '{
"name": "i-bought-a-potato",
"notes": "Potatoes are offensive",
"source": "Public Block list"
}' Unblock ArNS Name Gateway operators can unblock ArNS names that were previously blocked.This is done via an authenticated PUT request to the endpoint /ar-io/admin/unblock-name containing a json object with a single key:name: The ArNS name to be unblocked curl -X 'PUT' \
'http://localhost:3000/ar-io/admin/unblock-name' \
-H 'accept: */*' \
-H 'Authorization: Bearer secret' \
-H 'Content-Type: application/json' \
-d '{
"name": "i-bought-a-potato",
}' How is this guide?Gateway Filters Comprehensive guide to configuring AR.IO Gateway filters for efficient data processing and indexing Importing SQLite Database Snapshots Learn how to import SQLite database snapshots to quickly bootstrap your AR.IO Gateway and reduce synchronization time.

---

# 3. Bundler  ARIO Documentation

Document Number: 3
Source: https://docs.ar.io/build/extensions/bundler
Words: 1098
Quality Score: 0.679
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Extensions & Sidecars Overview A Turbo ANS-104 data item bundler can be run alongside an AR.IO gateway. This allows gateways the ability to accept data items to be submitted to the Arweave blockweave.The bundler service can be easily run inside Docker in the same way that the gateway is. It utilizes a separate docker compose file for configuration and deployment, which also allows for the use of a separate file for environmental variables specific to the bundler service. Additionally, the separation allows operators to spin their bundler service up or down at any time without affecting their core gateway service. Despite the use of separate docker compose files, the bundler service shares a docker network with the AR.IO gateway, and so is able to directly interact with the gateway service and data.For more information on ANS-104 Bundles, see the ANS-104 Bundles page.Getting Started NOTE: The bundler service relies on GraphQL indexing of recently bundled
and uploaded data to manage its pipeline operations. The AR.IO gateway should
have its indexes synced up to Arweave's current block height before starting
the bundler's service stack.Configure Environmental Variables Environmental variables must be provided for the bundler to function and integrate properly with an existing AR.IO gateway. The gateway repository provides a .env.bundler.example file that can be renamed to .env.bundler and used as a starting point. It contains the following: BUNDLER_ARWEAVE_WALLET must be the entire jwk of an Arweave wallet's keyfile, stringified. All uploads of bundled data items to Arweave will be signed and paid for by this wallet, so it must maintain a balance of AR tokens sufficient to handle the uploads.BUNDLER_ARWEAVE_ADDRESS must be the normalized public address for the provided Arweave wallet.APP_NAME is a GraphQL tag that will be added to uploaded bundles.The remaining lines in the .env.bundler.example file control settings that allow the bundler service to share data with the AR.IO gateway. Data sharing of contiguous data between a bundler and a gateway allows the gateway to serve optimistically cached data without waiting for it to fully settle on chain.Configure Optimistic Indexing By default, the bundler will only accept data items uploaded by data item signers whose normalized wallet addresses are in the ALLOW_LISTED_ADDRESSES list. This is an additional environmental variable that can be added to your .env.bundler file, and must be a comma separated list of normalized public wallet addresses for wallets that should be allowed to bundle and upload data through your gateway.ALLOW_LISTED_ADDRESSES=, The following permissioning configurations schemes are also possible:Scheme ALLOW_LISTED_ADDRESSES SKIP_BALANCE_CHECKS ALLOW_LISTED_SIGNATURE_TYPES PAYMENT_SERVICE_BASE_URL Allow Specific Wallets Comma-separated normalized wallet addresses false EMPTY or supplied EMPTY Allow Specific chains EMPTY or supplied false arbundles sigtype int EMPTY Allow All n/a true n/a n/a Allow None EMPTY false EMPTY EMPTY Allow Payers EMPTY or supplied false EMPTY or supplied Your payment service url Set Up Indexing Bundlers submit data to the Arweave network as an ANS-104 data item bundle. This means it is several transactions wrapped into one. A gateway will need to unbundle these transactions in order to index them. A gateway should include the following ANS-104 filters in order to unbundle and index transactions from a particular bundler:ANS104_INDEX_FILTER={ "always": true }
ANS104_UNBUNDLE_FILTER={ "attributes": { "owner_address": "$BUNDLER_ARWEAVE_ADDRESS" } } $BUNDLER_ARWEAVE_ADDRESS should be replaced with the normalized public wallet address associated with the bundler.NOTE: The above filters must be placed in the .env file for the core gateway service, not the bundler.Gateways handle data item indexing asynchronously. This means they establish a queue of items to index, and work on processing the queue in the background while the gateway continues with its normal operations. If a gateway has broad indexing filters, there can be some latency in indexing data items from the bundler while the gateway works through its queue.Configure Optimistic Indexing Gateway operators control access to their optimistic data item indexing API via an admin key that must be supplied by all bundling clients in order for their requests to be accepted. This key should be made available in the environment configuration files for BOTH the core gateway, and the bundler, and should be provided as AR_IO_ADMIN_KEY:AR_IO_ADMIN_KEY="Admin password" NOTE: If a gateway is started without providing the admin key, a random string will be generated to protect the gateway's admin endpoints. This can be reset by restarting the gateway with the admin key provided in the .env file.Starting and ping the Bundler Starting The bundler service is designed to run in conjunction with an AR.IO gateway, and so relies on the ar-io-network network created in Docker when the core gateway services are spun up. It is possible to spin up the bundler while the core services are down, but the network must exist in Docker.To start the bundler, specify the env and docker-compose files being used in a docker compose up command:docker compose --env-file ./.env.bundler --file docker-compose.bundler.yaml up -d The -d flag runs the command in "detached" mode, so it will run in the background without requiring the terminal to remain active.ping To spin the bundler service down, specify the docker-compose file in a docker compose down command:docker compose --file docker-compose.bundler.yaml down Logs While the bundler service is running in detached mode, logs can be checked by specifying the docker-compose file in a docker compose logs command:docker compose --file docker-compose.bundler.yaml logs -f --tail=0 -f runs the command in "follow" mode, so the terminal will continue to watch and dis new logs.--tail= defines the number of logs to dis that existed prior to running the command. 0 diss only new logs.Useful Docker Commands Monitor and manage your bundler service with these commands:# View all running services
docker ps
# Start bundler service in background
docker compose --env-file ./.env.bundler --file docker-compose.bundler.yaml up -d
# bundler service
docker compose --file docker-compose.bundler.yaml down
# Pull latest bundler images
docker compose --file docker-compose.bundler.yaml pull
# Follow bundler logs
docker compose --file docker-compose.bundler.yaml logs -f --tail=10
# Check bundler service status
docker compose --file docker-compose.bundler.yaml ps
# Restart bundler service
docker compose --file docker-compose.bundler.yaml restart Next Steps Now that you have a bundler set up to accept data uploads, continue building your gateway infrastructure:Set Up Monitoring Deploy Grafana to visualize your gateway's performance metrics Add ClickHouse Improve query performance with ClickHouse and Parquet integration Run Compute Unit Execute AO processes locally for maximum efficiency Buy an ArNS Name Get a human-readable name for your gateway and start serving the permanent web How is this guide?ClickHouse & Parquet Learn how to use Parquet files and ClickHouse to improve performance and scalability of your AR.IO gateway for large datasets.AO Compute Unit (CU) Steps for deploying an AO Compute Unit (CU) sidecar alongside your AR.IO Gateway.

---

# 4. Turbo SDK  ARIO Documentation

Document Number: 4
Source: https://docs.ar.io/sdks/turbo-sdk
Words: 347
Quality Score: 0.674
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

The Turbo SDK provides a high-level interface for uploading data to Arweave through Turbo's optimized infrastructure. Built with TypeScript, it offers seamless integration with built-in error handling, automatic retries, and transparent pricing.Quick Start Install the SDK npm install @ardrive/turbo-sdk Use the SDK import { TurboFactory, USD } from '@ardrive/turbo-sdk';
import fs from 'fs';
// Create an authenticated client
const turbo = TurboFactory.authenticated({ privateKey: yourPrivateKey });
// Upload data with automatic payment
const result = await turbo.uploadFile({
fileStreamFactory: () => fs.createReadStream('./my-file.pdf'),
fileSizeFactory: () => fs.statSync('./my-file.pdf').size,
});
console.log('Upload successful:', result);Install the SDK npm install @ardrive/turbo-sdk Install polyfills (required for web environments) npm install --save-dev vite-plugin-node-polyfills // vite.config.js
import { defineConfig } from 'vite';
import { nodePolyfills } from 'vite-plugin-node-polyfills';
export default defineConfig({
plugins: [
nodePolyfills({
globals: {
Buffer: true,
global: true,
process: true,
},
}),
],
});Configure your bundler (Webpack, Vite, Rollup, etc.) to provide polyfills for crypto, process, and buffer. Refer to your bundler's documentation for polyfill configuration.Use the SDK import { TurboFactory, USD } from '@ardrive/turbo-sdk';
// Create an authenticated client
const turbo = TurboFactory.authenticated({ privateKey: yourPrivateKey });
// Upload data with automatic payment
const fileInput = document.querySelector('input[type="file"]');
const file = fileInput.files[0];
const result = await turbo.uploadFile({
fileStreamFactory: () => file.stream(),
fileSizeFactory: () => file.size,
});
console.log('Upload successful:', result);
Turbo SDK Upload Example

# Turbo SDK Upload Example

Private Key (JWK):

Select File:

Upload to Arweave


API Reference & Documentation API Reference Complete API documentation for all Turbo client methods SDK Details Advanced features, events, logging, and credit sharing Core Features Upload Management Authenticated and unauthenticated upload clients with retry logic Events & Monitoring Monitor upload progress and handle events in real-time Credit Sharing Manage shared credit pools for streamlined billing Logging & Configuration Configure logging for debugging and monitoring uploads How is this guide?Pagination TypeScript/JavaScript SDK for interacting with the AR.IO ecosystem TurboFactory SDK for interacting with Turbo, a fast and efficient data upload service for Arweave On this page Quick Start Install the SDK Use the SDK Install the SDK Install polyfills (required for web environments) Use the SDK API Reference & Documentation Core Features

---

# 5. Storing DePIN Data on Arweave Using Turbo  ARIO Documentation

Document Number: 5
Source: https://docs.ar.io/build/guides/depin
Words: 914
Quality Score: 0.670
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Guides DePIN networks require scalable and cost-effective storage solutions they can trust. With vast amounts of data generated by decentralized physical infrastructure networks, traditional on-chain storage is prohibitively expensive, yet networks need reliable, long-term access to their device data.Arweave via AR.IO Network provides chain-agnostic, permanent and immutable storage for a one-time fee, ensuring networks can access any device data previously stored and verify it has not been tampered with.Getting Started with DePIN Data Storage Prepare Your Data Structure Organize your DePIN device data in a consistent format. Here's an example for environmental sensor data:{
"device_id": "airmon-007",
"timestamp": "2025-09-22T14:31:05Z",
"location": { "lat": 51.5098, "lon": -0.118 },
"pm25": 16,
"co2_ppm": 412,
"noise_dB": 41.2
} Best Practices:Use consistent field names across all devices Include timestamps in ISO format Add device identifiers for tracking Consider data compression for large datasets Tag Your Data for Discovery Proper tagging is essential for finding your data later. Consider these tags for DePIN data:{
"name": "App-Name",
"value": "AirQuality-DePIN-v1.0"
},
{
"name": "Device-ID",
"value": "airmon-007"
},
{
"name": "Device-Type",
"value": "Environmental-Sensor"
},
{
"name": "Network-Name",
"value": "AirQuality-Network"
},
{
"name": "Data-Category",
"value": "Air-Quality"
},
{
"name": "Location",
"value": "London-UK"
},
{
"name": "Device-Timestamp",
"value": "2025-09-22T14:31:05Z"
} Tagging Strategy:Use consistent naming conventions Include geographic identifiers Add device type classifications Include data categories for filtering For more detailed information on tagging, see our Tagging documentation Upload to Arweave Select the best method for your DePIN network's needs:import { TurboFactory } from '@ardrive/turbo-sdk'
// Initialize with your wallet
const turbo = await TurboFactory.authenticated({
privateKey: jwk, // Your Arweave wallet
token: 'arweave'
})
// Upload device data
const result = await turbo.upload({
data: JSON.stringify(deviceData),
dataItemOpts: {
tags: [
{ name: "Content-Type", value: "application/json" },
{ name: "App-Name", value: "AirQuality-DePIN-v1.0" },
{ name: "Device-ID", value: "airmon-007" },
{ name: "Device-Type", value: "Environmental-Sensor" },
{ name: "Network-Name", value: "AirQuality-Network" },
{ name: "Data-Category", value: "Air-Quality" },
{ name: "Location", value: "London-UK" },
{ name: "Device-Timestamp", value: "2025-09-22T14:31:05Z" }
]
}
}) # Install Turbo CLI
npm install -g @ardrive/turbo-sdk
# Upload a single file
turbo upload-file --file-path sensor-data.json \
--tag "Content-Type:application/json" \
--tag "App-Name:AirQuality-DePIN-v1.0" \
--tag "Device-Type:Environmental-Sensor" \
--tag "Network-Name:AirQuality-Network" \
--tag "Data-Category:Air-Quality" \
--tag "Location:London-UK" \
--tag "Device-Timestamp:2025-09-22T14:31:05Z"
# Upload entire folder
turbo upload-folder --folder-path ./sensor-data \
--tag "App-Name:AirQuality-DePIN-v1.0" \
--tag "Network-Name:AirQuality-Network" \
--tag "Data-Category:Air-Quality" \
--index-file index.json For more advanced uploading options, see our Advanced Uploading with Turbo guide, or the Turbo SDK documentation directly.Querying Your DePIN Data Find Your Data Use GraphQL to search for your DePIN data by tags and criteria:# Find all data for a specific device, most recent results first
query {
transactions(
tags: [
{ name: "App-Name", values: ["AirQuality-DePIN-v1.0"] }
{ name: "Device-ID", values: ["airmon-007"] }
]
first: 100
sort: HEIGHT_DESC
) {
edges {
node {
id
tags {
name
value
}
data {
size
}
}
}
}
} # Find data by location
query {
transactions(
tags: [
{ name: "App-Name", values: ["AirQuality-DePIN-v1.0"] }
{ name: "Location", values: ["London-UK"] }
]
first: 50
) {
edges {
node {
id
tags {
name
value
}
}
}
}
} For more advanced querying options, see our Find Your Data documentation.Access and Use Your Data Once you have transaction IDs from your queries, choose how to fetch and process the data:Direct data fetching:// Example: Process air quality data
async function processAirQualityData(transactionIds) {
const results = []
for (const txId of transactionIds) {
const response = await fetch(`https://arweave.net/${txId}`)
const data = await response.json()
// Process the data
const processed = {
Device_ID: data.device_id,
timestamp: data.timestamp,
location: data.location,
pm25: data.pm25,
co2_ppm: data.co2_ppm,
noise_dB: data.noise_dB
}
results.push(processed)
}
return results
} For more information on fetching data, see our Fetch Data documentation.Verified data with optimized routing:import {
createWayfinderClient,
PreferredWithFallbackRoutingStrategy,
FastestPingRoutingStrategy,
HashVerificationStrategy
} from "@ar.io/wayfinder-core";
import { ARIO } from '@ar.io/sdk';
const wayfinder = createWayfinderClient({
ario: ARIO.mainnet(),
routingStrategy: new PreferredWithFallbackRoutingStrategy({
preferredGateway: 'https://your-gateway.com',
fallbackStrategy: new FastestPingRoutingStrategy({ timeoutMs: 500 }),
}),
verificationStrategy: new HashVerificationStrategy({
trustedGateways: ['https://arweave.net'],
}),
telemetrySettings: {
enabled: true,
clientName: 'AirQuality-DePIN-v1.0',
},
});
// Fetch and verify data using ar:// protocol
async function processVerifiedAirQualityData(transactionIds) {
const results = []
for (const txId of transactionIds) {
const response = await wayfinder.request(`ar://${txId}`)
const data = await response.json()
// Process the verified data
const processed = {
Device_ID: data.device_id,
timestamp: data.timestamp,
location: data.location,
pm25: data.pm25,
co2_ppm: data.co2_ppm,
noise_dB: data.noise_dB,
noise_level: data.noise_dB,
verified: true // Data is cryptographically verified
}
results.push(processed)
}
return results
} verification with Wayfinder.Next Steps In production, teams have several options to take this further to provide significantly more value to the network and its users including:Advanced Uploading with Turbo Pay in different Tokens and organise device data files with folders or manifests.Run a Gateway Operate a gateway optimised to index and serve your device data fast.Arweave Name System (ArNS) Create mutable data structures for permanent device data and decentralised apps.These approaches can make your DePIN data even more resilient and useful. See more detailed guides about this below and or join our discord to find out more.Need Help?If you're interested in exploring these advanced features for your DePIN network, join our Discord community or reach out to our team.How is this guide?Guides Discover what you can build with Arweave and AR.IO infrastructure Hosting Decentralized Websites Build permanent, censorship-resistant websites on Arweave using manifests and deployment tools On this page Getting Started with DePIN Data Storage Prepare Your Data Structure Tag Your Data for Discovery Upload to Arweave Querying Your DePIN Data Find Your Data Access and Use Your Data Next Steps Need Help?

---

# 6. ClickHouse  Parquet  ARIO Documentation

Document Number: 6
Source: https://docs.ar.io/build/extensions/clickhouse
Words: 2041
Quality Score: 0.658
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Extensions & Sidecars Overview AR.IO gateway Release 33 introduces a new configuration option for using Parquet files and ClickHouse to improve performance and scalability of your AR.IO gateway for large datasets.This guide will walk you through the process of setting up ClickHouse with your AR.IO gateway, and importing Parquet files to bootstrap your ClickHouse database.What is Parquet?Apache Parquet is a columnar storage file format designed for efficient data storage and retrieval. Unlike row-based storage formats like SQLite, Parquet organizes data by column rather than by row, which provides several advantages for analytical workloads:Efficient compression: Similar data is stored together, leading to better compression ratios Columnar access: You can read only the columns you need, reducing I/O operations Predicate pushdown: Filter operations can be pushed down to the storage layer, improving query performance For more information about Parquet, see the Parquet documentation.Current Integration with AR.IO Gateways In the current AR.IO gateway implementation, Parquet and ClickHouse run alongside SQLite rather than replacing it. This parallel architecture allows each database to handle what it does best:SQLite continues to handle transaction writes and updates ClickHouse with Parquet files is optimized for fast query performance, especially with large datasets The gateway continues to operate with SQLite just as it always has, maintaining all of its normal functionality. Periodically, the gateway will export batches of data from SQLite to Parquet files, which are then imported into ClickHouse. This batch-oriented approach is much more efficient than attempting to synchronize the databases in real-time, as it leverages Parquet's strength in handling large, immutable data sets.Note that despite Parquet's efficient compression, gateways may not see significant disk space reduction in all cases. While bundled transaction data is exported to Parquet, L1 data remains in SQLite. Without substantial unbundling and indexing filters, minimal data gets exported to Parquet, limiting potential storage savings.With ClickHouse integration enabled, GraphQL queries are primarily routed to ClickHouse, leveraging its superior performance for large datasets. This significantly improves response times while maintaining SQLite's reliability for transaction processing.For more information about gateway architecture and data processing, see our Gateway Architecture documentation.Parquet vs. SQLite in AR.IO Gateways While SQLite is excellent for transactional workloads and small to medium datasets, it faces challenges with very large datasets:Feature SQLite Parquet + ClickHouse Storage model Row-based Column-based Query optimization Basic Advanced analytical optimization Compression Limited High compression ratios Scaling Limited by single file Distributed processing capable Write speed Fast for small transactions Optimized for batch operations Read speed for analytics Slower for large datasets Optimized for analytical queries Ideal use case Recent transaction data, OLTP Historical data, OLAP workloads Benefits for Gateway Operators Implementing Parquet and ClickHouse alongside SQLite in your AR.IO gateway offers several key advantages:Dramatically improved query performance for GraphQL endpoints, especially for large result sets Reduced storage requirements through efficient columnar compression Better scalability for growing datasets Faster bootstrapping of new gateways through Parquet file imports Reduced load on SQLite by offloading query operations to ClickHouse The primary focus of the Parquet/ClickHouse integration is the significant speed improvement for querying large datasets. Gateway operators managing significant s of data will notice substantial performance gains when using this configuration.Storage Considerations While Parquet files offer more efficient compression for the data they contain, it's important to understand the storage impact:Bundled transaction data is exported to Parquet and removed from SQLite, potentially saving space L1 data remains in SQLite regardless of Parquet configuration Space savings are highly dependent on your unbundling filters - without substantial unbundling configurations, minimal data gets exported to Parquet The more data you unbundle and export to Parquet, the greater the potential storage efficiency For gateway operators, this means proper filter configuration is crucial to realize storage benefits. The primary advantage remains significantly improved query performance for large datasets, with potential space savings as a secondary benefit depending on your specific configuration.The following sections will guide you through setting up ClickHouse with your AR.IO gateway, exporting data from SQLite to Parquet, and importing Parquet files to bootstrap your ClickHouse database.Note The below instructions are designed to be used in a linux environment. Windows and MacOS users must modify the instructions to use the appropriate package manager/ command syntax for their platform.Unless otherwise specified, all commands should be run from the root directory of the gateway.Installing ClickHouse ClickHouse is a powerful, open-source analytical database that excels at handling large datasets and complex queries. It is the tool used by the gateway to integrate with the Parquet format.For more information about ClickHouse, see the ClickHouse documentation.Add ClickHouse Repository It is recommended to use official pre-compiled deb packages for Debian or Ubuntu. Run these commands to install packages: This will verify the installation package from official sources and enable installation via apt-get.Install ClickHouse sudo apt-get install -y clickhouse-client This will perform the actual installation of the ClickHouse server and client.During installation, you will be prompted to set a password for the default user. This is required to connect to the ClickHouse server.Advanced users may also choose to create a designated user account in clickhouse for the gateway to use, but the default gateway configuration will assume the default user.Configure Gateway to use ClickHouse Set Basic ClickHouse Configuration Because the gateway will be accessing ClickHouse, host address andthe password for the selected user must be provided. This is done via the CLICKHOUSE_PASSWORD environment variable.Update your.env file with the following:CLICKHOUSE_URL="http://clickhouse:8123"
CLICKHOUSE_PASSWORD= If you set a specific user account for the gateway to use, you can set the CLICKHOUSE_USER environment variable to the username.CLICKHOUSE_USER= If omitted, the gateway will use the default user.Configure Unbundling Filters Additionally, The Parquet file provided below contains an unbundled data set that includes all data items uploaded via an ArDrive product, including Turbo. Because of this, it is recommended to include unbundling filters that match, or expand, this configuration.ANS104_UNBUNDLE_FILTER='{ "and": [ { "not": { "or": [ { "tags": [ { "name": "Bundler-App-Name", "value": "Warp" } ] }, { "tags": [ { "name": "Bundler-App-Name", "value": "Redstone" } ] }, { "tags": [ { "name": "Bundler-App-Name", "value": "KYVE" } ] }, { "tags": [ { "name": "Bundler-App-Name", "value": "AO" } ] }, { "attributes": { "owner_address": "-OXcT1sVRSA5eGwt2k6Yuz8-3e3g9WJi5uSE99CWqsBs" } }, { "attributes": { "owner_address": "ZE0N-8P9gXkhtK-07PQu9d8me5tGDxa_i4Mee5RzVYg" } }, { "attributes": { "owner_address": "6DTqSgzXVErOuLhaP0fmAjqF4yzXkvth58asTxP3pNw" } } ] } }, { "tags": [ { "name": "App-Name", "valueStartsWith": "ArDrive" } ] } ] }'
ANS104_INDEX_FILTER='{ "tags": [ { "name": "App-Name", "value": "ArDrive-App" } ] }' Set Admin API Key Lastly, you must have a gateway admin password set. This is used for the periodic export of data from SQLite to Parquet.ADMIN_API_KEY= Once the.env file is updated, restart the gateway to apply the changes.Downloading and Importing the Parquet File Download the Parquet File A Parquet archive file is available for download from ar://JVmsuD2EmFkhitzWN71oi9woADE4WUfvrbBYgremCBM. This file contains an unbundled data set that includes all data items uploaded via an ArDrive product, current to April 23, 2025, and compressed using tar.gz.To download the file, run the following command:curl -L https://arweave.net/JVmsuD2EmFkhitzWN71oi9woADE4WUfvrbBYgremCBM -o 2025-04-23-ardrive-ans104-parquet.tar.gz or visit the url https://arweave.net/JVmsuD2EmFkhitzWN71oi9woADE4WUfvrbBYgremCBM and download the file manually.Note If downloaded manually, it will download as a binary file named JVmsuD2EmFkhitzWN71oi9woADE4WUfvrbBYgremCBM. This is normal and must be converted to a tar.gz file by renaming it to 2025-04-23-ardrive-ans104-parquet.tar.gz.It should also be placed in the root directory of the gateway.The downloaded file will be approximately 3.5GB in size.Extract the Parquet Files With the parquet file downloaded and placed in the root directory of the gateway, you can extract the file and import it into ClickHouse.tar -xzf 2025-04-23-ardrive-ans104-parquet.tar.gz This will extract the file into a directory named 2025-04-23-ardrive-ans104-parquet, and take a while to complete.Prepare the Data Directory Next, if you do not already have a data/parquet directory, you must create it. Release 33 does not have this directory by default, but future Releases will. You can create the directory by using the following command:mkdir -p data/parquet or by starting the gateway ClickHouse container with the following command:docker compose --profile clickhouse up clickhouse -d Note Depending on your system configurations, allowing the gateway to create the directory may result in the directory being created with incorrect permissions. If this is the case, you can remove the restrictions by running the following command:sudo chmod -R 777 data/parquet With the directory created, you can now move the extracted parquet files into it.mv 2025-04-23-ardrive-ans104-parquet/* data/parquet Import Data into ClickHouse When this is complete, you can run the import script to import the parquet files into ClickHouse.If you haven't done so already, start the ClickHouse container with the following command:docker compose --profile clickhouse up clickhouse -d Then run the import script with the following command:./scripts/clickhouse-import This process will take several minutes, and will output the progress of the import.Verifying Successful Import Verify ClickHouse Import To verify that the import was successful, run the following commands:clickhouse client --password -h localhost -q 'SELECT COUNT(DISTINCT id) FROM transactions' Being sure to replace with the password you set for the selected ClickHouse user.This should return a count of the number of unique transactions in the parquet file, which is 32712311.Test GraphQL Endpoint You can also verify that the data is being served by the gateway's GraphQL endpoint by ensuring the gateway is not proxying its GraphQL queries (Make sure GRAPHQL_HOST is not set) and running the following command:curl -g -X POST \
-H "Content-Type: application/json" \
-d '{"query":"query { transactions(ids: [\"YSNwoYB01EFIzbs6HmkGUjjxHW3xuqh-rckYhi0av4A\"]) { edges { node { block { height } bundledIn { id } } } } }"}' \
http://localhost:3000/graphql
# Expected output:
# {"data":{"transactions":{"edges":[{"node":{"block":{"height":1461918},"bundledIn":{"id":"ylhb0PqDtG5HwBg00_RYztUl0x2RuKvbNzT6YiNR2JA"}}}]}}} Starting and ping the Gateway with ClickHouse The gateway ClickHouse container is run as a "profile" in the main docker compose file. That means you must specify the profile when starting or ping the gateway if you want to include the ClickHouse container in the commands.Start Gateway with ClickHouse To start the gateway with the ClickHouse profile, run the following command:docker compose --profile clickhouse up -d This will start all of the containers normally covered by the docker compose up command, but will also start the ClickHouse container. Gateway with ClickHouse To the gateway with the ClickHouse profile, run the following command:docker compose --profile clickhouse down This will all of the containers normally covered by the docker compose down command, but will also the ClickHouse container.Manage ClickHouse Container Only To start or only the ClickHouse container, you can use the following commands:docker compose --profile clickhouse up clickhouse -d and docker compose --profile clickhouse down clickhouse Useful Docker Commands Monitor and manage your gateway with ClickHouse using these commands:# View all running services
docker ps
# Start gateway with ClickHouse profile
docker compose --profile clickhouse up -d
# gateway with ClickHouse profile
docker compose --profile clickhouse down
# Pull latest images
docker compose --profile clickhouse pull
# Start only ClickHouse container
docker compose --profile clickhouse up clickhouse -d
# only ClickHouse container
docker compose --profile clickhouse down clickhouse
# Follow gateway logs
docker compose logs core -f -n 10
# Follow ClickHouse logs
docker compose --profile clickhouse logs clickhouse -f -n 10
# Check ClickHouse container status
docker compose --profile clickhouse ps clickhouse
# Restart ClickHouse container
docker compose --profile clickhouse restart clickhouse Next Steps Now that you have ClickHouse set up for improved query performance, continue building your gateway infrastructure:Set Up Monitoring Deploy Grafana to visualize your gateway's performance metrics Deploy Bundler Accept data uploads directly through your gateway Run Compute Unit Execute AO processes locally for maximum efficiency Join the Network Register your gateway and start serving the permanent web How is this guide?Grafana Comprehensive guide to deploying and configuring Grafana for AR.IO Gateway monitoring and analytics Bundler Learn about the Turbo ANS-104 data item bundler that can be run alongside an AR.IO Gateway to accept and submit data items to Arweave On this page Overview What is Parquet?Current Integration with AR.IO Gateways Parquet vs. SQLite in AR.IO Gateways Benefits for Gateway Operators Storage Considerations Installing ClickHouse Add ClickHouse Repository Install ClickHouse Configure Gateway to use ClickHouse Set Basic ClickHouse Configuration Configure Unbundling Filters Set Admin API Key Downloading and Importing the Parquet File Download the Parquet File Extract the Parquet Files Prepare the Data Directory Import Data into ClickHouse Verifying Successful Import Verify ClickHouse Import Test GraphQL Endpoint Starting and ping the Gateway with ClickHouse Start Gateway with ClickHouse Gateway with ClickHouse Manage ClickHouse Container Only Useful Docker Commands Next Steps

---

# 7. Crossmint NFT Minting App  ARIO Documentation

Document Number: 7
Source: https://docs.ar.io/build/guides/crossmint-nft-minting-app
Words: 1066
Quality Score: 0.654
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Guides Build a completely decentralized NFT minting app that leverages the power of Arweave for permanent storage and Crossmint for simplified NFT creation. Learn how to store NFT content permanently, create and mint NFTs, build a frontend with authentication and payment options, and deploy your application to Arweave.What You'll Learn How to store NFT content permanently on Arweave How to create and mint NFTs using Crossmint's API How to build a frontend with authentication and payment options How to deploy your application to Arweave How to configure a human-readable ArNS domain Example Project Live Demo: https://crossmint_zerotoarweave.arweave.net GitHub Repository: https://github.com/ar-io/crossmint-arweave-example Prerequisites Node.js environment Arweave wallet with AR tokens Crossmint developer account Basic understanding of React and JavaScript Quick Start Storage Setup Store your NFT image permanently on Arweave using ArDrive.io:Generate AI Image Create an AI-generated image for your NFT:Visit ChatGPT or another AI image generation tool Use a prompt to generate an interesting image for your NFT Download the generated image to your local machine Make sure to save it in a common format like PNG or JPG Upload to Arweave Store the image permanently on Arweave:Visit ArDrive.io and log in to your account Fund your ArDrive wallet if needed (requires AR tokens) Create a new folder for your NFT project Drag and drop your AI-generated image into this folder Wait for the upload to complete and for the transaction to be processed Get Transaction ID Retrieve the Arweave Transaction ID:Click on the uploaded image in your ArDrive folder Look for the "Transaction ID" or "TX ID" in the file details Copy this Transaction ID - it looks like Abc123XYZ...Save this Transaction ID - you'll need it for creating your NFT metadata Collection and Template Creation Create an ERC-1155 collection and template using Crossmint's API:Create Account Set up your Crossmint developer account:Visit the Crossmint Staging Console Sign in and accept the dialog to continue Note that Crossmint provides two environments:Staging: For development and testing (what we'll use first) Production: For your final, live application Get API Key Get a server-side API key:After logging in, navigate to the "Integrate" tab Click on "API Keys" at the top of the page In the "Server-side keys" section, click "Create new key" Select the following scopes under "Minting API":collections.create - Required for creating a new collection nfts.create - Required for minting NFTs nfts.read - Needed to read NFT information Create and save this API key securely Create Collection Create an ERC-1155 collection:const apiKey = "YOUR_API_KEY";
const env = "staging"; // Using staging environment for development
const url = `https://${env}.crossmint.com/api/2022-06-09/collections`;
const options = {
method: "POST",
headers: {
"accept": "application/json",
"content-type": "application/json",
"x-api-key": apiKey,
},
body: JSON.stringify({
chain: "ethereum-sepolia", // Using Ethereum testnet for development
fungibility: "semi-fungible", // For ERC-1155 tokens
metadata: {
name: "lil dumdumz SFT Collection",
imageUrl: "https://arweave.net/YOUR_ARWEAVE_TX_ID", // Optional collection image
description: "A collection of semi-fungible tokens with images stored on Arweave"
}
}),
};
fetch(url, options)
.then((res) => res.json())
.then((json) => {
console.log("Collection created! Collection ID:", json.id);
console.log("Save this Collection ID for the next steps");
})
.catch((err) => console.error("Error:", err));Create Template Create an SFT template:Frontend Development Clone and set up the Zero-to-Arweave starter kit:Clone Repository Clone the starter kit:git clone https://github.com/ar-io/crossmint-arweave-example.git
cd crossmint-arweave-example Install Dependencies Install required packages:npm install
# or
yarn install Configure Environment Set up your environment variables:Create a .env file in the root directory:VITE_CROSSMINT_API_KEY=your_api_key_here
VITE_CROSSMINT_ENV=staging
VITE_COLLECTION_ID=your_collection_id_here
VITE_TEMPLATE_ID=your_template_id_here Authentication Integration Implement Crossmint's client-side authentication:Payment Integration Add Crossmint's embedded checkout for NFT purchases:import { CrossmintPaymentButton } from "@crossmint/client-sdk-react";
function NFTMinting() {
const handlePaymentSuccess = (result) => {
console.log("Payment successful:", result);
// Handle successful payment
};
return (

);
} Deploy to Arweave Deploy your completed application to Arweave:Build Application Build your React application:npm run build
# or
yarn build Deploy with ArDrive Deploy using ArDrive:Visit ArDrive.io Create a new folder for your application Upload the contents of your dist folder Wait for the upload to complete Get Manifest ID Retrieve the manifest ID:Click on your uploaded application folder Look for the "Manifest ID" in the folder details Copy this ID - you'll need it for domain configuration Domain Configuration Connect your application to a human-readable domain name using ArNS:Purchase ARNS Name Get an ARNS name (if needed):Visit arns.app Connect your Arweave wallet Search for an available name Purchase it with $ARIO tokens Get Process ID Get your Process ID:Visit arns.app Connect your Arweave wallet Click "Manage Assets" in the top-right Find your ARNS name and click on the settings icon Copy the Process ID dised Update Configuration Update the configuration:const ant = ANT.init({
signer: new ArweaveSigner(jwk),
processId: 'YOUR_PROCESS_ID_HERE' // Replace with your Process ID
});
const result = await ant.setRecord({
name: '@',
ttlSeconds: 900, // 15 minutes
dataLink: 'YOUR_MANIFEST_ID' // Replace with the manifest ID
});Set Base Record Set the base record:# Using pnpm
pnpm run set-base
# Using yarn
yarn set-base When successful, you'll see:✅ Base record update successful!
🔗 Your application is now available at: https://YOUR-NAME.ar.io Advanced Features Custom NFT Metadata const customMetadata = {
name: "Custom NFT Name",
description: "A unique NFT with custom attributes",
imageUrl: "https://arweave.net/YOUR_TX_ID",
attributes: [
{
trait_type: "Rarity",
value: "Legendary"
},
{
trait_type: "Power",
value: 95
},
{
trait_type: "Element",
value: "Fire"
}
]
};Batch Minting NFTs const batchMint = async (templateId, quantity) => {
const promises = Array(quantity).fill().map(() =>
mintNFT(templateId)
);
const results = await Promise.all(promises);
return results;
};Track Sales and Engagement const trackMint = (nftId, userEmail) => {
// Send analytics data
analytics.track('nft_minted', {
nftId,
userEmail,
timestamp: Date.now()
});
};Comprehensive Error Handling const mintWithErrorHandling = async (templateId) => {
try {
const result = await mintNFT(templateId);
return { success: true, data: result };
} catch (error) {
console.error('Minting failed:', error);
return {
success: false,
error: error.message
};
}
};Benefits of This Approach True Permanence: NFT images are stored permanently on Arweave Accessibility: Credit card payments make NFTs accessible to mainstream users Complete Decentralization: Both application and assets are stored on decentralized networks User-Friendly Experience: Seamless experience for both creators and collectors No Server Maintenance: No need to manage servers or renew domains Ready to Build?Clone the Example Get started with the complete example project Crossmint Documentation 's APIs and features ArFS Documentation Understand Arweave's file system for advanced storage How is this guide?ArNS Undernames for Permasite Versioning Use ArNS undernames to manage different versions and components of your permanent website Using Turbo in a Browser Learn how to integrate Turbo SDK with different web frameworks and vanilla HTML

---

# 8. Hosting Decentralized Websites  ARIO Documentation

Document Number: 8
Source: https://docs.ar.io/build/guides/hosting-decentralized-websites
Words: 419
Quality Score: 0.654
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Guides Create permanent websites that can't be censored, taken down, or modified after deployment. Host your content on Arweave and serve it through AR.IO gateways for a truly decentralized web experience.What Makes It Different?Traditional websites:Hosted on centralized servers Can be taken down or censored Require ongoing hosting costs Single point of failure Decentralized websites:Stored permanently on Arweave Censorship-resistant Pay once, host forever Distributed across the network How It Works 1. Arweave Manifests Arweave manifests are JSON files that define how your website's files are organized and linked together. They enable:Friendly URLs - Access files with readable paths instead of transaction IDs Relative linking - Use ./style.css instead of full transaction IDs Fallback pages - Handle 404 errors gracefully File organization - Structure your website like a traditional site Example manifest:{
"manifest": "arweave/paths",
"version": "0.2.0",
"index": {
"path": "index.html"
},
"fallback": {
"id": "404-page-transaction-id"
},
"paths": {
"index.html": {
"id": "main-page-transaction-id"
},
"style.css": {
"id": "css-transaction-id"
},
"script.js": {
"id": "js-transaction-id"
}
}
} 2. Deployment Tools Permaweb Deploy - CLI deployment tool that:Uploads your build folder to Arweave using Turbo Creates a manifest automatically Updates your ArNS domain Integrates with GitHub Actions Requires --deploy-folder and --arns-name parameters Arlink - User-friendly web interface for:Quick website uploads through the browser Manifest generation ArNS integration ArDrive Web - User-friendly interface for:File management Website building Deployment workflows 3. ArNS Integration Primary Names - Decentralized domain names that:Point to your website's manifest Provide human-readable URLs Can be updated to point to new versions Are owned and controlled by you Quick Start 1. Build your website - Create a static website with HTML, CSS, and JavaScript 2. Choose a deployment tool:# Using permaweb-deploy (CLI tool)
npm install permaweb-deploy --save-dev
npx permaweb-deploy --deploy-folder ./build --arns-name your-domain
# Using arlink (web interface)
# Visit the arlink website and upload through the browser 3. Get an ArNS domain - Register a primary name to point to your website 4. Access your site - Visit https://your-domain.arweave.net or any AR.IO gateway Benefits Permanent hosting - Your website will exist forever Censorship resistance - Cannot be taken down by authorities Cost efficiency - Pay once, host forever Global distribution - Served from multiple AR.IO gateways Version control - Update your ArNS domain to point to new versions How is this guide?Storing DePIN Data on Arweave Using Turbo Complete guide to storing and accessing DePIN network data permanently on Arweave using Turbo and AR.IO Network Deploy a dApp with ArDrive Web How to upload a dApp to the permaweb using ArDrive web

---

# 9. Using Turbo SDK with Vanilla HTML  ARIO Documentation

Document Number: 9
Source: https://docs.ar.io/build/guides/using-turbo-in-a-browser/html
Words: 997
Quality Score: 0.638
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Guides Using Turbo in a Browser Using Turbo SDK with Vanilla HTML Overview This guide demonstrates how to integrate the @ardrive/turbo-sdk directly into vanilla HTML pages using CDN imports. No build tools, bundlers, or polyfills are required - just modern ES modules support in browsers.Prerequisites Modern browser with ES modules support (Chrome 61+, Firefox 60+, Safari 10.1+, Edge 16+) Basic understanding of HTML, CSS, and JavaScript HTTPS hosting for production (required for browser wallet integrations) Create a basic HTML file with Turbo SDK integration:



Turbo SDK Example



# Turbo SDK - Vanilla HTML Demo
Current Rates
Loading rates...
Upload File



Upload File


Select the appropriate CDN import method for your needs:Latest Version (Recommended for Development) import { TurboFactory } from "https://esm.sh/@ardrive/turbo-sdk";Specific Version (Recommended for Production) import { TurboFactory } from "https://esm.sh/@ardrive/turbo-sdk@1.20.0";Alternative CDN Providers Connect your browser wallet to enable file uploads:Uploading with Wander Complete HTML page with Wander wallet integration:



Turbo SDK - Wander Wallet



⚡ Turbo SDK + Wander Wallet

Wander Wallet Connection

Connect your Wander wallet to upload files to Arweave using your AR
balance.


Connect Wander Wallet




📁 File Upload


Upload to Arweave


Browser wallet integrations require HTTPS in production:Implement comprehensive error handling:// Network error handling
async function robustApiCall(apiFunction, retries = 3) {
for (let i = 0; i < retries; i++) {
try {
return await apiFunction();
} catch (error) {
console.error(`Attempt ${i + 1} failed:`, error);
if (i === retries - 1) throw error;
await new Promise((resolve) =>
setTimeout(resolve, 1000 * Math.pow(2, i))
);
}
}
}
// Usage example
const rates = await robustApiCall(() => turbo.getFiatRates());Optimize for production environments:
Best Practices 1. User Experience Loading States: Always show loading indicators during API calls Error Recovery: Provide clear error messages with recovery options Progress Tracking: Show upload progress for large files Wallet Detection: Guide users to install wallets if missing 2. Security Never expose private keys in browser applications Validate user inputs before API calls Use HTTPS for all production deployments Implement CSP headers to prevent XSS attacks 3. Performance Cache API responses where appropriate (rates, costs) Use specific CDN versions in production Implement retry logic for network failures Optimize file handling for large uploads 4. Development Use development endpoints during testing Test wallet integrations across different browsers Validate upload functionality with small files first Monitor API rate limits and implement backoff Troubleshooting Common Issues CDN Import Errors If you encounter errors like:The requested module does not provide an export named 'TurboFactory' Module resolution failures Solution: Use esm.sh instead of unpkg.com:// ❌ Problematic
import { TurboFactory } from "https://unpkg.com/@ardrive/turbo-sdk";
// ✅ Working
import { TurboFactory } from "https://esm.sh/@ardrive/turbo-sdk";Function Scope Issues If onclick handlers throw ReferenceError: function is not defined:Solution: Use explicit global assignment:// ❌ Problematic
window.myFunction = async function() { ... }
// ✅ Working
async function myFunction() { ... }
window.myFunction = myFunction;Upload Result Properties If upload results have undefined properties:Solution: Use original file size for dis:// ❌ Problematic - these properties don't exist in result object
const totalBytes = result.totalBytes || result.dataSizeBytes;
// ✅ Correct - use original file size
const disBytes = originalFile.size;
// Available result properties: id, timestamp, winc, version,
// deadlineHeight, dataCaches, fastFinalityIndexes, public, signature, owner Upload Cost Properties If cost calculations fail:Solution: Use correct cost object structure:// ❌ Problematic - adjustedBytes doesn't exist in cost objects
const cost = costs[0];
console.log(`Adjusted: ${cost.adjustedBytes.toLocaleString()}`);
// ✅ Correct - use available properties
const cost = costs[0];
console.log(`Cost: ${cost.winc} winc);
console.log(File size: ${originalFile.size.toLocaleString()} bytes`);
// Available cost properties: winc (string), adjustments (array) Testing Your Implementation 1. Basic Functionality Test // Test CDN import
console.log("Testing Turbo SDK import...");
import { TurboFactory } from "https://esm.sh/@ardrive/turbo-sdk";
const turbo = TurboFactory.unauthenticated();
console.log("✅ SDK imported successfully");
// Test rate fetching
const rates = await turbo.getFiatRates();
console.log("✅ Rates fetched:", rates);2. Wallet Integration Test Connect to MetaMask/Wander wallet Verify address dis Test small file upload (< 1MB) Check transaction ID and Arweave confirmation 3. Production Readiness Test with HTTPS hosting Verify CSP headers don't block resources Test error scenarios (network offline, wallet disconnected) Validate cross-browser compatibility API Object Structures Understanding the actual structure of API responses helps prevent common errors:Upload Cost Object const costs = await turbo.getUploadCosts({ bytes: [file.size] });
const cost = costs[0];
// Actual structure:
{
winc: "15763844", // string - cost in Winston credits
adjustments: [] // array - currently empty
}
// Note: adjustedBytes property does NOT exist Upload Result Object const result = await turboClient.uploadFile({...});
// Actual structure:
{
id: "K2wbyN85FlZMBYyfn4fnk5A-fp-pmnrQWpgfuKI4UCc",
timestamp: 1752094894060,
winc: "0",
version: "0.2.0",
deadlineHeight: 1708455,
dataCaches: ["arweave.net"],
fastFinalityIndexes: ["arweave.net"],
public: "wZgP9Rpfh0nXb5EdzBUg7y2LFMkBp2ADX3gdZhLXHYbz...",
signature: "k31SCZwxerhuEojUZ7rnLMr0T6CwgVp1_dKDZc7UdvV...",
owner: "cF0H0SKdnaDTqWKY9iJKBktTpdEWgb3GnlndE7ABv0Q"
}
// Note: totalBytes and dataSizeBytes properties do NOT exist Fiat Rates Object const rates = await turbo.getFiatRates();
// Actual structure:
{
winc: "2257047178957", // string - current winc rate
fiat: { // object - fiat currency rates
aud: 25.13395879439, // number - AUD per GiB
brl: 91.578363344626, // number - BRL per GiB
cad: 22.482075685955, // number - CAD per GiB
eur: 13.996049738963, // number - EUR per GiB
gbp: 12.080800827315, // number - GBP per GiB
hkd: 129.06624536489, // number - HKD per GiB
inr: 1409.435250458, // number - INR per GiB
jpy: 2406.336355749, // number - JPY per GiB
sgd: 21.058978043112, // number - SGD per GiB
usd: 16.428221816529 // number - USD per GiB
},
adjustments: [] // array - currently empty
} Progress Event Object events: {
onProgress: (progressEvent) => {
// Actual structure:
{
processedBytes: 4326, // number - bytes processed so far
totalBytes: 8652, // number - total bytes to process
step: "signing" // string - current step: "signing" or "upload"
}
}
} Additional Resources Turbo SDK Documentation Browser Wallet Security Guide Arweave Developer Documentation CDN Import Best Practices For more advanced implementations, see the Next.js and Vite framework guides, or explore the Turbo SDK examples repository.How is this guide?Using Turbo in a Browser Learn how to integrate Turbo SDK with different web frameworks and vanilla HTML Using Turbo SDK with Next.js Configure Turbo SDK in a Next.js application with proper polyfills for client-side usage

---

# 10. ArNS Undernames for Permasite Versioning  ARIO Documentation

Document Number: 10
Source: https://docs.ar.io/build/guides/arns-undernames-versioning
Words: 553
Quality Score: 0.626
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Guides Use ArNS undernames to organize and version your permanent website components. Undernames allow you to create sub-domains under your main ArNS name, making it easy to manage different versions, pages, and assets.What Are Undernames?Undernames are sub-domains under your main ArNS name that can point to different Arweave transactions. They provide a structured way to organize your permanent website content.Example structure:yourname.arweave.dev - Main site v1_yourname.arweave.dev - Version 1 v2_yourname.arweave.dev - Version 2 api_yourname.arweave.dev - API endpoints docs_yourname.arweave.dev - Documentation Real-World Example: ArDrive The ArDrive website uses undernames to organize different components and versions:{
"@": {
"priority": 0,
"ttlSeconds": 3600,
"transactionId": "Vrf5_MrC1R-6rAk7o_E52DwOsKhyJmkSUqh0h5q4mDQ",
"index": 0
},
"dapp": {
"ttlSeconds": 3600,
"transactionId": "1ubf6cW8T5dYN3COApn8Yii4bA0HKoGeid-z2IjelTo",
"index": 1
},
"home": {
"ttlSeconds": 900,
"transactionId": "V9rQR06L1w9eLBHh2lY7o4uaDO6OqBI8j7TM_qjmNfE",
"index": 2
},
"v1_home": {
"ttlSeconds": 900,
"transactionId": "YzD_Pm5VAfYpMD3zQCgMUcKKuleGhEH7axlrnrDCKBo",
"index": 9
},
"v2_home": {
"ttlSeconds": 900,
"transactionId": "nOXJjj_vk0Dc1yCgdWD8kti_1iHruGzLQLNNBHVpN0Y",
"index": 10
},
"v3_home": {
"ttlSeconds": 900,
"transactionId": "YvGRDf0h2F7LCaGPvdH19m5lqbag5DGRnw607ZJ1oUg",
"index": 11
}
} This structure provides:@ - Main site (ardrive.arweave.dev) dapp - Application interface (dapp_ardrive.arweave.dev) home - Homepage (home_ardrive.arweave.dev) v1_home - Version 1 homepage (v1_home_ardrive.arweave.dev) v2_home - Version 2 homepage (v2_home_ardrive.arweave.dev) v3_home - Version 3 homepage (v3_home_ardrive.arweave.dev) Use Cases for Undernames 1. Website Versioning Maintain multiple versions:v1_yourname.arweave.dev - Previous version v2_yourname.arweave.dev - Current version beta_yourname.arweave.dev - Beta testing staging_yourname.arweave.dev - Staging environment 2. Component Organization Separate different parts:api_yourname.arweave.dev - API endpoints docs_yourname.arweave.dev - Documentation assets_yourname.arweave.dev - Static assets blog_yourname.arweave.dev - Blog content 3. Content Management Organize by content type:home_yourname.arweave.dev - Homepage about_yourname.arweave.dev - About page contact_yourname.arweave.dev - Contact page privacy_yourname.arweave.dev - Benefits of Undername Versioning Easy access to versions:Users can access any version directly via URL No need to remember transaction IDs Clear versioning structure Permanent version history:All versions remain accessible forever Historical record of your website evolution Easy rollback to previous versions Organized content:Logical structure for different components Easy to manage and update Clear separation of concerns Transferable with ANT:Undernames transfer with the main ArNS name Maintain ownership of all versions Sell or transfer entire website structure How to Set Up Undernames 1. Register your main ArNS name:Choose your primary name (e.g., myapp) Register through ArNS App 2. Create undernames:Use the ANT interface to add undernames Point each undername to different transaction IDs Set appropriate TTL values 3. Deploy different versions:Upload each version to Arweave Get transaction IDs for each version Update undername records Example Implementation Deploy version 1:# Deploy to main site
npx permaweb-deploy --arns-name myapp --deploy-folder ./v1-build
# Deploy to v1 undername
npx permaweb-deploy --arns-name myapp --undername v1 --deploy-folder ./v1-build Deploy version 2:# Deploy to main site
npx permaweb-deploy --arns-name myapp --deploy-folder ./v2-build
# Deploy to v2 undername
npx permaweb-deploy --arns-name myapp --undername v2 --deploy-folder ./v2-build Access different versions:myapp.arweave.dev - Current version v1_myapp.arweave.dev - Version 1 v2_myapp.arweave.dev - Version 2 Ready to Version Your Site?Want to learn more? Check out ArNS Primary Names for identity management.Need deployment help? See Hosting Decentralized Websites for setup guides.Want to trade domains? Explore ArNS Marketplace for buying and selling.How is this guide?Working With Primary Names Create web3 identity using ArNS names that resolve to wallet addresses Crossmint NFT Minting App Build a decentralized NFT minting app with Arweave and Crossmint On this page What Are Undernames?Real-World Example: ArDrive Use Cases for Undernames 1. Website Versioning 2. Component Organization 3. Content Management Benefits of Undername Versioning How to Set Up Undernames Example Implementation Ready to Version Your Site?

---

# 11. Advanced Uploading with Turbo  ARIO Documentation

Document Number: 11
Source: https://docs.ar.io/build/upload/advanced-uploading-with-turbo
Words: 1822
Quality Score: 0.625
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Upload Data Learn how to upload data to Arweave using the Turbo SDK for a streamlined upload experience with multiple payment options and authentication methods.What You'll Learn How to install and authenticate with the Turbo SDK Different authentication methods (Arweave, Ethereum, Solana, etc.) How to purchase Turbo Credits How to upload files, strings, binary data, and entire folders to Arweave Browser and Node.js implementation examples Using the versatile upload method for all data types Prerequisites Node.js environment or modern web browser Wallet for authentication (Arweave, Ethereum, Solana, etc.) Basic understanding of JavaScript/TypeScript Quick Start Install the Turbo SDK # For Node.js
npm install @ardrive/turbo-sdk
# For Yarn users
yarn add @ardrive/turbo-sdk Authenticate with Your Wallet Choose your preferred authentication method:import { TurboFactory } from '@ardrive/turbo-sdk'
import fs from 'fs'
// Load your Arweave JWK file
const jwk = JSON.parse(fs.readFileSync('wallet.json', 'utf-8'))
const turbo = await TurboFactory.authenticated({
privateKey: jwk, // ArweaveJWK type
token: 'arweave', // Default token type
}) import { TurboFactory, EthereumSigner } from '@ardrive/turbo-sdk'
// Your Ethereum private key (with 0x prefix)
const privateKey = '0x1234...' // EthPrivateKey type
// Create an Ethereum signer instance
const signer = new EthereumSigner(privateKey)
const turbo = await TurboFactory.authenticated({
signer,
token: 'ethereum',
}) import { TurboFactory } from '@ardrive/turbo-sdk'
import bs58 from 'bs58'
// Your Solana secret key (as Uint8Array)
const secretKey = new Uint8Array([...]) // SolSecretKey type
const turbo = await TurboFactory.authenticated({
privateKey: bs58.encode(secretKey),
token: 'solana'
}) import { TurboFactory, EthereumSigner } from '@ardrive/turbo-sdk'
// Your Polygon private key (with 0x prefix)
const privateKey = '0x1234...' // EthPrivateKey type
// Create an Ethereum signer instance for Polygon
const signer = new EthereumSigner(privateKey)
const turbo = await TurboFactory.authenticated({
signer,
token: 'matic', // or 'pol'
}) import { TurboFactory } from '@ardrive/turbo-sdk'
// Your KYVE private key (hexadecimal)
const privateKey = '0x1234...' // KyvePrivateKey type
const turbo = await TurboFactory.authenticated({
privateKey,
token: 'kyve',
}) import { TurboFactory, ArConnectSigner } from '@ardrive/turbo-sdk/web'
async function initializeTurbo() {
await window.arweaveWallet.connect([
'ACCESS_ADDRESS',
'ACCESS_PUBLIC_KEY',
'SIGN_TRANSACTIONS',
'SIGN_MESSAGE',
'SIGNATURE',
])
const turbo = await TurboFactory.authenticated({
signer: new ArConnectSigner(window.arweaveWallet),
})
} import { TurboFactory } from '@ardrive/turbo-sdk/web'
import { InjectedEthereumSigner } from '@dha-team/arbundles'
import { getAccount, signMessage } from 'wagmi/actions'
import { hashMessage, recoverPublicKey, toBytes } from 'viem'
// Global variables for Wagmi config and connector
let config = null
let connector = null
let turboInstance = null
// Function to set up Wagmi configuration
export function setWagmiConfig(wagmiConfig, wagmiConnector) {
config = wagmiConfig
connector = wagmiConnector
}
// Function to initialize Turbo with Wagmi
export async function initializeTurbo(userAddress) {
try {
if (!config || !connector) {
throw new Error(
'Wagmi config and connector not set. Call setWagmiConfig first.',
)
}
console.log('Initializing Turbo client...')
// Create a provider that uses wagmi's signMessage
const provider = {
getSigner: () => ({
signMessage: async (message) => {
const arg = message instanceof String ? message : { raw: message }
const ethAccount = getAccount(config)
return await signMessage(config, {
message: arg,
account: ethAccount.address,
connector: connector,
})
},
}),
}
// Create the Turbo signer
const signer = new InjectedEthereumSigner(provider)
// Set up the public key
signer.setPublicKey = async () => {
const message = 'Sign this message to connect to Turbo'
const ethAccount = getAccount(config)
const signature = await signMessage(config, {
message: message,
account: ethAccount.address,
connector: connector,
})
const hash = await hashMessage(message)
const recoveredKey = await recoverPublicKey({
hash,
signature,
})
signer.publicKey = Buffer.from(toBytes(recoveredKey))
}
// Initialize the signer
await signer.setPublicKey()
turboInstance = await TurboFactory.authenticated({
signer: signer,
token: 'base-eth', // Can be changed to 'ethereum' or 'matic', etc.
})
console.log('Turbo client initialized successfully')
return turboInstance
} catch (error) {
console.error('Error initializing Turbo client:', error)
turboInstance = null
throw error
}
} import { BrowserProvider } from 'ethers'
import { TurboFactory } from '@ardrive/turbo-sdk/web'
import { InjectedEthereumSigner } from '@dha-team/arbundles'
export const connectToMetaMask = async () => {
if (!window.ethereum) {
throw new Error('Please install MetaMask to use this application')
}
try {
const accounts = await window.ethereum.request({
method: 'eth_requestAccounts',
})
const metaMaskProvider = window.ethereum.providers?.find(
(p) => p.isMetaMask,
)
const provider = new BrowserProvider(metaMaskProvider ?? window.ethereum)
const signer = await provider.getSigner()
const turbo = TurboFactory.authenticated({
signer: new InjectedEthereumSigner({ getSigner: () => signer }),
token: 'ethereum',
})
return { turbo, address: accounts[0] }
} catch (error) {
console.error('Connection failed:', error)
throw error
}
} import { TurboFactory, SolanaWalletAdapter } from '@ardrive/turbo-sdk/web'
import { PublicKey } from '@solana/web3.js'
export async function initializeSolanaTurbo() {
try {
// Check if Phantom is installed
if (window.solana) {
const provider = window.solana
const publicKey = new PublicKey((await provider.connect()).publicKey)
const wallet: SolanaWalletAdapter = {
publicKey,
signMessage: async (message: Uint8Array) => {
// Call Phantom's signMessage method
const { signature } = await provider.signMessage(message)
return signature
},
}
solanaTurboInstance = TurboFactory.authenticated({
token: 'solana',
walletAdapter: wallet,
})
}
} catch (err) {
console.error(err)
}
} Purchase Turbo Credits Turbo Credits are the payment medium used by the Turbo Upload Service. Each Credit represents a 1:1 conversion from the upload power of the Arweave native token (AR).Fiat Currency: Credit/debit cards via the Turbo Top Up App Cryptocurrencies: AR, ETH, SOL, MATIC, ARIO, USDC, KYVE, ETH (BASE) Multiple Wallets: Ethereum, Solana, and Arweave wallets supported import { TurboFactory, WinstonToTokenAmount } from '@ardrive/turbo-sdk'
// Initialize authenticated client
const turbo = await TurboFactory.authenticated({
privateKey: jwk
})
// Top up with AR tokens
const topUpResult = await turbo.topUpWithTokens({
tokenAmount: WinstonToTokenAmount(100_000_000), // 0.0001 AR
}) import { TurboFactory, EthereumSigner } from '@ardrive/turbo-sdk'
// Initialize authenticated client
const turbo = await TurboFactory.authenticated({
signer: new EthereumSigner(privateKey),
token: 'ethereum',
})
// Top up with ETH tokens
const topUpResult = await turbo.topUpWithTokens({
tokenAmount: 0.001, // 0.001 ETH
}) import { TurboFactory } from '@ardrive/turbo-sdk'
// Initialize authenticated client
const turbo = await TurboFactory.authenticated({
privateKey: bs58.encode(secretKey),
token: 'solana'
})
// Top up with SOL tokens
const topUpResult = await turbo.topUpWithTokens({
tokenAmount: 0.1, // 0.1 SOL
}) import { TurboFactory, EthereumSigner } from '@ardrive/turbo-sdk'
// Initialize authenticated client
const turbo = await TurboFactory.authenticated({
signer: new EthereumSigner(privateKey),
token: 'matic',
})
// Top up with MATIC tokens
const topUpResult = await turbo.topUpWithTokens({
tokenAmount: 1.0, // 1.0 MATIC
}) import { TurboFactory } from '@ardrive/turbo-sdk'
// Initialize authenticated client
const turbo = await TurboFactory.authenticated({
privateKey,
token: 'kyve',
})
// Top up with KYVE tokens
const topUpResult = await turbo.topUpWithTokens({
tokenAmount: 100, // 100 KYVE
}) Upload Your First File // Upload a single file using the versatile upload method
const result = await turbo.upload({
data: file, // Can be File, Blob, Buffer, Uint8Array, ArrayBuffer, or string
dataItemOpts: {
tags: [
{ name: "Content-Type", value: file.type || "application/octet-stream" },
{ name: "App-Name", value: "MyApp-v1.0" },
],
},
});
console.log("File uploaded!", {
id: result.id,
url: `https://arweave.net/${result.id}`,
owner: result.owner,
dataCaches: result.dataCaches,
});Uploading Files Basic File Upload // Upload a single file using the versatile upload method
const result = await turbo.upload({
data: file, // Can be File, Blob, Buffer, Uint8Array, ArrayBuffer, or string
dataItemOpts: {
tags: [
{ name: "Content-Type", value: file.type || "application/octet-stream" },
{ name: "App-Name", value: "MyApp-v1.0" },
],
},
});
console.log("File uploaded!", {
id: result.id,
url: `https://arweave.net/${result.id}`,
owner: result.owner,
dataCaches: result.dataCaches,
});Upload with Custom Tags const result = await turbo.upload({
data: file,
dataItemOpts: {
tags: [
{ name: "Content-Type", value: "application/json" },
{ name: "App-Name", value: "MyApp-v1.0" },
{ name: "App-Version", value: "1.0.0" },
{ name: "Description", value: "My application data" },
],
},
});Upload Strings // Upload a string
const stringResult = await turbo.upload({
data: "Hello, Arweave!",
dataItemOpts: {
tags: [
{ name: "Content-Type", value: "text/plain" },
{ name: "App-Name", value: "MyApp-v1.0" },
],
},
});Upload JSON Data // Upload a JSON object
const jsonData = { message: "Hello", timestamp: Date.now() };
const jsonResult = await turbo.upload({
data: JSON.stringify(jsonData),
dataItemOpts: {
tags: [
{ name: "Content-Type", value: "application/json" },
{ name: "App-Name", value: "MyApp-v1.0" },
],
},
});Upload Binary Data // Upload binary data
const binaryData = new Uint8Array([1, 2, 3, 4, 5]);
const binaryResult = await turbo.upload({
data: binaryData,
dataItemOpts: {
tags: [
{ name: "Content-Type", value: "application/octet-stream" },
{ name: "App-Name", value: "MyApp-v1.0" },
],
},
});Upload Multiple Files const files = [file1, file2, file3];
const uploadPromises = files.map((file) =>
turbo.upload({
data: file,
dataItemOpts: {
tags: [
{
name: "Content-Type",
value: file.type || "application/octet-stream",
},
{ name: "App-Name", value: "MyApp-v1.0" },
],
},
})
);
const results = await Promise.all(uploadPromises);
console.log("All files uploaded!", results);Upload an Entire Folder (Node.js) Upload Multiple Files as a Folder (Browser) const files = [file1, file2, file3];
const webFolderResult = await turbo.uploadFolder({
files: files,
dataItemOpts: {
tags: [{ name: "App-Name", value: "MyWebsite-v1.0" }],
},
manifetions: {
indexFile: "index.html",
},
});Browser Implementation Examples File Input with Drag & Drop

Turbo Upload Example




Drag and drop files here or click to select


Advanced Features Check Upload Costs // Get upload cost for specific file size
const costs = await turbo.getUploadCosts({
bytes: [file.size],
});
console.log(`Upload cost: ${costs[0].winc} Winston Credits);
console.log(USD cost: $${costs[0].usd}`);Check Balance // Get current balance
const balance = await turbo.getBalance();
console.log(`Available credits: ${balance.controlledWinc} Winston Credits);Upload with Progress Tracking const result = await turbo.upload({
data: file,
dataItemOpts: {
tags: [
{ name: "Content-Type", value: file.type || "application/octet-stream" },
{ name: "App-Name", value: "MyApp-v1.0" },
],
},
events: {
onUploadProgress: (progress) => {
console.log(
Upload progress: ${Math.round((progress.processedBytes / progress.totalBytes) * 100)}%`
);
},
onSigningProgress: (progress) => {
console.log(
`Signing progress: ${Math.round((progress.processedBytes / progress.totalBytes) * 100)}%`
);
},
},
});Upload with Error Handling try {
const result = await turbo.upload({
data: file,
dataItemOpts: {
tags: [
{ name: "Content-Type", value: file.type || "application/octet-stream" },
{ name: "App-Name", value: "MyApp-v1.0" },
],
},
events: {
onUploadError: (error) => {
console.error("Upload failed:", error);
},
onSigningError: (error) => {
console.error("Signing failed:", error);
},
},
});
console.log("Upload successful:", result);
} catch (error) {
console.error("Upload error:", error);
// Handle error appropriately
} Benefits of Using Turbo Versatile upload method - Upload files, strings, binary data, or entire folders with a single method Multiple payment options - Pay with fiat, crypto, or AR tokens Easy integration - Simple SDK for both Node.js and browsers Automatic retry - Built-in retry logic for failed uploads Cost transparency - See upload costs before confirming Fast uploads - Optimized for speed and reliability Folder support - Upload entire directories with automatic manifest generation Ready to Upload?Purchase Credits Buy Turbo Credits with fiat or crypto Learn About Tagging Discover best practices for organizing your data Create Manifests Learn how to organize files with manifests How is this guide?Getting Started with Turbo Upload data to Arweave in a matter of minutes Paying for Uploads Understanding Turbo's credit system for flexible payment options and enterprise features On this page What You'll Learn Prerequisites Quick Start Install the Turbo SDK Authenticate with Your Wallet Purchase Turbo Credits Upload Your First File Uploading Files Basic File Upload Upload with Custom Tags Upload Strings Upload JSON Data Upload Binary Data Upload Multiple Files Upload an Entire Folder (Node.js) Upload Multiple Files as a Folder (Browser) Browser Implementation Examples File Input with Drag & Drop Advanced Features Check Upload Costs Check Balance Upload with Progress Tracking Upload with Error Handling Benefits of Using Turbo Ready to Upload?

---

# 12. Environment Variables  ARIO Documentation

Document Number: 12
Source: https://docs.ar.io/build/run-a-gateway/manage/environment-variables
Words: 1646
Quality Score: 0.621
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Build Run a gateway Manage Core AR.IO Node The main AR.IO Gateway service that handles data retrieval, indexing, and serving.Server Configuration Variable Type Default Description PORT number 4000 HTTP server port NODE_ENV string production Node.js environment LOG_LEVEL string info Logging level (error, warn, info, debug) LOG_FORMAT string simple Log format (simple, json) LOG_FILTER string {"always":true} Log filtering configuration LOG_ALL_STACKTRACES boolean false Include full stack traces in logs INSTANCE_ID string - Unique instance identifier Authentication & Security Variable Type Default Description ADMIN_API_KEY String Generated API key for admin endpoints (auto-generated if not set) ADMIN_API_KEY_FILE String - Path to file containing admin API key Network Configuration Variable Type Default Description TRUSTED_NODE_URL string https://arweave.net Trusted Arweave node URL TRUSTED_GATEWAY_URL string https://arweave.net Primary trusted gateway URL TRUSTED_GATEWAYS_URLS JSON {"https://arweave.net": 1} Weighted trusted gateway URLs TRUSTED_GATEWAYS_REQUEST_TIMEOUT_MS number 10000 Request timeout for trusted gateways ARWEAVE_NODE_IGNORE_URLS string - Comma-separated URLs to ignore Chunk Management Variable Type Default Description CHUNK_POST_URLS string https://arweave.net/chunk URLs for posting chunks CHUNK_POST_CONCURRENCY_LIMIT number 2 Max concurrent chunk posts CHUNK_POST_MIN_SUCCESS_COUNT number 3 Min successful chunk posts required CHUNK_POST_RESPONSE_TIMEOUT_MS number - Chunk POST response timeout CHUNK_POST_ABORT_TIMEOUT_MS number - Chunk POST abort timeout SECONDARY_CHUNK_POST_URLS string - Secondary chunk POST URLs SECONDARY_CHUNK_POST_CONCURRENCY_LIMIT number 2 Secondary chunk POST concurrency SECONDARY_CHUNK_POST_MIN_SUCCESS_COUNT number 1 Secondary chunk POST success count Data Sources Variable Type Default Description ON_DEMAND_RETRIEVAL_ORDER string s3,trusted-gateways,chunks,tx-data On-demand data retrieval priority BACKGROUND_RETRIEVAL_ORDER string chunks,s3,trusted-gateways,tx-data Background data retrieval priority CHUNK_DATA_SOURCE_TYPE string fs Chunk data source type (fs, legacy-s3) CHUNK_METADATA_SOURCE_TYPE string fs Chunk metadata source type (fs, legacy-psql) Indexing & Synchronization ANS-104 Bundle Processing Variable Type Default Description ANS104_UNBUNDLE_FILTER JSON {"never": true} Filter for bundles to unbundle ANS104_INDEX_FILTER JSON {"never": true} Filter for data items to index ANS104_UNBUNDLE_WORKERS number 1 Number of unbundling workers ANS104_DOWNLOAD_WORKERS number 5 Number of download workers FILTER_CHANGE_REPROCESS boolean false Reprocess old bundles with new filter BACKFILL_BUNDLE_RECORDS boolean false Backfill bundle records Data Management Variable Type Default Description WRITE_ANS104_DATA_ITEM_DB_SIGNATURES boolean false Write data item signatures to DB WRITE_TRANSACTION_DB_SIGNATURES boolean false Write transaction signatures to DB ENABLE_DATA_DB_WAL_CLEANUP boolean false Enable data DB WAL cleanup MAX_DATA_ITEM_QUEUE_SIZE number 100000 Max data items in queue BUNDLE_DATA_IMPORTER_QUEUE_SIZE number 1000 Max bundles in import queue VERIFICATION_DATA_IMPORTER_QUEUE_SIZE number 1000 Max verification items in queue DATA_ITEM_FLUSH_COUNT_THRESHOLD number 1000 Data items threshold for flushing MAX_FLUSH_INTERVAL_SECONDS number 600 Max interval between flushes File System Cleanup Variable Type Default Description FS_CLEANUP_WORKER_BATCH_SIZE number 2000 Files per cleanup batch FS_CLEANUP_WORKER_BATCHDURATION number 5000 between cleanup batches (ms) FS_CLEANUP_WORKER_RESTARTDURATION number 14400000 before restarting cleanup (ms) Background Verification Variable Type Default Description ENABLE_BACKGROUND_DATA_VERIFICATION boolean false Enable background data verification BACKGROUND_DATA_VERIFICATION_INTERVAL_SECONDS number 600 Verification interval BACKGROUND_DATA_VERIFICATION_WORKER_COUNT number 1 Number of verification workers BACKGROUND_DATA_VERIFICATION_STREAM_TIMEOUT_MS number 30000 Stream timeout for verification Bundle Repair Variable Type Default Description BUNDLE_REPAIR_RETRY_INTERVAL_SECONDS number 300 Bundle repair retry interval BUNDLE_REPAIR_UPDATE_TIMESTAMPS_INTERVAL_SECONDS number 300 Timestamp update interval BUNDLE_REPAIR_BACKFILL_INTERVAL_SECONDS number 900 Backfill interval BUNDLE_REPAIR_FILTER_REPROCESS_INTERVAL_SECONDS number 300 Filter reprocess interval BUNDLE_REPAIR_RETRY_BATCH_SIZE number 5000 Batch size for repair retries ArNS Configuration Variable Type Default Description ARNS_ROOT_HOST string - Root hostname for ArNS SANDBOX_PROTOCOL string - Protocol for sandboxing redirects (http or https) AR_IO_SDK_LOG_LEVEL string none AR.IO SDK log level ARNS_CACHE_TYPE string node ArNS cache type ARNS_CACHE_TTL_SECONDS number 86400 ArNS cache TTL ARNS_CACHE_MAX_KEYS number 10000 Max ArNS cache keys ARNS_RESOLVER_PRIORITY_ORDER string gateway,on-demand ArNS resolver priority ARNS_COMPOSITE_RESOLVER_TIMEOUT_MS number 3000 Composite resolver timeout ARNS_NAMES_CACHE_TTL_SECONDS number 3600 Names cache TTL ARNS_MAX_CONCURRENT_RESOLUTIONS number 1 Max concurrent resolutions AR.IO Network Apex Domain Variable Type Default Description APEX_TX_ID string - Apex transaction ID APEX_ARNS_NAME string - Apex ArNS name Caching Webhooks Variable Type Default Description WEBHOOK_TARGET_SERVERS string - Comma-separated webhook target servers WEBHOOK_INDEX_FILTER JSON {"never": true} Webhook index filter WEBHOOK_BLOCK_FILTER JSON {"never": true} Webhook block filter Mempool Watcher Variable Type Default Description ENABLE_MEMPOOL_WATCHER boolean false Enable mempool watcher MEMPOOL_POLLING_INTERVAL_MS number 30000 Mempool polling interval AWS S3 Variable Type Default Description AWS_ACCESS_KEY_ID string - AWS access key ID AWS_SECRET_ACCESS_KEY string - AWS secret access key AWS_SESSION_TOKEN string - AWS session token AWS_REGION string - AWS region AWS_ENDPOINT string - AWS endpoint AWS_S3_CONTIGUOUS_DATA_BUCKET string - S3 bucket for contiguous data AWS_S3_CONTIGUOUS_DATA_PREFIX string - S3 prefix for contiguous data ClickHouse Variable Type Default Description CLICKHOUSE_URL string - ClickHouse URL CLICKHOUSE_USER string - ClickHouse username CLICKHOUSE_PASSWORD string - ClickHouse password PostgreSQL (Legacy) Variable Type Default Description LEGACY_PSQL_CONNECTION_STRING string - PostgreSQL connection string LEGACY_PSQL_PASSWORD_FILE string - Path to PostgreSQL password file LEGACY_PSQL_SSL_REJECT_UNAUTHORIZED boolean true Reject unauthorized SSL connections AO (Autonomous Objects) Variable Type Default Description AO_CU_URL string - AO CU URL NETWORK_AO_CU_URL string - Network AO CU URL ANT_AO_CU_URL string - ANT AO CU URL AO_MU_URL string - AO MU URL AO_GATEWAY_URL string - AO Gateway URL AO_GRAPHQL_URL string - AO GraphQL URL Circuit Breaker Variable Type Default Description ARIO_PROCESS_DEFAULT_CIRCUIT_BREAKER_TIMEOUT_MS number 60000 Circuit breaker timeout ARIO_PROCESS_DEFAULT_CIRCUIT_BREAKER_ERROR_THRESHOLD_PERCENTAGE number 30 Error threshold percentage ARIO_PROCESS_DEFAULT_CIRCUIT_BREAKER_ROLLING_COUNT_TIMEOUT_MS number 600000 Rolling count timeout ARIO_PROCESS_DEFAULT_CIRCUIT_BREAKER_RESET_TIMEOUT_MS number 1200000 Reset timeout Performance Tuning Variable Type Default Description NODE_JS_MAX_OLD_SPACE_SIZE string - Node.js max old space size WEIGHTED_PEERS_TEMPERATURE_DELTA number 2 Weighted peers temperature delta GATEWAY_PEERS_WEIGHTS_CACHE_DURATION_MS number 5000 Gateway peers weights cache duration GATEWAY_PEERS_REQUEST_WINDOW_COUNT number 20 Gateway peers request window count TAG_SELECTIVITY JSON {"Parent-Folder-Id": 20, "Message": 20, "Drive-Id": 10, "Process": 10, "Recipient": 10, "App-Name": -10, "Content-Type": -10, "Data-Protocol": -10} Tag selectivity configuration Data Paths Observer Service Basic Configuration Variable Type Default Description PORT number 5050 Observer service port LOG_LEVEL string - Observer log level OBSERVER_WALLET string - Observer wallet IO_PROCESS_ID string - AR.IO process ID AR_IO_NODE_RELEASE string 33 AR.IO node release version Observer Operation Variable Type Default Description SUBMIT_CONTRACT_INTERACTIONS boolean true Submit contract interactions NUM_ARNS_NAMES_TO_OBSERVE_PER_GROUP number 8 Number of ArNS names per observation group REPORT_GENERATION_INTERVAL_MS string - Report generation interval REPORT_DATA_SINK string - Report data sink TURBO_UPLOAD_SERVICE_URL string - Turbo upload service URL RUN_OBSERVER boolean true Run observer service MIN_RELEASE_NUMBER number 0 Minimum release number Report Configuration Variable Type Default Description REPORT_GENERATION_INTERVAL_MS string - Report generation interval REPORT_DATA_SINK string - Report data sink Gateway Assessment Variable Type Default Description NUM_ARNS_NAMES_TO_OBSERVE_PER_GROUP number 8 Number of ArNS names per observation group ArNS Names Variable Type Default Description NUM_ARNS_NAMES_TO_OBSERVE_PER_GROUP number 8 Number of ArNS names per observation group Contract Interaction Variable Type Default Description SUBMIT_CONTRACT_INTERACTIONS boolean true Submit contract interactions Offset Observation Variable Type Default Description REPORT_GENERATION_INTERVAL_MS string - Report generation interval AO (Autonomous Objects) Variable Type Default Description AO_CU_URL string - AO CU URL NETWORK_AO_CU_URL string - Network AO CU URL AO_MU_URL string - AO MU URL AO_GATEWAY_URL string - AO Gateway URL AO_GRAPHQL_URL string - AO GraphQL URL Data Paths Variable Type Default Description TEMP_DATA_PATH string./data/tmp Path to temporary data REPORTS_DATA_PATH string./data/reports Path to reports data WALLETS_PATH string./wallets Path to wallets Envoy Proxy Basic Configuration Variable Type Default Description LOG_LEVEL string info Envoy log level TVAL_AR_IO_HOST string core AR.IO host TVAL_AR_IO_PORT number 4000 AR.IO port TVAL_OBSERVER_HOST string observer Observer host TVAL_OBSERVER_PORT number 5050 Observer port TVAL_GATEWAY_HOST string arweave.net Gateway host TVAL_GRAPHQL_HOST string core GraphQL host TVAL_GRAPHQL_PORT number 4000 GraphQL port TVAL_ARNS_ROOT_HOST string - ArNS root host Redis Cache Basic Configuration Variable Type Default Description REDIS_IMAGE_TAG string 7 Redis image tag REDIS_MAX_MEMORY string 256mb Redis max memory EXTRA_REDIS_FLAGS string --save "" --appendonly no Extra Redis flags Data Paths Variable Type Default Description REDIS_DATA_PATH string./data/redis Path to Redis data ClickHouse Basic Configuration Variable Type Default Description CLICKHOUSE_IMAGE_TAG string 25.4 ClickHouse image tag CLICKHOUSE_USER string - ClickHouse username CLICKHOUSE_PASSWORD string - ClickHouse password Data Paths Variable Type Default Description CLICKHOUSE_DATA_PATH string./data/clickhouse Path to ClickHouse data CLICKHOUSE_LOGS_PATH string./logs/clickhouse Path to ClickHouse logs ClickHouse Auto-Import Variable Type Default Description CLICKHOUSE_AUTO_IMPORT_IMAGE_TAG string 79792e1b549f64edad3e338769949fd9bffa62db ClickHouse auto-import image tag CLICKHOUSE_DEBUG string - ClickHouse debug flag AR_IO_HOST string core AR.IO host AR_IO_PORT number 4000 AR.IO port ADMIN_API_KEY string - Admin API key PARQUET_DATA_PATH string./data/parquet Path to Parquet data CLICKHOUSE_HOST string clickhouse ClickHouse host CLICKHOUSE_PORT string - ClickHouse port (defaults to 9000) CLICKHOUSE_USER string - ClickHouse username (defaults to 'default') CLICKHOUSE_PASSWORD string - ClickHouse password (required) CLICKHOUSE_AUTO_IMPORT_SLEEP_INTERVAL string - Auto-import sleep interval CLICKHOUSE_AUTO_IMPORT_HEIGHT_INTERVAL string - Auto-import height interval CLICKHOUSE_AUTO_IMPORT_MAX_ROWS_PER_FILE string - Max rows per file for auto-import Litestream Backup S3 Configuration Variable Type Default Description LITESTREAM_IMAGE_TAG string be121fc0ae24a9eb7cdb2b92d01f047039b5f5e8 Litestream image tag AR_IO_SQLITE_BACKUP_S3_BUCKET_NAME string - S3 bucket name for SQLite backups AR_IO_SQLITE_BACKUP_S3_BUCKET_REGION string - S3 bucket region for SQLite backups AR_IO_SQLITE_BACKUP_S3_BUCKET_ACCESS_KEY string - S3 access key for SQLite backups AR_IO_SQLITE_BACKUP_S3_BUCKET_SECRET_KEY string - S3 secret key for SQLite backups AR_IO_SQLITE_BACKUP_S3_BUCKET_PREFIX string - S3 prefix for SQLite backups Data Paths Variable Type Default Description SQLITE_DATA_PATH string./data/sqlite Path to SQLite data Autoheal Service Configuration Variable Type Default Description AUTOHEAL_CONTAINER_LABEL string autoheal Container label for autoheal AUTOHEAL_ONLY_MONITOR_RUNNING boolean false Only monitor running containers RUN_AUTOHEAL boolean false Enable autoheal service OpenTelemetry Tracing Basic Configuration Performance Tuning Variable Type Default Description OTEL_BATCH_LOG_PROCESSOR_SCHEDULED_DELAY_MS number 5000 Batch log processor scheduled delay OTEL_BATCH_LOG_PROCESSOR_MAX_EXPORT_BATCH_SIZE number 512 Max export batch size OTEL_TRACING_SAMPLING_RATE_DENOMINATOR number 1000 Tracing sampling rate denominator Image Tags Service Images Variable Type Default Description ENVOY_IMAGE_TAG string 4789af164fcd3029a65a1d6739f2d9026567206e Envoy image tag CORE_IMAGE_TAG string 3a793c6ee06f5e1df56920fc70184b213ceb8c6e Core image tag OBSERVER_IMAGE_TAG string e5f6ae36fd6eea04be5ebba2624f8ecc08db4ea0 Observer image tag LITESTREAM_IMAGE_TAG string be121fc0ae24a9eb7cdb2b92d01f047039b5f5e8 Litestream image tag CLICKHOUSE_AUTO_IMPORT_IMAGE_TAG string 79792e1b549f64edad3e338769949fd9bffa62db ClickHouse auto-import image tag Additional Paths Data Directories Usage Notes All environment variables are optional unless otherwise specified Default values are shown in the "Default" column Boolean values should be set to true or false JSON values should be valid JSON strings Path values should be absolute or relative to the project root Some variables are only used in specific deployment scenarios (e.g., ClickHouse, Litestream) Image tags can be updated to use different versions of the services Data paths can be customized based on your storage requirements Configuration Examples Basic Gateway Setup # Core configuration
NODE_ENV=production
LOG_LEVEL=info
PORT=4000
ADMIN_API_KEY=your-admin-key-here
# Network configuration
TRUSTED_NODE_URL=https://arweave.net
TRUSTED_GATEWAY_URL=https://arweave.net
# Data paths
CHUNKS_DATA_PATH=/data/chunks
CONTIGUOUS_DATA_PATH=/data/contiguous
SQLITE_DATA_PATH=/data/sqlite Advanced Gateway with ClickHouse # Core configuration
NODE_ENV=production
LOG_LEVEL=info
PORT=4000
ADMIN_API_KEY=your-admin-key-here
# ClickHouse configuration
CLICKHOUSE_URL=http://clickhouse:8123
CLICKHOUSE_USER=default
CLICKHOUSE_PASSWORD=your-password
# Bundle processing
ANS104_UNBUNDLE_FILTER={"and": [{"equals": {"App-Name": "MyApp-v1.0"}}]}
ANS104_INDEX_FILTER={"and": [{"equals": {"App-Name": "MyApp-v1.0"}}]}
ANS104_UNBUNDLE_WORKERS=2
ANS104_DOWNLOAD_WORKERS=5 Gateway with Redis Caching # Core configuration
NODE_ENV=production
LOG_LEVEL=info
PORT=4000
ADMIN_API_KEY=your-admin-key-here
# Redis configuration
CHAIN_CACHE_TYPE=redis
REDIS_CACHE_URL=redis://redis:6379
REDIS_USE_TLS=false
REDIS_CACHE_TTL_SECONDS=28800
# ArNS configuration
ARNS_ROOT_HOST=your-domain.com
ARNS_CACHE_TYPE=redis This comprehensive reference should help you configure your AR.IO Gateway with the appropriate environment variables for your specific use case.How is this guide?

---

# 13. AO Compute Unit (CU)  ARIO Documentation

Document Number: 13
Source: https://docs.ar.io/build/extensions/compute-unit
Words: 1236
Quality Score: 0.608
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Extensions & Sidecars Overview An AO Compute Unit (CU) is a critical component in the AO ecosystem responsible for executing AO processes and maintaining their state. CUs serve as the computational backbone of the AO network by:Processing Messages: CUs receive and process messages sent to AO processes Executing WASM Modules: CUs run the WebAssembly (WASM) code that defines process behavior Maintaining State: CUs track and update the state of AO processes Creating Checkpoints: CUs periodically save process state to the Arweave network as checkpoints Running a CU alongside your gateway allows you to:Process AO requests locally rather than relying on external services Improve response times for AO-related queries Contribute computational resources to the AO network Ensure your gateway has reliable access to AO functionality For more detailed information about Compute Units, please refer to the AO Cookbook: Units.System Requirements Before deploying a CU, ensure your system meets the following requirements:Recommended: At least 16GB RAM for optimal CU operation Minimum: 4GB RAM is possible with adjusted memory limits (see resource allocation settings) At least 100GB disk space dedicated to CU operation These requirements are separate from your gateway requirements Resource Requirements Running a CU is resource-intensive. Make sure your system has sufficient
resources to handle both the gateway and the CU. While you can run a CU with
less than the recommended RAM, you'll need to adjust the memory limits
accordingly.Deploying an AO CU Configure Environment Variables Copy the example environment file:cp .env.ao.example .env.ao Default.env.ao.example Contents The default .env.ao.example file contains the following settings:CU_WALLET='[wallet json here]'
PROCESS_CHECKPOINT_TRUSTED_OWNERS=fcoN_xJeisVsPXA-trzVAuIiqO3ydLQxM-L4XbrQKzY
GATEWAY_URL=http://envoy:3000
UPLOADER_URL=http://envoy:3000/bundler These default settings are configured to work with a gateway running on the same machine, but you'll need to modify them as described below.Open the .env.ao file in your preferred text editor:nano .env.ao Configure the following settings:CU_WALLET: Replace '[wallet json here]' with the JSON from an Arweave wallet.PROCESS_CHECKPOINT_TRUSTED_OWNERS: This is a comma-separated list of trusted wallet addresses:PROCESS_CHECKPOINT_TRUSTED_OWNERS=fcoN_xJeisVsPXA-trzVAuIiqO3ydLQxM-L4XbrQKzY Adding Your Own Wallet If you are uploading your own checkpoints, you should add your own CU wallet address after the default value, separated by a comma:PROCESS_CHECKPOINT_TRUSTED_OWNERS=fcoN_xJeisVsPXA-trzVAuIiqO3ydLQxM-L4XbrQKzY,YOUR_WALLET_ADDRESS_HERE This allows your CU to trust checkpoints from both the official source and your own wallet.GATEWAY_URL: By default, this is set to use your own gateway:GATEWAY_URL=http://envoy:3000 A gateway must be set to index all ANS-104 data items from AO or the CU will not operate properly. Most users will want to set this to:GATEWAY_URL=https://arweave.net UPLOADER_URL: By default, this is set to use a bundler sidecar run by your gateway:UPLOADER_URL=http://envoy:3000/bundler Important: Checkpoint Uploads Require Payment Checkpoints are uploaded to Arweave, so the upload must be paid for. You
must ensure your wallet has sufficient funds: - If using https://up.arweave.net (recommended), your CU_WALLET must contain Turbo
Credits - If using your own bundler or another service, you'll need the
appropriate token (AR or other) - Without proper funding, checkpoints will
fail to upload and your CU may not function correctly The simplest option for most users is to use:UPLOADER_URL=https://up.arweave.net This requires your CU_WALLET to contain Turbo Credits.Optional: Disable Checkpoint Creation: If you want to disable checkpoint uploads, add:DISABLE_PROCESS_CHECKPOINT_CREATION=true Example of a Completed.env.ao File Here's an example of what your completed .env.ao file might look like with common settings:CU_WALLET='{"kty":"RSA","e":"AQAB","n":"mYM07..."}'
PROCESS_CHECKPOINT_TRUSTED_OWNERS=fcoN_xJeisVsPXA-trzVAuIiqO3ydLQxM-L4XbrQKzY
GATEWAY_URL=https://arweave.net
UPLOADER_URL=https://up.arweave.net After making your changes, save and exit the nano editor:Press Ctrl+X to exit Press Y to confirm saving changes Press Enter to confirm the filename Optional Resource Allocation Settings You can fine-tune the CU's resource usage by adding these optional environment variables:PROCESS_WASM_MEMORY_MAX_LIMIT: Sets the maximum memory limit (in bytes) for WASM processes.PROCESS_WASM_MEMORY_MAX_LIMIT=17179869184 # 16GB (16 * 1024^3) Important Memory Requirement To work with the AR.IO process, PROCESS_WASM_MEMORY_MAX_LIMIT must be at least 17179869184 (16GB).Note: This doesn't mean your server needs 16GB of RAM. This is the maximum memory limit the CU will support for processes. Most processes don't use their maximum allocated memory.You can set this value to 16GB even if your server only has 4GB of RAM. However, if a process requires more memory than your server has available, the CU will fail when evaluating messages that need more memory.WASM_EVALUATION_MAX_WORKERS: Sets the maximum number of worker threads for WASM evaluation.WASM_EVALUATION_MAX_WORKERS=4 # Example: Use 4 worker threads Worker Thread Configuration This will default to (available CPUs - 1) if not specified. If you're
running a gateway and unbundling on the same server, consider setting this
to 2 or less to avoid overloading your CPU.PROCESS_WASM_COMPUTE_MAX_LIMIT: The maximum Compute-Limit, in bytes, supported for ao processes (defaults to 9 billion) PROCESS_WASM_COMPUTE_MAX_LIMIT=9000000000 NODE_OPTIONS: Sets Node.js memory allocation for the Docker container.NODE_OPTIONS=--max-old-space-size=8192 # Example: 8GB for Node.js heap Start the CU Container Once your environment file is configured, start the CU container:docker compose --env-file .env.ao -f docker-compose.ao.yaml up -d This command uses the following flags:--env-file .env.ao: Specifies the environment file to use -f docker-compose.ao.yaml: Specifies the Docker Compose file to use up: Creates and starts the containers -d: Runs containers in detached mode (background) Check the Logs To check the logs of your CU container:docker compose -f docker-compose.ao.yaml logs -f --tail=20 This command uses the following flags:-f: Follows the log output (continuous dis) --tail=20: Shows only the last 20 lines of logs Exit the logs by pressing Ctrl+C.Connecting Your Gateway to the CU To make your gateway use your local CU:Add the following line to your gateway's .env file:AO_CU_URL=http://ao-cu:6363 This assumes the CU is running on the same machine as the gateway.Restart your gateway:docker compose down
docker compose up -d Accessing Your CU Once properly set up and connected to your gateway, you can access your CU via:https:///ao/cu This endpoint allows you to interact with your CU directly through your gateway's domain.Important Notes Initial Processing Time: A CU will need to process AO history before it can give valid responses. This process can take several hours.Gateway Fallback: A gateway on release 27 or above will fallback to arweave.net if its default CU is not responding quickly enough, so gateway operations will not be significantly impacted during the initial processing.Monitoring Progress: Check the CU logs after pointing a gateway at it to watch the process of working through AO history:docker compose -f docker-compose.ao.yaml logs -f --tail=20 Resource Usage: Running a CU is resource-intensive. Monitor your system's performance to ensure it can handle both the gateway and CU workloads.Useful Docker Commands Monitor and manage your AO Compute Unit with these commands:# View all running services
docker ps
# Start CU container with environment file
docker compose --env-file .env.ao -f docker-compose.ao.yaml up -d
# CU container
docker compose -f docker-compose.ao.yaml down
# Pull latest CU images
docker compose -f docker-compose.ao.yaml pull
# Follow CU logs
docker compose -f docker-compose.ao.yaml logs -f --tail=20
# Check CU container status
docker compose -f docker-compose.ao.yaml ps
# Restart CU container
docker compose -f docker-compose.ao.yaml restart
# View CU logs without following
docker compose -f docker-compose.ao.yaml logs --tail=50
# Start CU in foreground (for debugging)
docker compose --env-file .env.ao -f docker-compose.ao.yaml up Next Steps Now that you have a Compute Unit running alongside your gateway, continue building your infrastructure:Set Up Monitoring Deploy Grafana to visualize your gateway's performance metrics Add ClickHouse Improve query performance with ClickHouse and Parquet integration Deploy Bundler Accept data uploads directly through your gateway Join the Network Register your gateway and start serving the permanent web How is this guide?Bundler Learn about the Turbo ANS-104 data item bundler that can be run alongside an AR.IO Gateway to accept and submit data items to Arweave Guides Discover what you can build with Arweave and AR.IO infrastructure

---

# 14. Importing SQLite Database Snapshots  ARIO Documentation

Document Number: 14
Source: https://docs.ar.io/build/run-a-gateway/manage/index-snapshots
Words: 716
Quality Score: 0.577
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Run a Gateway Manage your Gateway Overview One of the challenges of running an AR.IO Gateway is the initial synchronization time as your gateway builds its local index of the Arweave network. This process can take days or even weeks, depending on your hardware and the amount of data you want to index. To accelerate this process, you can import a pre-synchronized SQLite database snapshot that contains transaction and data item records already indexed.This guide will walk you through the process of importing a database snapshot into your AR.IO Gateway.Note The below instructions are designed to be used in a linux environment. Windows and MacOS users must modify the instructions to use the appropriate package manager/ command syntax for their platform.Unless otherwise specified, all commands should be run from the root directory of the gateway.Quick Start Download Database Snapshot Download the latest database snapshot using BitTorrent:transmission-cli "magnet:?xt=urn:btih:62ca6e05248e6df59fac9e38252e9c71951294ed&dn=2025-04-23-sqlite.tar.gz&tr=udp%3A%2F%2Ftracker.opentrackr.org%3A1337%2Fannounce&tr=http%3A%2F%2Ftracker.opentrackr.org%3A1337%2Fannounce&tr=udp%3A%2F%2Fopen.demonii.com%3A1337%2Fannounce&tr=udp%3A%2F%2Ftracker.torrent.eu.org%3A451%2Fannounce&tr=udp%3A%2F%2Fp4p.arenabg.com%3A1337%2Fannounce&tr=https%3A%2F%2Ftracker.bt4g.com%3A443%2Fannounce" This downloads a 42.8GB snapshot current to April 23, 2025.Extract the Snapshot Extract the downloaded tarball:tar -xzf 2025-04-23-sqlite.tar.gz This creates a directory with the extracted database files.Import the Snapshot Replace your existing database with the snapshot:# the gateway
docker compose down
# Backup existing database (optional)
mkdir sqlite-backup
mv data/sqlite/* sqlite-backup/
# Remove old database
rm data/sqlite/*
# Import new snapshot
mv 2025-04-23-sqlite/* data/sqlite/
# Start the gateway
docker compose up -d Detailed Instructions Obtaining a Database Snapshot SQLite database snapshots are very large and not easy to incrementally update. For these reasons, AR.IO is distributing them using BitTorrent.Install Torrent Client Install a BitTorrent client. We recommend transmission-cli:# Ubuntu/Debian
sudo apt-get install transmission-cli
# CentOS/RHEL
sudo yum install transmission-cli
# macOS
brew install transmission-cli Download Snapshot Download the latest snapshot using the magnet link:transmission-cli "magnet:?xt=urn:btih:62ca6e05248e6df59fac9e38252e9c71951294ed&dn=2025-04-23-sqlite.tar.gz&tr=udp%3A%2F%2Ftracker.opentrackr.org%3A1337%2Fannounce&tr=http%3A%2F%2Ftracker.opentrackr.org%3A1337%2Fannounce&tr=udp%3A%2F%2Fopen.demonii.com%3A1337%2Fannounce&tr=udp%3A%2F%2Ftracker.torrent.eu.org%3A451%2Fannounce&tr=udp%3A%2F%2Fp4p.arenabg.com%3A1337%2Fannounce&tr=https%3A%2F%2Ftracker.bt4g.com%3A443%2Fannounce" This will download a snapshot, current to April 23, 2025, of an unbundled data set that includes all data items uploaded via an ArDrive product, including Turbo. The file will be named 2025-04-23-sqlite.tar.gz and be approximately 42.8GB in size.Consider Seeding Seeding Recommendation While continuing to seed the torrent after download is not required, it is
highly recommended to help ensure the continued availability of the snapshot
for others, as well as the integrity of the data. Seeding this file should not
cause any issues with your internet service provider.Extracting the Database Snapshot Once the file has downloaded, you can extract it using the following command.Verify Download Check that the file downloaded completely:ls -lh 2025-04-23-sqlite.tar.gz
# Should show approximately 42.8GB Extract the Archive Extract the tarball:tar -xzf 2025-04-23-sqlite.tar.gz Be sure to replace the filename with the actual filename of the snapshot you are using, if not using the example above.Verify Extraction Check that the extraction was successful:ls -la 2025-04-23-sqlite/
# Should show SQLite database files This will extract the file into a directory matching the filename, minus the .tar.gz extension.Importing the Database Snapshot Once you have an extracted database snapshot, you can import it into your AR.IO gateway by replacing the existing SQLite database files. the Gateway your AR.IO gateway:docker compose down Backup Existing Database (Optional) Backup your existing SQLite database files:mkdir sqlite-backup
mv data/sqlite/* sqlite-backup/ Remove Old Database Delete the existing SQLite database files:rm data/sqlite/* Import New Snapshot Move the snapshot files into the data/sqlite directory:mv 2025-04-23-sqlite/* data/sqlite/ Be sure to replace 2025-04-23-sqlite with the actual directory name of the extracted snapshot you are using.Start the Gateway Start your AR.IO gateway:docker compose up -d Verifying the Import The simplest way to verify the import is to check the gateway logs to see what block number is being imported.Check Gateway Logs View the gateway logs to see the current block height:docker compose logs -f gateway Look for messages indicating the current block being processed.Verify Block Height The 2025-04-23 snapshot was taken at block 1645229, so the gateway will start importing blocks after this height if the snapshot was imported successfully.You should see logs showing blocks being processed starting from block 1645230 or higher.Use Grafana (Optional) You can also use the Grafana Extension to view the last block imported in a more human readable format.How is this guide?Content Moderation Gateway operators have the right and ability to blocklist any content or ArNS name that is deemed in violation of its content policies or is non-compliant with local regulations.Setting Apex Domain Content Complete guide to configuring your AR.IO Gateway to serve custom content from the apex domain

---

# 15. Index Querying  ARIO Documentation

Document Number: 15
Source: https://docs.ar.io/apis/ar-io-node/index-querying
Words: 158
Quality Score: 0.551
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

AR.IO Gateway Get data from the AR.IO Gateway index using GQL Query indexed data using GraphQL GraphQL endpoint for querying indexed transaction and block data. Supports:Transaction queries by ID, owner, recipient, tags, and bundle Block queries by ID and height Pagination and sorting Rich metadata including sizes, content types, and signatures See the GraphQL ground at /graphql for full schema documentation and interactive querying.Request Body query string GraphQL query string variables?object Query variables Empty Object Response Body curl -X POST "https://ardrive.net/graphql" \
-H "Content-Type: application/json" \
-d '{
"query": "query {\n transaction(\n id: \"D6I-Ke9oLg7sU_PS4oADQmnyFRa1jj2Zs1DP9BltrFs\"\n ) {\n signature\n owner {\n address\n }\n bundledIn {\n id\n }\n block {\n height\n }\n }\n}\n"
}' {
"data": "{\n \"transaction\": {\n \"signature\": \"4wh6PDJH6eyCKAWZoW26T0qt5NNjnVgyPjLs5HDR7fYgOyzEZF8FyIJiz01IRVvmXC9WZKvy2uLGiIdW4GtUNhs\",\n \"owner\": {\n \"address\": \"WbE3R_GcAalEP-VonRpL2P5TG30PJRA1-Tj20E_xIK0\"\n },\n \"bundledIn\": {\n \"id\": \"yU5ilscWlDecDhUmNcd24zqe9HmNZ31h31BxC_VcXIM\"\n },\n \"block\": null\n }\n}\n",
"errors": [
{
"message": "string",
"locations": [
{
"line": 0,
"column": 0
}
],
"path": [
"string"
]
}
]
} Empty Empty How is this guide?

---

# 16. Wayfinder React  ARIO Documentation

Document Number: 16
Source: https://docs.ar.io/sdks/wayfinder/wayfinder-react
Words: 261
Quality Score: 0.550
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Wayfinder SDK's A set of React hooks and components for integrating Wayfinder, the decentralized data access system for Arweave.Wayfinder-react wraps the functionality of wayfinder-core in user-friendly React components and hooks, making it easy to integrate AR.IO network functionality into your React applications with built-in loading states, error handling, and caching.Quick Start Install Wayfinder React npm install @ar.io/wayfinder-react @ar.io/wayfinder-core @ar.io/sdk Install polyfills (required for web environments) npm install --save-dev vite-plugin-node-polyfills // vite.config.js
import { defineConfig } from 'vite';
import { nodePolyfills } from 'vite-plugin-node-polyfills';
export default defineConfig({
plugins: [
nodePolyfills({
globals: {
Buffer: true,
global: true,
process: true,
},
}),
],
});Configure your bundler (Webpack, Vite, Rollup, etc.) to provide polyfills for crypto, process, and buffer. Refer to your bundler's documentation for polyfill configuration.Setup the provider // App.tsx
import { WayfinderProvider } from '@ar.io/wayfinder-react';
function App() {
return (

);
} Use the available hooks import { useWayfinderUrl } from '@ar.io/wayfinder-react';
function WayfinderImage({ txId }: { txId: string }) {
const { resolvedUrl, isLoading, error } = useWayfinderUrl({ txId });
if (error) {
return Error resolving URL: {error.message}
;
}
if (isLoading) {
return Resolving URL...
;
}
return (

);
} Next Steps Hooks Reference Comprehensive guide to all available React hooks Wayfinder Core Learn about the underlying core library How is this guide?Request Flow JavaScript/TypeScript SDK for accessing Arweave data with built-in verification and gateway routing useWayfinderUrl React hooks and components for integrating Wayfinder into React applications On this page Quick Start Install Wayfinder React Install polyfills (required for web environments) Setup the provider Use the available hooks Next Steps

---

# 17. Wayfinder  ARIO Documentation

Document Number: 17
Source: https://docs.ar.io/build/access/wayfinder
Words: 388
Quality Score: 0.537
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Access Data Wayfinder is a client-side routing and verification protocol that provides decentralized, cryptographically verified access to data stored on Arweave via the AR.IO Network.What is Wayfinder?Wayfinder solves the challenge of reliable data access on the permaweb by:Intelligent Routing - Automatically selects the best gateway for each request Data Verification - Cryptographically verifies data integrity Decentralized Access - Eliminates single points of failure Seamless Integration - Works behind the scenes for fast, reliable access Get Started Installation:npm install @ar.io/wayfinder-core @ar.io/sdk Basic Usage:import { createWayfinderClient } from "@ar.io/wayfinder-core";
import { ARIO } from "@ar.io/sdk";
// Create wayfinder with default settings
const wayfinder = createWayfinderClient({
ario: ARIO.mainnet(),
});
// Fetch data using ar:// protocol
try {
const response = await wayfinder.request("ar://transaction-id");
const data = await response.text();
console.log("Data:", data);
} catch (error) {
console.error("Failed to fetch data:", error);
} React Integration For React applications, use the wayfinder-react package:npm install @ar.io/wayfinder-react @ar.io/sdk import { WayfinderProvider, useWayfinder } from "@ar.io/wayfinder-react";
function App() {
return (

);
}
function YourComponent() {
const request = useWayfinderRequest();
const [data, setData] = useState(null);
useEffect(() => {
(async () => {
const response = await request(`ar://${txId}`, {
verificationSettings: {
enabled: true,
strict: true,
},
});
const data = await response.arrayBuffer();
setData(data);
})();
}, [request, txId]);
return {data && {data}}
;
} Why Use Wayfinder?Wayfinder eliminates centralized points of failure by distributing data access across the decentralized AR.IO Network, reducing dependency on arweave.net and providing advanced capabilities for production applications:Maximum Reliability Intelligent gateway selection eliminates single points of failure Automatic failover ensures data is always accessible Built-in retry mechanisms handle network issues gracefully Data Verification Cryptographic verification ensures data integrity Multiple verification strategies protect against tampering Trust but verify approach validates all responses Performance Optimization Fastest ping routing selects optimal gateways Round-robin distribution balances load across the network Caching strategies reduce latency for frequently accessed data Production Ready Developer-friendly APIs with React integration Comprehensive error handling and logging Configurable routing and verification strategies Next Steps Get Wayfinder SDK Start building with the Wayfinder SDK.Simple Data Access Use REST API for basic data retrieval.Data Discovery Use GraphQL to search for data.Use ArNS for Human-Readable URLs Create memorable names for your Arweave data.How is this guide?Arweave Name System (ArNS) Assign ArNS names to transaction IDs Run a Gateway Deploy your own AR.IO gateway to power the permanent web and earn rewards

---

# 18. Gateway Filters  ARIO Documentation

Document Number: 18
Source: https://docs.ar.io/build/run-a-gateway/manage/filters
Words: 1442
Quality Score: 0.537
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Run a Gateway Manage your Gateway Configure your AR.IO Gateway to efficiently process and index only the data you need. This comprehensive guide covers advanced filtering techniques, performance optimization, and real-world use cases.Overview The AR.IO Gateway uses a flexible JSON-based filtering system to control data processing and indexing. The system provides precise control over which bundles are processed and which data items are indexed for querying.Understanding the Filtering System The AR.IO Gateway uses two primary filters to control data processing:ANS104_UNBUNDLE_FILTER - Controls which bundles are processed and unbundled ANS104_INDEX_FILTER - Controls which data items from unbundled bundles are indexed for querying Core Environment Variables Configure Data Management Optimize data storage and processing:# Number of new data items before flushing to stable storage
DATA_ITEM_FLUSH_COUNT_THRESHOLD=1000
# Maximum time between flushes (in seconds)
MAX_FLUSH_INTERVAL_SECONDS=600
# Maximum number of data items to queue for indexing
MAX_DATA_ITEM_QUEUE_SIZE=100000
# Enable background verification
ENABLE_BACKGROUND_DATA_VERIFICATION=true Set Up GraphQL Configuration Choose between local-only or proxied queries:# For new gateways - proxy to arweave.net for complete index
GRAPHQL_HOST=arweave.net
GRAPHQL_PORT=443
# For local-only queries (uncomment to use)
# GRAPHQL_HOST= Filter Construction Basic Filters The simplest filters you can use are "always" and "never" filters. The "never" filter is the default behavior and will match nothing, while the "always" filter matches everything.{
"never": true //default behavior
} {
"always": true
} Tag Filters Tag filters allow you to match items based on their tags in three different ways. You can match exact tag values, check for the presence of a tag regardless of its value, or match tags whose values start with specific text. All tag values are automatically base64url-decoded before matching.{
"tags": [
{
"name": "Content-Type",
"value": "image/jpeg"
}
]
} {
"tags": [
{
"name": "App-Name"
}
]
} {
"tags": [
{
"name": "Protocol",
"valueStartsWith": "AO"
}
]
} Attribute Filters Attribute filtering allows you to match items based on their metadata properties. The system automatically handles owner public key to address conversion, making it easy to filter by owner address. You can combine multiple attributes in a single filter:{
"attributes": {
"owner_address": "xyz123...",
"data_size": 1000
}
} Nested Bundle Filter The isNestedBundle filter is a specialized filter that checks whether a data item is part of a nested bundle structure. It's particularly useful when you need to identify or process data items in bundles that are contained within other bundles.{
"isNestedBundle": true
} Note: When processing nested bundles, be sure to include filters that match the nested bundles in both ANS104_UNBUNDLE_FILTER and ANS104_INDEX_FILTER. The bundle data items (nested bundles) need to be indexed to be matched by the unbundle filter.Complex Filters Using Logical Operators For more complex scenarios, the system provides logical operators (AND, OR, NOT) that can be combined to create sophisticated filtering patterns. These operators can be nested to any depth:{
"and": [
{
"tags": [
{
"name": "App-Name",
"value": "ArDrive-App"
}
]
},
{
"tags": [
{
"name": "Content-Type",
"valueStartsWith": "image/"
}
]
}
]
} {
"or": [
{
"tags": [
{
"name": "App-Name",
"value": "ArDrive-App"
}
]
},
{
"attributes": {
"data_size": 1000
}
}
]
} {
"not": {
"tags": [
{
"name": "Content-Type",
"value": "application/json"
}
]
}
} Filter Configuration Strategies Process Everything {
"always": true
} Process Nothing (Default) {
"never": true
} Process Specific App Data {
"tags": [
{
"name": "App-Name",
"valueStartsWith": "MyApp"
}
]
} Single Application {
"tags": [
{
"name": "App-Name",
"value": "MyApp-v1.0"
}
]
} Multiple Applications {
"or": [
{
"tags": [
{
"name": "App-Name",
"value": "MyApp-v1.0"
}
]
},
{
"tags": [
{
"name": "App-Name",
"value": "AnotherApp-v2.1"
}
]
}
]
} Application with Version Range {
"tags": [
{
"name": "App-Name",
"valueStartsWith": "MyApp"
}
]
} Content Type Filtering {
"tags": [
{
"name": "Content-Type",
"valueStartsWith": "image/"
}
]
} Specific File Types {
"or": [
{
"tags": [
{
"name": "Content-Type",
"value": "application/json"
}
]
},
{
"tags": [
{
"name": "Content-Type",
"value": "text/plain"
}
]
}
]
} File Size Filtering {
"attributes": {
"data_size": 1000000
}
} Single Owner {
"attributes": {
"owner_address": "YOUR_WALLET_ADDRESS"
}
} Multiple Owners {
"or": [
{
"attributes": {
"owner_address": "WALLET_ADDRESS_1"
}
},
{
"attributes": {
"owner_address": "WALLET_ADDRESS_2"
}
}
]
} Exclude Specific Owners {
"not": {
"attributes": {
"owner_address": "UNWANTED_WALLET_ADDRESS"
}
}
} Complex Multi-Condition Filter {
"and": [
{
"tags": [
{
"name": "App-Name",
"valueStartsWith": "MyApp"
}
]
},
{
"attributes": {
"owner_address": "YOUR_WALLET_ADDRESS"
}
},
{
"not": {
"tags": [
{
"name": "Content-Type",
"value": "application/octet-stream"
}
]
}
}
]
} Exclude Common Bundlers {
"and": [
{
"not": {
"or": [
{
"tags": [
{
"name": "Bundler-App-Name",
"value": "Warp"
}
]
},
{
"tags": [
{
"name": "Bundler-App-Name",
"value": "Redstone"
}
]
},
{
"attributes": {
"owner_address": "-OXcT1sVRSA5eGwt2k6Yuz8-3e3g9WJi5uSE99CWqsBs"
}
}
]
}
},
{
"tags": [
{
"name": "App-Name",
"valueStartsWith": "MyApp"
}
]
}
]
} Real-World Use Cases Personal Data Gateway Perfect for individuals who want to process only their own data:Unbundle Filter:{
"and": [
{
"not": {
"or": [
{
"tags": [
{
"name": "Bundler-App-Name",
"value": "Warp"
}
]
},
{
"tags": [
{
"name": "Bundler-App-Name",
"value": "Redstone"
}
]
}
]
}
},
{
"tags": [
{
"name": "App-Name",
"valueStartsWith": "MyApp"
}
]
}
]
} Index Filter:{
"attributes": {
"owner_address": "YOUR_WALLET_ADDRESS"
}
} Application-Specific Service Ideal for building services around specific applications:Unbundle Filter:{
"tags": [
{
"name": "App-Name",
"valueStartsWith": "MyApp"
}
]
} Index Filter:{
"or": [
{
"tags": [
{
"name": "ArFS",
"value": "0.10"
}
]
},
{
"tags": [
{
"name": "ArFS",
"value": "0.11"
}
]
},
{
"tags": [
{
"name": "ArFS",
"value": "0.12"
}
]
}
]
} Content-Type Focused Gateway For gateways specializing in specific content types:Unbundle Filter:{
"tags": [
{
"name": "Content-Type",
"valueStartsWith": "image/"
}
]
} Index Filter:{
"and": [
{
"tags": [
{
"name": "Content-Type",
"valueStartsWith": "image/"
}
]
},
{
"attributes": {
"data_size": 100000
}
}
]
} Performance Optimization Worker Configuration Understanding Default Worker Settings The gateway uses sensible defaults that work well for most users:# Default values (no need to set unless customizing)
# ANS104_UNBUNDLE_WORKERS=1 (default: 0, or 1 if filters are set)
# ANS104_DOWNLOAD_WORKERS=5 (default: 5)
# Only adjust if you have specific hardware requirements
# or want to optimize for your system's capabilities Optimize Data Flushing Balance between memory usage and database performance:# For high-memory systems, increase threshold
DATA_ITEM_FLUSH_COUNT_THRESHOLD=2000
# For low-memory systems, decrease threshold
DATA_ITEM_FLUSH_COUNT_THRESHOLD=500
# Adjust flush interval based on data MAX_FLUSH_INTERVAL_SECONDS=300 Enable Background Processing # Enable background verification
ENABLE_BACKGROUND_DATA_VERIFICATION=true
# Enable WAL cleanup for better performance
ENABLE_DATA_DB_WAL_CLEANUP=true Webhook Filters There are also two filters available that are used to trigger webhooks. When a transaction is processed that matches one of the webhook filters, the gateway will send a webhook to the specified WEBHOOK_TARGET_SERVERS urls containing the transaction data.WEBHOOK_INDEX_FILTER=""
WEBHOOK_BLOCK_FILTER="" The WEBHOOK_INDEX_FILTER is used to trigger a webhook when a transaction is indexed. The WEBHOOK_BLOCK_FILTER is used to trigger a webhook when a block is processed.Important Notes All tag names and values are base64url-decoded before matching Owner addresses are automatically converted from owner public keys Empty or undefined filters default to "never match" Tag matching requires all specified tags to match Attribute matching requires all specified attributes to match The filter system supports nested logical operations to any depth, allowing for very precise control over what data gets processed Best Practices Filter Design Start Simple - Begin with basic filters and gradually add complexity Test Thoroughly - Use FILTER_CHANGE_REPROCESS=true when changing filters Monitor Performance - Watch system resources during processing Document Changes - Keep track of filter modifications and their effects Regular Monitoring - Check gateway logs for errors and warnings Resource Cleanup - Periodically clean up old data and logs Filter Optimization - Refine filters based on actual data patterns Backup Configuration - Keep copies of working filter configurations Troubleshooting If your gateway s processing data after changing filters, check: - Filter
syntax is valid JSON - Required environment variables are set - Gateway has
been restarted after changes - System has sufficient resources Next Steps Now that you understand gateway filtering, continue building your infrastructure:Set Up Monitoring Deploy Grafana to visualize your gateway's performance metrics Add ClickHouse Improve query performance with ClickHouse and Parquet integration Deploy Bundler Accept data uploads directly through your gateway Run Compute Unit Execute AO processes locally for maximum efficiency How is this guide?Automating SSL Certificate Renewal Step-by-step guide to configure Certbot with automatic SSL certificate renewal using DNS API for AR.IO Gateway Content Moderation Gateway operators have the right and ability to blocklist any content or ArNS name that is deemed in violation of its content policies or is non-compliant with local regulations.

---

# 19. Data Model  ARIO Documentation

Document Number: 19
Source: https://docs.ar.io/build/advanced/arfs/data-model
Words: 599
Quality Score: 0.531
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Advanced ArFS Protocol Because of Arweave's permanent and immutable nature, traditional file structure operations such as renaming and moving files or folders cannot be accomplished by simply updating on-chain data. ArFS works around this by defining an append-only transaction data model based on the metadata tags found in the Arweave Transaction Headers.This model uses a bottom-up reference method, which avoids race conditions in file system updates. Each file contains metadata that refers to the parent folder, and each folder contains metadata that refers to its parent drive. A top-down data model would require the parent model (i.e. a folder) to store references to its children.These defined entities allow the state of the drive to be constructed by a client to look and feel like a file system:Drive Entities contain folders and files Folder Entities contain other folders or files File Entities contain both the file data and metadata Snapshot entities contain a state rollups of all entities' (such as drive, folder, file and snapshot) metadata within a drive Entity Relationships The following diagram shows the high level relationships between drive, folder, and file entities, and their associated data. More detailed information about each Entity Type can be found in the ArFS specification documentation.As you can see, each file and folder contains metadata which points to both the parent folder and the parent drive. The drive entity contains metadata about itself, but not the child contents. So clients must build drive states from the lowest level and work their way up.Metadata Format Metadata stored in any Arweave transaction tag will be defined in the following manner:{ "name": "Example-Tag", "value": "example-data" } Metadata stored in the Transaction Data Payload will follow JSON formatting like below:{
"exampleField": "exampleData"
} Fields with a ? suffix are optional.{
"name": "My Project",
"description": "This is a sample project.",
"version?": "1.0.0",
"author?": "John Doe"
} Enumerated field values (those which must adhere to certain values) are defined in the format "value 1 | value 2".All UUIDs used for Entity-Ids are based on the Universally Unique Identifier standard.There are no requirements to list ArFS tags in any specific order.Building Drive State To construct the current state of a drive, clients must:Query for all entities associated with a specific Drive-Id Sort by block height to establish chronological order Process entities bottom-up starting with files and folders Build the hierarchy by following parent-child relationships Handle conflicts by using the most recent entity version Example Drive State Construction Entity Lifecycle Each ArFS entity follows a specific lifecycle pattern:Creation Generate unique UUID for entity Create metadata transaction with required tags For files: create separate data transaction Upload to Arweave network Updates Create new entity with same ID Update metadata as needed Upload new transaction Client processes both versions and uses latest Deletion Mark entity as hidden (isHidden: true) Upload new transaction Entity remains in history but hidden from UI Data Integrity ArFS ensures data integrity through:Immutable transactions - Once uploaded, data cannot be modified Cryptographic signatures - All transactions are signed by the owner Version tracking - Multiple versions of entities can exist Conflict resolution - Clients use block height and timestamps to resolve conflicts Performance Considerations For large drives, consider these optimization strategies:Use snapshots for quick state reconstruction Implement caching for frequently accessed data Batch operations when possible Query by date ranges to limit data transfer Next Steps Now that you understand the ArFS data model, learn how to work with it:Privacy & Encryption - Secure your data with private drives Creating Drives - Start building with ArFS Reading Data - Query and retrieve your data How is this guide?

---

# 20. ARIO SDK  ARIO Documentation

Document Number: 20
Source: https://docs.ar.io/sdks/ar-io-sdk
Words: 330
Quality Score: 0.528
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

The AR.IO SDK provides comprehensive tools for interacting with the AR.IO Network and Arweave ecosystem. Built with TypeScript, it offers type-safe interfaces for ArNS name management, gateway operations, and AO contract interactions.Quick Start Install the SDK npm install @ar.io/sdk Use the SDK import { ARIO } from '@ar.io/sdk/node';
// Connect to mainnet
const ario = ARIO.mainnet();
// Get paginated gateway registry
const { items: gateways } = await ario.getGateways();
// Get paginated ArNS registry
const { items: records } = await ario.getArNSRecords();
console.log('Network data:', { gateways, records });Install the SDK npm install @ar.io/sdk Install polyfills (required for web environments) npm install --save-dev vite-plugin-node-polyfills // vite.config.js
import { defineConfig } from 'vite';
import { nodePolyfills } from 'vite-plugin-node-polyfills';
export default defineConfig({
plugins: [
nodePolyfills({
globals: {
Buffer: true,
global: true,
process: true,
},
}),
],
});Configure your bundler (Webpack, Vite, Rollup, etc.) to provide polyfills for crypto, process, and buffer. Refer to your bundler's documentation for polyfill configuration.Use the SDK import { ARIO } from '@ar.io/sdk/web';
// Connect to mainnet
const ario = ARIO.mainnet();
// Get paginated gateway registry
const { items: gateways } = await ario.getGateways();
// Get paginated ArNS registry
const { items: records } = await ario.getArNSRecords();
console.log('Network data:', { gateways, records });
AR.IO SDK Example

# AR.IO SDK Example
Loading AR.IO data...
API Reference & Documentation API Reference Complete API documentation for all SDK methods and classes SDK Details Detailed guides for ARIO contracts, ANT operations, and utilities Core Features ARIO Contract Operations ArNS management, gateway discovery, and network configuration ANT Contract Integration Initialize, manage records, and transfer ANT ownership Pagination & Utilities Handle large datasets and token conversions efficiently Token Operations ARIO token conversions and management utilities How is this guide?Introduction Software Development Kits for building on AR.IO General TypeScript/JavaScript SDK for interacting with the AR.IO ecosystem On this page Quick Start Install the SDK Use the SDK Install the SDK Install polyfills (required for web environments) Use the SDK API Reference & Documentation Core Features

---

# 21. Guides  ARIO Documentation

Document Number: 21
Source: https://docs.ar.io/build/guides
Words: 345
Quality Score: 0.528
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Explore real-world applications and use cases for Arweave and AR.IO infrastructure. These examples show what's possible with permanent data storage and decentralized web services.What You Can Build Arweave and AR.IO enable:Decentralized websites - Host permanent, censorship-resistant web content ArNS domains - Create and manage decentralized domain names Data marketplaces - Trade and sell digital assets and data Permanent applications - Deploy apps that can't be taken down And much more - The permanent web is only limited by your imagination Getting Started Hosting Decentralized Websites Build permanent websites that can't be censored or taken down Key topics:Arweave manifests for file routing Permaweb deployment tools ArNS domain integration ArNS Primary Names Create and manage decentralized domain names Key topics:Primary name registration Domain management Integration with applications ArNS Undernames for Versioning Version and organize your permanent website content Key topics:Undername management Website versioning Component organization ArNS Marketplace Trade and sell ArNS tokens and digital assets Key topics:Arweave Name Token (ANT) trading Marketplace dynamics Asset ownership Deploy a dApp with ArDrive Web Deploy dApps easily using the ArDrive web interface Key topics:ArDrive web deployment Manifest creation ArNS name assignment Version management Crossmint NFT Minting App Build a decentralized NFT minting app with Arweave and Crossmint Key topics:Permanent NFT storage on Arweave Crossmint API integration Payment processing Decentralized deployment Why Use Arweave?Permanent storage - Data stored on Arweave is permanent and cannot be deleted Decentralized - No single point of failure or control Cost-effective - Pay once, store forever Censorship-resistant - Content cannot be taken down by authorities Ready to Build?Start with websites - Learn how to host decentralized websites with Hosting Decentralized Websites.Want domains? Explore ArNS Primary Names for decentralized domain management.Interested in trading? Check out ArNS Marketplace for digital asset trading.How is this guide?AO Compute Unit (CU) Steps for deploying an AO Compute Unit (CU) sidecar alongside your AR.IO Gateway.Storing DePIN Data on Arweave Using Turbo Complete guide to storing and accessing DePIN network data permanently on Arweave using Turbo and AR.IO Network On this page What You Can Build Getting Started Why Use Arweave?Ready to Build?

---

# 22. Arweave Name System (ArNS)  ARIO Documentation

Document Number: 22
Source: https://docs.ar.io/learn/arns
Words: 437
Quality Score: 0.527
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

What is ArNS?Arweave URLs and transaction IDs are long, difficult to remember, and occasionally categorized as spam. The Arweave Name System (ArNS) aims to resolve these problems in a decentralized manner.ArNS is a censorship-resistant naming system stored on Arweave, powered by ARIO tokens, enabled through AR.IO gateway domains, and used to connect friendly domain names to permaweb apps, web pages, data, and identities.It's an open, permissionless, domain name registrar that doesn't rely on a single TLD.How ArNS Works This system works similarly to traditional DNS services, where users can purchase a name in a registry and DNS Name servers resolve these names to IP addresses. The system is flexible and allows users to purchase names permanently or lease them for a defined duration based on their use case.With ArNS, the registry is stored permanently on Arweave via AO, making it immutable and globally resilient. This also means that apps and infrastructure cannot just read the latest state of the registry but can also check any point in time in the past, creating a "Wayback Machine" of permanent data.Name Resolution Users can register a name, like ardrive, within the ArNS Registry. Before owning a name, they must create an Arweave Name Token (ANT), an AO Computer based token and open-source protocol used by ArNS to track the ownership and control over the name.ANTs allow the owner to set a mutable pointer to any type of permaweb data, like a page, app or file, via its Arweave transaction ID.Each AR.IO gateway acts as an ArNS Name resolver. They fetch the latest state of both the ArNS Registry and its associated ANTs from an AO compute unit (CU) and serve this information rapidly for apps and users.AR.IO gateways will also resolve that name as one of their own subdomains, e.g., https://ardrive.arweave.net and proxy all requests to the associated Arweave transaction ID. This means that ANTs work across all AR.IO gateways that support them: https://ardrive.ar-io.dev, https://ardrive.g8way.io/, etc.Users can easily reference these friendly names in their browsers, and other applications and infrastructure can build rich solutions on top of these ArNS primitives.Key Benefits Human-readable URLs instead of complex transaction IDs Censorship-resistant and decentralized Permanent storage on Arweave Cross-gateway compatibility - works on all AR.IO gateways Historical data access - check any point in time Flexible ownership - permanent or leased names Explore ArNS Register ArNS Names Learn how to register permanent names and understand validation rules Arweave Name Tokens (ANTs) Understand ownership, control, and interaction permissions for names Pricing Model Explore dynamic pricing, demand factors, and gateway discounts Buy ArNS Names Start registering names for your permanent applications How is this guide?

---

# 23. Working With Primary Names  ARIO Documentation

Document Number: 23
Source: https://docs.ar.io/build/guides/arns-primary-names
Words: 554
Quality Score: 0.518
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Guides Create web3 identity using ArNS names. Primary names allow you to use human-readable names as your identity in the Arweave ecosystem, making it easy for others to find and interact with you.What Are Primary Names?Primary names are ArNS names used as identity that:Resolve to wallet addresses - Link human-readable names to wallet addresses Provide web3 identity - Give users friendly names for their Arweave identity Are bidirectional - Can resolve from name to address or address to name Require ownership - Only the owner of an ArNS name can set it as their primary name Enable secure verification - Ownership requirement ensures identity authenticity Work across gateways - Accessible from any AR.IO gateway How It Works 1. Identity Registration Register a primary name:Choose a unique name (e.g., jonniesparkles) Pay the registration fee Link the name to your wallet address Use as your web3 identity 2. Bidirectional Resolution Name to address resolution:jonniesparkles → OU48aJtcq3KjsEqSUWDVpynh1xP2Y1VI-bwiSukAktU Others can find your wallet using your name Use in dApps and applications Address to name resolution:OU48aJtcq3KjsEqSUWDVpynh1xP2Y1VI-bwiSukAktU → jonniesparkles Find the name associated with any wallet Verify identity in transactions 3. Application Integration Use in supported apps:Send tokens to "jonniesparkles" instead of copying long wallet addresses Dis friendly names as usernames when connecting wallets Apps resolve names to wallet addresses using the AR.IO SDK Seamless user experience with human-readable identifiers Basic Integration Using the AR.IO SDK Get a primary name by address:import { ARIO } from "@ar-io/sdk";
const ario = new ARIO();
// Get the primary name for a wallet address
const nameData = await ario.getPrimaryName({
address: "OU48aJtcq3KjsEqSUWDVpynh1xP2Y1VI-bwiSukAktU",
});
console.log(nameData.name); // e.g., "jonniesparkles" Get primary name data:import { ARIO } from "@ar-io/sdk";
const ario = new ARIO();
// Get primary name data for a name
const nameData = await ario.getPrimaryName({
name: "jonniesparkles",
});
console.log(nameData.owner); // e.g., "OU48aJtcq3KjsEqSUWDVpynh1xP2Y1VI-bwiSukAktU"
console.log(nameData.name); // e.g., "jonniesparkles" How Apps Use Primary Names Token transfers:Send tokens to "jonniesparkles" instead of copying OU48aJtcq3KjsEqSUWDVpynh1xP2Y1VI-bwiSukAktU Apps automatically resolve the name to the wallet address Much more user-friendly than long wallet addresses User interfaces:Dis "jonniesparkles" as username when wallet is connected Show friendly names in transaction histories Make interactions more personal and memorable Developer integration:Use the AR.IO SDK to resolve names Support primary names in your dApp Enhance user experience with human-readable identifiers Trust identity ownership - Only name owners can set primary names, ensuring secure verification Benefits Web3 identity - Use human-readable names as your identity Easy discovery - Others can find you by name instead of wallet address Bidirectional resolution - Resolve name to address or address to name Secure verification - Only name owners can set primary names, preventing impersonation Permanent ownership - Own your identity forever App integration - Works in any app that supports primary names Ready to Learn More?Trade Domains Check out ArNS Marketplace for buying and selling.Deploy Websites See hosting decentralized websites for website setup.Technical Details Explore the ArNS documentation for advanced features.How is this guide?Deploy a dApp with ArDrive Web How to upload a dApp to the permaweb using ArDrive web ArNS Undernames for Permasite Versioning Use ArNS undernames to manage different versions and components of your permanent website On this page What Are Primary Names?How It Works 1. Identity Registration 2. Bidirectional Resolution 3. Application Integration Basic Integration Using the AR.IO SDK How Apps Use Primary Names Benefits Ready to Learn More?

---

# 24. Find Data (via GraphQL)  ARIO Documentation

Document Number: 24
Source: https://docs.ar.io/build/access/find-data
Words: 882
Quality Score: 0.514
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Access Data Use GraphQL to find and identify Arweave data with powerful search and filtering capabilities. GraphQL is used for discovery - you query to get transaction IDs, then use those IDs to fetch the actual data.GraphQL is for Discovery, Not Direct Access GraphQL finds data, it doesn't
access it directly. Use GraphQL to get transaction IDs, then use those IDs
with the REST API to fetch the actual data.How GraphQL Works GraphQL on Arweave follows a two-step process:Find - Query GraphQL to discover transactions by tags, metadata, owner, or other criteria Fetch - Use the transaction IDs from your query results to retrieve the actual data via the REST API This separation allows for powerful data discovery while keeping data retrieval fast and efficient.GraphQL Providers arweave.net - https://arweave.net/graphql - Comprehensive indexing of all Arweave data Goldsky - https://arweave-search.goldsky.com/graphql - High-performance GraphQL service with full data coverage AR.IO Gateways: AR.IO gateways support the /graphql endpoint, but they
only return data they've indexed. If you're uploading data and want it
unbundled and indexed, you can run a gateway and configure it to unbundle your
data, or post data items/bundles via the gateway's APIs (recommended). Learn
more.Quick Start The easiest way to get started is using the interactive GraphQL ground:Navigate to https://arweave.net/graphql in your browser Enter your GraphQL query in the interface Press the "" button to execute and see results Basic Query Structure Try this example query in the ground - it fetches the most recent 10 HTML pages from "MyApp":query {
transactions(
tags: [
{ name: "Content-Type", values: ["text/html"] }
{ name: "App-Name", values: ["MyApp"] }
]
sort: HEIGHT_DESC
first: 10
) {
edges {
node {
id
tags {
name
value
}
data {
size
}
}
}
}
} Example Queries Here's how to find videos using GraphQL: // First page
const query = `
query {
transactions(
tags: [{ name: "App-Name", values: ["MyApp"] }]
first: 10
) {
pageInfo {
hasNextPage
}
edges {
cursor
node {
id
tags {
name
value
}
}
}
}
}
`;
const response = await fetch("https://arweave.net/graphql", {
method: "POST",
headers: {
"Content-Type": "application/json",
},
body: JSON.stringify({ query }),
});
const data = await response.json();
const { edges, pageInfo } = data.data.transactions;
// Next page using cursor
if (pageInfo.hasNextPage) {
const nextQuery = `
query($cursor: String) {
transactions(
tags: [{ name: "App-Name", values: ["MyApp"] }]
after: $cursor
first: 10
) {
pageInfo {
hasNextPage
}
edges {
cursor
node {
id
tags {
name
value
}
}
}
}
}
`;
const nextResponse = await fetch("https://arweave.net/graphql", {
method: "POST",
headers: {
"Content-Type": "application/json",
},
body: JSON.stringify({
query: nextQuery,
variables: { cursor: edges[edges.length - 1].cursor },
}),
});
const nextData = await nextResponse.json();
console.log(nextData.data);
} Pagination As of September 2025, GraphQL endpoints have different limits:arweave.net: Supports queries up to 1,000 items at once Goldsky: Supports queries up to 100 items at once For larger datasets, use cursor-based pagination to navigate through results.How Pagination Works:Use first parameter to specify page size (max 1,000 for arweave.net, max 100 for Goldsky) Use pageInfo.hasNextPage to check if more results exist Use cursor from the last item with after parameter for the next page let allTransactions = [];
let hasNextPage = true;
let cursor = null;
while (hasNextPage) {
const query = `
query($cursor: String) {
transactions(
tags: [{ name: "App-Name", values: ["MyApp"] }]
first: 100
${cursor ? "after: $cursor" : ""}
) {
pageInfo {
hasNextPage
}
edges {
cursor
node {
id
tags {
name
value
}
}
}
}
}
`;
const response = await fetch("https://arweave.net/graphql", {
method: "POST",
headers: {
"Content-Type": "application/json",
},
body: JSON.stringify({
query,
variables: cursor ? { cursor } : {},
}),
});
const data = await response.json();
const { edges, pageInfo } = data.data.transactions;
allTransactions.push(...edges);
hasNextPage = pageInfo.hasNextPage;
cursor = edges.length > 0 ? edges[edges.length - 1].cursor : null;
console.log(
`Loaded ${edges.length} transactions. Total: ${allTransactions.length}`
);
}
console.log(`Found ${allTransactions.length} total transactions`);Query Optimization Tips Follow these guidelines for optimal performance:Specificity:Use the most precise tags possible to narrow search scope Query with essential tags only to reduce processing time Schema Design:Design your app's schema to reflect query patterns Use tags that encapsulate frequent combinations of criteria Include Non-tag Fields:Add fields like owner to refine your search This makes queries more efficient and targeted Order Your Tags:Arrange tags from most specific to most general This leverages Arweave's indexing more effectively Example Optimized Query:// Well-optimized query with specific tags and useful fields
const query = `
query {
transactions(
tags: [
{ name: "App-Name", values: ["MyApp"] }
{ name: "Content-Type", values: ["application/json"] }
{ name: "Version", values: ["1.0"] }
]
owners: ["your-wallet-address"]
first: 20
) {
edges {
node {
id
data {
size
type
}
tags {
name
value
}
block {
height
timestamp
}
owner {
address
}
}
}
}
}
`;Next Steps Fetch Data via REST API Learn how to retrieve the actual data using transaction IDs.Run Your Own Gateway Set up a gateway to index and serve your specific data.Upload Data with Turbo Start uploading your data to Arweave's permanent storage.Use Wayfinder for Smart Routing Automatically route requests to the best performing gateway.How is this guide?Fetch Data (via REST API) Retrieve data bytes from Arweave using the Gateway REST API Arweave Name System (ArNS) Assign ArNS names to transaction IDs

---

# 25. Creating Drives  ARIO Documentation

Document Number: 25
Source: https://docs.ar.io/build/advanced/arfs/creating-drives
Words: 710
Quality Score: 0.510
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Advanced ArFS Protocol To properly create a new drive, two new entities need to be created: a new Drive entity and a new Folder entity to serve as the root folder of that drive.New Drive Entity The user must specify a name of the drive which is stored within the Drive Entity's metadata JSON.ArDrive generates a new unique uuidv4 for the drive entity's Drive-Id.ArDrive also generates a new unique uuidv4 for the drive entity's rootFolderId, which will refer to the Folder-Id of the new folder entity that will be created.This rootFolderId is stored within the Drive Entity's metadata JSON.Drive Entity Metadata transactions must have Entity-Type: "drive".ArDrive will that the current local system time as seconds since Unix epoch for the Drive Entity's Unix-Time.The Drive Entity's Drive-Privacy must also be set to public or private in order for its subfolders and files to have the correct security settings.If the drive is private:Its Cipher tag must be filled out with the correct encryption algorithm (currently AES256-GCM).Its Cipher-IV tag must be filled out with the generated Initialization Vector for the private drive.The ArFS client must derive the Drive Key and encrypt the Drive Entity's metadata JSON using the assigned Cipher and Cipher-IV.New Root Folder Entity The name of the drive and folder entities must be the same.This name is stored within the Folder Entity's metadata JSON.The Folder Entity's Folder-Id must match the rootFolderId previously created for the Drive Entity.The Folder Entity's Drive-Id must match the Drive-Id previously created for the Drive Entity.The Folder Entity must not include a Parent-Folder-Id tag.This is how it is determined to be the root folder for a drive.Folder Entity metadata transactions must have Entity-Type: 'folder'.The client gets the user's local time for the Unix-Time tag, represented as seconds since Unix Epoch.Public folders must have the content type Content-Type: "application/json".If the folder is private Its Cipher tag must be filled out with the correct encryption algorithm (currently AES256-GCM).Its Cipher-IV tag must be filled out with the generated Initialization Vector for the private folder.Its content type must be Content-Type: "application/octet-stream".The ArFS client must encrypt the Drive Entity's metadata JSON using the assigned Cipher and Cipher-IV.Creating Files Files in ArFS require two separate transactions:File Metadata Transaction - Contains file information and references File Data Transaction - Contains the actual file data File Metadata Transaction ArFS: "0.15",
Cipher?: "AES256-GCM",
Cipher-IV?: "<12 byte initialization vector as Base64>",
Content-Type: "",
Drive-Id: "",
Entity-Type: "file",
File-Id: "",
Parent-Folder-Id: "",
Unix-Time: ""
Metadata JSON {
"name": "",
"size": ,
"lastModifiedDate": ,
"dataTxId": "",
"dataContentType": "",
"isHidden": false,
"pinnedDataOwner": ""
} File Data Transaction Cipher?: "AES256-GCM",
Cipher-IV?: "<12 byte initialization vector as Base64>",
Content-Type: "",
{ File Data - Encrypted if private } Creating Folders Folders are simpler than files as they only require a metadata transaction:ArFS: "0.15",
Cipher?: "AES256-GCM",
Cipher-IV?: "<12 byte initialization vector as Base64>",
Content-Type: "",
Drive-Id: "",
Entity-Type: "folder",
Folder-Id: "",
Parent-Folder-Id?: "",
Unix-Time: ""
Metadata JSON {
"name": "",
"isHidden": false
} Creating Snapshots Snapshots provide a way to quickly synchronize drive state by rolling up all metadata into a single transaction:ArFS: "0.15",
Drive-Id: "",
Entity-Type: "snapshot",
Snapshot-Id: "",
Content-Type: "",
Block-Start: "",
Block-End: "",
Data-Start: "",
Data-End: "",
Unix-Time: "" Implementation Example Here's a practical example of creating a complete drive structure:Best Practices Naming Conventions Use descriptive names for drives, folders, and files Avoid special characters that might cause issues Keep names under 255 characters Use consistent casing Organization Create logical folder structures Use meaningful folder names Implement proper versioning Document your structure Performance Batch operations when possible Use efficient queries Implement caching Consider file sizes Security Use strong passwords for private drives Implement proper key management Follow encryption best practices Regular security audits Error Handling When creating ArFS entities, handle these common scenarios:Transaction Failures Implement retry logic for failed uploads Validate data before uploading Check transaction confirmation status Validation Errors Verify required tags are present Check data format compliance Validate UUID formats Network Issues Implement timeout handling Provide user feedback Graceful degradation Next Steps Now that you know how to create ArFS entities, learn how to work with them:Reading Data - Query and retrieve your ArFS data Privacy & Encryption - Secure your data with private drives Upgrading Private Drives - Update legacy drives to v0.15 How is this guide?

---

# 26. Join the Network  ARIO Documentation

Document Number: 26
Source: https://docs.ar.io/build/run-a-gateway/join-the-network
Words: 766
Quality Score: 0.505
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Run a Gateway Take control of the permanent web by running your own AR.IO Gateway. Join the decentralized network that powers the permaweb and earn rewards for providing infrastructure services.Prerequisites Running Gateway Required You must have a fully functional AR.IO Gateway running with a custom domain and SSL certificates.Don't have a gateway yet? Follow our Production Setup Guide to get your gateway running with proper DNS configuration.Requirements:Gateway accessible via your custom domain (e.g., https://yourdomain.com) SSL certificates properly configured ArNS subdomain resolution working Gateway responding to test requests Minimum Stake Requirement To join the network as a gateway operator, you need 10,000 ARIO tokens as the minimum stake requirement.Need to acquire ARIO tokens? Visit our Get the Token guide to learn about all available methods including exchanges, DEXs, and network participation.Acquisition Options:Purchase on centralized exchanges like Gate.io Trade on decentralized exchanges (Dexi, Botega, Vento) Use Wander wallet for easy exchange and swap functionality Earn through network participation and community programs Join the Network Choose your preferred method to register your gateway:Connect Your Wallet Click the "Start your own gateway" button to begin the registration process. You'll be prompted to connect your wallet. Choose your preferred wallet (Wander, Metamask, or Beacon) to connect.Fill Out Gateway Information Complete the gateway registration form with your gateway details: Required Fields:Label: A dis name for your gateway (e.g., "My New Gateway") Address: Your gateway's domain with port (e.g., https://fastandfurious.io:443) Observer Wallet: The public address of your observer wallet Properties ID: Transaction ID of your gateway properties Stake (ARIO): Minimum stake required (typically 10,000 ARIO) Delegated Staking: Enable to allow others to delegate stake to your gateway Minimum Delegated Stake: Set minimum delegation amount (e.g., 100 ARIO) Reward Share Ratio: Percentage of rewards shared with delegators (e.g., 50%) Note: Additional information about your gateway (e.g., "AR.IO rules!") Confirm Registration Review all information carefully and click "Confirm" to submit your gateway registration to the network.What happens next:Your gateway will be added to the Gateway Address Registry Observers will start observing your gateway at the next Epoch (day) You will begin to receive rewards based on your gateway performance You can monitor your gateway's performance in the portal Confirm your gateway registration:Your gateway should now be viewable at gateways.ar.io/#/ with the wallet address you used to join. This dashboard shows your gateway's information, stats, and performance metrics including join date, uptime, operator stake, and delegated stake details.Install the AR.IO CLI First, install the AR.IO CLI tool if you haven't already:npm install -g @ar.io/sdk Run the Join Network Command Use the ar.io join-network command with your gateway configuration: Wallet File Requirement The wallet file used in the --wallet-file parameter must be the same wallet configured in your AR.IO Gateway's AR_IO_WALLET environment variable. This ensures your gateway registration is properly linked to your running gateway instance.Parameter explanations:--qty 10000000000 - 10,000 ARIO in mARIO (multiply by 1,000,000) --min-delegated-stake 100000000 - 100 ARIO in mARIO --delegate-reward-share-ratio 10 - 10% shared with delegators --observer-wallet - Must match your gateway's OBSERVER_WALLET env var --fqdn - Your gateway's domain name Verify Registration After running the command, verify your gateway registration using the CLI:ar.io get-gateway 0VE0wIhDy90WiQoV3U2PeY44FH1aVetOoulPGqgYukj The status should show joined when your gateway is successfully registered.You can also verify by visiting: gateways.ar.io/#/ The CLI will output transaction details and your gateway should appear in the network portal within a few minutes.What Happens After Registration After joining the network:Your gateway will be monitored by the Observer system You'll earn rewards for providing reliable service You can monitor your gateway's performance and earnings in the portal You may be selected as an Observer to help monitor other gateways Next Steps Your gateway is now part of the AR.IO Network! Here are some next steps to maximize your participation:Delegate to Gateways Participate in the network by delegating your stake to other gateways and earn rewards Start Indexing Data Configure your gateway to index specific data types and optimize performance for your use case Use Wayfinder SDK Fetch data from your gateway and the network using the Wayfinder SDK for optimal routing Join the Community Connect with other gateway operators and get support from the AR.IO community How is this guide?Installation & Setup Get started running AR.IO gateway using Docker - minimal setup, maximum results Manage your Gateway Comprehensive guides for advanced AR.IO Gateway operations including monitoring, optimization, content moderation, and specialized configurations On this page Prerequisites Running Gateway Required Minimum Stake Requirement Join the Network Visit the Network Portal Connect Your Wallet Fill Out Gateway Information Confirm Registration Install the AR.IO CLI Run the Join Network Command Verify Registration What Happens After Registration Next Steps

---

# 27. Access Data  ARIO Documentation

Document Number: 27
Source: https://docs.ar.io/build/access
Words: 297
Quality Score: 0.504
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Once data is stored on Arweave, it's permanently available. Here's how to access it efficiently for your applications.Access Methods Different methods serve different needs. Each provides unique capabilities for retrieving data from Arweave.Find Data Search and discover data on Arweave Query by tags and metadata Filter by app, owner, timestamp Get transaction IDs for fetching Fetch Data Retrieve data bytes from Arweave REST API endpoints GET arweave.net/[txId] Returns raw data/files ArNS Names Assign names to data and apps Create names like ardrive.ar.io Point to any Arweave data Update targets as needed Common Access Patterns Finding Data Search for data by tags, owner, or timestamp Discover content from specific applications Get transaction IDs for data retrieval Fetching Data Retrieve the actual files/data using transaction IDs Access data via REST API: GET arweave.net/[txId] Stream large files efficiently Naming with ArNS Register memorable names for your apps and data Create permanent links like ardrive.ar.io Update where names point without changing the URL Quick Example: Find and Fetch Find Data Use GraphQL to search for data and get transaction IDs:query {
transactions(
tags: [{ name: "App-Name", values: ["ArDrive"] }]
first: 1
) {
edges {
node {
id
}
}
}
} Fetch Data Use the transaction ID to retrieve the actual data:curl https://arweave.net/[transaction-id-from-above] Access Tutorial Complete guide to data retrieval ArNS Documentation Learn about the naming system Additional Access Options Wayfinder SDK Advanced gateway routing for production apps Run a Gateway Build and run a gateway Data Verification Ensure data integrity and authenticity How is this guide?Encryption Understanding data encryption for secure storage on Arweave Fetch Data (via REST API) Retrieve data bytes from Arweave using the Gateway REST API On this page Access Methods Common Access Patterns Quick Example: Find and Fetch Find Data Fetch Data Additional Access Options

---

# 28. Arweave Name Tokens (ANTs)  ARIO Documentation

Document Number: 28
Source: https://docs.ar.io/learn/arns/ants
Words: 619
Quality Score: 0.504
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Arweave Name System (ArNS) To establish ownership of a record in the ArNS Registry, each record contains both a friendly name and a reference to an Arweave Name Token, ANT. Name Tokens are unique AO Computer based tokens/processes that give their owners the ability to update the Arweave Transaction IDs that their associated friendly names point to.What is an ANT?The ANT smart contract process is a standardized contract that implements the specific Arweave Name Process specification required by AR.IO gateways who resolve ArNS names and their Arweave Transaction IDs. It also contains other basic functionality to establish ownership and the ability to transfer ownership and update the Arweave Transaction ID.Name Tokens have an owner, who can transfer the token and control its modifiable settings. These settings include modifying the address resolution time to live (ttl) for each name contained in the ANT, and other settings like the ANT Name, Ticker, and an ANT Controller.Ownership and Control The controller can only manage the ANT and set and update records, name, and the ticker, but cannot transfer the ANT. Note that ANTs are initially created in accordance with network standards by an end user who then has the ability to transfer its ownership or assign a controller as they see fit.Owners of names should ensure their ANT supports evolve ability if future modifications are desired. Loss of a private key for a permanently purchased name can result in the name being "bricked".Under_name Ownership Undernames can have an owner set on them. This owner is empowered to set that undername as their primary name, can remove that undername as their primary name, and has full control over that Undername's metadata, such as:Transaction Id - the data the record resolves to.TTL Seconds - the Time To Live in seconds the data is cached for by clients.Owner - the owner of the record.Description - the description of the record.Dis Name - the dis name for the owner of the record.Keywords - the keywords for the record.Logo - the logo of the record.They do NOT have control over the priority of the undername, which is restricted to the ANT Controllers and Owner.ANT Interactions The table below indicates some of the possible interactions with the ArNS registry, corresponding ANTs, and who can perform them:Type ANT Owner ANT Controller Undername Owner Any ARIO Token Holder Transfer ownership ✔ Add / remove controllers ✔ Approve/Remove Primary name ✔ ✔ Reassign name to new ANT process ✔ Return a permanent name ✔ Set records (pointers, record metadata) ✔ ✔ ✔ Update records, name, ticker ✔ ✔ Update descriptions and keywords ✔ ✔ Create and assign undernames ✔ ✔ Extend / renew lease ✔ ✔ ✔ ✔ Increase undernames ✔ ✔ ✔ ✔ Convert lease to permanent ✔ ✔ ✔ ✔ Under_names ANT owners and controllers can configure multiple subdomains for their registered ArNS name known as "under_names" or more easily written "undernames". These undernames are assigned individually at the time of registration or can be added on to any registered name at any time.Under names use an underscore " " in place of a more typically used dot "." to separate the subdomain from the main ArNS domain.Secondary Markets Secondary markets could be created by ecosystem partners that facilitate the trading of Name Tokens. Additionally, tertiary markets could be created that support the leasing of these friendly names to other users. Such markets, if any, would be created by third parties unrelated to and outside of the scope of this paper or control of the Foundation.Next Steps Ready to understand how pricing works? Learn about the Pricing Model to see how costs are calculated dynamically, or go back to Name Registration to review the registration process.How is this guide?

---

# 29. Upgrading your Gateway  ARIO Documentation

Document Number: 29
Source: https://docs.ar.io/build/run-a-gateway/manage/upgrading-a-gateway
Words: 603
Quality Score: 0.504
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Run a Gateway Manage your Gateway To ensure the optimal performance and security of your AR.IO Gateway, it's essential to regularly upgrade to the latest version. Notably, indexed data resides separate from Docker. As a result, neither upgrading the Gateway nor pruning Docker will erase your data or progress. Here's how you can perform the upgrade:Prerequisites Your Gateway should have been cloned using git. If you haven't, follow the installation instructions.Checking your Release Number Effective with release 3, you can view the currently implemented release on any gateway by visiting https:///ar-io/info in a browser. Be sure to replace with the domain of the gateway you are checking.If the release number dised includes -pre it means that your gateway is using the develop branch of the github repo for the gateway code. Follow steps in our troubleshooting guide to switch over to the more stable main branch.Announcements will be made in our discord server showing each new release.Quick Start Shut Down Docker your gateway:sudo docker compose down -v docker compose down -v Restart Gateway Start your gateway with the new version:sudo docker compose up -d docker compose up -d Release #3 Note Effective with Release #3, it is no longer required to include the --build flag when starting your gateway. Docker will automatically build using the
image specified in the docker-compose.yaml file.Detailed Upgrade Process Full Upgrade Process Shut Down Docker your gateway:sudo docker compose down -v docker compose down -v Check for New Environment Variables Read the update release change logs and community announcements to see if the new version includes any new environmental variables that you should set before restarting your gateway.Restart the Gateway Start your gateway with the new version:sudo docker compose up -d docker compose up -d Release #3 Note Effective with Release #3, it is no longer required to include the --build flag when starting your gateway. Docker will automatically build using the
image specified in the docker-compose.yaml file.Docker Pruning (Optional) It's a good practice to clean up unused Docker resources after shutting down your gateway.Shut Down Gateway First, your gateway:sudo docker compose down -v docker compose down -v Prune Docker System Clean up unused Docker resources:sudo docker system prune docker system prune Restart Gateway Start your gateway:sudo docker compose up -d docker compose up -d Checking for New Environment Variables New gateway releases may introduce new environment variables that you need to configure.Review Release Notes Check the release notes and community announcements for any new environment variables:Review the GitHub releases Check the AR.IO Discord for announcements Look for changes in the .env.example file Update Your.env File Add any new environment variables to your .env file:# Example: Add new environment variables
NEW_FEATURE_ENABLED=true
NEW_CONFIG_VALUE=default_value Restart Gateway Restart your gateway to apply the new environment variables:sudo docker compose up -d docker compose up -d That's it! Your AR.IO Gateway is now upgraded to the latest version. Ensure to test and verify that everything is functioning as expected. If you encounter any issues, reach out to the AR.IO community for assistance.How is this guide?Manage your Gateway Comprehensive guides for advanced AR.IO Gateway operations including monitoring, optimization, content moderation, and specialized configurations Automating SSL Certificate Renewal Step-by-step guide to configure Certbot with automatic SSL certificate renewal using DNS API for AR.IO Gateway On this page Prerequisites Checking your Release Number Quick Start Pull Latest Changes Shut Down Docker Restart Gateway Detailed Upgrade Process Full Upgrade Process Pull Latest Changes Shut Down Docker Check for New Environment Variables Restart the Gateway Docker Pruning (Optional) Shut Down Gateway Prune Docker System Restart Gateway Checking for New Environment Variables Review Release Notes Update Your.env File Restart Gateway

---

# 30. Run a Gateway  ARIO Documentation

Document Number: 30
Source: https://docs.ar.io/build/run-a-gateway
Words: 332
Quality Score: 0.502
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Join the decentralized network that powers permanent data access. Run your own AR.IO Gateway to support the permaweb infrastructure and earn rewards.Gateway Options Choose the deployment approach that fits your needs - from local testing to production infrastructure.Production Gateway Earn Rewards Join the AR.IO Network and earn ARIO tokens Earn ARIO token rewards Serve Wayfinder traffic Cache and serve Arweave data Local Gateway Perfect for development and testing Quick Docker setup Test gateway features No commitment required Custom Configuration Optimize for specific use cases • Data filtering options • Performance tuning • Advanced features Why Run a Gateway?Economic Benefits Earn ARIO tokens through network participation Set custom pricing for premium services Build sustainable infrastructure business Technical Advantages Full control over data access and caching Custom configuration for your applications Direct integration with your services Network Impact Support decentralized web infrastructure Increase network reliability and redundancy Enable censorship-resistant data access Quick Start in 30 Seconds Get a gateway running locally with a single command:# Prerequisites: Docker installed on your system
docker run -p 4000:4000 ghcr.io/ar-io/ar-io-core:latest Test your gateway:# Fetch a transaction
curl localhost:4000/4jBV3ofWh41KhuTs2pFvj-KBZWUkbrbCYlJH0vLA6LM Your gateway is now serving Arweave data! This local setup is perfect for:Testing gateway functionality Developing applications Understanding gateway operations Complete Setup Guide Full instructions for production deployment Join the Network Stake tokens and earn rewards Learn Before You Build Understanding gateways helps you make informed infrastructure decisions.What Are Gateways?Core concepts and architecture Gateway Benefits Economic and technical advantages Network Overview How the AR.IO Network operates Ready to Deploy?Whether you're exploring gateway capabilities or ready to join the network, we have resources to help:Documentation Technical specs and configuration Community Support Get help in our Discord Gateway Dashboard Monitor network gateways How is this guide?Wayfinder Use AR.IO Wayfinder for decentralized content discovery and optimized data access Installation & Setup Get started running AR.IO gateway using Docker - minimal setup, maximum results On this page Gateway Options Why Run a Gateway?Quick Start in 30 Seconds Learn Before You Build Ready to Deploy?

---

# 31. Fetch Data (via REST API)  ARIO Documentation

Document Number: 31
Source: https://docs.ar.io/build/access/fetch-data
Words: 360
Quality Score: 0.501
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Access Data The simplest way to access data on Arweave is through HTTP requests to gateways. This method works in any web browser and requires no additional setup.Fetching Data from Gateways Gateways are the most performant way to fetch data from Arweave, providing significant advantages over accessing Arweave nodes directly.Why Gateways Are Faster:Content Caching - Pre-cached data for instant retrieval Data Indexing - Fast search and query capabilities Network Optimization - Distributed infrastructure for better performance Content Delivery - Optimized serving with compression and CDN features REST APIs for Fetching Data Gateways support multiple API endpoints for accessing data:Standard Endpoint Access any transaction using this URL structure:https:/// Examples:https://arweave.net/bVLEkL1SOPFCzIYi8T_QNnh17VlDp4RylU6YTwCMVRw https://permagate.io/FguFk5eSth0wO8SKfziYshkSxeIYe7oK9zoPN2PhSc0 Raw Data Endpoint For raw data access that bypasses manifest path resolution:https:///raw/ This endpoint returns the raw data bytes without resolving manifest paths, useful when you need the exact stored data.Sandboxing AR.IO gateways implement security measures by redirecting requests to sandbox subdomains for enhanced browser security.Why Redirects Happen:Security Isolation - Content is served from isolated sandbox environments CSP Protection - Prevents cross-site scripting attacks Resource Isolation - Limits potential security vulnerabilities Browser Sandboxing - Leverages same-origin policy for enhanced security What to Expect:Initial request: https://arweave.net/transaction-id Redirects to: https://sandbox.arweave.net/transaction-id (or similar) Final content served from sandbox subdomain Important: Always follow redirects in your applications - the final sandbox URL contains the actual content.Using in Applications JavaScript Example with Fetch:// Fetch data from Arweave (follows redirects automatically)
const response = await fetch("https://arweave.net/your-transaction-id", {
redirect: "follow", // Follow redirects automatically
});
if (!response.ok) {
throw new Error(`HTTP error! status: ${response.status}`);
}
const data = await response.text();
console.log(data);HTML Example:
Manifests For organized file collections, use manifests to create friendly path-based URLs:https://arweave.net//path/to/file Example:https://arweave.net/X8Qm…AOhA/index.html https://arweave.net/X8Qm…AOhA/styles.css https://arweave.net/X8Qm…AOhA/assets/logo.png Next Steps Find Data via GraphQL Discover data by searching with tags, metadata, and filters.Run Your Own Gateway Set up a gateway to serve and cache your specific data.Upload Data with Turbo Start uploading your data to Arweave's permanent storage.Use Wayfinder for Smart Routing Automatically route requests to the best performing gateway.How is this guide?Access Data Learn how to retrieve and query data from Arweave's permanent storage network Find Data (via GraphQL) Search and discover data on Arweave using GraphQL queries

---

# 32. Getting Started with Turbo  ARIO Documentation

Document Number: 32
Source: https://docs.ar.io/build/upload/bundling-services
Words: 552
Quality Score: 0.498
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Upload Data Upload data to Arweave using Turbo - the most reliable way to upload data to Arweave. Turbo provides enterprise-grade infrastructure with flexible payment options and optimized performance.What is Turbo?Turbo is a ultrahigh-throughput Permaweb service that streamlines the funding, indexing, and transmission of data to and from Arweave. It provides graphical and programmatic interfaces for payment options in fiat currency with credit or debit cards as well as cryptocurrencies such as ETH, SOL, USDC, and AR. It integrates two key components: a service that bundles uploads for efficiency and ease, and a payment system designed for straightforward transactions. Turbo Credits, which users can purchase within the ArDrive web app, the Turbo Top Up App, or by using the Turbo SDK/CLI, have the same storage purchasing power of AR tokens, along with the additional benefits provided by Turbo. These credits are meticulously calibrated, with the Winston Credit (winc) representing the smallest unit, ensuring users have precise control over their storage needs. As an open-source technology, Turbo encourages community engagement, allowing developers to contribute to its continuous enhancement.Get Started Install the SDK npm install @ardrive/turbo-sdk Set Up Your Wallet Create a new wallet or use an existing one:# Create a new wallet (easy way)
npx permaweb/wallet > key.json Then load it in your code:import { TurboFactory, ArweaveSigner } from "@ardrive/turbo-sdk";
import fs from "fs";
// Load your wallet
const jwk = JSON.parse(fs.readFileSync("./key.json", "utf-8"));
const signer = new ArweaveSigner(jwk);
// Initialize Turbo
const turbo = TurboFactory.authenticated({ signer });Get Turbo Credits Purchase Turbo Credits to pay for uploads. When you upload, credits are automatically used and Turbo handles the payment to Arweave.Option 1: Via the Web Interface Go to turbo-topup.com Pay with fiat currencies (credit cards) or crypto tokens (ARIO, USDC, SOL, MATIC, AR) Option 2: Via the SDK // Purchase credits programmatically
const fundResult = await turbo.topUpWithTokens({
tokenAmount: TOKEN_AMOUNT,
tokenType: "solana", // or 'ethereum', 'matic', 'arweave'
});Check Your Balance const balance = await turbo.getBalance();
console.log(`Balance: ${balance.winc} Winston Credits`);Upload Your Data const fileData = fs.readFileSync("./myfile.jpg");
const result = await turbo.upload({
data: fileData,
dataItemOpts: {
tags: [
{ name: "Content-Type", value: "image/jpeg" },
{ name: "Title", value: "My Image" },
],
},
});
console.log("Upload ID:", result.id);
console.log("Owner:", result.owner);Advanced Features Turbo Credits System Learn about our flexible payment system that supports multiple currencies and payment methods.→ Understanding Turbo Credits Data Organization Tagging - Organize your data with metadata Manifests - Create folder structures and bundles Encryption - Secure your sensitive data ArFS - File system protocol for structured storage Production Ready Turbo implements the ANS-104 bundling specification, providing enterprise-grade infrastructure for permanent data storage.Feature Turbo Bundling Alternative Options Payment Options Fiat, ARIO, USDC, SOL, MATIC, AR AR tokens only Implementation Simple SDK integration Manual transaction handling Performance Optimized bundling & retry logic Depends on implementation Reliability Built-in redundancy Manual error handling Cost Optimized for large uploads Higher per-transaction costs Setup Complexity Easy with SDK Complex protocol knowledge Ready to Get Started?Launch Turbo Start building with Turbo's powerful bundling service.Turbo SDK Documentation Explore the full SDK documentation and examples.Learn About Tagging Organize your data with metadata and tags.How is this guide?Upload Data Start uploading to Arweave's permanent storage network with our recommended tools and best practices Advanced Uploading with Turbo Learn how to upload data to Arweave using the Turbo SDK, including authentication, purchasing credits, and file uploads

---

# 33. Payments  ARIO Documentation

Document Number: 33
Source: https://docs.ar.io/apis/turbo/payment-service/payments
Words: 392
Quality Score: 0.496
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Turbo Payment Service Payment processing and top-up operations Get Top Up Quote for Credits Get a top up quote and payment session for a given method (payment-intent or checkout-session), destination address, currency type, and payment amount Path Parameters method string address string Destination wallet address currency string Currency type for a given payment amount amount integer Payment amount in a given currency's smallest unit value. For example, $10 USD is 1000. 1 AR is 1000000000000 Query Parameters promoCode?string Comma-separated list of promo codes uiMode?string Which UI Mode to create the checkout session in Default "hosted" returnUrl?string The URL to return to after a successful payment Default "https://app.ardrive.io" successUrl?string The URL to return to after a successful payment Default "https://app.ardrive.io" cancelUrl?string The URL to return to after a canceled payment Default "https://app.ardrive.io" Header Parameters x-signature?string The signature value derived from signing the request's data concatenated with the provided nonce using the private key from the provided public key x-nonce?string The nonce value concatenated with the request's data when deriving the provided the signature Response Body Post a pending payment transaction Post a transaction ID that has been sent to the payment service's wallet Path Parameters token string Token type for a given transaction Request Body JSON with tx_id key of the pending payment transaction tx_id?string The transaction ID of the pending payment transaction Response Body curl -X POST "https://loading/v1/account/balance/arweave" \
-H "Content-Type: application/json" \
-d '{}' {
"message": "Transaction credited",
"creditedTransaction": {
"allOf": {
"transactionId": "string",
"transactionQuantity": 0,
"createdAt": "string",
"tokenType": "arweave",
"destinationAddress": "abcdefghijklmnopqrxtuvwxyz123456789ABCDEFGH",
"destinationAddressType": "arweave",
"winstonCreditAmount": "332824926",
"adjustments": [
{
"name": "Adjustment",
"description": "Some great subsidy",
"operatorMagnitude": "0.6",
"operator": "multiply",
"adjustmentAmount": "-12300",
"promoCode": "SOME-GREAT-CODE"
}
]
},
"blockHeight": 0,
"creditedAt": "string"
}
} {
"message": "Transaction pending",
"pendingTransaction": {
"transactionId": "string",
"transactionQuantity": 0,
"createdAt": "string",
"tokenType": "arweave",
"destinationAddress": "abcdefghijklmnopqrxtuvwxyz123456789ABCDEFGH",
"destinationAddressType": "arweave",
"winstonCreditAmount": "332824926",
"adjustments": [
{
"name": "Adjustment",
"description": "Some great subsidy",
"operatorMagnitude": "0.6",
"operator": "multiply",
"adjustmentAmount": "-12300",
"promoCode": "SOME-GREAT-CODE"
}
]
}
} {
"message": "Transaction has already failed!",
"failedTransaction": {
"allOf": {
"transactionId": "string",
"transactionQuantity": 0,
"createdAt": "string",
"tokenType": "arweave",
"destinationAddress": "abcdefghijklmnopqrxtuvwxyz123456789ABCDEFGH",
"destinationAddressType": "arweave",
"winstonCreditAmount": "332824926",
"adjustments": [
{
"name": "Adjustment",
"description": "Some great subsidy",
"operatorMagnitude": "0.6",
"operator": "multiply",
"adjustmentAmount": "-12300",
"promoCode": "SOME-GREAT-CODE"
}
]
},
"failedAt": "string",
"failureReason": "string"
}
} "Transaction ID not found!" "Error while processing transaction!" How is this guide?Balance GET Previous Page Pricing Next Page

---

# 34. Logging  ARIO Documentation

Document Number: 34
Source: https://docs.ar.io/sdks/turbo-sdk/logging
Words: 52
Quality Score: 0.494
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Turbo SDK The SDK uses winston for logging. You can set the log level using the setLogLevel method.TurboFactory.setLogLevel('debug');How is this guide?Events SDK for interacting with Turbo, a fast and efficient data upload service for Arweave Turbo Credit Sharing SDK for interacting with Turbo, a fast and efficient data upload service for Arweave

---

# 35. Arweave Name System (ArNS)  ARIO Documentation

Document Number: 35
Source: https://docs.ar.io/build/access/arns
Words: 386
Quality Score: 0.493
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Access Data ArNS provides human-readable URLs for your Arweave data, making it easy to share and remember permanent addresses.What is ArNS?ArNS is a naming system that allows you to register human-readable names that point to your Arweave transactions. Instead of sharing long transaction IDs, you can use memorable URLs.Example:Before:https://arweave.net/bVLEkL1SOPFCzIYi8T_QNnh17VlDp4RylU6YTwCMVRw After:https://myapp.arweave.net Get an ArNS Name The easiest way to get an ArNS name is via arns.ar.io, which supports multiple payment methods:Fiat payments - Credit cards and bank transfers Turbo Credits - Use existing Turbo credits ARIO tokens - Pay with ARIO cryptocurrency Alternative registration methods:Wander Chrome Extension - Browser-based registration Wander Mobile App - Register on iOS and Android AR.IO SDK - Programmatic registration using the buyRecord API Using the AR.IO SDK For developers, you can register ArNS names programmatically:import { ARIO } from '@ar.io/sdk';
const ario = ARIO.mainnet();
// Buy a record with Turbo Credits or ARIO tokens
const result = await ario.buyRecord({
name: 'my-domain',
years: 1,
// Payment method: 'turbo-credits' or 'ario-tokens'
});
console.log('Record purchased:', result);Fetching Data via ArNS Once you've set up your ArNS name, fetch data using standard HTTP requests:// Fetch content from your ArNS name
const response = await fetch("https://my-data.arweave.net");
if (!response.ok) {
throw new Error(`HTTP error! status: ${response.status}`);
}
const data = await response.text();
console.log(data);Why Use ArNS?ArNS provides significant advantages for accessing data on Arweave:Decentralized Data Index ArNS creates a decentralized index of data accessible through any gateway in the AR.IO network No single point of failure - names resolve across all participating gateways Censorship-resistant access to your content Flexible Data Management Permanent references - Keep stable URLs even when updating underlying data Replaceable data - Point names to new transaction IDs as content evolves Undernames - Organize related content under a single name using underscores (e.g., v2_myapp.arweave.net, docs_myapp.arweave.net) Supporting Network Decentralization ArNS purchases contribute to the protocol balance Fees reward AR.IO gateway operators for participating in the network This economic model preserves decentralized access to data on Arweave Your name registration helps maintain the infrastructure that serves your content Next Steps How is this guide?Find Data (via GraphQL) Search and discover data on Arweave using GraphQL queries Wayfinder Use AR.IO Wayfinder for decentralized content discovery and optimized data access On this page What is ArNS?Get an ArNS Name Using the AR.IO SDK Fetching Data via ArNS Why Use ArNS?Next Steps

---

# 36. Entity Types  ARIO Documentation

Document Number: 36
Source: https://docs.ar.io/build/advanced/arfs/entity-types
Words: 1465
Quality Score: 0.493
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Advanced ArFS Protocol Overview Arweave transactions provide for a separation between data and metadata about that data via the use of headers. Key-value tags in the headers provide for expressive description about the data as well as searchability via gateway GraphQL APIs.ArFS adds an additional layer of separation between data and metadata by using separate transactions for ArFS metadata and, where applicable, ArFS file data. But it also makes use of tags and data separation within an ArFS metadata transaction by including data critical to tracking drive composition in the tags space of ArFS metadata transactions and having most of the other metadata encoded as JSON in the data body of the metadata transaction. In the case of private entities, JSON data and file data payloads are always encrypted according to the protocol processes defined below.Drive entities require a single metadata transaction, with standard Drive tags and encoded JSON with secondary metadata.Folder entities require a single metadata transaction, with standard Folder tags and an encoded JSON with secondary metadata.File entities require a metadata transaction, with standard File tags and an encoded Data JSON with secondary metadata relating to the file.File entities also require a second data transaction, which includes a limited set of File tags and the actual file data itself.Snapshot entities require a single transaction, which contains a Data JSON with all of the Drive's rolled up ArFS metadata and standard Snapshot GQL tags that identify the Snapshot.ArFS v0.14 introduces the isHidden property. isHidden is a boolean (true/false) that tells clients if they should dis the file or folder. Hidden files still exist and will be included in snapshots, but should not be rendered by clients. If isHidden is not present, its value should be assumed false.ArFS v0.15 introduces the Signature-Type metadata property on Drive entities, and a new entity type DriveSignature.Drive A drive is the highest level logical grouping of folders and files. All folders and files must be part of a drive, and reference the Drive ID of that drive.When creating a Drive, a corresponding "root" folder must be created as well. This separation of drive and folder entity enables features such as folder view queries, renaming, and linking. Drive-Signature ArFS versions prior to v0.15 applied encryption to drive contents with a signing scheme that, while secure, is now deprecated in modern Arweave software wallets. ArFS v0.15 introduces an updated signing scheme compatible with these wallets and as well as "Drive Signatures", a new entity type to help bridge the signature derivation schemes across ArFS versions.A drive signature uses the v0.15 encryption scheme to encrypt and store the pre-v0.15 wallet signature for a private drive that is necessary for deriving the "drive key" for that drive. This allows for continued access of historical drive contents into the future.ArFS: "0.15",
Entity-Type: "drive-signature",
Signature-Format: "1",
Cipher?: "AES256-GCM",
Cipher-IV: "<12 byte initialization vector as Base64>"
{data: } The encrypted "type 1" signature for the drive must be provided in the data field of the transaction creating the drive-signature entity.Folder A folder is a logical grouping of other folders and files. Folder entity metadata transactions without a parent folder id are considered the Drive Root Folder of their corresponding Drives. All other Folder entities must have a parent folder id. Since folders do not have underlying data, there is no Folder data transaction required.ArFS: "0.15",
Cipher?: "AES256-GCM",
Cipher-IV?: "<12 byte initialization vector as Base64>",
Content-Type: "",
Drive-Id: "",
Entity-Type: "folder",
Folder-Id: "",
Parent-Folder-Id?: "",
Unix-Time: ""
Metadata JSON {
"name": "",
"isHidden": false
} File A File contains uploaded data, like a photo, document, or movie.In the Arweave File System, a single file is broken into 2 parts - its metadata and its data.A File entity metadata transaction does not include the actual File data. Instead, the File data must be uploaded as a separate transaction, called the File Data Transaction. The File JSON metadata transaction contains a reference to the File Data Transaction ID so that it can retrieve the actual data. This separation allows for file metadata to be updated without requiring the file itself to be reuploaded. It also ensures that private files can have their JSON Metadata Transaction encrypted as well, ensuring that no one without authorization can see either the file or its metadata.ArFS: "0.15",
Cipher?: "AES256-GCM",
Cipher-IV?: "<12 byte initialization vector as Base64>",
Content-Type: "",
Drive-Id: "",
Entity-Type: "file",
File-Id: "",
Parent-Folder-Id: "",
Unix-Time: ""
Metadata JSON {
"name": "",
"size": ,
"lastModifiedDate": ,
"dataTxId": "",
"dataContentType": "",
"isHidden": false,
"pinnedDataOwner": "", # Optional
} Pinning Files Since the version v0.13, ArFS supports Pins. Pins are files whose data may be any transaction uploaded to Arweave, that may or may not be owned by the wallet that created the pin.When a new File Pin is created, the only created transaction is the Metadata Transaction. The dataTxId field will point it to any transaction in Arweave, and the optional pinnedDataOwner field is gonna hold the address of the wallet that owns the original copy of the data transaction.File Data Transaction Example The File Data Transaction contains limited information about the file, such as the information required to decrypt it, or the Content-Type (mime-type) needed to view in the browser.Cipher?: "AES256-GCM",
Cipher-IV?: "<12 byte initialization vector as Base64>",
Content-Type: "",
{ File Data - Encrypted if private } File Metadata Transaction Example The File Metadata Transaction contains the GQL Tags necessary to identify the file within a drive and folder.Its data contains the JSON metadata for the file. This includes the file name, size, last modified date, data transaction id, and data content type.ArFS: "0.15",
Cipher?: "AES256-GCM",
Cipher-IV?: "<12 byte initialization vector as Base64>",
Content-Type: "",
Drive-Id: "",
Entity-Type: "file",
File-Id: "",
Parent-Folder-Id: "",
Unix-Time: "",
{ File JSON Metadata - Encrypted if private } Snapshot ArFS applications generate the latest state of a drive by querying for all ArFS transactions made relating to a user's particular Drive-Id. This includes both paged queries for indexed ArFS data via GQL, as well as the ArFS JSON metadata entries for each ArFS transaction.For small drives (less than 1000 files), a few thousand requests for very small s of data can be achieved relatively quickly and reliably. For larger drives, however, this results in long sync times to pull every piece of ArFS metadata when the local database cache is empty. This can also potentially trigger rate-limiting related ArWeave Gateway delays.Once a drive state has been completely, and accurately generated, in can be rolled up into a single snapshot and uploaded as an Arweave transaction. ArFS clients can use GQL to find and retrieve this snapshot in order to rapidly reconstitute the total state of the drive, or a large portion of it. They can then query individual transactions performed after the snapshot.This optional method offers convenience and resource efficiency when building the drive state, at the cost of paying for uploading the snapshot data. Using this method means a client will only have to iterate through a few snapshots instead of every transaction performed on the drive.Snapshot Entity Tags Snapshot entities require the following tags. These are queried by ArFS clients to find drive snapshots, organize them together with any other transactions not included within them, and build the latest state of the drive.ArFS: "0.15",
Drive-Id: "",
Entity-Type: "snapshot",
Snapshot-Id: "",
Content-Type: "",
Block-Start: "",
Block-End: "",
Data-Start: "" Snapshot Entity Data A JSON data object must also be uploaded with every ArFS Snapshot entity. This data contains all ArFS Drive, Folder, and File metadata changes within the associated drive, as well as any previous Snapshots. The Snapshot Data contains an array txSnapshots. Each item includes both the GQL and ArFS metadata details of each transaction made for the associated drive, within the snapshot's start and end period.A tsSnapshot contains a gqlNode object which uses the same GQL tags interface returned by the Arweave Gateway. It includes all of the important block, owner, tags, and bundledIn information needed by ArFS clients. It also contains a dataJson object which stores the correlated Data JSON for that ArFS entity.For private drives, the dataJson object contains the JSON-string-escaped encrypted text of the associated file or folder. This encrypted text uses the file's existing Cipher and Cipher-IV. This ensures clients can decrypt this information quickly using the existing ArFS privacy protocols. Schema Diagrams The following diagrams show complete examples of Drive, Folder, and File entity Schemas.Public Drive Private Drive Next Steps Now that you understand the different ArFS entity types, explore how they work together:Data Model - Learn how entities relate to each other Privacy & Encryption - Understand how private entities work Creating Drives - Start building with ArFS How is this guide?ArFS Protocol A decentralized file system on Arweave for structured data storage and retrieval Data Model Understanding how ArFS organizes data hierarchically using entity relationships

---

# 37. Automating SSL Certificate Renewal  ARIO Documentation

Document Number: 37
Source: https://docs.ar.io/build/run-a-gateway/manage/ssl-certs
Words: 883
Quality Score: 0.492
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Run a Gateway Manage your Gateway Secure your AR.IO Gateway with automated SSL certificate renewal using Certbot and DNS challenge validation. This guide covers setup for different DNS providers to automatically renew certificates without manual intervention.Overview Using DNS challenge validation with Certbot allows you to:Automatically renew SSL certificates Support wildcard certificates Avoid manual certificate management Ensure continuous gateway security Prerequisites A running AR.IO Gateway Domain name configured with your DNS provider Administrative access to your server API access to your DNS provider DNS Provider Setup Cloudflare Configuration Create Cloudflare API Token Navigate to Cloudflare → My Profile → API Tokens → Create Token Configure the token with these permissions:Zone → Zone → Read Zone → DNS → Edit Install Certbot and Cloudflare Plugin apt update
apt install certbot python3-certbot-dns-cloudflare -y Configure API Credentials Create the credentials file:nano /etc/letsencrypt/cloudflare.ini Add your API token:dns_cloudflare_api_token = your_api_token_here Secure the file:chmod 600 /etc/letsencrypt/cloudflare.ini Generate SSL Certificate Request the certificate with wildcard support:certbot certonly --dns-cloudflare \
--dns-cloudflare-credentials /etc/letsencrypt/cloudflare.ini \
-d example.com -d *.example.com Expected output:Successfully received certificate.
Certificate is saved at: /etc/letsencrypt/live/example.com/fullchain.pem
Key is saved at: /etc/letsencrypt/live/example.com/privkey.pem Test Automatic Renewal Perform a dry run to validate the renewal process:certbot renew --dry-run Expected output:Saving debug log to /var/log/letsencrypt/letsencrypt.log
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
Processing /etc/letsencrypt/renewal/example.com.conf
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
Account registered.
Simulating renewal of an existing certificate for example.com and *.example.com
Waiting 10 seconds for DNS changes to propagate
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
Congratulations, all simulated renewals succeeded:
/etc/letsencrypt/live/example.com/fullchain.pem (success) Verify Automatic Renewal Timer Check that the certbot timer is active:systemctl list-timers | grep certbot Expected output:Tue 2024-11-05 02:22:10 UTC 3h 21min Mon 2024-11-04 17:16:51 UTC 5h 43min ago certbot.timer certbot.service Namecheap Configuration API Requirements: Namecheap requires specific conditions to create API keys:At least 20 domains under your account Minimum $50 account balance At least $50 spent within the last 2 years If you don't meet these requirements, contact Namecheap support for a waiver.Install Certbot and Dependencies apt update
apt install certbot python3-pip -y Install the Namecheap DNS plugin:pip install certbot-dns-namecheap Configure API Credentials Create the credentials file:nano /etc/letsencrypt/namecheap.ini Add your API credentials:dns_namecheap_username = your_username
dns_namecheap_api_key = your_api_key Secure the file:chmod 600 /etc/letsencrypt/namecheap.ini Generate SSL Certificate Request the certificate with wildcard support:certbot certonly --dns-namecheap \
--dns-namecheap-credentials /etc/letsencrypt/namecheap.ini \
-d example.com -d *.example.com Expected output:Successfully received certificate.
Certificate is saved at: /etc/letsencrypt/live/example.com/fullchain.pem
Key is saved at: /etc/letsencrypt/live/example.com/privkey.pem Test Automatic Renewal Perform a dry run to validate the renewal process:certbot renew --dry-run Expected output:Saving debug log to /var/log/letsencrypt/letsencrypt.log
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
Processing /etc/letsencrypt/renewal/example.com.conf
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
Account registered.
Simulating renewal of an existing certificate for example.com and *.example.com
Waiting 10 seconds for DNS changes to propagate
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
Congratulations, all simulated renewals succeeded:
/etc/letsencrypt/live/example.com/fullchain.pem (success) Verify Automatic Renewal Timer Check that the certbot timer is active:systemctl list-timers | grep certbot Expected output:Tue 2024-11-05 02:22:10 UTC 3h 21min Mon 2024-11-04 17:16:51 UTC 5h 43min ago certbot.timer certbot.service Post-Installation Steps After successfully setting up automatic SSL renewal:Update Gateway Configuration Configure your AR.IO Gateway to use the new certificates. Update your gateway's SSL configuration to point to:Certificate:/etc/letsencrypt/live/your-domain.com/fullchain.pem Private Key:/etc/letsencrypt/live/your-domain.com/privkey.pem Reload Web Server (Optional) If you're using nginx or another web server, reload it to apply the new certificates:systemctl reload nginx Monitor Renewal Process Certbot automatically sets up a systemd timer for renewal. Certificates will be renewed when they have 30 days or less remaining.To manually check renewal status:certbot certificates Troubleshooting Common Issues DNS propagation delays: Wait 5-10 minutes for DNS changes to propagate API rate limits: Check your DNS provider's API rate limits Permission errors: Ensure credential files have correct permissions (600) Logs and Debugging Check certbot logs for detailed error information:tail -f /var/log/letsencrypt/letsencrypt.log Next Steps With SSL certificates automated, consider:Setting up monitoring to track certificate expiration Configuring gateway filters for optimal performance Implementing content moderation policies How is this guide?Upgrading your Gateway Step-by-step guide to upgrading your AR.IO Gateway to the latest version safely without losing data or progress Gateway Filters Comprehensive guide to configuring AR.IO Gateway filters for efficient data processing and indexing

---

# 38. Reading Data  ARIO Documentation

Document Number: 38
Source: https://docs.ar.io/build/advanced/arfs/reading-data
Words: 1020
Quality Score: 0.488
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Advanced ArFS Protocol Clients can perform read operations to create a timeline of entity write transactions which can then be reed to construct the Drive state. This is done by querying an Arweave GraphQL index for the user's respective transactions. Arweave GraphQL Guide can provide more information on how to use Arweave GraphQL. If no GraphQL index is available, drive state can only be generated by downloading and inspecting all transactions made by the user's wallet.This timeline of transactions should be grouped by the block number of each transaction. At every step of the timeline, the client can check if the entity was written by an authorized user. This also conveniently enables the client to surface a trusted entity version history to the user.To determine the owner of a Drive, clients must check for who created the first Drive Entity transaction using that Drive-Id. Until a trusted permissions or ACL system is put in place, any transaction in a drive created by any wallet other than the one who created the first Drive Entity transaction could be considered spam.The Unix-Time defined on each transaction should be reserved for tie-breaking same entity updates in the same block and should not be trusted as the source of truth for entity write ordering. This is unimportant for single owner drives but is crucial for multi-owner drives with updateable permissions (currently undefined in this spec) as a malicious user could fake the Unix-Time to modify the drive timeline for other users.Drives that have been updated many times can have a long entity timeline which can be a performance bottleneck. To avoid this, clients can cache the drive state locally and sync updates to the file system by only querying for entities in blocks higher than the last time they checked.Not checking for Drive Ownership could result in seeing incorrect drive state and GraphQL queries.Folder/File Paths ArweaveFS does not store folder or file paths along with entities as these paths will need to be updated whenever the parent folder name changes which can require many updates for deeply nested file systems. Instead, folder/file paths are left for the client to generate from the folder/file names.Folder View Queries Clients that want to provide users with a quick view of a single folder can simply query for an entity timeline for a particular folder by its id. Clients with multi-owner permissions will additionally have to query for the folder's parent drive entity for permission based filtering of the timeline.Basic Query Patterns Query All Drive Entities query {
transactions(
tags: [
{ name: "ArFS", values: ["0.15"] }
{ name: "Entity-Type", values: ["drive"] }
{ name: "Drive-Id", values: ["your-drive-id"] }
]
) {
edges {
node {
id
block {
height
timestamp
}
tags {
name
value
}
}
}
}
} Query Folder Contents query ($parentFolderId: String!) {
transactions(
tags: [
{ name: "ArFS", values: ["0.15"] }
{ name: "Parent-Folder-Id", values: [$parentFolderId] }
]
) {
edges {
node {
id
block {
height
timestamp
}
tags {
name
value
}
}
}
}
} Query File Entities query ($fileId: String!) {
transactions(
tags: [
{ name: "ArFS", values: ["0.15"] }
{ name: "Entity-Type", values: ["file"] }
{ name: "File-Id", values: [$fileId] }
]
) {
edges {
node {
id
block {
height
timestamp
}
tags {
name
value
}
}
}
}
} Building Drive State The process of building drive state involves several steps:Step-by-Step Process Query for all entities associated with a specific Drive-Id Sort by block height to establish chronological order Process entities bottom-up starting with files and folders Build the hierarchy by following parent-child relationships Handle conflicts by using the most recent entity version Example Implementation async function buildDriveState(driveId) {
// Query all entities for the drive
const entities = await queryDriveEntities(driveId);
// Sort by block height
entities.sort((a, b) => a.block.height - b.block.height);
// Process entities
const driveState = {
drive: null,
folders: new Map(),
files: new Map(),
};
for (const entity of entities) {
const entityType = getTagValue(entity.tags, "Entity-Type");
switch (entityType) {
case "drive":
driveState.drive = processDriveEntity(entity);
break;
case "folder":
driveState.folders.set(
getTagValue(entity.tags, "Folder-Id"),
processFolderEntity(entity)
);
break;
case "file":
driveState.files.set(
getTagValue(entity.tags, "File-Id"),
processFileEntity(entity)
);
break;
}
}
return driveState;
} Using Snapshots For large drives, snapshots can significantly improve performance:Snapshot Query query ($driveId: String!) {
transactions(
tags: [
{ name: "ArFS", values: ["0.15"] }
{ name: "Entity-Type", values: ["snapshot"] }
{ name: "Drive-Id", values: [$driveId] }
]
sort: HEIGHT_DESC
first: 1
) {
edges {
node {
id
block {
height
timestamp
}
tags {
name
value
}
}
}
}
} Performance Optimization Caching Strategies Local caching - Store frequently accessed data locally Incremental updates - Only fetch new transactions since last sync Snapshot usage - Use snapshots for large drives Batch queries - Combine multiple queries when possible Query Optimization Use specific tags - Narrow down queries with relevant tags Limit results - Use pagination for large result sets Filter by date - Query specific time ranges Index utilization - Leverage GraphQL indexes effectively Error Handling Common Issues Network timeouts - Implement retry logic Invalid data - Validate entity structure Missing entities - Handle incomplete data gracefully Decryption errors - Proper error handling for private data Best Practices Validate ownership - Check drive ownership before processing Handle conflicts - Resolve entity version conflicts Graceful degradation - Provide fallbacks for missing data User feedback - Inform users of sync status Security Considerations Data Validation Verify signatures - Check transaction signatures Validate ownership - Ensure drive ownership Check timestamps - Validate entity timestamps Sanitize data - Clean user-provided data Privacy Protection Decrypt carefully - Handle private data securely Key management - Protect encryption keys Access control - Implement proper permissions Audit logging - Track data access Next Steps Now that you understand how to read ArFS data, explore these related topics:Privacy & Encryption - Secure your data with private drives Upgrading Private Drives - Update legacy drives to v0.15 Creating Drives - Start building with ArFS How is this guide?Creating Drives Learn how to create ArFS drives, folders, and files Upgrading Private Drives Learn how to upgrade legacy private drives to ArFS v0.15

---

# 39. Pricing Model  ARIO Documentation

Document Number: 39
Source: https://docs.ar.io/learn/arns/pricing-model
Words: 1071
Quality Score: 0.486
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Arweave Name System (ArNS)Pricing ModelCopy MarkdownOpenAddressing Variable Market Conditions
The future market landscape is unpredictable, and the AR.IO Network smart contract is designed to be immutable, operating without governance or manual intervention. Using a pricing oracle to fix name prices relative to a stable currency is not viable due to the infancy of available solutions and reliance on external dependencies.
To address these challenges, ArNS is self-contained and adaptive, with name prices reflecting network activity and market conditions over time.
To achieve this, ArNS incorporates:
A dynamic pricing model that adjusts fees using a "Demand Factor" based on ArNS purchase activity
A Returned Name Premium (RNP) system that applies a timed, descending multiplier to registration prices for names that have recently expired or been returned to the protocol
This approach ensures that name valuations adapt to market conditions within the constraints of an immutable, maintenance-free smart contract framework.
You can view current live pricing at ArNS.app to see these formulas in action.
Key Definitions
Protocol Revenue: Accumulated ARIO tokens from name registrations, lease extensions, and under_name sales
Period (P): The time unit for DF adjustments, equivalent to one (1) day, denoted in milliseconds
n: The current period indicator
Price: The cost for permabuy or lease of a name
Under_names: Subdomain equivalents, denoted by an underscore "_" prefixing the base domain
Dynamic Pricing Model
ArNS employs an adaptive pricing model to balance market demand with pricing fairness for name registration within the network. This model integrates static and dynamic elements, adjusting prices based on name length and purchase options like leasing, permanent acquisition, and undername amounts.
Core Pricing Components
Base Registration Fee (BRF)
The fundamental price for names, varying by character length, adjusted periodically.
Genesis Registration Fee (GRF)
The starting price for name registrations varies by character length. This is superseded by Base Registration Fees as the protocol evolves.
Table: Genesis Registration Fees
Name LengthFee (ARIO)11,000,0002200,000320,000410,00052,50061,50078008500940010350113001225013-51200
Demand Factor (DF)
A global price multiplier, reflecting namespace demand, adjusted each period based on revenue trends.
DF Mechanics:
Intent: The Demand Factor adjusts based on protocol revenue comparison to the Revenue Moving Average (RMA)
Increase DF: When recent revenue is higher than or equal to (but non-zero) the RMA, the DF increases by 5.0%
Decrease DF: When recent revenue is less than the RMA or both are zero, the DF decreases by 1.5%
Maximum DF Value: Unbounded
Minimum DF Value: 0.5
Starting Demand Factor: 1 (initial value at network launch)
Revenue Moving Average (RMA)
The average of protocol revenue from the past seven (7) periods.
Pricing Formulas
Adjusted Registration Fee (ARF)
ARF=BRF×DFARF = BRF × DF
ARF=BRF×DF
Annual Fee
Annual Fee=ARF×20Annual ~Fee = ARF × 20%
Annual Fee=ARF×20
Lease Pricing
Lease Registration Price:
Lease Price=ARF+(Annual Fee×Years)Lease ~Price = ARF + (Annual ~Fee × Years)
Lease Price=ARF+(Annual Fee×Years)
Lease Extension/Renewal Price:
Lease Renewal Price=Annual Fee×Years(max5years)Lease ~Renewal ~Price = Annual ~Fee × Years (max 5 years)
Lease Renewal Price=Annual Fee×Years(max5years)
Grace period: Two (2) weeks
Permanent Purchases
Permabuy Price:
Permabuy Price=ARF+(AnnualFee×20years)Permabuy ~Price = ARF + (Annual Fee × 20 years)
Permabuy Price=ARF+(AnnualFee×20years)
Lease to Permabuy Price: Same as above
Under Name Fees
Initial Allocation: 10 under_names are included with each name registration
For Leases:
Lease Under Name Fee=BRF×DF×0.1Lease ~Under ~Name ~Fee = BRF × DF × 0.1%
Lease Under Name Fee=BRF×DF×0.1
For Permabuys:
Permabuy Under Name Fee=BRF×DF×0.5Permabuy ~Under ~Name ~Fee = BRF × DF × 0.5%
Permabuy Under Name Fee=BRF×DF×0.5
Primary Name Fee
Set or change primary name: The fee is equal to the associated fee for a single under_name purchase of a 51-character name of equivalent purchase type to the new primary name, regardless of the new primary name's length.
Step Pricing Mechanics
Synchronizes BRF (Base Rate Factor) with ARF (Adjusted Rate Factor) after seven (7) consecutive periods at the minimum DF value
Resets DF to 1 following a step pricing adjustment
Returned Name Premiums (RNP)
ArNS applies a Returned Name Premium (RNP) to names that re-enter the market after expiration or permanent return. This premium starts at a maximum value and decreases linearly over a predefined window, ensuring fair and transparent pricing for re-registered names.
RNP Mechanics
Intent
The premium starts at its maximum and decreases linearly until the name is purchased. If the name is not purchased before the premium window closes, it reverts to standard pricing and is no longer classified as "recently returned."
RNP Window
Duration: Fourteen (14) periods
Returned Name Premium Formula
The premium multiplier follows a linearly declining function:
RNP=50−(49/14)×tRNP = 50 - (49 / 14) × t
RNP=50−(49/14)×t
Where:
RNP: The Returned Name Premium multiplier applied to the purchased name price
t: Amount of time (or time-intervals) elapsed since the start of the return window
RNP Registration Price
Price=RNP×(Lease Or Permabuy) Registration PricePrice = RNP × (Lease~Or~Permabuy) ~Registration~ Price
Price=RNP×(Lease Or Permabuy) Registration Price
Permanent Name Return Proceeds Split
50% goes to the returning name owner
50% goes to the protocol balance
The RNP multiplier is applied to the registration price of both permanently purchased and leased names.
Gateway Operator ArNS Discount
Gateway operators who demonstrate consistent, healthy participation in the network are eligible for a 20% discount on certain ArNS interactions.
Qualification Requirements
To qualify for the discount:
The gateway must maintain a "Gateway Performance Ratio Weight" (GPRW) of 0.9 or higher
The gateway must have a "Tenure Weight" (TW) of 1.0 or greater
A gateway marked as "Leaving" shall not be eligible for this discount
Eligible Discounted Interactions
Purchasing a name
Extending a lease
Upgrading a lease to permabuy
Increasing undernames capacity
Next Steps
Congratulations! You now understand the complete ArNS pricing system. Ready to get started?
View Live PricingSee current ArNS pricing in real-time with the live pricing chart.Register a NameVisit ArNS.app to register your first name and explore the pricing in action.Explore GatewaysLearn about AR.IO gateways and how they integrate with ArNS.Build with ArNSStart building applications that leverage ArNS for decentralized naming.How is this guide?GoodBadArweave Name Tokens (ANTs)Learn about Arweave Name Tokens (ANTs) - the ownership and control system for ArNS namesWayfinder ProtocolLearn about the Wayfinder Protocol - a URI scheme for translating Arweave content requests into user-friendly ar:// URLsOn this pageAddressing Variable Market ConditionsKey DefinitionsDynamic Pricing ModelCore Pricing ComponentsBase Registration Fee (BRF)Genesis Registration Fee (GRF)Demand Factor (DF)Revenue Moving Average (RMA)Pricing FormulasAdjusted Registration Fee (ARF)Annual FeeLease PricingPermanent PurchasesUnder Name FeesPrimary Name FeeStep Pricing MechanicsReturned Name Premiums (RNP)RNP MechanicsIntentRNP WindowReturned Name Premium FormulaRNP Registration PricePermanent Name Return Proceeds SplitGateway Operator ArNS DiscountQualification RequirementsEligible Discounted InteractionsNext Steps

---

# 40. Wayfinder Protocol  ARIO Documentation

Document Number: 40
Source: https://docs.ar.io/learn/wayfinder
Words: 604
Quality Score: 0.485
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

The Problem: Centralized Gateway Reliance Today, most Arweave content is accessed through a single gateway: arweave.net. This creates a critical centralization risk:Single point of failure - If arweave.net goes down, content becomes inaccessible Censorship vulnerability - A single gateway can block or filter content Performance bottlenecks - All traffic flows through one gateway No content verification - Users must trust the gateway to serve authentic content What is Wayfinder?The Wayfinder protocol solves these problems by enabling decentralized access to Arweave content through any gateway in the AR.IO network. It's a URI scheme that transforms centralized URLs like https://arweave.net/txid into decentralized ar:// URLs that can be resolved by any participating gateway.Key capabilities:Multi-gateway routing - Access content through any AR.IO gateway Built-in verification - Verify content authenticity regardless of which gateway serves it Automatic failover - If one gateway is down, requests route to another User control - Choose routing strategies based on speed, trust, or randomization How Wayfinder Works The Wayfinder protocol consists of three core components that work together to resolve and serve Arweave content:vs.Wayfinder enables:Decentralized Routing: Select from multiple gateways instead of relying on arweave.net Redundant Retrieval: If one gateway fails, automatically failover to another Trust-minimized Verification: Verify content authenticity regardless of which gateway serves it Transaction ID Resolution To access content tied to an Arweave Transaction ID (TxId), simply append the TxId to ar://:ar://qI19W6spw-kzOGl4qUMNp2gwFH2EBfDXOFsjkcNyK9A Inputting this into a WayFinder-equipped browser will route your request through the right AR.IO Gateway, translating it as per your Routing Method settings.ArNS Name Resolution Fetching content via an Arweave Name System (ArNS) name is straightforward. Attach the ArNS name to ar://:ar://good-morning The Wayfinder protocol, along with the WayFinder App, discerns between TxIds and ArNS names. Once the suitable https:// request is formulated, the chosen gateway translates the ArNS name based on the ArNS aoComputer contract.Detailed Flow Why Decentralized Access Matters Resilience Against Censorship With centralized gateways like arweave.net, content can be blocked or filtered at a single point. Wayfinder distributes access across multiple independent gateways, making censorship significantly more difficult.Always-Available Content When arweave.net experiences downtime or congestion, all content becomes inaccessible. Wayfinder automatically routes around failed gateways, ensuring your content remains available.Trust Through Verification Centralized gateways require blind trust - you can't verify if the content served matches what's stored on Arweave. Wayfinder includes built-in verification capabilities, allowing clients to cryptographically verify content authenticity from any gateway.Performance Through Competition Multiple gateways create a competitive ecosystem where gateways optimize for speed and reliability. Users benefit from automatic routing to the fastest available gateway.Verification: Trust but Verify Wayfinder supports content verification at multiple levels:Transaction verification - Verify that content matches the requested transaction ID Data integrity checks - Ensure content hasn't been tampered with during transmission Manifest validation - For bundled content, verify all components are authentic ArNS resolution verification - Confirm ArNS names resolve to the correct transaction IDs This verification happens transparently, giving users confidence that they're receiving authentic Arweave content regardless of which gateway serves it.Explore Wayfinder Integration Methods Learn how to integrate Wayfinder in browsers and applications Use Cases Discover practical applications and implementation examples Gateway Registry Understand how gateways participate in the decentralized network Access Data Start accessing Arweave content through multiple gateways How is this guide?Pricing Model Learn about ArNS dynamic pricing, demand factors, and returned name premiums Integration Use the Wayfinder browser extension or integrate Wayfinder libraries into your applications On this page The Problem: Centralized Gateway Reliance What is Wayfinder?How Wayfinder Works Transaction ID Resolution ArNS Name Resolution Detailed Flow Why Decentralized Access Matters Resilience Against Censorship Always-Available Content Trust Through Verification Performance Through Competition Verification: Trust but Verify Explore Wayfinder

---

# 41. Tagging  ARIO Documentation

Document Number: 41
Source: https://docs.ar.io/build/upload/tagging
Words: 387
Quality Score: 0.484
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Upload Data Tags are key-value pairs that provide metadata about your uploaded data on Arweave. They enable discoverability, proper content serving, and integration with various protocols.Essential Tags Every upload should include these tags:Content-Type: Required - tells gateways how to serve your data App-Name: Best practice - identifies your application for discoverability const result = await turbo.upload({
data: fileData,
dataItemOpts: {
tags: [
{ name: "Content-Type", value: "image/jpeg" },
{ name: "App-Name", value: "MyApp-v1.0" },
{ name: "Title", value: "My Image" },
],
},
});Common Tag Types Content Types image/jpeg, image/png - Images application/json - JSON data text/html - HTML pages video/mp4 - Videos application/pdf - Documents App-Specific Tags App-Name - Your application identifier (e.g., "MyApp-v1.0", "PhotoGallery-2024") Title - Human-readable title Description - Content description Author - Content creator Version - Application version Protocol Tags License - Universal Data License (UDL) transaction ID License-Fee - Fee for UDL licensing Advanced Tagging Folder Uploads const folderResult = await turbo.uploadFolder({
folderPath: "./my-website",
dataItemOpts: {
tags: [
{ name: "Bundle-Format", value: "binary" },
{ name: "Bundle-Version", value: "2.0.0" },
{ name: "App-Name", value: "MyWebsite-v2.1" },
{ name: "Version", value: "2.1.0" },
],
},
});Licensed Content const licensedTags = [
{ name: "Content-Type", value: "image/jpeg" },
{ name: "App-Name", value: "ArtGallery-v3.2" },
{ name: "Version", value: "3.2.1" },
{ name: "License", value: "udl-tx-id-here" },
{ name: "License-Fee", value: "1000000" }, // Fee in Winston
];App-Name Best Practices Naming Convention Use descriptive, versioned App-Name values for better organization:Include version: MyApp-v1.0, PhotoGallery-2024 Be specific: EcommerceStore-v2.1 instead of just Store Use consistent format: ProjectName-vMajor.Minor Include year for time-based apps: YearlyReport-2024 Tag Limitations 4KB total for bundled data items (Turbo) 2KB total for direct L1 uploads No maximum number of tags (limited by total size) Tag names are case-sensitive No duplicate tag names allowed Querying Data by Tags Once you've tagged your data, you can use GraphQL to search and filter based on those tags. This enables powerful discovery and retrieval of your stored content.Learn GraphQL Queries Discover how to query for data based on tags Next Steps Understanding Manifests Organize files with manifests for better structure.Data Encryption Secure your sensitive data with encryption.ArFS File System Advanced file organization with ArFS.How is this guide?Paying for Uploads Understanding Turbo's credit system for flexible payment options and enterprise features Manifests Understanding manifests for organizing folder structures and bundles

---

# 42. Get Started  ARIO Documentation

Document Number: 42
Source: https://docs.ar.io/build
Words: 258
Quality Score: 0.483
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Welcome to AR.IO Network's developer documentation.This section will guide you through everything you need to know for building on top of AR.IO Network from uploading and accessing your data, to operating and extending your own infrastructure to support your unique use-case.If you're unfamiliar with Arweave's permanent storage and AR.IO Network we recommend reading this introduction section first.Get Started Building with AR.IO Uploading Data Learn how to permanently store files, websites, and application data on Arweave Accessing Data Query, retrieve, and interact with data stored on the permanent web Running Your Own Gateway Deploy and operate AR.IO gateway infrastructure to support the network Developer Resources Turbo SDK Reference Fast upload service SDK with payment processing and instant confirmation Wayfinder SDK Reference Decentralized data access SDK with built-in verification and routing AR.IO SDK Reference Complete SDK documentation for interacting with AR.IO Network protocols Gateway API Reference Direct API access for custom implementations and integrations Use Cases & Guides Hosting Decentralized Websites Build and deploy censorship-resistant web applications on the permanent web ArNS Primary Names Set up primary names for user-friendly wallet addresses ArNS Undernames & Versioning Manage subdomains and versioning for your ArNS names ArNS Marketplace Explore the ArNS marketplace for name trading and management Get Help Browse Examples Explore code examples and sample applications Join the Community Connect with other developers on Discord Ready to build on the permanent web? Choose your path above and start creating applications that last forever.How is this guide?On this page Get Started Building with AR.IO Developer Resources Use Cases & Guides Get Help

---

# 43. Gateway  ARIO Documentation

Document Number: 43
Source: https://docs.ar.io/apis/ar-io-node/gateway
Words: 327
Quality Score: 0.480
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

AR.IO Gateway Operations related to the AR.IO Gateway server itself, including health checks, metrics, and gateway-specific information Gateway Info or Apex Content Returns either gateway information or serves content based on configuration:If neither APEX_TX_ID nor APEX_ARNS_NAME is set, returns gateway information If APEX_TX_ID is set, serves that transaction's content If APEX_ARNS_NAME is set, resolves and serves that ArNS name's content The Content-Type of the response will match the content type of the transaction or ArNS-resolved data (e.g., text/html for HTML documents, application/json for JSON documents, application/octet-stream for binary data, etc.).Response Body curl -X GET "https://ardrive.net" {
"wallet": "string",
"processId": "string",
"ans104UnbundleFilter": {},
"ans104IndexFilter": {},
"supportedManifestVersions": [
"0.1.0"
],
"release": "string"
} Health check endpoint Get the current health status of the AR.IO Gateway.Response Body curl -X GET "https://ardrive.net/ar-io/healthcheck" {
"status": "ok",
"uptime": 0,
"date": "2019-08-24T14:15:22Z",
"reasons": [
"string"
]
} Get AR.IO Gateway information Returns information about the AR.IO Gateway, including:Gateway wallet address Process ID ANS-104 filter configurations Supported manifest versions Gateway software release version Response Body curl -X GET "https://ardrive.net/ar-io/info" {
"wallet": "string",
"processId": "string",
"ans104UnbundleFilter": {},
"ans104IndexFilter": {},
"supportedManifestVersions": [
"0.1.0"
],
"release": "string"
} Get AR.IO Gateway peer information Returns information about AR.IO Gateway peers and Arweave node peers.
For gateways, includes both data and chunk weights used for peer selection.
Peer keys are formatted as host:port.Response Body curl -X GET "https://ardrive.net/ar-io/peers" {
"gateways": {
"gateway.example.com:443": {
"url": "https://gateway.example.com",
"dataWeight": 50,
"chunkWeight": 50
}
},
"arweaveNodes": {
"arweave.example.com:1984": {
"url": "http://arweave.example.com:1984",
"blocks": 165967,
"height": 1732652,
"lastSeen": 1755190447700
}
}
} Get Prometheus metrics Returns metrics in Prometheus format for monitoring the Gateway's performance and status.
These metrics include various counters, gauges, and histograms tracking:HTTP request statistics Transaction processing metrics System resource usage Cache performance Bundle processing statistics Response Body curl -X GET "https://ardrive.net/ar-io/__gateway_metrics" "# HELP errors_total Total error count\n# TYPE errors_total counter\nerrors_total 0\n\n# HELP uncaught_exceptions_total Count of uncaught exceptions\n# TYPE uncaught_exceptions_total counter\nuncaught_exceptions_total 0\n" How is this guide?Network Previous Page Index Querying POST Next Page

---

# 44. Events  ARIO Documentation

Document Number: 44
Source: https://docs.ar.io/sdks/turbo-sdk/events
Words: 338
Quality Score: 0.479
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Turbo SDK The SDK provides events for tracking the state signing and uploading data to Turbo. You can listen to these events by providing a callback function to the events parameter of the upload, uploadFile, and uploadSignedDataItem methods.onProgress - emitted when the overall progress changes (includes both upload and signing). Each event consists of the total bytes, processed bytes, and the step (upload or signing) onError - emitted when the overall upload or signing fails (includes both upload and signing) onSuccess - emitted when the overall upload or signing succeeds (includes both upload and signing) - this is the last event emitted for the upload or signing process onSigningProgress - emitted when the signing progress changes.onSigningError - emitted when the signing fails.onSigningSuccess - emitted when the signing succeeds onUploadProgress - emitted when the upload progress changes onUploadError - emitted when the upload fails onUploadSuccess - emitted when the upload succeeds const uploadResult = await turbo.upload({
data: 'The contents of my file!',
signal: AbortSignal.timeout(10_000), // cancel the upload after 10 seconds
dataItemOpts: {
// optional
},
events: {
// overall events (includes signing and upload events)
onProgress: ({ totalBytes, processedBytes, step }) => {
const percentComplete = (processedBytes / totalBytes) * 100;
console.log('Overall progress:', {
totalBytes,
processedBytes,
step,
percentComplete: percentComplete.toFixed(2) + '%', // eg 50.68%
});
},
onError: (error) => {
console.log('Overall error:', { error });
},
onSuccess: () => {
console.log('Signed and upload data item!');
},
// upload events
onUploadProgress: ({ totalBytes, processedBytes }) => {
console.log('Upload progress:', { totalBytes, processedBytes });
},
onUploadError: (error) => {
console.log('Upload error:', { error });
},
onUploadSuccess: () => {
console.log('Upload success!');
},
// signing events
onSigningProgress: ({ totalBytes, processedBytes }) => {
console.log('Signing progress:', { totalBytes, processedBytes });
},
onSigningError: (error) => {
console.log('Signing error:', { error });
},
onSigningSuccess: () => {
console.log('Signing success!');
},
},
});How is this guide?TurboAuthenticatedClient SDK for interacting with Turbo, a fast and efficient data upload service for Arweave Logging SDK for interacting with Turbo, a fast and efficient data upload service for Arweave

---

# 45. Privacy  Encryption  ARIO Documentation

Document Number: 45
Source: https://docs.ar.io/build/advanced/arfs/privacy
Words: 968
Quality Score: 0.476
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Advanced ArFS Protocol The Arweave blockweave is inherently public. But with apps that use ArFS, like ArDrive, your private data never leaves your computer without using military grade (and quantum resistant) encryption. This privacy layer is applied at the Drive level, and users determine whether a Drive is public or private when they first create it. Private drives must follow the ArFS privacy model.With ArDrive specifically, every file within a Private Drive is symmetrically encrypted using AES-256-GCM (for small files and metadata transactions) or AES-256-CTR (for large files, over 100MiB). Every Private drive has a master "Drive Key" which uses a combination of the user's Arweave wallet signature, a user defined drive password, and a unique drive identifier (uuidv4). Each file has its own "File Key" derived from the "Drive Key". This allows for single files to be shared without exposing access to the other files within the Drive.Once a file is encrypted and stored on Arweave, it is locked forever and can only be decrypted using its file key.NOTE: Usable encryption standards are not limited to AES-256-GCM or AES-256-CTR. Any Encryption method may be used so long as it is clearly indicated in the cipher tag.Deriving Keys Private drives have a global drive key, D, and multiple file keys F, for encryption. This enables a drive to have as many uniquely encrypted files as needed. One key is used for all versions of a single file (since new file versions use the same File-Id) D is used for encrypting both Drive and Folder metadata, while F is used for encrypting File metadata and the actual stored data. Having these different keys, D and F, allows a user to share specific files without revealing the contents of their entire drive.D is derived using HKDF-SHA256 with an unsalted RSA-PSS signature of the drive's id and a user provided password.F is also derived using HKDF-SHA256 with the drive key and the file's id.Other wallets (like ArConnect) integrate with this Key Derivation protocol just exposing an API to collect a signature from a given Arweave Wallet in order to get the SHA-256 signature needed for the HKDF to derive the Drive Key.An example implementation, using Dart, is available here, with a Typescript implementation here.Private Drives Drives can store either public or private data. This is indicated by the Drive-Privacy tag in the Drive entity metadata. If a Drive entity is private, an additional tag Drive-Auth-Mode must also be used to indicate how the Drive Key is derived. ArDrive clients currently leverage a secure password along with the Arweave Wallet private key signature to derive the global Drive Key.Drive-Auth-Mode?: 'password' On every encrypted Drive Entity, a Cipher tag must be specified, along with the public parameters for decrypting the data. This is done by specifying the parameter with a Cipher-* tag. eg. Cipher-IV. If the parameter is byte data, it must be encoded as Base64 in the tag.ArDrive clients currently leverage AES256-GCM for all symmetric encryption, which requires a Cipher Initialization Vector consisting of 12 random bytes.Cipher?: "AES256-GCM"
Cipher-IV?: "<12 byte initialization vector as Base64>" Additionally, all encrypted transactions must have the Content-Type tag application/octet-stream as opposed to application/json Private Drive Entities and their corresponding Root Folder Entities will both use these keys and ciphers generated to symmetrically encrypt the JSON files that are included in the transaction. This ensures that only the Drive Owner (and whomever the keys have been shared with) can open the drive, discover the root folder, and continue to load the rest of the children in the drive.Private Files When a file is uploaded to a private drive, it by default also becomes private and leverages the same drive keys used for its parent drive. Each unique file in a drive will get its own set of file keys based off of that file's unique FileId. If a single file gets a new version, its File-Id will be reused, effectively leveraging the same File Key for all versions in that file's history.These file keys can be shared by the drive's owner as needed.Private File entities have both its metadata and data transactions encrypted using the same File Key, ensuring all facets of the data is truly private. As such, both the file's metadata and data transactions must both have a unique Cipher-IV and Cipher tag:Cipher?: "AES256-GCM"
Cipher-IV?: "<12 byte initialization vector as Base64>" Just like drives, private files must have the Content-Type tag set as application/octet-stream in both its metadata and data transactions:Content-Type: "application/octet-stream" Encryption Process Here's how the encryption process works for private drives:Security Best Practices When working with private drives, follow these security guidelines:Password Management Use strong, unique passwords for each drive Consider using a password manager Never share passwords in plain text Key Storage Never store drive keys in plain text Use secure key derivation functions Implement proper key rotation if needed Access Control Share file keys only with authorized users Implement proper access logging Regularly audit drive access Data Handling Encrypt data before transmission Use secure communication channels Implement proper error handling Drive Signature (ArFS v0.15) ArFS v0.15 introduces a new Drive-Signature entity type to help bridge signature derivation schemes across ArFS versions. This is particularly important for maintaining access to private drives created with older wallet signing methods.The drive signature entity stores an encrypted version of the pre-v0.15 wallet signature that's necessary for deriving the drive key. This allows continued access to historical drive contents while using modern wallet signing APIs.Next Steps Ready to implement privacy in your ArFS applications?Creating Private Drives - Learn how to create secure drives Upgrading Private Drives - Update legacy drives to v0.15 Reading Data - Query and decrypt your private data How is this guide?Data Model Understanding how ArFS organizes data hierarchically using entity relationships Creating Drives Learn how to create ArFS drives, folders, and files

---

# 46. Upload Data  ARIO Documentation

Document Number: 46
Source: https://docs.ar.io/build/upload
Words: 391
Quality Score: 0.475
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Arweave enables permanent data storage with a single payment. Unlike traditional cloud storage that requires ongoing fees, your data is preserved forever.Upload Methods There are multiple ways to upload data to Arweave. Each has its own attributes and characteristics to help you decide which is best for your use case.Turbo Recommended Production-ready bundling service with enterprise features Credit cards, AR, ETH, SOL, MATIC Free uploads under 100 KiB Automatic retry & confirmation ArDrive No-code solution for personal and business files Drag-and-drop interface End-to-end encryption Powered by Turbo Direct to Arweave Raw protocol access for advanced use cases • AR tokens required • Manual transaction handling • Complex setup needed Why Developers Choose Turbo Cost Effective Pay per byte, not empty chunks - only pay for actual data uploaded Free uploads under 100 KiB - subsidized small file uploads No failed upload charges - automatic retry without extra costs Developer Experience TypeScript & CLI support - choose your preferred tools Simple 3-line integration - get started in minutes Comprehensive documentation - extensive guides and examples Enterprise Ready High Availability - reliable service for production apps Handles millions of uploads daily - battle-tested infrastructure used by ArDrive Open source infrastructure - fully auditable and transparent Get Started in Minutes With Turbo, uploading to Arweave is as simple as using any cloud storage API:import { TurboFactory } from "@ardrive/turbo-sdk";
const turbo = TurboFactory.authenticated({ privateKey });
const uploadResult = await turbo.uploadFile({
fileStreamFactory: () => fs.createReadStream("./my-file.pdf"),
});
// Your file is now permanently stored!Quick Start Guide Upload your first file in under 5 minutes Payment Methods Credit cards, crypto, and Turbo Credits explained Organize Your Data Before uploading, learn best practices for structuring and tagging your data for optimal retrieval and organization.Tagging System Add metadata and queryable attributes to uploads Manifests Create folder structures and host websites Encryption Secure your data with client-side encryption Advanced Uploading with Turbo Comprehensive guide to Turbo SDK with authentication and payment options Additional Resources API Reference Complete SDK documentation and examples Pricing Calculator Estimate costs for your uploads Get Help Join our Discord community How is this guide?Get Started Developer documentation and resources for building on the AR.IO ecosystem Getting Started with Turbo Upload data to Arweave in a matter of minutes On this page Upload Methods Why Developers Choose Turbo Get Started in Minutes Organize Your Data Additional Resources

---

# 47. Using Turbo SDK with Vite  ARIO Documentation

Document Number: 47
Source: https://docs.ar.io/build/guides/using-turbo-in-a-browser/vite
Words: 1505
Quality Score: 0.475
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Guides Using Turbo in a Browser Using Turbo SDK with Vite Overview This guide demonstrates how to configure the @ardrive/turbo-sdk in a Vite application with proper polyfills for client-side usage. Vite provides excellent support for modern JavaScript features and can be easily configured to work with the Turbo SDK through plugins.Prerequisites Vite 5+ Node.js 18+ React 18+ (or your preferred framework) Basic familiarity with Vite configuration Install the main Turbo SDK package:npm install @ardrive/turbo-sdk Add the Vite node polyfills plugin for browser compatibility:npm install --save-dev vite-plugin-node-polyfills Wallet Integration Dependencies: The Turbo SDK includes @dha-team/arbundles as a peer dependency, which provides the necessary
signers for browser wallet integration (like InjectedEthereumSigner and ArconnectSigner). You can import these directly without additional
installation.Add React and TypeScript dependencies (if using React):npm install react react-dom
npm install --save-dev @vitejs/plugin-react @types/react @types/react-dom Create or update your vite.config.js file:import react from "@vitejs/plugin-react";
import { defineConfig } from "vite";
import { nodePolyfills } from "vite-plugin-node-polyfills";
export default defineConfig({
base: "/",
plugins: [
react(),
nodePolyfills({
// Enable specific polyfills for Turbo SDK requirements
include: ["crypto", "stream", "buffer", "process"],
globals: {
Buffer: true,
global: true,
process: true,
},
}),
],
define: {
// Define globals for browser compatibility
global: "globalThis",
},
});If you're using TypeScript, update your tsconfig.json:{
"compilerOptions": {
"target": "ESNext",
"lib": ["DOM", "DOM.Iterable", "ESNext"],
"allowJs": true,
"skipLibCheck": true,
"esModuleInterop": true,
"allowSyntheticDefaultImports": true,
"strict": true,
"forceConsistentCasingInFileNames": true,
"module": "ESNext",
"moduleResolution": "Bundler",
"isolatedModules": true,
"jsx": "react-jsx",
"paths": {
"buffer/": ["./node_modules/vite-plugin-node-polyfills/shims/buffer"]
}
},
"include": ["src"]
} TypeScript Wallet Types Create a types/wallet.d.ts file to properly type wallet objects:// types/wallet.d.ts
interface Window {
ethereum?: {
request: (args: { method: string; params?: any[] }) => Promise;
on?: (event: string, handler: (...args: any[]) => void) => void;
removeListener?: (event: string, handler: (...args: any[]) => void) => void;
isMetaMask?: boolean;
};
arweaveWallet?: {
connect: (permissions: string[]) => Promise;
disconnect: () => Promise;
getActiveAddress: () => Promise;
getPermissions: () => Promise;
sign: (transaction: any) => Promise;
getPublicKey: () => Promise;
};
} Select between MetaMask or Wander wallet integration:Create a React component for MetaMask wallet integration:import { TurboFactory } from "@ardrive/turbo-sdk/web";
import { InjectedEthereumSigner } from "@dha-team/arbundles";
import { useState, useCallback } from "react";
export default function MetaMaskUploader() {
const [connected, setConnected] = useState(false);
const [address, setAddress] = useState("");
const [uploading, setUploading] = useState(false);
const [uploadResult, setUploadResult] = useState(null);
const connectMetaMask = useCallback(async () => {
try {
if (!window.ethereum) {
alert("MetaMask is not installed!");
return;
}
// Request account access
await window.ethereum.request({
method: "eth_requestAccounts",
});
// Get the current account
const accounts = await window.ethereum.request({
method: "eth_accounts",
});
if (accounts.length > 0) {
setAddress(accounts[0]);
setConnected(true);
// Log current chain for debugging
const chainId = await window.ethereum.request({
method: "eth_chainId",
});
console.log("Connected to chain:", chainId);
}
} catch (error) {
console.error("Failed to connect to MetaMask:", error);
}
}, []);
const uploadWithMetaMask = async (event) => {
const file = event.target.files?.[0];
if (!file || !connected) return;
setUploading(true);
try {
// Create a provider wrapper for InjectedEthereumSigner
const providerWrapper = {
getSigner: () => ({
signMessage: async (message: string | Uint8Array) => {
const accounts = await window.ethereum!.request({
method: "eth_accounts",
});
if (accounts.length === 0) {
throw new Error("No accounts available");
}
// Convert message to hex if it's Uint8Array
const messageToSign =
typeof message === "string"
? message
: "0x" +
Array.from(message)
.map((b) => b.toString(16).padStart(2, "0"))
.join("");
return await window.ethereum!.request({
method: "personal_sign",
params: [messageToSign, accounts[0]],
});
},
}),
};
// Create the signer using InjectedEthereumSigner
const signer = new InjectedEthereumSigner(providerWrapper);
const turbo = TurboFactory.authenticated({
signer,
token: "ethereum", // Important: specify token type for Ethereum
});
// Upload file with progress tracking
const result = await turbo.uploadFile({
fileStreamFactory: () => file.stream(),
fileSizeFactory: () => file.size,
dataItemOpts: {
tags: [
{ name: "Content-Type", value: file.type },
{ name: "App-Name", value: "My-Vite-App" },
{ name: "Funded-By", value: "Ethereum" },
],
},
events: {
onProgress: ({ totalBytes, processedBytes, step }) => {
console.log(
`${step}: ${Math.round((processedBytes / totalBytes) * 100)}%`
);
},
onError: ({ error, step }) => {
console.error(`Error during ${step}:`, error);
console.error("Error details:", JSON.stringify(error, null, 2));
},
},
});
setUploadResult(result);
} catch (error) {
console.error("Upload failed:", error);
console.error("Error details:", JSON.stringify(error, null, 2));
alert(`Upload failed: ${error.message}`);
} finally {
setUploading(false);
}
};
return (
MetaMask Upload
{!connected ? (

Connect MetaMask

) : (


✅ Connected: {address.slice(0, 6)}...{address.slice(-4)}



Select File to Upload:



{uploading && (

🔄 Up Please confirm transaction in MetaMask

)}
{uploadResult && (


✅ Upload Successful!


Transaction ID: {uploadResult.id}


Data Size: {uploadResult.totalBytes} bytes


)}

)}
);
} Create a React component for Wander wallet integration:import { TurboFactory, ArconnectSigner } from "@ardrive/turbo-sdk/web";
import { useState, useCallback } from "react";
export default function WanderWalletUploader() {
const [connected, setConnected] = useState(false);
const [address, setAddress] = useState("");
const [uploading, setUploading] = useState(false);
const [uploadResult, setUploadResult] = useState(null);
const connectWanderWallet = useCallback(async () => {
try {
if (!window.arweaveWallet) {
alert("Wander wallet is not installed!");
return;
}
// Required permissions for Turbo SDK
const permissions = [
"ACCESS_ADDRESS",
"ACCESS_PUBLIC_KEY",
"SIGN_TRANSACTION",
"SIGNATURE",
];
// Connect to wallet
await window.arweaveWallet.connect(permissions);
// Get wallet address
const walletAddress = await window.arweaveWallet.getActiveAddress();
setAddress(walletAddress);
setConnected(true);
} catch (error) {
console.error("Failed to connect to Wander wallet:", error);
}
}, []);
const uploadWithWanderWallet = async (event) => {
const file = event.target.files?.[0];
if (!file || !connected) return;
setUploading(true);
try {
// Create ArConnect signer using Wander wallet
const signer = new ArconnectSigner(window.arweaveWallet);
const turbo = TurboFactory.authenticated({ signer });
// Note: No need to specify token for Arweave as it's the default
// Upload file with progress tracking
const result = await turbo.uploadFile({
fileStreamFactory: () => file.stream(),
fileSizeFactory: () => file.size,
dataItemOpts: {
tags: [
{ name: "Content-Type", value: file.type },
{ name: "App-Name", value: "My-Vite-App" },
{ name: "Funded-By", value: "Arweave" },
],
},
events: {
onProgress: ({ totalBytes, processedBytes, step }) => {
console.log(
`${step}: ${Math.round((processedBytes / totalBytes) * 100)}%`
);
},
onError: ({ error, step }) => {
console.error(`Error during ${step}:`, error);
},
},
});
setUploadResult(result);
} catch (error) {
console.error("Upload failed:", error);
alert(`Upload failed: ${error.message}`);
} finally {
setUploading(false);
}
};
return (
Wander Wallet Upload
{!connected ? (

Connect Wander Wallet

) : (


✅ Connected: {address.slice(0, 6)}...{address.slice(-4)}



Select File to Upload:



{uploading && (

🔄 Up Please confirm transaction in Wander wallet

)}
{uploadResult && (


✅ Upload Successful!


Transaction ID: {uploadResult.id}


Data Size: {uploadResult.totalBytes} bytes


)}

)}
);
} Here's a complete package.json example for a Vite + React + Turbo SDK project:{
"name": "vite-turbo-app",
"version": "0.1.0",
"private": true,
"type": "module",
"scripts": {
"dev": "vite",
"build": "vite build",
"preview": "vite preview",
"lint": "eslint . --ext ts,tsx --report-unused-disable-directives --max-warnings 0"
},
"dependencies": {
"@ardrive/turbo-sdk": "^1.20.0",
"react": "^18.3.1",
"react-dom": "^18.3.1"
},
"devDependencies": {
"@types/react": "^18.3.1",
"@types/react-dom": "^18.3.0",
"@vitejs/plugin-react": "^4.2.1",
"typescript": "^5.3.3",
"vite": "^5.2.14",
"vite-plugin-node-polyfills": "^0.17.0"
}
} Common Issues and Solutions Build Errors "global is not defined" Ensure you have global: 'globalThis' in your Vite config's define section Buffer polyfill issues Make sure vite-plugin-node-polyfills is properly configured with Buffer globals Add the buffer path mapping in your tsconfig.json Module resolution errors Use moduleResolution: "Bundler" in TypeScript configuration Ensure you're importing from @ardrive/turbo-sdk/web for browser usage Runtime Errors "process is not defined" Enable process globals in the node polyfills plugin configuration Wallet integration errors For MetaMask, use InjectedEthereumSigner from @dha-team/arbundles For Wander wallet, use ArconnectSigner from the Turbo SDK Always check wallet availability before attempting connection Development Experience Hot reload issues with wallet connections Wallet state may not persist across hot reloads Consider using localStorage to persist connection state Console warnings about dependencies Some peer dependency warnings are normal for wallet libraries Focus on runtime functionality rather than dependency warnings Best Practices Development vs Production Use debug logs during development: TurboFactory.setLogLevel('debug') Remove debug logs in production builds Error Handling Always wrap wallet operations in try-catch blocks Provide meaningful error messages to users Log detailed error information for debugging Performance Initialize Turbo clients once and reuse them Consider lazy loading wallet integration components Use loading states for better user experience Security Never expose private keys in browser applications Always validate wallet connections before operations Use secure wallet connection methods in production Production Deployment Checklist For production builds:Build optimization Vite automatically optimizes builds with tree shaking Polyfills are only included when needed Testing Test wallet connections across different browsers Verify polyfills work in production builds Test with actual wallet extensions Monitoring Monitor bundle sizes to ensure polyfills don't bloat your app Set up error tracking for wallet connection failures Implementation Verification To verify your Vite setup is working correctly:Check Development Server: Start your dev server and verify no polyfill errors Test Wallet Connections: Ensure both MetaMask and Wander wallet integrations work Build Verification: Run npm run build and check for any build errors Bundle Analysis: Use vite-bundle-analyzer to inspect your bundle size Additional Resources Vite Documentation vite-plugin-node-polyfills Turbo SDK Documentation Web Usage Examples ArDrive Examples Repository For more examples and advanced usage patterns, refer to the Turbo SDK examples directory or the main SDK documentation.How is this guide?Using Turbo SDK with Next.js Configure Turbo SDK in a Next.js application with proper polyfills for client-side usage Advanced Advanced topics and specialized guides for building on Arweave and AR.IO

---

# 48. Pagination  ARIO Documentation

Document Number: 48
Source: https://docs.ar.io/sdks/ar-io-sdk/pagination
Words: 333
Quality Score: 0.474
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

AR.IO SDK Overview Certain APIs that could return a large amount of data are paginated using cursors. The SDK uses the cursor pattern (as opposed to pages) to better protect against changing data while paginating through a list of items. For more information on pagination strategies refer to this article.Paginated results include the following properties:items: the list of items on the current request, defaulted to 100 items.nextCursor: the cursor to use for the next batch of items. This is undefined if there are no more items to fetch.hasMore: a boolean indicating if there are more items to fetch. This is false if there are no more items to fetch.totalItems: the total number of items available. This may change as new items are added to the list, only use this for informational purposes.sortBy: the field used to sort the items, by default this is startTimestamp.sortOrder: the order used to sort the items, by default this is desc.To request all the items in a list, you can iterate through the list using the nextCursor until hasMore is false.let hasMore = true;
let cursor: string | undefined;
const gateaways = [];
while (hasMore) {
const page = await ario.getGateways({ limit: 100, cursor });
gateaways.push(...items);
cursor = page.nextCursor;
hasMore = page.hasMore;
} Filtering Paginated APIs also support filtering by providing a filters parameter. Filters can be applied to any field in the response. When multiple keys are provided, they are treated as AND conditions (all conditions must match). When multiple values are provided for a single key (as an array), they are treated as OR conditions (any value can match).Example:const records = await ario.getArNSRecords({
filters: {
type: 'lease',
processId: [
'ZkgLfyHALs5koxzojpcsEFAKA8fbpzP7l-tbM7wmQNM',
'r61rbOjyXx3u644nGl9bkwLWlWmArMEzQgxBo2R-Vu0',
],
},
});In the example above, the query will return ArNS records where:The type is "lease" AND The processId is EITHER "ZkgLfyHALs5koxzojpcsEFAKA8fbpzP7l-tbM7wmQNM" OR "r61rbOjyXx3u644nGl9bkwLWlWmArMEzQgxBo2R-Vu0" How is this guide?Logging TypeScript/JavaScript SDK for interacting with the AR.IO ecosystem Turbo SDK JavaScript/TypeScript SDK for uploading data to Arweave via Turbo services with built-in payment handling and optimized performance

---

# 49. APIs Reference  ARIO Documentation

Document Number: 49
Source: https://docs.ar.io/apis
Words: 347
Quality Score: 0.473
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Explore the REST APIs available in the AR.IO ecosystem. Our services are built with a commitment to open source principles, and all repositories are publicly available under AGPL-3 licenses.Available Services AR.IO Gateway The core gateway software providing access to data on Arweave. Includes data retrieval, ArNS resolution, and network management.Turbo Upload and payment services providing fast, reliable data uploads to Arweave with instant confirmation and transparent pricing.AR.IO Gateway APIs The AR.IO Gateway serves as the primary interface for accessing Arweave data through the AR.IO network. Key endpoints include:Data Access - Retrieve transaction data and files from Arweave ArNS Resolution - Resolve human-readable names to Arweave transaction IDs Network Information - Query gateway health, pricing, and network status Transaction Management - Submit and track transactions Admin Functions - Gateway administration and configuration Turbo APIs Turbo provides high-performance upload services for the Arweave network with additional features:Data Upload - Fast, reliable uploads with instant confirmation Payment Processing - Transparent pricing and payment management Upload Tracking - Monitor upload status and metadata Credit Management - Handle payment credits and billing Open Source Commitment We believe strongly in open source development. All AR.IO services are:Publicly Available - Source code is open and accessible AGPL-3 Licensed - Ensuring software freedom and transparency Community Driven - Built with input from the developer community Auditable - Code can be reviewed and verified by anyone Getting Started Choose your service - Select the APIs that fit your needs Review the documentation - Each service has comprehensive APIs documentation Test endpoints - Use the interactive examples to explore functionality Integrate - Implement the APIs in your applications For SDK alternatives to these REST APIs, visit our SDK documentation.Explore More SDK Documentation Use our TypeScript SDKs for easier integration and development Quick Start - Upload Start uploading data to Arweave with our upload guides Quick Start - Access Learn how to retrieve and query data from Arweave Run a Gateway Deploy your own AR.IO gateway and access these APIs directly How is this guide?AR.IO Gateway APIs Core gateway software for accessing, caching, and querying data on Arweave

---

# 50. Manifests  ARIO Documentation

Document Number: 50
Source: https://docs.ar.io/build/upload/manifests
Words: 647
Quality Score: 0.473
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Upload Data Manifests enable friendly-path-name routing for data on Arweave, greatly improving the programmability of data relationships. Instead of accessing data with complex transaction IDs, manifests allow you to organize files with readable paths and relative links.What are Manifests?Manifests, also known as "Path Manifests" or "Arweave Manifests," are JSON objects that connect various Arweave data items and define relational paths for easy navigation. A common use case is permanently hosting websites on Arweave by linking all necessary files together.The Problem Manifests Solve Without manifests, accessing data on Arweave looks like this:http:///cG7Hdi_iTQPoEYgQJFqJ8NMpN4KoZ-vH_j7pG4iP7NI (txID of a website's index.html)
http:///3zFsd7bkCAUtXUKBQ4XiPiQvpLVKfZ6kiLNt2XVSfoV (txID of its js/style.css)
http:///or0_fRYFcQYWh-QsozygI5Zoamw_fUsYu2w8_X1RkYZ (txID of its assets/img/logo.png) With manifests, the same data becomes:http:/// (resolves to the txID of index.html)
http:////js/style.css
http:////assets/img/logo.png Manifest Structure Manifests are JSON objects that define how data items are connected and accessed through friendly paths.Sample Manifest {
"manifest": "arweave/paths",
"version": "0.2.0",
"index": {
"path": "index.html"
},
"fallback": {
"id": "iXo3LSfVKVtXUKBzfZ4d7bkCAp6kiLNt2XVUFsPiQvQ"
},
"paths": {
"index.html": {
"id": "cG7Hdi_iTQPoEYgQJFqJ8NMpN4KoZ-vH_j7pG4iP7NI"
},
"404.html": {
"id": "iXo3LSfVKVtXUKBzfZ4d7bkCAp6kiLNt2XVUFsPiQvQ"
},
"js/style.css": {
"id": "3zFsd7bkCAUtXUKBQ4XiPiQvpLVKfZ6kiLNt2XVSfoV"
},
"css/style.css": {
"id": "sPiQvpAUXLVK3zF6iXSfo7bkCVQkiLNt24dVtXUKBfZ"
},
"css/mobile.css": {
"id": "fZ4d7bkCAUiXSfo3zFsPiQvpLVKVtXUKB6kiLNt2XVQ"
},
"assets/img/logo.png": {
"id": "or0_fRYFcQYWh-QsozygI5Zoamw_fUsYu2w8_X1RkYZ"
},
"assets/img/icon.png": {
"id": "0543SMRGYuGKTaqLzmpOyK4AxAB96Fra2guHzYxjRGo"
}
}
} How it Works A resolver, typically an AR.IO gateway, resolves URLs requesting content based on a manifest transaction ID to the corresponding path key in the paths object. The URL schema for this type of request is https:////.Example Usage Assume the manifest above is uploaded to Arweave with the transaction ID UyC5P5qKPZaltMmmZAWdakhlDXsBF6qmyrbWYFchRTk. The below table shows https requests to the AR.IO gateway arweave.net:Creating Manifests with Turbo Turbo makes it easy to create manifests automatically when uploading folders, or you can create custom manifests manually.Folder Upload with Manifest const folderResult = await turbo.uploadFolder({
folderPath: "./my-website",
dataItemOpts: {
tags: [
{ name: "Bundle-Format", value: "binary" },
{ name: "Bundle-Version", value: "2.0.0" },
{ name: "App-Name", value: "Website" },
],
},
});
console.log("Folder Upload ID:", folderResult.id);
console.log("Manifest ID:", folderResult.manifestId);Custom Manifest Creation const manifest = {
manifest: "arweave/paths",
version: "0.2.0",
index: {
path: "index.html",
},
fallback: {
id: "fallback-tx-id",
},
paths: {
"index.html": {
id: "abc123...def789",
},
"css/style.css": {
id: "def456...ghi012",
},
},
};
const manifestResult = await turbo.upload({
data: JSON.stringify(manifest),
dataItemOpts: {
tags: [
{ name: "Content-Type", value: "application/x.arweave-manifest+json" },
{ name: "App-Name", value: "CustomManifest" },
],
},
});Manifest Specifications Required Transaction Tags Manifests must be uploaded with specific tags so that AR.IO gateways can recognize and properly resolve them:{ "name": "Content-Type", "value": "application/x.arweave-manifest+json" } Required JSON Attributes manifest "manifest": "arweave/paths" Must have the value arweave/paths for gateways to resolve the manifest.version "version": "0.2.0" Defines the version of manifest schema being used.index "index": {
"path": "index.html"
} or "index": {
"id": "cG7Hdi_iTQPoEYgQJFqJ8NMpN4KoZ-vH_j7pG4iP7NI"
} Defines the base or 'starting' data item. Accepts either path (key in paths object) or id (specific transaction ID). If both are defined, id overrides path.fallback "fallback": {
"id": "iXo3LSfVKVtXUKBzfZ4d7bkCAp6kiLNt2XVUFsPiQvQ"
} Defines a fallback data item for when requested paths don't exist (like a 404 page).paths "paths": {
"index.html": {
"id": "cG7Hdi_iTQPoEYgQJFqJ8NMpN4KoZ-vH_j7pG4iP7NI"
},
"css/style.css": {
"id": "3zFsd7bkCAUtXUKBQ4XiPiQvpLVKfZ6kiLNt2XVSfoV"
}
} Defines the URL paths that a manifest can resolve to. Each path maps to a specific Arweave transaction ID.Relative Path Routing AR.IO gateways support relative path routing, making it easy to develop and maintain websites hosted on Arweave. Instead of using fully qualified URLs: You can use relative paths: This makes HTML more readable and ensures links remain valid even if the hosting domain changes.Best Practices File Organization Use descriptive file paths Organize files in logical folders Keep manifest files small Use consistent naming conventions Performance Considerations Minimize manifest size Use relative paths Avoid deep nesting Consider file size limits Next Steps Data Encryption Secure your sensitive data with encryption.ArFS File System Advanced file organization with ArFS.Getting Started with Turbo Complete upload guide with Turbo.How is this guide?Tagging Understanding metadata and tagging for organized data storage Encryption Understanding data encryption for secure storage on Arweave

---

# 51. What is ARIO  ARIO Documentation

Document Number: 51
Source: https://docs.ar.io/learn/what-is-ario
Words: 633
Quality Score: 0.473
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Introduction The AR.IO Network is the first permanent cloud network.A decentralized infrastructure layer built on Arweave and AO, making permanent data accessible, discoverable, and usable. Think of it as the gateway to Arweave's permaweb, turning its tamper-proof storage into a fully functional, user-friendly ecosystem for apps, websites, and data. Features of The AR.IO Network Gateways AR.IO operates a network of gateways — nodes that serve as entry points to Arweave’s data. These gateways fetch and deliver data quickly, supporting everything from static files to dynamic web apps.Arweave Name System (ArNS) The Arweave Name System (ArNS) is a decentralized naming system for Arweave. It allows users to register and resolve human-readable names to Arweave transaction IDs.Data Access AR.IO offers a range of tools for accessing and querying data on Arweave, including:HTTP Requests via gateways GraphQL Queries for finding data by tags and metadata ArNS for human-readable URLs Wayfinder for decentralized content discovery The Problem Arweave stores data forever, but accessing and organizing that data isn't always straightforward. Without efficient tools, retrieving files, serving websites, or finding specific content on Arweave's blockweave can be slow or complex, limiting its potential for developers and users.The Solution The AR.IO Network builds on Arweave's permanent storage to create a decentralized, scalable access layer. It provides gateways, domain names, and indexing services, making it easy to interact with permaweb content as seamlessly as the traditional web.How It Works Decentralized Gateways: AR.IO operates a network of gateways—nodes that serve as entry points to Arweave’s data. These gateways fetch and deliver data quickly, supporting everything from static files to dynamic web apps.ArNS (Arweave Name Service): AR.IO introduces decentralized domain names (e.g., yourname.arweave), mapping human-readable names to Arweave’s data IDs. This makes content easy to find and share, like URLs on the traditional web.Indexing and Querying: AR.IO enables efficient data indexing, allowing developers to search and retrieve specific content from Arweave’s vast storage without scanning the entire blockweave.Routing and verification: AR.IO 's ar://wayfinder Protocol intelligently routes requests to available gateways in the network and verifies the data's authenticity.Observation and incentives: ARIO's Observation and Incentive Protocol (OIP), ensures gateway operators are serving the right data and rewards them in the protocol native token, $ARIO, to create a secure and self-sustaining network.In Simple Terms: Imagine Arweave as a massive, unerasable library. The AR.IO Network is the librarian who organizes the shelves, provides a catalog, and hands you the books you need—fast.Why It Matters Accessible: Gateways make permaweb content load as quickly as traditional websites.Discoverable: ArNS provides user-friendly domain names, simplifying navigation.Scalable: Supports growing permaweb usage, from small apps to global platforms.Decentralized: No single entity controls access, ensuring censorship resistance.Building on The AR.IO Network The AR.IO Network empowers developers to create permaweb apps with tools for hosting, querying, and monetizing content, all while leveraging Arweave's permanent storage.In Simple Terms: Arweave locks data forever; The AR.IO Network makes it ready for the world to use.Ready to Dive Deeper?The AR.IO Network transforms Arweave into a vibrant permaweb ecosystem. Ready to start building? Explore our comprehensive guides and start creating on the permanent web.Explore AR.IO Start Building Check out our SDKs and build guides to start creating on AR.IO Run a Gateway Learn how to deploy and operate your own AR.IO gateway ArNS Names Discover the decentralized naming system for the permaweb Gateway Architecture Understand how AR.IO gateways provide access to permanent data How is this guide?What is Arweave?Arweave is permanent information storage - a decentralized web inside an open ledger, like Bitcoin but for data What is the Permaweb?Understand how the permaweb works through its four-layer architecture: storage, compute, gateways, and applications On this page Features of The AR.IO Network Gateways Arweave Name System (ArNS) Data Access The Problem The Solution How It Works Why It Matters Building on The AR.IO Network Ready to Dive Deeper?Explore AR.IO

---

# 52. Advanced  ARIO Documentation

Document Number: 52
Source: https://docs.ar.io/build/advanced
Words: 131
Quality Score: 0.470
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Overview Explore advanced topics and specialized guides for building on Arweave and AR.IO. These resources are designed for developers and operators who need deeper technical knowledge and advanced configuration options.Advanced Topics ArFS Protocol Advanced ArFS documentation for structured data storage Normalized Addresses Understanding wallet address normalization across different networks Browser Sandboxing Security mechanisms in AR.IO gateways Key topics: - Same-origin policy EthAReum Protocol Generate Arweave wallets from Ethereum or Solana wallets Ready to Go Advanced?New to Arweave? Start with our Getting Started guide to understand the basics.Building dApps? Check out ArFS Protocol for structured data storage solutions.How is this guide?Using Turbo SDK with Vite Configure Turbo SDK in a Vite application with proper polyfills for client-side usage ArFS Protocol A decentralized file system on Arweave for structured data storage and retrieval

---

# 53. TurboAuthenticatedClient  ARIO Documentation

Document Number: 53
Source: https://docs.ar.io/sdks/turbo-sdk/turboauthenticatedclient
Words: 1522
Quality Score: 0.469
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Turbo SDKAPIsTurboAuthenticatedClientCopy MarkdownOpengetBalance()
Issues a signed request to get the credit balance of a wallet measured in AR (measured in Winston Credits, or winc).
const { winc: balance } = await turbo.getBalance();
signer.getNativeAddress()
Returns the [native address][docs/native-address] of the connected signer.
const address = await turbo.signer.getNativeAddress();
getWincForFiat()
Returns the current amount of Winston Credits including all adjustments for the provided fiat currency, amount, and optional promo codes.
const { winc, paymentAmount, quotedPaymentAmount, adjustments } =
await turbo.getWincForFiat({
amount: USD(100),
promoCodes: ['MY_PROMO_CODE'], // promo codes require an authenticated client
});
createCheckoutSession()
Creates a Stripe checkout session for a Turbo Top Up with the provided amount, currency, owner, and optional promo codes. The returned URL can be opened in the browser, all payments are processed by Stripe. Promo codes require an authenticated client.
const { url, winc, paymentAmount, quotedPaymentAmount, adjustments } =
await turbo.createCheckoutSession({
amount: USD(10.0), // $10.00 USD
owner: publicArweaveAddress,
promoCodes: ['MY_PROMO_CODE'], // promo codes require an authenticated client
});
// open checkout session in a browser
window.open(url, '_blank');
upload()
The easiest way to upload data to Turbo. The signal is an optional [AbortSignal] that can be used to cancel the upload or timeout the request. dataItemOpts is an optional object that can be used to configure tags, target, and anchor for the data item upload.
const uploadResult = await turbo.upload({
data: 'The contents of my file!',
signal: AbortSignal.timeout(10_000), // cancel the upload after 10 seconds
dataItemOpts: {
// optional
},
events: {
// optional
},
});
uploadFile()
Signs and uploads a raw file. There are two ways to provide the file to the SDK:
Using a file parameter
Using a fileStreamFactory and fileSizeFactory
Using file`
In Web with a file input:
const selectedFile = e.target.files[0];
const uploadResult = await turbo.uploadFile({
file: selectedFile,
dataItemOpts: {
tags: [{ name: 'Content-Type', value: 'text/plain' }],
},
events: {
onUploadProgress: ({ totalBytes, processedBytes }) => {
console.log('Upload progress:', { totalBytes, processedBytes });
},
onUploadError: (error) => {
console.log('Upload error:', { error });
},
onUploadSuccess: () => {
console.log('Upload success!');
},
},
});
In NodeJS with a file path:
const filePath = path.join(__dirname, './my-unsigned-file.txt');
const fileSize = fs.stateSync(filePath).size;
const uploadResult = await turbo.uploadFile({
file: filePath,
dataItemOpts: {
tags: [{ name: 'Content-Type', value: 'text/plain' }],
},
});
Using fileStreamFactoryandfileSizeFactory
Note: The provided fileStreamFactory should produce a NEW file data stream each time it is invoked. The fileSizeFactory is a function that returns the size of the file. The signal is an optional [AbortSignal] that can be used to cancel the upload or timeout the request. dataItemOpts is an optional object that can be used to configure tags, target, and anchor for the data item upload.
const filePath = path.join(__dirname, './my-unsigned-file.txt');
const fileSize = fs.stateSync(filePath).size;
const uploadResult = await turbo.uploadFile({
fileStreamFactory: () => fs.createReadStream(filePath),
fileSizeFactory: () => fileSize,
});
By default, the Turbo upload methods will split files that are larger than 10 MiB into chunks and send them to the upload service multi-part endpoints. This behavior can be customized with the following inputs:
chunkByteCount: The maximum size in bytes for each chunk. Must be between 5 MiB and 500 MiB. Defaults to 5 MiB.
maxChunkConcurrency: The maximum number of chunks to upload concurrently. Defaults to 5. Reducing concurrency will slow down uploads, but reduce memory utilization and serialize network calls. Increasing it will upload faster, but can strain available resources.
chunkingMode: The chunking mode to use. Can be 'auto', 'force', or 'disabled'. Defaults to 'auto'. Auto behavior means chunking is enabled if the file would be split into at least three chunks.
maxFinalizeMs: The maximum time in milliseconds to wait for the finalization of all chunks after the last chunk is uploaded. Defaults to 1 minute per GiB of the total file size.
// Customize chunking behavior
await turbo.upload({
...params,
chunkByteCount: 1024 * 1024 * 500, // Max chunk size
maxChunkConcurrency: 1, // Minimize concurrency
});
// Disable chunking behavior
await turbo.upload({
...params,
chunkingMode: 'disabled',
});
// Force chunking behavior
await turbo.upload({
...params,
chunkingMode: 'force',
});
On Demand Uploads
With the upload methods, you can choose to Top Up with selected crypto token on demand if the connected wallet does not have enough credits to complete the upload.
This is done by providing the OnDemandFunding class to the fundingMode parameter on upload methods. The maxTokenAmount (optional) is the maximum amount of tokens in the token type's smallest unit value (e.g: Winston for arweave token type) to fund the wallet with. The topUpBufferMultiplier (optional) is the multiplier to apply to the estimated top-up amount to avoid underpayment during on-demand top-ups due to price fluctuations on longer uploads. Defaults to 1.1, meaning a 10% buffer.
Note: On demand API currently only available for ARIO(‘ario‘),ARIO (ario), ARIO(‘ario‘),SOL (solana), and $ETH on Base Network (base-eth) token types.
const turbo = TurboFactory.authenticated({
signer: arweaveSignerWithARIO,
token: 'ario',
});
await turbo.upload({
...params,
fundingMode: new OnDemandFunding({
maxTokenAmount: ARIOToTokenAmount(500), // Max 500 $ARIO
topUpBufferMultiplier: 1.1, // 10% buffer to avoid underpayment
}),
});
uploadFolder()
Signs and uploads a folder of files. For NodeJS, the folderPath of the folder to upload is required. For the browser, an array of files is required. The dataItemOpts is an optional object that can be used to configure tags, target, and anchor for the data item upload. The signal is an optional [AbortSignal] that can be used to cancel the upload or timeout the request. The maxConcurrentUploads is an optional number that can be used to limit the number of concurrent uploads. The throwOnFailure is an optional boolean that can be used to throw an error if any upload fails. The manifetions is an optional object that can be used to configure the manifest file, including a custom index file, fallback file, or whether to disable manifests altogether. Manifests are enabled by default.
const folderPath = path.join(__dirname, './my-folder');
const { manifest, fileResponses, manifestResponse } = await turbo.uploadFolder({
folderPath,
dataItemOpts: {
// optional
tags: [
{
// User defined content type will overwrite file content type
name: 'Content-Type',
value: 'text/plain',
},
{
name: 'My-Custom-Tag',
value: 'my-custom-value',
},
],
// no timeout or AbortSignal provided
},
manifetions: {
// optional
indexFile: 'custom-index.html',
fallbackFile: 'custom-fallback.html',
disableManifests: false,
},
});
topUpWithTokens()
Tops up the connected wallet with Credits by submitting a payment transaction for the token amount to the Turbo wallet and then submitting that transaction id to Turbo Payment Service for top up processing.
The tokenAmount is the amount of tokens in the token type's smallest unit value (e.g: Winston for arweave token type) to fund the wallet with.
The feeMultiplier (optional) is the multiplier to apply to the reward for the transaction to modify its chances of being mined. Credits will be added to the wallet balance after the transaction is confirmed on the given blockchain. Defaults to 1.0, meaning no multiplier.
Arweave (AR) Crypto Top Up
const turbo = TurboFactory.authenticated({ signer, token: 'arweave' });
const { winc, status, id, ...fundResult } = await turbo.topUpWithTokens({
tokenAmount: WinstonToTokenAmount(100_000_000), // 0.0001 AR
feeMultiplier: 1.1, // 10% increase in reward for improved mining chances
});
AR.IO Network (ARIO) Crypto Top Up
const turbo = TurboFactory.authenticated({ signer, token: 'ario' });
const { winc, status, id, ...fundResult } = await turbo.topUpWithTokens({
tokenAmount: ARIOToTokenAmount(100), // 100 $ARIO
});
Ethereum (ETH) Crypto Top Up
const turbo = TurboFactory.authenticated({ signer, token: 'ethereum' });
const { winc, status, id, ...fundResult } = await turbo.topUpWithTokens({
tokenAmount: ETHToTokenAmount(0.00001), // 0.00001 ETH
});
Polygon (POL / MATIC) Crypto Top Up
const turbo = TurboFactory.authenticated({ signer, token: 'pol' });
const { winc, status, id, ...fundResult } = await turbo.topUpWithTokens({
tokenAmount: POLToTokenAmount(0.00001), // 0.00001 POL
});
Eth on Base Network Crypto Top Up
const turbo = TurboFactory.authenticated({ signer, token: 'base-eth' });
const { winc, status, id, ...fundResult } = await turbo.topUpWithTokens({
tokenAmount: ETHToTokenAmount(0.00001), // 0.00001 ETH bridged on Base Network
});
Solana (SOL) Crypto Top Up
const turbo = TurboFactory.authenticated({ signer, token: 'solana' });
const { winc, status, id, ...fundResult } = await turbo.topUpWithTokens({
tokenAmount: SOLToTokenAmount(0.00001), // 0.00001 SOL
});
KYVE Crypto Top Up
const turbo = TurboFactory.authenticated({ signer, token: 'kyve' });
const { winc, status, id, ...fundResult } = await turbo.topUpWithTokens({
tokenAmount: KYVEToTokenAmount(0.00001), // 0.00001 KYVE
});
shareCredits()
Shares credits from the connected wallet to the provided native address and approved winc amount. This action will create a signed data item for the approval
const { approvalDataItemId, approvedWincAmount } = await turbo.shareCredits({
approvedAddress: '2cor...VUa',
approvedWincAmount: 800_000_000_000, // 0.8 Credits
expiresBySeconds: 3600, // Credits will expire back to original wallet in 1 hour
});
revokeCredits()
Revokes all credits shared from the connected wallet to the provided native address.
const revokedApprovals = await turbo.revokeCredits({
revokedAddress: '2cor...VUa',
});
getCreditShareApprovals()
Returns all given or received credit share approvals for the connected wallet or the provided native address.
const { givenApprovals, receivedApprovals } =
await turbo.getCreditShareApprovals({
userAddress: '2cor...VUa',
});How is this guide?GoodBadTurboUnauthenticatedClientSDK for interacting with Turbo, a fast and efficient data upload service for ArweaveEventsSDK for interacting with Turbo, a fast and efficient data upload service for ArweaveOn this pagegetBalance()signer.getNativeAddress()getWincForFiat()createCheckoutSession()upload()uploadFile()Using fileUsing fileStreamFactoryandfileSizeFactory`Customize Multi-Part Upload BehaviorOn Demand UploadsuploadFolder()NodeJS Upload FolderBrowser Upload FoldertopUpWithTokens()Arweave (AR) Crypto Top UpAR.IO Network (ARIO) Crypto Top UpEthereum (ETH) Crypto Top UpPolygon (POL / MATIC) Crypto Top UpEth on Base Network Crypto Top UpSolana (SOL) Crypto Top UpKYVE Crypto Top UpshareCredits()revokeCredits()getCreditShareApprovals()

---

# 54. Data  ARIO Documentation

Document Number: 54
Source: https://docs.ar.io/apis/ar-io-node/data
Words: 169
Quality Score: 0.468
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

AR.IO Gateway Core data retrieval operations for accessing transaction and data item content. Supports manifest resolution,
range requests, caching, and verification status. These endpoints serve as the primary interface for retrieving
data from the Permaweb.Get transaction or data item content Get the content of a specified transaction or data item. Supports manifest path resolution,
range requests, and returns various informational headers about data verification and caching status.Path Parameters txId string Match ^[0-9a-zA-Z_-]{43}$ Header Parameters Range?string Byte range(s) to retrieve Match ^bytes=\d*-\d*(?:,\d*-\d*)*$ Response Body curl -X GET "https://ardrive.net/string" \
-H "Range: bytes=0-1023" Empty Empty Empty Empty Empty Get transaction or data item headers Get the headers for a specified transaction or data item without the content.
Returns the same headers as the GET request.Path Parameters txId string Match ^[0-9a-zA-Z_-]{43}$ Header Parameters Range?string Byte range(s) to check Match ^bytes=\d*-\d*(?:,\d*-\d*)*$ Response Body curl -X HEAD "https://ardrive.net/string" \
-H "Range: bytes=0-1023" Empty How is this guide?AR.IO Gateway APIs Core gateway software for accessing, caching, and querying data on Arweave ArNS GET Next Page

---

# 55. Using Turbo SDK with Nextjs  ARIO Documentation

Document Number: 55
Source: https://docs.ar.io/build/guides/using-turbo-in-a-browser/nextjs
Words: 1700
Quality Score: 0.467
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Guides Using Turbo in a Browser Using Turbo SDK with Next.js Overview This guide demonstrates how to configure the @ardrive/turbo-sdk in a Next.js application with proper polyfills for client-side usage. Next.js uses webpack under the hood, which requires specific configuration to handle Node.js modules that the Turbo SDK depends on.Polyfills: Polyfills are required when using the Turbo SDK in Next.js
applications. The SDK relies on Node.js modules like crypto, buffer,process, and stream that are not available in the browser by default.Prerequisites Next.js 13+ (with App Router or Pages Router) Node.js 18+ Basic familiarity with Next.js configuration Install the main Turbo SDK package:npm install @ardrive/turbo-sdk Add required polyfill packages for browser compatibility:npm install --save-dev crypto-browserify stream-browserify process buffer Wallet Integration Dependencies: The Turbo SDK includes @dha-team/arbundles as a peer dependency, which provides the necessary
signers for browser wallet integration (like InjectedEthereumSigner and ArconnectSigner). You can import these directly without additional
installation.Create or update your next.config.js file to include the necessary polyfills:/** @type {import('next').NextConfig} */
const nextConfig = {
webpack: (config, { isServer }) => {
// Only configure polyfills for client-side bundles
if (!isServer) {
config.resolve.fallback = {
...config.resolve.fallback,
crypto: require.resolve("crypto-browserify"),
stream: require.resolve("stream-browserify"),
buffer: require.resolve("buffer"),
process: require.resolve("process/browser"),
fs: false,
net: false,
tls: false,
};
// Provide global process and Buffer
config.plugins.push(
new config.webpack.ProvidePlugin({
process: "process/browser",
Buffer: ["buffer", "Buffer"],
})
);
}
return config;
},
};
module.exports = nextConfig;If you're using TypeScript, update your tsconfig.json to include proper module resolution:{
"compilerOptions": {
"moduleResolution": "bundler",
"lib": ["es2015", "dom", "dom.iterable"]
// ... other options
}
} TypeScript Wallet Types Create a types/wallet.d.ts file to properly type wallet objects:// types/wallet.d.ts
interface Window {
ethereum?: {
request: (args: { method: string; params?: any[] }) => Promise;
on?: (event: string, handler: (...args: any[]) => void) => void;
removeListener?: (event: string, handler: (...args: any[]) => void) => void;
isMetaMask?: boolean;
};
arweaveWallet?: {
connect: (permissions: string[]) => Promise;
disconnect: () => Promise;
getActiveAddress: () => Promise;
getPermissions: () => Promise;
sign: (transaction: any) => Promise;
getPublicKey: () => Promise;
};
} Select between MetaMask or Wander wallet integration:Create a React component for MetaMask wallet integration:"use client";
import { TurboFactory } from "@ardrive/turbo-sdk/web";
import { InjectedEthereumSigner } from "@dha-team/arbundles";
import { useState, useCallback } from "react";
export default function MetaMaskUploader() {
const [connected, setConnected] = useState(false);
const [address, setAddress] = useState("");
const [uploading, setUploading] = useState(false);
const [uploadResult, setUploadResult] = useState(null);
const connectMetaMask = useCallback(async () => {
try {
if (!window.ethereum) {
alert("MetaMask is not installed!");
return;
}
// Request account access
await window.ethereum.request({
method: "eth_requestAccounts",
});
// Get the current account
const accounts = await window.ethereum.request({
method: "eth_accounts",
});
if (accounts.length > 0) {
setAddress(accounts[0]);
setConnected(true);
// Log current chain for debugging
const chainId = await window.ethereum.request({
method: "eth_chainId",
});
console.log("Connected to chain:", chainId);
}
} catch (error) {
console.error("Failed to connect to MetaMask:", error);
}
}, []);
const uploadWithMetaMask = async (event) => {
const file = event.target.files?.[0];
if (!file || !connected) return;
setUploading(true);
try {
// Create a provider wrapper for InjectedEthereumSigner
const providerWrapper = {
getSigner: () => ({
signMessage: async (message: string | Uint8Array) => {
const accounts = await window.ethereum!.request({
method: "eth_accounts",
});
if (accounts.length === 0) {
throw new Error("No accounts available");
}
// Convert message to hex if it's Uint8Array
const messageToSign =
typeof message === "string"
? message
: "0x" +
Array.from(message)
.map((b) => b.toString(16).padStart(2, "0"))
.join("");
return await window.ethereum!.request({
method: "personal_sign",
params: [messageToSign, accounts[0]],
});
},
}),
};
// Create the signer using InjectedEthereumSigner
const signer = new InjectedEthereumSigner(providerWrapper);
const turbo = TurboFactory.authenticated({
signer,
token: "ethereum", // Important: specify token type for Ethereum
});
// Upload file with progress tracking
const result = await turbo.uploadFile({
fileStreamFactory: () => file.stream(),
fileSizeFactory: () => file.size,
dataItemOpts: {
tags: [
{ name: "Content-Type", value: file.type },
{ name: "App-Name", value: "My-Next-App" },
{ name: "Funded-By", value: "Ethereum" },
],
},
events: {
onProgress: ({ totalBytes, processedBytes, step }) => {
console.log(
`${step}: ${Math.round((processedBytes / totalBytes) * 100)}%`
);
},
onError: ({ error, step }) => {
console.error(`Error during ${step}:`, error);
console.error("Error details:", JSON.stringify(error, null, 2));
},
},
});
setUploadResult(result);
} catch (error) {
console.error("Upload failed:", error);
console.error("Error details:", JSON.stringify(error, null, 2));
alert(`Upload failed: ${error.message}`);
} finally {
setUploading(false);
}
};
return (
MetaMask Upload
{!connected ? (

Connect MetaMask

) : (


✅ Connected: {address.slice(0, 6)}...{address.slice(-4)}



Select File to Upload:



{uploading && (

🔄 Up Please confirm transaction in MetaMask

)}
{uploadResult && (


✅ Upload Successful!


Transaction ID: {uploadResult.id}


Data Size: {uploadResult.totalBytes} bytes


)}

)}
);
} Create a React component for Wander wallet integration:"use client";
import { TurboFactory, ArconnectSigner } from "@ardrive/turbo-sdk/web";
import { useState, useCallback } from "react";
export default function WanderWalletUploader() {
const [connected, setConnected] = useState(false);
const [address, setAddress] = useState("");
const [uploading, setUploading] = useState(false);
const [uploadResult, setUploadResult] = useState(null);
const connectWanderWallet = useCallback(async () => {
try {
if (!window.arweaveWallet) {
alert("Wander wallet is not installed!");
return;
}
// Required permissions for Turbo SDK
const permissions = [
"ACCESS_ADDRESS",
"ACCESS_PUBLIC_KEY",
"SIGN_TRANSACTION",
"SIGNATURE",
];
// Connect to wallet
await window.arweaveWallet.connect(permissions);
// Get wallet address
const walletAddress = await window.arweaveWallet.getActiveAddress();
setAddress(walletAddress);
setConnected(true);
} catch (error) {
console.error("Failed to connect to Wander wallet:", error);
}
}, []);
const uploadWithWanderWallet = async (event) => {
const file = event.target.files?.[0];
if (!file || !connected) return;
setUploading(true);
try {
// Create ArConnect signer using Wander wallet
const signer = new ArconnectSigner(window.arweaveWallet);
const turbo = TurboFactory.authenticated({ signer });
// Note: No need to specify token for Arweave as it's the default
// Upload file with progress tracking
const result = await turbo.uploadFile({
fileStreamFactory: () => file.stream(),
fileSizeFactory: () => file.size,
dataItemOpts: {
tags: [
{ name: "Content-Type", value: file.type },
{ name: "App-Name", value: "My-Next-App" },
{ name: "Funded-By", value: "Arweave" },
],
},
events: {
onProgress: ({ totalBytes, processedBytes, step }) => {
console.log(
`${step}: ${Math.round((processedBytes / totalBytes) * 100)}%`
);
},
onError: ({ error, step }) => {
console.error(`Error during ${step}:`, error);
},
},
});
setUploadResult(result);
} catch (error) {
console.error("Upload failed:", error);
alert(`Upload failed: ${error.message}`);
} finally {
setUploading(false);
}
};
return (
Wander Wallet Upload
{!connected ? (

Connect Wander Wallet

) : (


✅ Connected: {address.slice(0, 6)}...{address.slice(-4)}



Select File to Upload:



{uploading && (

🔄 Up Please confirm transaction in Wander wallet

)}
{uploadResult && (


✅ Upload Successful!


Transaction ID: {uploadResult.id}


Data Size: {uploadResult.totalBytes} bytes


)}

)}
);
} Common Issues and Solutions Build Errors If you encounter build errors related to missing modules:"Module not found: Can't resolve 'fs'" Ensure fs: false is set in your webpack fallback configuration "process is not defined" Make sure you have the ProvidePlugin configuration for process "Buffer is not defined" Verify the Buffer polyfill is properly configured in ProvidePlugin Runtime Errors "crypto.getRandomValues is not a function" This usually indicates the crypto polyfill isn't working. Double-check your webpack configuration."TypeError: e.startsWith is not a function" This indicates incorrect signer usage. For MetaMask integration, use InjectedEthereumSigner from @dha-team/arbundles, not EthereumSigner.EthereumSigner expects a private key string, while InjectedEthereumSigner expects a provider wrapper."No accounts available" during wallet operations Ensure the wallet is properly connected before attempting operations Add validation to check account availability after connection Message signing failures with wallets For InjectedEthereumSigner, ensure your provider wrapper correctly implements the getSigner() method Handle both string and Uint8Array message types in your signMessage implementation Use MetaMask's personal_sign method with proper parameter formatting Server-side rendering issues Always use 'use client' directive for components that use the Turbo SDK Consider dynamic imports with ssr: false for complex cases:import dynamic from "next/dynamic";
const TurboUploader = dynamic(() => import("./TurboUploader"), {
ssr: false,
});Wallet Integration Issues Incorrect Signer Import // ❌ INCORRECT - For Node environments
import { EthereumSigner } from "@ardrive/turbo-sdk/web";
// ✅ CORRECT - For browser wallets
import { InjectedEthereumSigner } from "@dha-team/arbundles";Provider Interface Mismatch // ❌ INCORRECT - window.ethereum doesn't have getSigner()
const signer = new InjectedEthereumSigner(window.ethereum);
// ✅ CORRECT - Use a provider wrapper
const providerWrapper = {
getSigner: () => ({
signMessage: async (message: string | Uint8Array) => {
// Implementation here
},
}),
};
const signer = new InjectedEthereumSigner(providerWrapper);Missing Dependencies If you encounter import errors for @dha-team/arbundles, note that it's available as a peer dependency through @ardrive/turbo-sdk. You may need to ensure it's properly resolved in your build process.Best Practices Use Client Components: Always mark components using the Turbo SDK with 'use client' Error Handling: Implement proper error handling for network requests and wallet interactions Environment Variables: Store sensitive configuration in environment variables:// next.config.js
const nextConfig = {
env: {
TURBO_UPLOAD_URL: process.env.TURBO_UPLOAD_URL,
TURBO_PAYMENT_URL: process.env.TURBO_PAYMENT_URL,
},
// ... webpack config
};Bundle Size: Consider code splitting for large applications to reduce bundle size Wallet Security:Never expose private keys in client-side code Always use browser wallet integrations (MetaMask, Wander, etc.) Request only necessary permissions from wallets Validate wallet connections before use Handle wallet disconnection gracefully Production Deployment Checklist For production deployments:Verify polyfills work correctly in your build environment Test wallet connections with various providers (Wander, MetaMask, etc.) Monitor bundle sizes to ensure polyfills don't significantly increase your app size Use environment-specific configurations for different Turbo endpoints Implement proper error boundaries for wallet connection failures Add loading states for wallet operations to improve UX Test across different browsers to ensure wallet compatibility Implementation Verification To verify your MetaMask integration is working correctly:Check Console Logs: After connecting to MetaMask, you should see:Connected to chain: 0x1 (or appropriate chain ID) Test Balance Retrieval: Add this to verify your authenticated client works:// After creating authenticated turbo client
const balance = await turbo.getBalance();
console.log("Current balance:", balance);Verify Signer Setup: Your implementation should:Use InjectedEthereumSigner from @dha-team/arbundles Include a proper provider wrapper with getSigner() method Handle both string and Uint8Array message types Use MetaMask's personal_sign method Common Success Indicators:No TypeError: e.startsWith is not a function errors Successful wallet connection and address dis Ability to fetch balance without errors Upload operations work with proper MetaMask transaction prompts Additional Resources Turbo SDK Documentation Web Usage Examples Next.js Webpack Configuration ArDrive Examples Repository For more examples and advanced usage patterns, refer to the Turbo SDK examples directory or the main SDK documentation.How is this guide?Using Turbo SDK with Vanilla HTML Integrate Turbo SDK directly into vanilla HTML pages using CDN imports Using Turbo SDK with Vite Configure Turbo SDK in a Vite application with proper polyfills for client-side usage

---

# 56. TurboFactory  ARIO Documentation

Document Number: 56
Source: https://docs.ar.io/sdks/turbo-sdk/turbofactory
Words: 195
Quality Score: 0.465
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Turbo SDK APIs unauthenticated() Creates an instance of a client that accesses Turbo's unauthenticated services.const turbo = TurboFactory.unauthenticated();authenticated() Creates an instance of a client that accesses Turbo's authenticated and unauthenticated services. Requires either a signer, or private key to be provided.Arweave JWK const jwk = await arweave.crypto.generateJWK();
const turbo = TurboFactory.authenticated({ privateKey: jwk });ArweaveSigner const signer = new ArweaveSigner(jwk);
const turbo = TurboFactory.authenticated({ signer });ArconnectSigner const signer = new ArconnectSigner(window.arweaveWallet);
const turbo = TurboFactory.authenticated({ signer });EthereumSigner const signer = new EthereumSigner(privateKey);
const turbo = TurboFactory.authenticated({ signer });Ethereum Private Key const turbo = TurboFactory.authenticated({
privateKey: ethHexadecimalPrivateKey,
token: 'ethereum',
});POL (MATIC) Private Key const turbo = TurboFactory.authenticated({
privateKey: ethHexadecimalPrivateKey,
token: 'pol',
});HexSolanaSigner const signer = new HexSolanaSigner(bs58.encode(secretKey));
const turbo = TurboFactory.authenticated({ signer });Solana Secret Key const turbo = TurboFactory.authenticated({
privateKey: bs58.encode(secretKey),
token: 'solana',
});KYVE Private Key const turbo = TurboFactory.authenticated({
privateKey: kyveHexadecimalPrivateKey,
token: 'kyve',
});KYVE Mnemonic import { privateKeyFromKyveMnemonic } from '@ardrive/turbo-sdk';
const turbo = TurboFactory.authenticated({
privateKey: privateKeyFromKyveMnemonic(mnemonic),
token: 'kyve',
});How is this guide?Turbo SDK JavaScript/TypeScript SDK for uploading data to Arweave via Turbo services with built-in payment handling and optimized performance TurboUnauthenticatedClient SDK for interacting with Turbo, a fast and efficient data upload service for Arweave

---

# 57. Introduction  ARIO Documentation

Document Number: 57
Source: https://docs.ar.io/sdks
Words: 220
Quality Score: 0.464
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Build powerful applications with our comprehensive suite of SDKs designed for the AR.IO ecosystem.Upload data with the Turbo SDK High-performance data upload service for Arweave with instant confirmation and transparent pricing Interact with the AR.IO Network using the AR.IO SDK Access AR.IO Network protocols, manage ArNS names, interact with ANTs, and integrate gateway services Decentralized access with Wayfinder SDK Robust, censorship-resistant access to Arweave data through the distributed AR.IO gateway network Choose Your SDK Each SDK serves a specific purpose in the AR.IO ecosystem:Turbo SDK - For applications that need fast, reliable data uploads to Arweave AR.IO SDK - For interacting with AR.IO Network smart contracts and services Wayfinder SDK - For decentralized data access with built-in verification and gateway routing All SDKs are available for both Node.js and browser environments, with TypeScript support included.Next Steps Quick Start - Upload Data Get started quickly by uploading your first file using the Turbo SDK Quick Start - Access Data Learn how to retrieve and query data using our access tools API Reference Explore detailed API documentation for all available endpoints Join the Community Connect with other developers building on AR.IO How is this guide?AR.IO SDK JavaScript/TypeScript SDK for interacting with the AR.IO Network, including ArNS name management, gateway interactions, and AO contract operations On this page Choose Your SDK Next Steps

---

# 58. Using Turbo in a Browser  ARIO Documentation

Document Number: 58
Source: https://docs.ar.io/build/guides/using-turbo-in-a-browser
Words: 252
Quality Score: 0.463
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Guides Using Turbo in a Browser Integrate the Turbo SDK directly into your web applications for fast, reliable data uploads to Arweave. Choose the approach that best fits your development workflow and framework preferences.What You Can Build With Turbo SDK in browsers, you can:Upload files directly from web applications to Arweave Pay with different tokens (AR, Ethereum, and more) Integrate with popular wallets (MetaMask, Wander, ArConnect) Build permanent web apps that store data on Arweave Create data marketplaces and decentralized applications Getting Started Vanilla HTML Start with the simplest approach - no build tools required Key topics:CDN imports for instant setup Wallet integration examples Production deployment considerations Error handling and troubleshooting Next.js Full-stack React applications with server-side rendering Key topics:Webpack polyfill configuration Client-side component setup TypeScript integration Production optimization Vite Fast development with modern build tools Key topics:Vite plugin configuration React and TypeScript setup Hot module replacement Bundle optimization Why Use Turbo SDK?Fast uploads - Upload data to Arweave in seconds, not minutes Multiple payment options - Pay with AR, Ethereum, or other supported tokens Wallet integration - Seamlessly connect with popular browser wallets Reliable infrastructure - Built on Arweave's permanent storage network Developer-friendly - Simple APIs with comprehensive documentation How is this guide?Crossmint NFT Minting App Build a decentralized NFT minting app with Arweave and Crossmint Using Turbo SDK with Vanilla HTML Integrate Turbo SDK directly into vanilla HTML pages using CDN imports On this page Using Turbo in a Browser What You Can Build Getting Started Why Use Turbo SDK?

---

# 59. Staking  ARIO Documentation

Document Number: 59
Source: https://docs.ar.io/learn/token/staking
Words: 853
Quality Score: 0.463
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Token Overview Staking tokens within the AR.IO Network serves a dual primary purpose: it signifies a public commitment by gateway operators and qualifies them and their delegates for reward distributions.In the AR.IO ecosystem, "staking" refers to the process of locking a specified amount of ARIO tokens into a protocol-controlled vault. This act signifies an opportunity cost for the staker, acting both as a motivator and a public pledge to uphold the network's collective interests. Once staked, tokens remain locked until the staker initiates an 'unstake / withdraw' action or reaches the end of the vault’s lock period.It is important to note that the ARIO Token is non-inflationary, distinguishing the AR.IO Network's staking mechanism from yield-generation tools found in other protocols. Staking in this context is about eligibility for potential rewards rather than direct token yield. By staking tokens, gateway operators (and their delegates) demonstrate their commitment to the network, thereby gaining eligibility for protocol-driven rewards and access to the network’s shared resources. Gateway Staking A gateway operator must stake tokens to join their gateway to the network, which not only makes them eligible for protocol rewards but also promotes network reliability. This staking requirement reassures users and developers of the gateway's commitment to the network’s objectives, and gateways that adhere to or surpass network performance standards become eligible for these rewards. Gateway operators may increase their stake above the minimum, known as excess stake. A gateway’s total stake is impacted the following epoch once excess stake is added or removed.Delegated Staking To promote participation from a wider audience, the network allows anyone with available ARIO tokens to partake in delegated staking. Users can choose to take part in the risk and rewards of gateway operations by staking their tokens with an active gateway (or multiple gateways) through an act known as delegating. Delegators can select which gateways to stake with in gateways.ar.io - maximize their potential rewards based on operator performance, stakes, and weights How Delegated Staking Works Delegated staking allows you to participate in the AR.IO Network's reward system without running your own gateway. By staking your ARIO tokens on existing gateways, you can earn rewards while supporting network infrastructure.When you delegate stake to a gateway, you're essentially lending your tokens to increase that gateway's total stake. This increases the gateway's chances of being selected as an observer, which means more potential rewards for both the gateway operator and you as a delegator.Benefits Passive Income: Earn rewards without running infrastructure Network Participation: Support the AR.IO Network's growth Flexibility: Redelegate to different gateways as conditions change Low Barrier to Entry: No technical expertise required Transparent Rewards: Clear visibility into reward distribution Getting Started Get ARIO Tokens You'll need ARIO tokens to delegate. See our comprehensive guide on How to Get ARIO Tokens for detailed information about acquiring tokens through exchanges, swaps, and network participation.Choose a Gateway Research gateways on the Gateway Portal to find one that matches your preferences for reward sharing and performance. Look for gateways with strong uptime, competitive reward sharing percentages, and reliable operation history.Delegate Your Stake Use the Gateway Portal to delegate your tokens. The process is straightforward and your tokens remain secure throughout.Important Considerations Gateway Performance: Your rewards depend on the gateway's performance and observer selection Reward Sharing: Gateway operators set the percentage of rewards shared with delegators Redelegation: You can move your stake between gateways as network conditions change Withdrawal Delays: There may be delays when withdrawing your delegated stake Stake Redelegation This feature enables existing stakers to reallocate their staked tokens between gateways, known as redelegation. Both delegated stakers and gateway operators with excess stake (stake above the minimum network-join requirement) can take advantage of this feature. Redelegation is intended to offer users flexibility and the ability to respond to changing network conditions.Redeeming Delegated Stake for ArNS Staked tokens generally have restricted liquidity to maintain a healthy degree of stability in the network. However, an exception to these restrictions allows delegated stakers to use their staked tokens for specific ArNS-related services. By leveraging their staking rewards, delegates can further engage with ArNS, strengthening the name system’s utilization and impact across the network.Expedited Withdrawal Fees Gateway operators and delegated stakers can shorten the standard withdrawal delay period after initiating a withdrawal (or being placed into an automatic withdrawal by protocol mechanisms); this action is subject to a dynamic fee. At any point during the delay, users can choose to expedite access to their pending withdrawal tokens by paying a fee to the protocol balance, calculated based on how much sooner they want to receive their funds. Once triggered, the tokens are returned immediately to the user’s wallet.Explore Staking Delegate Stake Start staking your ARIO tokens with gateways to earn rewards Gateway Registry Learn how gateways join the network and stake requirements Observer Protocol Understand how gateway performance affects staking rewards ARIO Token Learn about the token that powers the AR.IO Network How is this guide?Architecture Explore the technical architecture of the $ARIO contract and the AR.IO Network system components Get the Token Learn how to acquire $ARIO tokens through various methods including exchanges, swaps, and network participation

---

# 60. Manage your Gateway  ARIO Documentation

Document Number: 60
Source: https://docs.ar.io/build/run-a-gateway/manage
Words: 228
Quality Score: 0.462
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Run a Gateway Master the advanced features and configurations of your AR.IO Gateway. These comprehensive guides cover everything from performance optimization to content moderation, helping you run a professional-grade gateway infrastructure.Gateway Management Importing SQLite Database Snapshots Learn how to import pre-synchronized database snapshots to quickly bootstrap your gateway and reduce initial sync time from weeks to hours.Upgrading a Gateway Step-by-step guide to safely upgrade your AR.IO Gateway to the latest version without losing data or progress.Monitoring & Analytics Monitoring with Grafana Deploy and configure Grafana for comprehensive gateway monitoring,
performance analytics, and operational insights.Performance Optimization Gateway Filters Configure advanced filters to efficiently process and index only the data you need, optimizing performance and resource usage.Setting Apex Domain Content Customize your gateway's root domain to serve custom content, project information, or documentation instead of default network info.Content Management Content Moderation Implement content moderation policies using blocklisting and filtering to
control what content your gateway serves.Configuration Reference Environment Variables Reference Comprehensive reference for all AR.IO Gateway environment variables
organized by service component.Support & Troubleshooting Gateway Troubleshooting & FAQ Comprehensive troubleshooting guide and FAQ for common gateway issues,
failed epoch guidance, and frequently asked questions.How is this guide?Join the Network Register your AR.IO Gateway with the network to start earning rewards Upgrading your Gateway Step-by-step guide to upgrading your AR.IO Gateway to the latest version safely without losing data or progress

---

# 61. Token Conversion  ARIO Documentation

Document Number: 61
Source: https://docs.ar.io/sdks/ar-io-sdk/token-conversion
Words: 115
Quality Score: 0.456
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

AR.IO SDK The ARIO process stores all values as mARIO (milli-ARIO) to avoid floating-point arithmetic issues. The SDK provides an ARIOToken and mARIOToken classes to handle the conversion between ARIO and mARIO, along with rounding logic for precision.All process interactions expect values in mARIO. If numbers are provided as inputs, they are assumed to be in raw mARIO values.Converting ARIO to mARIO import { ARIOToken, mARIOToken } from '@ar.io/sdk';
const arioValue = 1;
const mARIOValue = new ARIOToken(arioValue).toMARIO();
const mARIOValue = 1_000_000;
const arioValue = new mARIOToken(mARIOValue).toARIO();How is this guide?Static Methods TypeScript/JavaScript SDK for interacting with the AR.IO ecosystem Logging TypeScript/JavaScript SDK for interacting with the AR.IO ecosystem On this page Converting ARIO to mARIO

---

# 62. Paying for Uploads  ARIO Documentation

Document Number: 62
Source: https://docs.ar.io/build/upload/turbo-credits
Words: 512
Quality Score: 0.456
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Upload Data Turbo Credits are the payment medium used by Turbo's upload service, providing a 1:1 conversion from Arweave's native AR token with additional benefits and flexible payment options.What are Turbo Credits?Turbo Credits represent upload power on the Arweave network, divisible down to 1 trillionth of a credit (Winston Credit). Unlike traditional crypto tokens, Turbo Credits cannot be traded, transferred, or exchanged - they exist solely for uploading data to Arweave.How to Purchase Credits Payment Methods Fiat Currency: Credit/debit cards via Stripe Crypto Tokens: AR, ETH, SOL, MATIC, ARIO, USDC, KYVE, ETH (BASE) Multiple Wallets: Ethereum, Solana, and Arweave wallets supported Supported Tokens & Purchase Methods Payment Method Turbo SDK Turbo CLI Turbo API Top Up App ArDrive App Fiat (credit/debit card) ✅ ✅ ✅ ✅ ✅ AR ✅ ✅ ✅ ✅ ❌ ETH ✅ ✅ ✅ ✅ ❌ SOL ✅ ✅ ✅ ✅ ❌ MATIC ✅ ✅ ✅ ❌ ❌ KYVE ✅ ✅ ✅ ❌ ❌ ETH (BASE) ✅ ✅ ✅ ❌ ❌ ARIO ✅ ✅ ✅ ❌ ❌ USDC ❌ ✅ ✅ ❌ ❌ Purchase Options Option 1: Turbo Top Up App Visit turbo-topup.com Purchase with USD or AR tokens Credits can be purchased into Ethereum or Solana wallets Option 2: ArDrive App Use ArDrive for simple purchases Buy credits with USD directly in the app Perfect for occasional users Option 3: Turbo SDK/CLI // Purchase credits programmatically
const fundResult = await turbo.topUpWithTokens({
tokenAmount: TOKEN_AMOUNT,
tokenType: "solana", // or 'ethereum', 'matic', 'arweave'
});
// Check your balance
const balance = await turbo.getBalance();
console.log(`Balance: ${balance.winc} Winston Credits`);Credit Sharing Turbo Credits can be shared with other users without transferring ownership, perfect for organizations and teams.How Credit Sharing Works Authorize Users: Grant specific wallets access to your credits Set Limits: Control how much each user can spend Time Limits: Set expiration dates for access Revoke Anytime: Regain control of shared credits instantly Use Cases Organizational Funds: Central wallet shares credits with employees Onboarding: Give new users free upload power for trials Collaboration: Share credits with project contributors Educational Programs: Provide students with controlled access Pricing & Fees 23.4% fee applied to credit purchases (covers infrastructure and benefits) No additional fees when using credits for uploads Same value per GiB as AR regardless of price fluctuations Subsidized uploads under 100 KiB are completely free Getting Started Ready to start using Turbo Credits? Choose your path:Purchase Credits Buy credits instantly with credit cards or crypto Start Uploading Learn how to upload data with your new credits Turbo SDK Integrate credit sharing and advanced features Next Steps Getting Started with Turbo Complete upload guide with Turbo.Tagging Your Data Organize with metadata and tags.Understanding Manifests Create folder structures with manifests.How is this guide?Advanced Uploading with Turbo Learn how to upload data to Arweave using the Turbo SDK, including authentication, purchasing credits, and file uploads Tagging Understanding metadata and tagging for organized data storage On this page What are Turbo Credits?How to Purchase Credits Payment Methods Supported Tokens & Purchase Methods Purchase Options Credit Sharing How Credit Sharing Works Use Cases Pricing & Fees Getting Started Next Steps

---

# 63. What is Arweave  ARIO Documentation

Document Number: 63
Source: https://docs.ar.io/learn/what-is-arweave
Words: 568
Quality Score: 0.456
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Introduction Arweave is a decentralized storage network that ensures data is permanent, affordable, and scalable. Think of it as a global, tamper-proof hard drive where your files—photos, documents, or apps—stay accessible forever. It's the foundation for the AR.IO Network, powering a "permaweb" where data never disappears.Below, we break down Arweave's core features in a simple, beginner-friendly way.A Datachain for Permanent Storage Arweave is like Bitcoin, but for data. It solves one problem really well: storing data permanently. Once uploaded, your data—whether a tweet, NFT, or website—is immutable and preserved indefinitely.How Does It Work?Blockweave Architecture: Unlike a blockchain's single chain, Arweave's blockweave links each new data block to the previous one and a random older block. Data is split into 256 KiB chunks in a secure Merkle tree, ensuring miners keep all data to add new blocks.Succinct Proofs of Random Access (SPoRA): Miners prove they store multiple data copies by accessing random chunks, verified efficiently with Verifiable Delay Functions (VDFs). This combines proof-of-work and proof-of-storage, making data loss nearly impossible.In Simple Terms: Picture a library where new books reference older ones, and librarians must keep every book to add more. SPoRA ensures they prove they’ve got the books, keeping your data safe forever.Pay Once, Store Forever: No Recurring Fees Pay a one-time fee to upload data, and it's stored "forever"—no subscriptions or renewals.How Does It Work?Endowment Fund: Your fee, based on 200 years of storage for 20 replicas, goes mostly into a fund that slowly pays miners in AR tokens to maintain data. It assumes storage costs drop over time, making the fund sustainable.In Simple Terms: It's a “forever stamp” for data. Your payment funds a pot that keeps paying storage keepers, lasting longer as tech gets cheaper.Practically Unlimited Storage Arweave can practically store unlimited data, from small files to entire digital archives, without hitting a ceiling. The theoretical limit is 2^256 bytes which for scale is more atoms than there are in the universe.How Does It Work?Layer 1 Transactions: Data is stored as 256 KiB chunks on the blockweave, replicated across many nodes. As more nodes join with standard hardware, storage capacity grows limitlessly.Bundling with AR.IO Network and Turbo: Bundling packs multiple files into one transaction, reducing costs and congestion. AR.IO Network and Turbo (a Layer 2 tool) optimize this, enabling fast, cheap uploads of large datasets like websites.What Arweave doesn't solve well? Access Arweave solve's one problem and solve's it well. Storing your data for a very long-time.It doesn't, however, incentivise the indexing and access for data.Ready to Dive Deeper?Arweave powers a permaweb where apps, websites and data live forever. For AR.IO Network developers, it's the bedrock for unpable decentralized applications. Learn more in the next section: What is AR.IO Network.Explore Arweave What is AR.IO?Learn how AR.IO provides the gateway layer for accessing permanent data The Permaweb Understand the permanent web architecture powered by Arweave Upload Data Start storing your data permanently on Arweave Access Data Learn how to retrieve and query permanent data How is this guide?Introduction Build on the permanent web with AR.IO's decentralized gateway protocol for Arweave What is AR.IO?AR.IO is the world's first permanent cloud network providing infrastructure for timeless, tamper-proof, and universally accessible data On this page A Datachain for Permanent Storage How Does It Work?Pay Once, Store Forever: No Recurring Fees How Does It Work?Practically Unlimited Storage How Does It Work?What Arweave doesn't solve well? Access Ready to Dive Deeper?Explore Arweave

---

# 64. ArNS Marketplace  ARIO Documentation

Document Number: 64
Source: https://docs.ar.io/build/guides/arns-marketplace
Words: 550
Quality Score: 0.455
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Build Guides ArNS tokens have the potential to be traded and sold in decentralized marketplaces. ANTs (Arweave Name Tokens) are both smart contracts and transferable tokens, making them valuable digital assets that could be bought, sold, and traded. However, no established marketplace has yet emerged as the preferred platform for ArNS trading.Current State of ArNS Trading No established marketplace exists yet - While ANTs are technically transferable tokens, there is currently no widely adopted marketplace specifically for ArNS trading.Direct transfers are possible - You can transfer ANTs directly between wallets, but this requires technical knowledge and direct coordination between buyer and seller.Future potential - As the ArNS ecosystem grows, dedicated marketplaces may emerge to facilitate easier trading of ArNS tokens and domains.What Are ANTs?Arweave Name Tokens (ANTs) are:Smart contracts - Define the rules and functionality of your domain Transferable tokens - Can be bought, sold, and traded Digital assets - Represent ownership of ArNS domains Permanent - Stored on Arweave forever How Trading Could Work 1. Token Ownership When you own an ANT:You control the domain name You can update where it points You can transfer ownership You could potentially sell it to others 2. Potential Marketplace Dynamics Possible trading mechanisms:Direct transfers - Send tokens directly to another wallet Marketplace platforms - Use dedicated trading platforms (when available) Auction systems - Bid on available domains (when implemented) Fixed price sales - Set a price and wait for buyers (when supported) 3. Name Characteristics What makes ANTs desirable:Domain length - Shorter names are more memorable Memorability - Easy-to-remember names are more useful Brand potential - Names that could become recognizable Uniqueness - Creative and distinctive names Content attached - Domains with established content Potential Trading Examples Popular Domain Types Short names:ar://ai - Single letter domains ar://web3 - Industry keywords ar://nft - Popular terms Brandable names:ar://crypto - Industry terms ar://decentralized - Descriptive names ar://permanent - Arweave-related terms Potential Use Cases Personal branding - Use memorable names for your identity Project organization - Create names for different projects Content management - Organize content under specific names Community building - Create recognizable names for communities Getting Started 1. Acquire ANTs Ways to get ANTs:Register new domains - Create your own primary names Buy from others - Purchase existing domains Participate in auctions - Bid on available names Trade with others - Exchange domains you own 2. Choose Names Consider these factors:Domain length - Shorter names are more memorable Memorability - Easy to remember and type Brand potential - Could become recognizable Current content - What's already attached to the domain Personal preference - What fits your needs and style 3. Trade Safely Best practices:Verify ownership - Confirm the seller owns the domain Check domain status - Ensure it's not expired or locked Use escrow services - Protect both buyer and seller Document transfers - Keep records of all transactions Benefits Transferable ownership - Move domains between wallets Creative expression - Own and manage creative domain names Community participation - Engage with the ArNS ecosystem Content organization - Structure your permanent web presence Identity management - Use names for personal or project identity Ready to Trade?Create Domains Learn about ArNS Primary Names for domain creation.Host Websites Check out hosting decentralized websites for content creation.Technical Details Explore the ArNS documentation for advanced features.How is this guide?

---

# 65. Static Methods  ARIO Documentation

Document Number: 65
Source: https://docs.ar.io/sdks/ar-io-sdk/static-methods
Words: 166
Quality Score: 0.455
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

AR.IO SDK ANT Contracts ANT.fork() Forks an existing ANT process to create a new one with the same state but potentially a different module. This is used for upgrading ANTs to new versions.const newProcessId = await ANT.fork({
signer: new ArweaveSigner(jwk),
antProcessId: 'existing-ant-process-id',
// Optional: specify a specific module ID, defaults to latest from registry
module: 'new-module-id',
onSigningProgress: (event, payload) => {
console.log(`Fork progress: ${event}`);
},
});
console.log(`Forked ANT to new process: ${newProcessId}`);ANT.upgrade() Static method to upgrade an ANT by forking it to the latest version and reassigning names.// Upgrade and reassign all affiliated names
const result = await ANT.upgrade({
signer: new ArweaveSigner(jwk),
antProcessId: 'existing-ant-process-id',
reassignAffiliatedNames: true,
arioProcessId: ARIO_MAINNET_PROCESS_ID
});
// Upgrade and reassign specific names
const result = await ANT.upgrade({
signer: new ArweaveSigner(jwk),
antProcessId: 'existing-ant-process-id',
names: ['ardrive', 'example'],
reassignAffiliatedNames: false,
arioProcessId: ARIO_MAINNET_PROCESS_ID
});
console.log(`Upgraded to process: ${result.forkedProcessId}`);
console.log(`Successfully reassigned names: ${Object.keys(result.reassignedNames)}`);
console.log(`Failed reassignments: ${Object.keys(result.failedReassignedNames)}`);How is this guide?Undername Ownership TypeScript/JavaScript SDK for interacting with the AR.IO ecosystem Token Conversion TypeScript/JavaScript SDK for interacting with the AR.IO ecosystem

---

# 66. Turbo Credit Sharing  ARIO Documentation

Document Number: 66
Source: https://docs.ar.io/sdks/turbo-sdk/turbo-credit-sharing
Words: 519
Quality Score: 0.453
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Turbo SDK Users can share their purchased Credits with other users' wallets by creating Credit Share Approvals. These approvals are created by uploading a signed data item with tags indicating the recipient's wallet address, the amount of Credits to share, and an optional amount of seconds that the approval will expire in. The recipient can then use the shared Credits to pay for their own uploads to Turbo.Shared Credits cannot be re-shared by the recipient to other recipients. Only the original owner of the Credits can share or revoke Credit Share Approvals. Credits that are shared to other wallets may not be used by the original owner of the Credits for sharing or uploading unless the Credit Share Approval is revoked or expired.Approvals can be revoked at any time by similarly uploading a signed data item with tags indicating the recipient's wallet address. This will remove all approvals and prevent the recipient from using the shared Credits. All unused Credits from expired or revoked approvals are returned to the original owner of the Credits.To use the shared Credits, recipient users must provide the wallet address of the user who shared the Credits with them in the x-paid-by HTTP header when uploading data. This tells Turbo services to look for and use Credit Share Approvals to pay for the upload before using the signer's balance.For user convenience, during upload the Turbo CLI will use any available Credit Share Approvals found for the connected wallet before using the signing wallet's balance. To instead ignore all Credit shares and only use the signer's balance, use the --ignore-approvals flag. To use the signer's balance first before using Credit shares, use the --use-signer-balance-first flag. In contrast, the Turbo SDK layer does not provide this functionality and will only use approvals when paidBy is provided.The Turbo SDK provides the following methods to manage Credit Share Approvals:shareCredits: Creates a Credit Share Approval for the specified wallet address and amount of Credits.revokeCredits: Revokes all Credit Share Approvals for the specified wallet address.listShares: Lists all Credit Share Approvals for the specified wallet address or connected wallet.dataItemOpts: { ...opts, paidBy: string[] }: Upload methods now accept 'paidBy', an array of wallet addresses that have provided credit share approvals to the user from which to pay, in the order provided and as necessary, for the upload.The Turbo CLI provides the following commands to manage Credit Share Approvals:share-credits: Creates a Credit Share Approval for the specified wallet address and amount of Credits.revoke-credits: Revokes all Credit Share Approvals for the specified wallet address.list-shares: Lists all Credit Share Approvals for the specified wallet address or connected wallet.paidBy: --paid-by : Upload commands now accept '--paid-by', an array of wallet addresses that have provided credit share approvals to the user from which to pay, in the order provided and as necessary, for the upload.--ignore-approvals: Ignore all Credit Share Approvals and only use the signer's balance.--use-signer-balance-first: Use the signer's balance first before using Credit Share Approvals.How is this guide?Logging SDK for interacting with Turbo, a fast and efficient data upload service for Arweave Wayfinder SDK's Decentralized access to Arweave data with built-in verification and gateway routing

---

# 67. Glossary  ARIO Documentation

Document Number: 67
Source: https://docs.ar.io/glossary
Words: 170
Quality Score: 0.450
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

AO Computer AO (Actor Oriented) is a hyper-parallel computing platform built on Arweave that enables decentralized applications to run with unlimited computational capacity. AO provides the compute layer for the AR.IO Network's smart contracts and token operations.Public Key A cryptographic key that can be shared publicly and is used to verify digital signatures or encrypt data. In the AR.IO context, public keys are used to identify wallet addresses and verify transactions.Native Address An address format that uses the raw public key bytes directly, without additional encoding or transformation. This is the most basic form of an Arweave address.Normalized Address A standardized address format that ensures consistent representation across different systems and contexts. Normalized addresses help prevent issues with address matching and lookup operations.Optimistic Indexing A data indexing strategy where new data is immediately made available for queries while verification processes continue in the background. This approach improves performance while maintaining data integrity through eventual consistency.How is this guide?Introduction Build on the permanent web with AR.IO's decentralized gateway protocol for Arweave

---

# 68. Logging  ARIO Documentation

Document Number: 68
Source: https://docs.ar.io/sdks/ar-io-sdk/logging
Words: 359
Quality Score: 0.449
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

AR.IO SDK The library uses a lightweight console logger by default for both Node.js and web environments. The logger outputs structured JSON logs with timestamps. You can configure the log level via setLogLevel() API or provide a custom logger that satisfies the ILogger interface.Default Logger import { Logger } from '@ar.io/sdk';
// set the log level
Logger.default.setLogLevel('debug');
// Create a new logger instance with a specific level
const logger = new Logger({ level: 'debug' });Custom Logger Implementation You can provide any custom logger that implements the ILogger interface:import { ARIO, ILogger } from '@ar.io/sdk';
// Custom logger example
const customLogger: ILogger = {
info: (message, ...args) => console.log(`[INFO] ${message}`, ...args),
warn: (message, ...args) => console.warn(`[WARN] ${message}`, ...args),
error: (message, ...args) => console.error(`[ERROR] ${message}`, ...args),
debug: (message, ...args) => console.debug(`[DEBUG] ${message}`, ...args),
setLogLevel: (level) => {
/* implement level filtering */
},
};
// Use custom logger with any class
const ario = ARIO.mainnet({ logger: customLogger });
// or set it as the default logger in the entire SDK
Logger.default = customLogger;Winston Logger (Optional) For advanced logging features, you can optionally install Winston and use the provided Winston logger adapter:yarn add winston import { ARIO, WinstonLogger } from '@ar.io/sdk';
// Create Winston logger with custom configuration
const winstonLogger = new WinstonLogger({
level: 'debug',
});
// Use with any class that accepts a logger
const ario = ARIO.mainnet({ logger: winstonLogger });
// or set it as the default logger in the entire SDK
Logger.default = winstonLogger;Other Popular Loggers You can easily integrate other popular logging libraries:// Bunyan example
import { ARIO, ILogger } from '@ar.io/sdk';
import bunyan from 'bunyan';
const bunyanLogger = bunyan.createLogger({ name: 'ar-io-sdk' });
const adapter: ILogger = {
info: (message, ...args) => bunyanLogger.info({ args }, message),
warn: (message, ...args) => bunyanLogger.warn({ args }, message),
error: (message, ...args) => bunyanLogger.error({ args }, message),
debug: (message, ...args) => bunyanLogger.debug({ args }, message),
setLogLevel: (level) => bunyanLogger.level(level),
};
const ario = ARIO.mainnet({ logger: adapter });
// or set it as the default logger in the entire SDK
Logger.default = adapter;How is this guide?Token Conversion TypeScript/JavaScript SDK for interacting with the AR.IO ecosystem Pagination TypeScript/JavaScript SDK for interacting with the AR.IO ecosystem

---

# 69. Upgrading Private Drives  ARIO Documentation

Document Number: 69
Source: https://docs.ar.io/build/advanced/arfs/upgrading-drives
Words: 947
Quality Score: 0.449
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Advanced ArFS Protocol Overview Private drives rely on a combination of user-set password and a wallet signature for encryption and decryption. Wander, formerly ArConnect, is a popular Arweave wallet that is deprecating its signature() method in favor of signDataItem() or signMessage(). In order to preserve access to private drive contents that were secured via drive keys created via 'signature()', ArFS v0.15 introduces a new drive key derivation scheme that both utilizes the modern signing APIs and bridges historical drive keys for usage with it.Because private drive entities exist on chain and their encryption cannot be altered, an upgrade is required to allow continued access to "V1" private drives. This upgrade essentially takes a signature from the drive owner wallet, encrypts it using the required signature structure for V2 private drives, and places it on Arweave as a new "Drive-Signature" entity. This allows the signature to be fetched and decrypted using the latest methods before using it to decrypt the private drive in the V1 format.Deprecation Period The below instructions for upgrading a private drive will work during the deprecation period for the signature() method from Wanter. Once this period is over, and signature() loses all support, additional steps will be required to obtain the correct signature format to decrypt V1 private drives in order to upgrade them.There is, at this time, no set date for when the deprecation period will end.The Upgrade Process The upgrade process involves creating a new Drive-Signature entity that contains an encrypted version of the legacy signature needed to decrypt the private drive.Drive-Signature Entity The Drive-Signature entity stores the encrypted legacy signature:ArFS: "0.15",
Entity-Type: "drive-signature",
Signature-Format: "1",
Cipher?: "AES256-GCM",
Cipher-IV: "<12 byte initialization vector as Base64>"
{data: } Updated Drive Entity The drive entity is updated with a new Signature-Type tag: Using ArDrive The upgrade process has been made simple by using the ArDrive app.Step 1: Log into ArDrive If the connected wallet has V1 private drives that need to be updated, a banner will appear at the top of the screen. Step 2: Click "Update Now!" This will open a modal listing the drives that need to be updated, and linking to more information about the upgrade process. Step 3: Click "Update" The process of upgrading the private drives will begin, and involve signing messages depending on how many drives are being upgraded. When the process is complete, a new modal will appear listing the drives that have been successfully updated. Manual Upgrade Process If you need to upgrade drives programmatically, here's the process:1. Identify V1 Drives Query for drives that don't have the Signature-Type tag: 2. Create Drive-Signature Entity async function createDriveSignature(driveId, legacySignature) {
// Encrypt the legacy signature
const encryptedSignature = await encryptSignature(legacySignature);
// Create the drive signature entity
const driveSignature = {
data: encryptedSignature,
tags: [
{ name: "ArFS", value: "0.15" },
{ name: "Entity-Type", value: "drive-signature" },
{ name: "Signature-Format", value: "1" },
{ name: "Cipher", value: "AES256-GCM" },
{ name: "Cipher-IV", value: cipherIV },
],
};
// Upload to Arweave
return await uploadTransaction(driveSignature);
} 3. Update Drive Entity async function updateDriveEntity(driveId) {
// Get existing drive entity
const driveEntity = await getDriveEntity(driveId);
// Add Signature-Type tag
const updatedTags = [
...driveEntity.tags,
{ name: "Signature-Type", value: "1" },
];
// Create updated drive entity
const updatedDrive = {
data: driveEntity.data,
tags: updatedTags,
};
// Upload to Arweave
return await uploadTransaction(updatedDrive);
} Verification After upgrading, verify the process was successful:Check Drive-Signature Entity query ($driveId: String!) {
transactions(
tags: [
{ name: "ArFS", values: ["0.15"] }
{ name: "Entity-Type", values: ["drive-signature"] }
{ name: "Drive-Id", values: [$driveId] }
]
) {
edges {
node {
id
block {
height
timestamp
}
tags {
name
value
}
}
}
}
} Check Updated Drive Entity query ($driveId: String!) {
transactions(
tags: [
{ name: "ArFS", values: ["0.15"] }
{ name: "Entity-Type", values: ["drive"] }
{ name: "Drive-Id", values: [$driveId] }
{ name: "Signature-Type", values: ["1"] }
]
) {
edges {
node {
id
block {
height
timestamp
}
tags {
name
value
}
}
}
}
} Troubleshooting Common Issues Signature not found - Ensure the wallet supports the required signing methods Encryption errors - Verify the encryption parameters are correct Upload failures - Check network connectivity and retry Permission denied - Ensure you own the drive being upgraded Error Handling async function upgradeDrive(driveId) {
try {
// Get legacy signature
const legacySignature = await getLegacySignature(driveId);
// Create drive signature entity
await createDriveSignature(driveId, legacySignature);
// Update drive entity
await updateDriveEntity(driveId);
console.log("Drive upgraded successfully");
} catch (error) {
console.error("Upgrade failed:", error);
// Handle error appropriately
}
} Best Practices Before Upgrading Backup your data - Ensure you have access to your drive contents Test with one drive - Start with a single drive to verify the process Check wallet compatibility - Ensure your wallet supports required methods Verify ownership - Confirm you own the drives being upgraded During Upgrading Monitor progress - Keep track of upgrade status Handle errors gracefully - Implement proper error handling Batch operations - Upgrade multiple drives efficiently User feedback - Provide clear status updates After Upgrading Verify functionality - Test drive access and operations Update clients - Ensure all clients support v0.15 Monitor performance - Check for any performance issues Document changes - Keep track of upgraded drives Migration Timeline Next Steps After upgrading your drives, explore these related topics:Privacy & Encryption - Understand the new encryption scheme Reading Data - Query your upgraded drives Creating Drives - Create new v0.15 drives How is this guide?Reading Data Learn how to query and retrieve ArFS data from the Arweave network Normalized Addresses Learn about normalized addresses - how different blockchain wallet addresses are standardized into Arweave-compatible format

---

# 70. Introduction  ARIO Documentation

Document Number: 70
Source: https://docs.ar.io/learn
Words: 177
Quality Score: 0.448
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

AR.IO is the decentralized gateway protocol for Arweave. Deploy gateways, register permanent names, and build applications with enterprise-grade infrastructure that lasts forever.Explore the Documentation What is AR.IO?Learn about the decentralized gateway protocol and how it powers the permanent web Build Get started building applications, running gateways, and uploading data SDKs Integrate AR.IO services into your applications with our developer SDKs API Reference Complete API documentation for AR.IO Node and Turbo services Quick Start Guides Upload Data to Arweave Learn how to permanently store files and data using Turbo SDK Run a Gateway Deploy your own AR.IO gateway and participate in the network Register ArNS Names Get human-readable names for your permanent applications AR.IO Ecosystem Join the Community Connect with developers, gateway operators, and the AR.IO team. Get help, share ideas, and stay updated on the latest developments.Join Discord View Guides How is this guide?What is Arweave?Arweave is permanent information storage - a decentralized web inside an open ledger, like Bitcoin but for data On this page Explore the Documentation Quick Start Guides AR.IO Ecosystem Join the Community

---

# 71. Normalized Addresses  ARIO Documentation

Document Number: 71
Source: https://docs.ar.io/build/advanced/normalized-addresses
Words: 675
Quality Score: 0.448
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Advanced Overview Different blockchains use different formats for the public keys of wallets, and the native addresses for those wallets. In most cases, when a system in the Arweave ecosystem needs to dis the wallet address of a wallet from a different blockchain, for instance in the Owner.address value of an AO process spawned by an ETH wallet, that address will be normalized into the format recognized by Arweave. Specifically, a 43 character base64url representation of the sha256 hash of the public key. This is done to prevent potential errors by systems in the Arweave ecosystem that expect these values to be a certain size and conform to a specific format.Essentially, normalized addresses are a way to represent public keys and wallet addresses from other blockchains in a way that is familiar to systems in the Arweave ecosystem.A tool for easily obtaining a normalized addresses from public keys can be found at ar://normalize-my-key At A Glance Arweave ETH/POL Solana Native Address 9ODOd-_ZT9oWoRMVmmD4G5f9Z6MjvYxO3Nen-T5OXvU 0x084af408C8E492aC52dc0Ec76514A7deF8D5F03f Cd5yb4mvbuQyyJgAkriFZbWQivh2zM68KGZX8Ksn1L85 base64url Encoded Public Key 0jkGWDFYI3DHEWaXhZitjTg67T-enQwXs50lTDrMhy2qb619_91drv_50J5PwrOYJiMmYhiEA5ojMvrrAFY-Dm1bJbJfVBU1kIsPho2tFcXnbSOa2_1bovAys0ckJU07wkbmIUpzp3trdxYReB4jayMMOXWw9B8xS0v81zFmK3IbCtL9N6WNTMONOSMATHFQrGqtDhDUqKyIsQZCBPFvfGykRWaLWzbtAUrApprqG9hfExQzppNsw0gsftNSHZ1emC5tC2fuib6FhQw9TE2ge9tUjEZNALcVZvopTtTX0H2gEfnRJ48UNeV3SKggjXcoPVeivmqXuPBGncXWWq1pHR-Xs4zSLA5Mgcw_tQJc4FIER0i7hUlZXoc991ZHyOvAC-GlHWzQwvrlY11oD38pB47NkHN2WVPtUCAtyYQe5TE6Xznd9kPgqqvVUkV0s0suh5vINGoiPEnMjyhYEN7eOmJRIJ_A87IJesbdPRV4ZzBsqPbd02RG3ZuVpc3gI1xKvwH1WS05XI8eWK-BbvB3oxB7WjaQTWcfBWhMEULiwx-SucuyAzPAw3i6Wjtq61TcL9SdWhmOf9_yo-Np052tj7MQ66nmgdOH_MEKYjAdFypxTsRQoSLbv28HEcSjwx8u3pY0q0gKMK_5X2XKJrp2i2GB_fVgbcpH9YsgrYxh1Q8 2W5VMzNKYwr51QsiYBHUS5h5wxZf_uBgG7C6xiHgBHwwLUty5LHKFFBDlAxTCTAhglcmys2_HQoOj_LnCkA3 rK8XXxd8JqsZFPXVOwkSWS5Gh1SJzftfCOLpLk4i1FY Normalized Address 9ODOd-_ZT9oWoRMVmmD4G5f9Z6MjvYxO3Nen-T5OXvU 5JtuS4yOFtUX2Rg3UU7AgBaUqh4s8wyyNTZk9UrzI-Q K8kpPM1RID8ZM2sjF5mYy0rP4gXSRDbrwPUd9Qths64 Public Keys and Addresses Crypto wallets consist of two separate components. The public keys, which are public knowledge and can be seen by anyone, and the private keys, which only the owner of a wallet should have access to. Crypto wallet addresses are derived from the public key.Encoded Public Keys It is important to note that all crypto wallet public and private keys are
binary data. The values provided below for Arweave and Ethereum/Polygon public
keys are base64url and hex encoded representations of that binary data
respectively.Arweave The public key for an Arweave wallet is the n field of the JWK json file.0jkGWDFYI3DHEWaXhZitjTg67T-enQwXs50lTDrMhy2qb619_91drv_50J5PwrOYJiMmYhiEA5ojMvrrAFY-Dm1bJbJfVBU1kIsPho2tFcXnbSOa2_1bovAys0ckJU07wkbmIUpzp3trdxYReB4jayMMOXWw9B8xS0v81zFmK3IbCtL9N6WNTMONOSMATHFQrGqtDhDUqKyIsQZCBPFvfGykRWaLWzbtAUrApprqG9hfExQzppNsw0gsftNSHZ1emC5tC2fuib6FhQw9TE2ge9tUjEZNALcVZvopTtTX0H2gEfnRJ48UNeV3SKggjXcoPVeivmqXuPBGncXWWq1pHR-Xs4zSLA5Mgcw_tQJc4FIER0i7hUlZXoc991ZHyOvAC-GlHWzQwvrlY11oD38pB47NkHN2WVPtUCAtyYQe5TE6Xznd9kPgqqvVUkV0s0suh5vINGoiPEnMjyhYEN7eOmJRIJ_A87IJesbdPRV4ZzBsqPbd02RG3ZuVpc3gI1xKvwH1WS05XI8eWK-BbvB3oxB7WjaQTWcfBWhMEULiwx-SucuyAzPAw3i6Wjtq61TcL9SdWhmOf9_yo-Np052tj7MQ66nmgdOH_MEKYjAdFypxTsRQoSLbv28HEcSjwx8u3pY0q0gKMK_5X2XKJrp2i2GB_fVgbcpH9YsgrYxh1Q8 The public wallet address for that wallet is 9ODOd-_ZT9oWoRMVmmD4G5f9Z6MjvYxO3Nen-T5OXvU, this is obtained by decoding the public key from base64url to normalize padding, sha256 hashing the result, and then base64url encoding that.Ethereum/Polygon The public key for an EVM wallet (Ethereum, Polygon/Matic) is derived from its private key, using the Elliptic Curve Digital Signature Algorithm, or ECDSA.0xb5d96e5533334a630af9d50b226011d44b9879c3165ffee0601bb0bac621e0047c302d4b72e4b1ca145043940c53093021825726cacdbf1d0a0e8ff2e70a4037 The public wallet address is 0x084af408C8E492aC52dc0Ec76514A7deF8D5F03f, this is obtained by removing the first byte from the public key, Keccak-256 hashing the remainder, taking the the last 20 bytes (40 hexadecimal characters) and prepending 0x to it.Solana A Solana wallet is an array of 64 bytes. The first 32 bytes are the private key, and the last 32 bytes are the public key. Below is the public key portion of a Solana wallet:[172, 175, 23, 95, 23, 124, 38, 171, 25, 20, 245, 213, 59, 9, 18, 89, 46, 70, 135, 84, 137, 205, 251, 95, 8, 226, 233, 46, 78, 34, 212, 86] The public wallet address for this wallet is Cd5yb4mvbuQyyJgAkriFZbWQivh2zM68KGZX8Ksn1L85, this is derived by base58 encoding the public key bytes.Normalizing Addresses As shown in the above examples, the format of public keys, and the resulting derived wallet addresses, vary widely between blockchains. Arweave manages this by applying the same derivation methods that Arweave uses for its own wallets to the public keys from other chains.Ethereum/Polygon The leading 0x and uncompressed flag 04 (if present) is removed from the public key of an EVM wallet, and then the remainder is base64url encoded to obtain the Arweave normalized public key. Continuing with the same public key in the above example, the normalized public key would be:2W5VMzNKYwr51QsiYBHUS5h5wxZf_uBgG7C6xiHgBHwwLUty5LHKFFBDlAxTCTAhglcmys2_HQoOj_LnCkA3 This value is what is used as the GraphQL tag owner value for data items being uploaded to Arweave using an EVM wallet. The normalized address is then derived from this value by sha256 hashing it, and then base64url encoding the result:5JtuS4yOFtUX2Rg3UU7AgBaUqh4s8wyyNTZk9UrzI-Q Solana The normalized public key for Solana wallets are derived similarly. The 32 byte public key is base64url encoded:rK8XXxd8JqsZFPXVOwkSWS5Gh1SJzftfCOLpLk4i1FY Again, this value is used for the GraphQl tag owner when uploading data. It can then be sha256 hashed, and base64url encoded again to derive the normalized address:K8kpPM1RID8ZM2sjF5mYy0rP4gXSRDbrwPUd9Qths64 How is this guide?Upgrading Private Drives Learn how to upgrade legacy private drives to ArFS v0.15 Browser Sandboxing Learn about browser sandboxing in AR.IO gateways - how security is enhanced through same-origin policy and subdomain redirection

---

# 72. ARIO Gateway APIs  ARIO Documentation

Document Number: 72
Source: https://docs.ar.io/apis/ar-io-node
Words: 351
Quality Score: 0.448
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

The AR.IO Gateway is the core software for the AR.IO network, serving the essential responsibility of gateways for accessing, caching, and querying data stored on Arweave. It provides a robust, decentralized infrastructure for interacting with the permanent web.Core Responsibilities The AR.IO Gateway handles fundamental operations for the Arweave ecosystem:Data Access - Retrieve transaction data, files, and metadata from Arweave Caching - Intelligent caching strategies for improved performance and availability Data Querying - Powerful search and indexing capabilities for Arweave data ArNS Resolution - Resolve human-readable names to Arweave transaction IDs Network Management - Coordinate with other gateways in the AR.IO network Advanced Features Beyond basic gateway functionality, AR.IO Gateway includes sophisticated capabilities:Parquet Generation - Convert Arweave data into optimized Parquet format for analytics Data Verification - Cryptographic verification of data integrity and authenticity Index Querying - Advanced search and filtering across Arweave datasets Farcaster Frames - Support for Farcaster protocol integration Admin Controls - Comprehensive gateway management and configuration APIs Categories Data Access Retrieve transaction data, files, and metadata from Arweave ArNS Resolution Resolve human-readable names to Arweave transaction IDs Transactions & Blocks Access transaction details, block information, and network data Index Querying Advanced search and filtering capabilities across Arweave data Network & Gateway Gateway status, network information, and peer coordination Admin & Management Gateway configuration, pricing, and administrative controls Get Involved with AR.IO Gateways Run a Gateway Join the AR.IO network by operating your own gateway and earn rewards Leverage Gateways with Wayfinder Use Wayfinder SDK to access data through the distributed gateway network Join the Network Learn about the AR.IO network and how to participate in the ecosystem Getting Started Explore the APIs endpoints - Review the comprehensive APIs documentation Test with sample requests - Try out the interactive examples Choose your integration approach - Direct APIs calls or SDK usage Consider running a gateway - Contribute to the network infrastructure The AR.IO Gateway APIs provide the foundation for building robust, decentralized applications on Arweave with reliable data access and advanced querying capabilities.How is this guide?APIs Reference REST APIs for interacting with AR.IO services and infrastructure Data Next Page

---

# 73. Troubleshooting  ARIO Documentation

Document Number: 73
Source: https://docs.ar.io/build/run-a-gateway/manage/troubleshooting
Words: 1871
Quality Score: 0.447
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Run a Gateway Manage your Gateway Welcome to the comprehensive troubleshooting and FAQ resource for AR.IO Gateway operators. Use the quick lookup table below for fast answers, or browse the detailed sections for in-depth guidance.Quick Lookup Below is a quick summary of what you should check when troubleshooting your gateway. Find more detailed information in the sections below.Issue What to Check My release number is wrong Pull the latest github updates and make sure you are on the main branch Gateway appears offline on Viewblock or https://gateways.ar.io Probably fine, but verify that your gateway is still running.'/ar-io/observer/reports/current' just says "report pending" Normal behavior, wait for the report to complete.Observer error "Cannot read properties of undefined" Normal behavior, Observer is checking for data not implemented yet.Observing my gateway shows failures Check AR_IO_WALLET and ARNS_ROOT_HOST settings.Updated.env settings not reflected on gateway Rebuild your gateway after editing.env file.Out of disk space error Check for inode exhaustion and delete files if necessary.Can't load ArNS names Check ARNS_ROOT_HOST setting in.env file, and DNS records."Your connection is not private" error Generate or renew SSL certificates.404/Nginx error when accessing domain Check Nginx settings and restart Nginx if necessary.502 error from Nginx Check for errors in your gateway.Trouble generating SSL certificates Ensure TXT records have propagated and follow certbot instructions.General Troubleshooting My Gateway Seems to be Running but...Troubleshooting Failed Epochs Overview The ARIO Network provides several tools to help troubleshoot problems with a gateway. The most powerful among these is the Observer.The Observer, which is a component of every gateway joined to the ARIO Network, checks all gateways in the network to ensure that they are functioning properly, and returning the correct data. The Observer then creates a report of the results of these checks, including the reasons why a gateway might have failed the checks.If a gateway fails the checks from more than half of the prescribed observers, the gateway is marked as failed for the epoch, and does not receive any rewards for that epoch.The first step in troubleshooting a failed gateway is always to attempt to resolve data on that gateway in a browser, but if that does not make the issue clear, the Observer report can be used to diagnose the problem.Manual Observation Manual observations may be run on a gateway at any time buy using the Network Portal. This allows operators (or anyone with an interest in the gateway's performance) to check the gateway's performance at any time. To run a manual observation:Navigate to the Network Portal Select the gateway you are interested in from the list of gateways Click on the "Observe" button in the top right corner of the page. Click on the "Run Observation" button in the bottom right corner of the page. Two randomly selected ArNS names will be entered automatically in the "ArNS names" field to the left of the "Run Observation" button. These can be changed, or additional ArNS names can be added to the list before running the observation.The Manual observation will run the same checks as the observer, and will dis the results on the right side of the page. Accessing the Observer Report The simplest way to access an observer report is via the Network Portal, following the steps below:Navigate to the Network Portal Select the gateway you are interested in from the list of gateways In the Observation window, select the epoch you are interested in. This will dis a list of the observers that failed the gateway for that epoch.Click on the "View Report" button to the right any observer on that list. This will dis the entire report that observer generated. Locate the gateway you are interested in in the report, and click on that row. This will dis the report for that gateway.Understanding the Observer Report The observer report will dis a list of checked ArNS names, and a reason if the gateway failed to return the correct data for that name. There are several reasons why a gateway might fail to return the correct data for an ArNS name. Below is a list of the most common reasons, and how to resolve them.Timeout awaiting 'socket', or Timeout awaiting 'connect' This failure means that the observer was unable to connect to the gateway when it tried to check the ArNS name. There are lots of reasons why this might happen, many of them unrelated to the gateway itself. If an observer report has a small number of these failures, among a larger number of successful checks, it is unlikely to be an issue with the gateway.If this failure occurs persistently for a large number, or all ArNS names checked, it likely means that the observer is having trouble connecting to the gateway at all. You can verify this by:Attempting to connect to the gateway in a browser Running manual observations on the gateway using the Network Portal Using tools like curl or ping to check the gateway's connectivity If these methods consistently fail to connect to the gateway, it is likely that the gateway is not properly configured or powered on. If this is the case:Check Docker and the gateway's logs to see if the gateway is on.Ensure that the SSL certificates are valid for the gateway's domain.Check DNS records for the gateway's domain, misconfigured or conflicting DNS records can cause connectivity issues.Some gateway operators who run their gateways on their personal home networks have also reported issues with their ISP blocking, throttling, or otherwise delaying traffic to a gateway. If none of the above steps resolve the issue, it may be worth checking with your ISP to see if they are blocking or throttling traffic to the gateway.Using Grafana can also provide a visual representation of the gateway's ArNS resolution times. If this is consistently high (above 10 seconds), it is likely that the gateway is not properly configured to resolve ArNS names. Ensure that the gateway is operating on the latest Release.Cert has expired This failure means that the gateway's SSL certificate has expired. Obtaining a new SSL certificate and updating the gateway's reverse proxy (nginx, etc) configuration to use the new certificate is the only solution to this issue.dataHashDigest mismatch This failure means that the gateway did respond to a resolution request, but the data it returned did not match the data that was expected. This could be due to a number of reasons, including:Cached data was returned by the gateway that doesnt match the most current data on the network.The gateway is configured to operate on testnet or devnet. Gateways joined to the ARIO Network MUST operate on mainnet in order to pass observation checks.The gateway is intentionally returning fraudulent data.A gateway will not return fraudulent data unless that operator intentionally rewrote the gateway's code to do so, and a major purpose of the Observation and Incentive Protocol is to catch and prevent this behavior. A gateway may return mistaken data on occasion, usually due to a cache mismatch between the gateway and the observer's authority (usually arweavae.net). This is a relatively rare occurrence, and should only be considered an issue if it occurs persistently. If most or all of the ArNS names checked are failing for this reason, it is likely that the gateway is not operating on mainnet.Response code 502 (Bad Gateway) This failure means that the observer was able to connect to the gateway's network, but the reverse proxy returned a 502 error. This is almost always a reverse proxy issue. Ensure that the gateway's reverse proxy is running, and that it is configured to forward requests to the gateway.Testing the validity of the reverse proxy's configuration file (sudo nginx -t on Nginx) may provide more information about the issue, and restarting the reverse proxy (sudo nginx -s reload) often resolves the issue if there are no problems with the configuration file.It is also possible that the gateway itself is not running at all. Check Docker and the gateway's logs to see if the gateway is on.Response code 503 (Service Unavailable) This failure means that the observer was able to connect to the gateway's network, but the reverse proxy was unable to forward the request to the gateway. It differs from the 502 error in that the reverse proxy is likely able to see that the gateway is running, but is unable to communicate with it. This is often a temporary issue, caused by the gateway not being able to handle a heavy load of requests, or the gateway being in the process of restarting. If this failure occurs once or twice in a report, it is likely a temporary issue and should not be considered an issue with the gateway. However, when this failure occurs persistently, particularly for every ArNS name checked on the report, it is likely that the gateway may have crashed.Manually restarting the gateway can likely resolve the issue.connect EHOSTUNREACH This failure means that the observer was unable to connect to the gateway at all. The connection was either refused, or the gateway was not able to find a target based on the domain name's DNS records.This is almost always an issue with DNS records or local network configuration. Ensure that the gateway domain has correct DNS records, and that the local network is set up to allow connections. Checking logs from the local network's reverse proxy (nginx, etc) may provide more information about the issue.getaddrinfo ENOTFOUND This is another DNS related issue. Likely, the gateway does not have a valid DNS record either for the top level domain or the required wildcard subdomain. Having this failure occur once or twice in a report could mean that the DNS server being used by the observer is having temporary issues and should not be considered an issue with the gateway. However, when this failure occurs persistently, particularly for every ArNS name checked on the report, it is likely that the gateway's DNS records are not set, or are misconfigured.Hostname/IP does not match certificate's altnames: Host: . is not in the cert's altnames: DNS: This failure means that the observer's SSL certificate does not match the gateway's domain name. This is almost always an issue with the gateway's SSL certificate. This most likely occurred because the gateway's operator did not update the gateway's SSL certificate when the gateway's domain name was changed. Obtaining a new SSL certificate and updating the gateway's reverse proxy configuration to use the new certificate is the only solution to this issue.write EPROTO :error::SSL routines:ssl3_read_bytes:tlsv1 unrecognized name::SSL alert number 112 This failure almost always means that the gateway operator did not properly obtain SSL certificates for the gateway's wildcard subdomain. Obtaining a new SSL certificate and updating the gateway's reverse proxy configuration to use the new certificate is the only solution to this issue.FAQ Getting Help If you encounter any issues during the troubleshooting process, please seek assistance from the AR.IO community.Ready to get back to building? Once your gateway is running smoothly, check out Manage your Gateway for guides on optimization, monitoring, and more.How is this guide?Setting Apex Domain Content Complete guide to configuring your AR.IO Gateway to serve custom content from the apex domain Extensions & Sidecars Modular tools that can be run alongside an AR.IO gateway to expand its capabilities or enhance the operator experience

---

# 74. Distributions  ARIO Documentation

Document Number: 74
Source: https://docs.ar.io/learn/oip/reward-distribution
Words: 799
Quality Score: 0.444
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Observation & Incentive ProtocolDistributionsCopy MarkdownOpenProtocol Balance and Funding
The AR.IO network maintains a protocol balance that funds all gateway and observer rewards. This balance is primarily funded through ArNS name purchases, ensuring sustainable network incentives aligned with usage.
Epoch Allocation
Each epoch, a portion of the protocol balance is earmarked for distribution as rewards. This value shall begin at 0.1% per epoch for the first year of operation, then linearly decline down to and stabilize at 0.05% over the following 6 months.
Funding Sources
ArNS Name Purchases: Primary funding mechanism - fees from ArNS name registrations and renewals
Network Genesis Allocation: Initial ARIO tokens allocated at network launch
Undistributed Rewards: Rewards not claimed due to poor performance roll forward to future epochs
From this allocation, two distinct reward categories are derived:
Base Rewards
Base Gateway Reward (BGR)
This is the portion of the reward allocated to each Functional Gateway within the network and is calculated as:
BGR=Epoch Reward Allocation×0.9Total Gateways in the NetworkBGR = \frac{\text{Epoch Reward Allocation} \times 0.9}{\text{Total Gateways in the Network}}
BGR=Total Gateways in the NetworkEpoch Reward Allocation×0.9
Base Observer Reward (BOR)
Observers, due to their additional responsibilities, have a separate reward calculated as:
BOR=Epoch Reward Allocation×0.1Total Selected Observers for the EpochBOR = \frac{\text{Epoch Reward Allocation} \times 0.1}{\text{Total Selected Observers for the Epoch}}
BOR=Total Selected Observers for the EpochEpoch Reward Allocation×0.1
Distribution Based on Performance
The reward distribution is contingent on the performance classifications derived from the Performance Evaluation:
Functional Gateways: Gateways that meet the performance criteria receive the Base Gateway Reward.
Deficient Gateways: Gateways falling short in performance do not receive any gateway rewards.
Functional Observers: Observers that fulfilled their duty receive the Base Observer Reward.
Deficient Observers: Observers failing to meet their responsibilities do not receive observer rewards. Furthermore, if they are also Functional Gateways, their gateway reward is reduced by 25% for that epoch as a consequence for not performing their observation duty.
Epoch reward distributions showing the relationship between eligible rewards (total available) and distributed rewards (actually paid out) across epochs. The difference represents rewards not distributed due to gateway or observer deficiencies.
Auto-Staking
Gateways shall be given the option to have their reward tokens "auto-staked" to their existing stake or sent to their wallet as unlocked tokens. The default setting shall be "auto-staked".
Distribution to Delegates
The protocol will automatically distribute a Functional Gateway's shared rewards with its delegates. The distribution will consider the gateway's total reward for the period (including observation rewards), the gateway's "Delegate Reward Share Ratio", and each delegate's stake proportional to the total delegation.
Each individual delegate reward is calculated as:
DRi=Total Rewards×Reward Share Ratio×Delegate’s StakeTotal Delegated StakeDR_i = \text{Total Rewards} \times \text{Reward Share Ratio} \times \frac{\text{Delegate's Stake}}{\text{Total Delegated Stake}}
DRi=Total Rewards×Reward Share Ratio×Total Delegated StakeDelegate’s Stake
Unlike gateways, token reward distributions to delegated stakers will only be "auto-staked" in that they will be automatically added to the delegate's existing stake associated with the rewarded gateway. The delegated staker is then free to withdraw their staked rewards at any time (subject to withdrawal delays).
Undistributed Rewards
In cases where rewards are not distributed, either due to the inactivity or deficiency of gateways or observers, the allocated tokens shall remain in the protocol balance and carry forward to the next epoch.
This mechanism is in place to discourage observers from frivolously marking their peers as offline in hopes of attaining a higher portion of the reward pool.
Note that if a gateway (and its delegates) leaves the network or a delegate fully withdraws stake from a gateway, they become ineligible to receive rewards within the corresponding epoch and the earmarked rewards will not be distributed.
Handling Deficient Gateways
To maintain network efficiency and reduce contract state bloat, gateways that are marked as deficient, and thus fail to receive rewards, for thirty (30) consecutive epochs will automatically trigger a "Network Leave" action and be subject to the associated stake withdrawal durations for both gateway stake and any delegated stake.
In addition, the gateway shall have its minimum network-join stake slashed by 100%. The slashed stake shall be immediately sent to the protocol balance.
Next Steps
Congratulations! You now understand the complete OIP system. Ready to learn more?
Explore Gateways → Gateway Documentation for technical details
Learn about ArNS → ArNS Documentation for naming system details
Back to Introduction → OIP Introduction to review the basics
How is this guide?GoodBadPerformance and WeightsLearn about how gateways are evaluated and how weights impact observer selectionArweave Name System (ArNS)ArNS is a censorship-resistant naming system stored on Arweave, powered by ARIO tokens, enabled through AR.IO gateway domains, and used to connect friendly domain names to permaweb apps, web pages, data, and identities.On this pageProtocol Balance and FundingEpoch AllocationFunding SourcesBase RewardsBase Gateway Reward (BGR)Base Observer Reward (BOR)Distribution Based on PerformanceAuto-StakingDistribution to DelegatesUndistributed RewardsHandling Deficient GatewaysNext Steps

---

# 75. Balance  ARIO Documentation

Document Number: 75
Source: https://docs.ar.io/apis/turbo/payment-service/balance
Words: 87
Quality Score: 0.444
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Turbo Payment Service Account balance and credit management Get Current Balance of winc Use a signed request or a previously obtained JWT to get the signing wallet's current service balance in winc Query Parameters Header Parameters x-signature?string The signature value derived from signing the request's data concatenated with the provided nonce using the private key from the provided public key x-nonce?string The nonce value concatenated with the request's data when deriving the provided the signature Response Body How is this guide?Service Info Previous Page Payments Next Page

---

# 76. ArFS Protocol  ARIO Documentation

Document Number: 76
Source: https://docs.ar.io/build/advanced/arfs
Words: 487
Quality Score: 0.442
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Advanced Arweave File System, or "ArFS" is a data modeling, storage, and retrieval protocol designed to emulate common file system operations and to provide aspects of mutability to your data hierarchy on Arweave 's otherwise permanent, immutable data storage blockweave.Due to Arweave's permanent, immutable and public nature traditional file system operations such as permissions, file/folder renaming and moving, and file updates cannot be done by simply updating the on-chain data model.ArFS works around this by implementing a privacy and encryption pattern and defining an append-only transaction data model using tags within Arweave Transaction headers.Key Features File Structure ArFS organizes files and folders using a hierarchical structure. Files are stored as individual transactions on the Arweave blockchain, while folders are metadata that reference these file transactions.Metadata Each file and folder has associated metadata, such as the name, type, size, and modification timestamp. ArFS leverages Arweave's tagging system to store this metadata in a standardized format, which allows for easy querying and organization.File Permissions ArFS supports public and private file permissions. Public files can be accessed by anyone on the network, while private files are encrypted using the owner's private key, ensuring only they can decrypt and access the content.File Versioning ArFS supports versioning of files, allowing users to store multiple versions of a file and access previous versions at any time. This is achieved by linking new file transactions to previous versions through the use of metadata tags.Data Deduplication To minimize storage redundancy and costs, ArFS employs data deduplication techniques. If a user tries to store a file that already exists on the network, the protocol will simply create a new reference to the existing file instead of storing a duplicate copy.Search and Discovery ArFS enables users to search and discover files based on their metadata, such as file names, types, and tags. This is made possible by indexing the metadata stored within the Arweave blockchain.Interoperability ArFS is designed to be interoperable with other decentralized applications and services built on the Arweave network. This allows for seamless integration and collaboration between different applications and users.Getting Started To start using ArFS, you'll need to familiarize yourself with the Arweave ecosystem, acquire AR tokens to cover storage costs, and choose a compatible client or library to interact with the ArFS protocol.ArFS Version History Next Steps Ready to dive deeper into ArFS? Here's what you should explore next:Entity Types - Understand the different ArFS entities and their structure Data Model - Learn how ArFS organizes data hierarchically Privacy & Encryption - Secure your data with private drives Creating Drives - Get started with your first ArFS drive Reading Data - Query and retrieve your ArFS data Resources For more information, documentation, and community support, refer to the following resources:Arweave Official Website Arweave Developer Documentation Arweave Community Forums How is this guide?Advanced Advanced topics and specialized guides for building on Arweave and AR.IO Entity Types Understanding ArFS entity types and their structure

---

# 77. Encryption  ARIO Documentation

Document Number: 77
Source: https://docs.ar.io/build/upload/encryption
Words: 512
Quality Score: 0.440
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Upload Data Arweave has no built-in encryption. All encryption and decryption must be handled client-side before uploading data to the network. Arweave is completely data-agnostic - it stores whatever data you provide without any knowledge of whether it's encrypted or not.How Encryption Works on Arweave Critical Points:No native encryption: Arweave provides no encryption services whatsoever Client-side only: You must encrypt data before uploading Data-agnostic storage: Arweave stores any data type, including encrypted data Your responsibility: You handle all encryption, key management, and decryption Permanent security: Once encrypted and stored, data remains secure forever Encryption Options 1. Manual Client-Side Encryption Encrypt your data before uploading with Turbo:import CryptoJS from "crypto-js";
// Encrypt sensitive data
const data = "Sensitive information";
const secretKey = "your-secret-key";
const encryptedData = CryptoJS.AES.encrypt(data, secretKey).toString();
// Upload encrypted data
const result = await turbo.upload({
data: encryptedData,
dataItemOpts: {
tags: [
{ name: "Content-Type", value: "application/octet-stream" },
{ name: "Encrypted", value: "true" },
{ name: "Cipher", value: "AES-256-GCM" },
{ name: "Cipher-IV", value: "YWJjZGVmZ2hpams=" }, // 12 byte initialization vector as Base64
],
},
});Encryption Standards Encryption Methods AES-256-GCM: Authenticated encryption (recommended) AES-256-CTR: Stream cipher for large files Any encryption method: Arweave supports any encryption you choose (must be indicated in Cipher tag for ArFS compliance) Required Tags When uploading encrypted data, include these tags:{
name: "Content-Type",
value: "application/octet-stream" // Required for encrypted data
},
{
name: "Cipher",
value: "AES-256-GCM" // Specify encryption method
},
{
name: "Cipher-IV",
value: "base64-encoded-iv" // Initialization vector
} ArFS Protocol (Optional Standardization) The Arweave File System (ArFS) protocol provides optional standardization for encrypted storage:Private Drives: Encrypt entire file systems File-level encryption: Each file has its own encryption key Selective sharing: Share individual files without exposing the entire drive Key derivation: Uses HKDF-SHA256 with wallet signatures Completely optional: You can use any encryption method you prefer ArDrive Web App: Data uploaded through the ArDrive web app to Private
Drives is encrypted for you using the standards set in the ArFS protocol.
ArDrive is simply a web application that implements ArFS - there is no
separate "ArDrive Encryption Service." Getting Started For most users, the ArDrive web app provides the easiest way to encrypt and store data using ArFS standards:Create a private drive in the ArDrive web app Set a strong password for your drive Upload files - they're automatically encrypted using ArFS Access files using your password and wallet For developers who need custom encryption:Choose an encryption library (Crypto-JS, Web Crypto API) Encrypt your data before uploading Add proper tags to indicate encryption Store keys securely for decryption Security Considerations Best Practices:Use strong, randomly generated keys Implement proper key rotation Store keys securely (not in code) Use authenticated encryption (AES-GCM) Validate data integrity after decryption Next Steps Try ArDrive Web App Use the ArDrive web app for easy encrypted file storage using ArFS.Learn About ArFS Explore the Arweave File System protocol for structured storage.Get Turbo Credits Purchase credits for programmatic uploads.How is this guide?Manifests Understanding manifests for organizing folder structures and bundles Access Data Learn how to retrieve and query data from Arweave's permanent storage network

---

# 78. Data Verification  ARIO Documentation

Document Number: 78
Source: https://docs.ar.io/learn/gateways/data-verification
Words: 539
Quality Score: 0.440
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Gateways AR.IO gateways continuously verify that data chunks are correctly stored and retrievable from Arweave. This ensures users receive authentic, uncorrupted data with cryptographic proof of integrity. The verification system is what makes AR.IO gateways trustworthy data providers for the permaweb.How Gateways Verify Data Data verification is an ongoing process that uses Merkle tree cryptography to provide mathematical proof of data integrity. The process involves multiple specialized components working together to ensure cached data matches what's stored on Arweave:The Verification Workflow:Gateways achieve verification through a systematic five-phase process orchestrated by the DataVerificationWorker. This process ensures that every piece of cached data cryptographically matches its original form on Arweave, providing mathematical proof of integrity before serving data to users.1. Discovery Phase Periodically scan for unverified data items Priority-based queue management (higher priority items first) Track retry attempts for failed verifications 2. Data Retrieval Fetch data attributes from gateway storage Retrieve the complete data stream Gather metadata needed for verification 3. Cryptographic Computation Calculate Merkle data root from actual data stream Generate cryptographic proofs using the same algorithm as Arweave Create verifiable hash chains 4. Root Comparison Compare computed root against indexed root in database Verify data hasn't been corrupted or altered Validate chunk integrity against Merkle proofs 5. Action Based on Results Success: Mark data as verified with timestamp Failure: Trigger re-import from Arweave or unbundle from parent Error: Increment retry counter and requeue for later Verification Types AR.IO gateways handle different types of data verification based on the data's origin:Transaction Data Verification For individual Arweave transactions:Direct root validation against transaction data roots stored on-chain Complete data reconstruction from chunks to ensure availability Cryptographic proof that data matches what was originally stored Bundle Data Verification For ANS-104 data bundles (collections of data items):Bundle integrity checks to verify the container is valid Individual item verification within each bundle Recursive unbundling when verification fails to re-extract items Nested bundle support for bundles containing other bundles Chunk-Level Validation At the most granular level:Merkle proof validation for individual data chunks Sequential integrity ensuring chunks form complete data Parallel verification of multiple chunks for performance Why Verification Matters Cryptographic Trust Foundation Mathematical Proof: Merkle tree cryptography provides irrefutable proof of data integrity Independent Validation: Multiple gateways verify the same data independently Network Consensus: Distributed verification creates trust without central authority Data Integrity Guarantees Tamper Detection: Any alteration to data is immediately detectable Corruption Recovery: Automatic healing of corrupted data through re-import Permanent Storage Validation: Ensures Arweave's permanence promise is maintained Gateway Reliability Continuous Monitoring: Ongoing verification catches issues before users encounter them Self-Healing System: Automatic recovery mechanisms maintain data availability Transparent Operations: Verification status and timestamps provide audit trails Explore Gateway Systems Data Retrieval Learn how gateways fetch data from multiple sources with verification Gateway Architecture Understand the technical architecture behind verification systems Run Your Own Gateway Set up a gateway with built-in verification capabilities Gateway Configuration Configure verification settings and optimization options How is this guide?Data Retrieval How AR.IO gateways retrieve and share data from multiple sources including trusted peers and Arweave nodes Gateway Registry The AR.IO Network consists of AR.IO gateway nodes, which are identified by their registered Arweave wallet addresses and either their IP addresses or hostnames, as stored in the network

---

# 79. Observation  Incentive Protocol  ARIO Documentation

Document Number: 79
Source: https://docs.ar.io/learn/oip
Words: 560
Quality Score: 0.435
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Overview The Observation and Incentive Protocol ensures network quality through peer monitoring and performance-based rewards. Gateways are incentivized to maintain high performance while also serving as "observers" that evaluate their peers' ArNS resolution capabilities and data integrity verification.The protocol operates on 24-hour epochs where up to 50 gateways are selected as observers to test other gateways against ArNS name resolution criteria and chunk/offset validation. This creates a self-regulating ecosystem with transparent, consensus-based performance evaluation.Architecture Overview The Observer Protocol operates through a systematic process where selected gateways monitor their peers and report findings to maintain network quality:Epoch Cycle and Responsibilities Each 24-hour epoch follows a structured process with specific responsibilities for gateways and observers:Epoch Start Smart Contract: Selects up to 50 observers using weighted random selection Smart Contract: Generates 2 prescribed ArNS names for all observers to test Selected Observers: Receive notification of selection and prescribed names Observation Phase Observers: Choose 8 additional ArNS names to test (total of 10 names per gateway) Observers: Select subset of gateways for chunk/offset validation based on sampling rate Observers: Test assigned gateways for ArNS resolution, wallet ownership, content hashes, and response times Observers: Validate chunk/offset data integrity using cryptographic Merkle proofs Target Gateways: Respond to resolution requests, serve content, and provide chunk data with proofs Reporting Phase Observers: Upload detailed JSON reports to Arweave for transparency Observers: Submit failed gateway lists to the AR.IO Smart Contract for consensus voting Evaluation and Distribution Smart Contract: Tallies all observer votes (≥50% pass = functional gateway) Smart Contract: Distributes rewards at epoch end based on performance Functional Gateways/Observers: Receive ARIO token rewards automatically Key Features Decentralized Monitoring: Peer-to-peer evaluation ensures no single point of failure Consensus-Based Scoring: Majority rule (≥50% pass votes) determines gateway functionality Performance Incentives: Only functional gateways and observers receive ARIO token rewards Data Integrity Validation: Cryptographic verification of chunk/offset data using Merkle proofs Transparent Accountability: All reports permanently stored on Arweave and viewable at gateways.ar.io Sustainable Funding: Protocol balance funded by ArNS name purchases, aligning rewards with network usage Chunk/Offset Validation The protocol includes advanced data integrity verification through chunk/offset observation. Observers validate that gateways can correctly serve and verify Arweave data chunks using cryptographic proofs:Validation Process Sampling: A subset of gateways is selected for chunk validation each epoch Offset Testing: Random offsets within the stable weave range are tested Merkle Proof Verification: Cryptographic validation ensures chunk authenticity Binary Search Optimization: Efficient transaction lookup using cached metadata Technical Implementation Chunk Retrieval: GET /chunk/{offset} returns chunk data and Merkle proof Proof Validation: Uses Arweave's validatePath() function for cryptographic verification Performance Optimization: LRU caching for blocks, transactions, and metadata Early ping: Tests immediately upon first successful validation View Live Data: See current observers and performance metrics at gateways.ar.io Explore the Protocol Observer Selection Learn how gateways are chosen as observers using weighted criteria and entropy Performance Evaluation Understand vote tallying, consensus mechanisms, and weight calculations Reporting System Explore observer responsibilities for dual-channel submission to Arweave Reward Distribution Learn about reward formulas, funding mechanisms, and penalty structures How is this guide?Gateway Registry The AR.IO Network consists of AR.IO gateway nodes, which are identified by their registered Arweave wallet addresses and either their IP addresses or hostnames, as stored in the network Observer Selection Learn about how gateways are selected as observers each epoch and how ArNS names are chosen using weighted random selection and Hashchain entropy

---

# 80. EthAReum Protocol  ARIO Documentation

Document Number: 80
Source: https://docs.ar.io/build/advanced/ethareum
Words: 764
Quality Score: 0.434
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Advanced The EthAReum protocol enables the generation of private keys for an Arweave wallet using a signature from an Ethereum or Solana wallet. This allows users to create an Arweave wallet directly through popular wallet providers like MetaMask, providing seamless cross-chain wallet management.Generated private keys provide a fully functional Arweave wallet, equipped to perform all standard operations, including holding AR tokens and Turbo Credits, and uploading data to the Arweave network.How It Works EthAReum uses a deterministic key derivation process that combines:Ethereum/Solana wallet signature - Provides the cryptographic foundation User-generated password - Adds additional entropy and security Standardized derivation algorithm - Ensures reproducible results The protocol generates a unique Arweave wallet that is cryptographically linked to your Ethereum or Solana wallet but remains completely independent.Browser Compatibility Recommended Browser: For optimal performance, use Chrome when working
with EthAReum and MetaMask. While EthAReum functions correctly in most
browsers, there are ongoing efforts to resolve some edge case compatibility
issues in other environments.Password Security The EthAReum protocol incorporates a user-generated password in the wallet derivation process. This password provides an extra layer of security by contributing additional entropy to the wallet's derivation and serves as a critical verification step for wallet access.Permanent Password: The password used during the derivation of private
keys is permanent and cannot be changed or recovered by any administrator.
ArDrive is a decentralized platform with no account administration. It is
crucial to keep this password secure.Password Requirements Must be set during initial wallet creation Used for all subsequent logins Required for encrypting private uploads Cannot be recovered if forgotten Wallet Addresses The public address of the generated Arweave wallet is derived from its public key and will be different from the public address of the Ethereum or Solana wallet used to generate it.Viewing Your Address The exact steps to obtain your generated wallet's public address depend on the dApp interface:ArDrive: Click the user profile icon in the top right when logged in Other dApps: Check the wallet settings or profile section Key Management Keyfiles vs Seed Phrases The Arweave ecosystem primarily uses keyfiles rather than seed phrases for wallet access:Keyfile: JSON file containing a Json Web Key (JWK) that acts as private keys Seed Phrase: Supported but not universally implemented across all dApps Accessing Your Keys Both keyfile and seed phrase are available for download in most dApps:ArDrive: Click the user profile icon in the top right when logged in Other dApps: Check wallet settings or export options Security Considerations One-Way Control EthAReum generates Arweave wallet private keys using a signature from your Ethereum/Solana wallet, ensuring that control only extends in one direction:✅ EthAReum can generate Arweave wallets from Ethereum/Solana signatures ❌ EthAReum cannot access your Ethereum/Solana wallet or assets ✅ Your Ethereum/Solana assets remain completely secure and independent Signature Security Beware of Malicious dApps: Some malicious dApps or websites may disguise
high-risk authorization transactions as simple signature requests. Always
ensure that you only provide signatures to reputable and trusted dApps like
ArDrive.Best Practices Verify dApp authenticity before providing signatures Use strong, unique passwords for wallet derivation Backup your keyfile in a secure location Never share your password or keyfile with anyone Test with small amounts before committing to large transactions Implementation Examples Basic Wallet Generation // Example: Generate Arweave wallet from Ethereum signature
async function generateArweaveWallet(ethereumSignature, password) {
// This is a conceptual example - actual implementation
// would use the EthAReum protocol specification
const derivedKey = await deriveKeyFromSignature(
ethereumSignature,
password,
"arweave" // derivation context
);
return {
address: getAddressFromKey(derivedKey),
keyfile: createKeyfile(derivedKey),
seedPhrase: generateSeedPhrase(derivedKey),
};
} Integration with MetaMask // Example: Request signature from MetaMask
async function requestEthereumSignature() {
const accounts = await ethereum.request({
method: "eth_requestAccounts",
});
const message = "Sign this message to generate your Arweave wallet";
const signature = await ethereum.request({
method: "personal_sign",
params: [message, accounts[0]],
});
return signature;
} Use Cases Cross-Chain dApp Development Unified wallet experience across Ethereum and Arweave Simplified onboarding for users familiar with Ethereum Reduced friction in multi-chain applications Data Storage Solutions Decentralized file storage using existing Ethereum wallets NFT metadata storage on Arweave with Ethereum wallet access Cross-chain data management for DeFi applications Developer Benefits Familiar wallet interfaces for users Reduced development complexity for multi-chain apps Enhanced user experience with single wallet management Next Steps ArFS Protocol Learn about structured data storage on Arweave using your generated wallet.Turbo Upload Upload data efficiently using Turbo Credits with your EthAReum wallet.Data Retrieval Learn how to find and access data stored with your generated wallet.How is this guide?Browser Sandboxing Learn about browser sandboxing in AR.IO gateways - how security is enhanced through same-origin policy and subdomain redirection

---

# 81. Arweave Name System (ArNS)  ARIO Documentation

Document Number: 81
Source: https://docs.ar.io/sdks/ar-io-sdk/arweave-name-system-arns
Words: 1061
Quality Score: 0.425
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

AR.IO SDK ARIO Contract resolveArNSName() Resolves an ArNS name to the underlying data id stored on the names corresponding ANT id.Resolving a base name const ario = ARIO.mainnet();
const record = await ario.resolveArNSName({ name: 'ardrive' });Output:{
"processId": "bh9l1cy0aksiL_x9M359faGzM_yjralacHIUo8_nQXM",
"txId": "kvhEUsIY5bXe0Wu2-YUFz20O078uYFzmQIO-7brv8qw",
"type": "lease",
"recordIndex": 0,
"undernameLimit": 100,
"owner": "t4Xr0_J4Iurt7caNST02cMotaz2FIbWQ4Kbj616RHl3",
"name": "ardrive"
} Resolving an undername const ario = ARIO.mainnet();
const record = await ario.resolveArNSName({ name: 'logo_ardrive' });Output:{
"processId": "bh9l1cy0aksiL_x9M359faGzM_yjralacHIUo8_nQXM",
"txId": "kvhEUsIY5bXe0Wu2-YUFz20O078uYFzmQIO-7brv8qw",
"type": "lease",
"recordIndex": 1,
"undernameLimit": 100,
"owner": "t4Xr0_J4Iurt7caNST02cMotaz2FIbWQ4Kbj616RHl3",
"name": "ardrive"
} buyRecord() Purchases a new ArNS record with the specified name, type, processId, and duration.Note: Requires signer to be provided on ARIO.init to sign the transaction.Arguments:name - required: the name of the ArNS record to purchase type - required: the type of ArNS record to purchase processId - optional: the process id of an existing ANT process. If not provided, a new ANT process using the provided signer will be spawned, and the ArNS record will be assigned to that process.years - optional: the duration of the ArNS record in years. If not provided and type is lease, the record will be leased for 1 year. If not provided and type is permabuy, the record will be permanently registered.referrer - optional: track purchase referrals for analytics (e.g. my-app.com) upgradeRecord() Upgrades an existing leased ArNS record to a permanent ownership. The record must be currently owned by the caller and be of type "lease".Note: Requires signer to be provided on ARIO.init to sign the transaction.const ario = ARIO.mainnet({ signer });
const record = await ario.upgradeRecord(
{
name: 'ardrive',
referrer: 'my-app.com', // optional: track purchase referrals for analytics
},
{
// optional tags
tags: [{ name: 'App-Name', value: 'ArNS-App' }],
},
);getArNSRecord() Retrieves the record info of the specified ArNS name.const ario = ARIO.mainnet();
const record = await ario.getArNSRecord({ name: 'ardrive' });Output:{
"processId": "bh9l1cy0aksiL_x9M359faGzM_yjralacHIUo8_nQXM",
"endTimestamp": 1752256702026,
"startTimestamp": 1720720819969,
"type": "lease",
"undernameLimit": 100
} getArNSRecords() Retrieves all registered ArNS records of the ARIO process, paginated and sorted by the specified criteria. The cursor used for pagination is the last ArNS name from the previous request.const ario = ARIO.mainnet();
// get the newest 100 names
const records = await ario.getArNSRecords({
limit: 100,
sortBy: 'startTimestamp',
sortOrder: 'desc',
});Available sortBy options are any of the keys on the record object, e.g. name, processId, endTimestamp, startTimestamp, type, undernames.Output:{
"items": [
{
"name": "ao",
"processId": "eNey-H9RB9uCdoJUvPULb35qhZVXZcEXv8xds4aHhkQ",
"purchasePrice": 75541282285,
"startTimestamp": 1720720621424,
"endTimestamp": 1752256702026,
"type": "permabuy",
"undernameLimit": 10
},
{
"name": "ardrive",
"processId": "bh9l1cy0aksiL_x9M359faGzM_yjralacHIUo8_nQXM",
"endTimestamp": 1720720819969,
"startTimestamp": 1720720620813,
"purchasePrice": 75541282285,
"type": "lease",
"undernameLimit": 100
},
{
"name": "arweave",
"processId": "bh9l1cy0aksiL_x9M359faGzM_yjralacHIUo8_nQXM",
"endTimestamp": 1720720819969,
"startTimestamp": 1720720620800,
"purchasePrice": 75541282285,
"type": "lease",
"undernameLimit": 100
},
{
"name": "ar-io",
"processId": "bh9l1cy0aksiL_x9M359faGzM_yjralacHIUo8_nQXM",
"endTimestamp": 1720720819969,
"startTimestamp": 1720720619000,
"purchasePrice": 75541282285,
"type": "lease",
"undernameLimit": 100
},
{
"name": "fwd",
"processId": "bh9l1cy0aksiL_x9M359faGzM_yjralacHIUo8_nQXM",
"endTimestamp": 1720720819969,
"startTimestamp": 1720720220811,
"purchasePrice": 75541282285,
"type": "lease",
"undernameLimit": 100
}
// ...95 other records
],
"hasMore": true,
"nextCursor": "fwdresearch",
"totalItems": 21740,
"sortBy": "startTimestamp",
"sortOrder": "desc"
} getArNSRecordsForAddress() Retrieves all registered ArNS records of the specified address according to the ANTRegistry access control list, paginated and sorted by the specified criteria. The cursor used for pagination is the last ArNS name from the previous request.const ario = ARIO.mainnet();
const records = await ario.getArNSRecordsForAddress({
address: 't4Xr0_J4Iurt7caNST02cMotaz2FIbWQ4Kbj616RHl3',
limit: 100,
sortBy: 'startTimestamp',
sortOrder: 'desc',
});Available sortBy options are any of the keys on the record object, e.g. name, processId, endTimestamp, startTimestamp, type, undernames.Output:{
"limit": 1,
"totalItems": 31,
"hasMore": true,
"nextCursor": "ardrive",
"items": [
{
"startTimestamp": 1740009600000,
"name": "ardrive",
"endTimestamp": 1777328018367,
"type": "permabuy",
"purchasePrice": 0,
"undernameLimit": 100,
"processId": "hpF0HdijWlBLFePjWX6u_-Lg3Z2E_PrP_AoaXDVs0bA"
}
],
"sortOrder": "desc",
"sortBy": "startTimestamp"
} increaseUndernameLimit() Increases the undername support of a domain up to a maximum of 10k. Domains, by default, support up to 10 undernames.Note: Requires signer to be provided on ARIO.init to sign the transaction.const ario = ARIO.mainnet({ signer: new ArweaveSigner(jwk) });
const { id: txId } = await ario.increaseUndernameLimit(
{
name: 'ar-io',
qty: 420,
referrer: 'my-app.com', // optional: track purchase referrals for analytics
},
// optional additional tags
{ tags: [{ name: 'App-Name', value: 'My-Awesome-App' }] },
);extendLease() Extends the lease of a registered ArNS domain, with an extension of 1-5 years depending on grace period status. Permanently registered domains cannot be extended.const ario = ARIO.mainnet({ signer: new ArweaveSigner(jwk) });
const { id: txId } = await ario.extendLease(
{
name: 'ar-io',
years: 1,
referrer: 'my-app.com', // optional: track purchase referrals for analytics
},
// optional additional tags
{ tags: [{ name: 'App-Name', value: 'My-Awesome-App' }] },
);getTokenCost() Calculates the price in mARIO to perform the interaction in question, eg a 'Buy-Name' interaction, where args are the specific params for that interaction.const price = await ario
.getTokenCost({
intent: 'Buy-Name',
name: 'ar-io',
type: 'permabuy',
})
.then((p) => new mARIOToken(p).toARIO()); // convert to ARIO for readability Output:1642.34 getCostDetails() Calculates the expanded cost details for the interaction in question, e.g a 'Buy-Name' interaction, where args are the specific params for that interaction. The fromAddress is the address that would be charged for the interaction, and fundFrom is where the funds would be taken from, either balance, stakes, or any.const costDetails = await ario.getCostDetails({
intent: 'Buy-Name',
fromAddress: 't4Xr0_J4Iurt7caNST02cMotaz2FIbWQ4Kbj616RHl3',
fundFrom: 'stakes',
name: 'ar-io',
type: 'permabuy',
});Output:{
"tokenCost": 2384252273,
"fundingPlan": {
"address": "t4Xr0_J4Iurt7caNST02cMotaz2FIbWQ4Kbj616RHl3",
"balance": 0,
"stakes": {
"Rc80LG6h27Y3p9TN6J5hwDeG5M51cu671YwZpU9uAVE": {
"vaults": [],
"delegatedStake": 2384252273
}
},
"shortfall": 0
},
"discounts": []
} getDemandFactor() Retrieves the current demand factor of the network. The demand factor is a multiplier applied to the cost of ArNS interactions based on the current network demand.const ario = ARIO.mainnet();
const demandFactor = await ario.getDemandFactor();Output:1.05256 getArNSReturnedNames() Retrieves all active returned names of the ARIO process, paginated and sorted by the specified criteria. The cursor used for pagination is the last returned name from the previous request.const ario = ARIO.mainnet();
const returnedNames = await ario.getArNSReturnedNames({
limit: 100,
sortBy: 'endTimestamp',
sortOrder: 'asc', // return the returned names ending soonest first
});Output:{
"items": [
{
"name": "permalink",
"endTimestamp": 1730985241349,
"startTimestamp": 1729775641349,
"baseFee": 250000000,
"demandFactor": 1.05256,
"initiator": "GaQrvEMKBpkjofgnBi_B3IgIDmY_XYelVLB6GcRGrHc",
"settings": {
"durationMs": 1209600000,
"decayRate": 0.000000000016847809193121693,
"scalingExponent": 190,
"startPriceMultiplier": 50
}
}
],
"hasMore": false,
"totalItems": 1,
"sortBy": "endTimestamp",
"sortOrder": "asc"
} getArNSReturnedName() Retrieves the returned name data for the specified returned name.const ario = ARIO.mainnet();
const returnedName = await ario.getArNSReturnedName({ name: 'permalink' });Output:{
"name": "permalink",
"endTimestamp": 1730985241349,
"startTimestamp": 1729775641349,
"baseFee": 250000000,
"demandFactor": 1.05256,
"initiator": "GaQrvEMKBpkjofgnBi_B3IgIDmY_XYelVLB6GcRGrHc",
"settings": {
"durationMs": 1209600000,
"decayRate": 0.000000000016847809193121693,
"scalingExponent": 190,
"startPriceMultiplier": 50
}
} How is this guide?Gateways TypeScript/JavaScript SDK for interacting with the AR.IO ecosystem Epochs TypeScript/JavaScript SDK for interacting with the AR.IO ecosystem

---

# 82. Data Retrieval  ARIO Documentation

Document Number: 82
Source: https://docs.ar.io/learn/gateways/data-retrieval
Words: 564
Quality Score: 0.424
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Gateways AR.IO gateways use a sophisticated multi-tier architecture to retrieve and serve Arweave data. This system ensures high availability, fast response times, and data integrity by leveraging multiple data sources with automatic fallback mechanisms.How Gateways Retrieve Data When a gateway needs to serve data, it follows a hierarchical retrieval pattern, trying each source in order until the data is successfully retrieved:Data Sources AR.IO gateways can retrieve data from multiple sources, each with different characteristics:1. Trusted Gateways Purpose: Peer-to-peer data sharing between verified AR.IO gateways Benefits: Distributed redundancy, load balancing, network resilience Trust Mechanism: Performance-based trust scores and reciprocity monitoring Selection: Prioritized based on established trust relationships 2. AR.IO Network (Untrusted Peers) Purpose: Broader network of AR.IO gateways without established trust Benefits: Geographic distribution, expanded data availability Selection: Weighted random selection based on performance metrics Validation: Enhanced verification required due to untrusted nature 3. Chunk Assembly Purpose: Direct reconstruction from Arweave chunks via known offsets Benefits: Data integrity guarantee, no intermediary trust required Process: Fetches individual chunks efficiently and assembles them into complete data Optimization: Uses offset awareness for faster chunk retrieval 4. TX Data Purpose: Direct access to transaction data from Arweave nodes Benefits: Authoritative data source, complete historical access Trade-off: Higher latency but guaranteed availability Use Case: Final fallback when other sources fail Retrieval Strategies Gateways employ different strategies based on the use case:On-Demand Retrieval Optimized for user requests with emphasis on speed:Priority order: Trusted Gateways → Untrusted Peers (AR.IO Network) → Chunks Assembly → Arweave Aggressive timeouts: Quick fallback to next source Parallel attempts: May query multiple sources simultaneously Response streaming: Begin serving data as soon as available Background Retrieval Used specifically for unbundling and verification processes:Unbundling operations: Extracting individual data items from ANS-104 bundles Data verification: Comprehensive validation of retrieved data integrity Integrity focus: Prefers authoritative sources for accurate processing Relaxed timeouts: Allows for slower but reliable retrieval during verification Verification priority: Extensive validation before caching verified data Trust and Validation Peer Trust Management Gateways maintain sophisticated trust relationships:Trust factors include:Response performance: Latency and throughput metrics Success rates: Percentage of successful requests Data validity: Cryptographic verification results Reciprocity: Mutual data sharing behavior Data Validation Process Every piece of retrieved data undergoes validation:Hash Verification: Computed hash must match expected value Merkle Proof Validation: Chunks proven against transaction root Signature Verification: Transaction signatures validated Size Confirmation: Data size matches header declaration Why Multi-Source Retrieval Matters For Gateway Operators Reduced infrastructure costs: Leverage peer resources Improved reliability: Multiple fallback options Better performance: Optimal source selection Network effects: Benefit from collective infrastructure For Users Faster access: Data served from optimal source High availability: Multiple paths to data Geographic optimization: Nearby sources preferred Consistent experience: Transparent source selection The data retrieval system is fundamental to AR.IO's mission of providing reliable, performant access to the permaweb. This sophisticated architecture ensures that Arweave's permanent data remains accessible through a resilient, distributed gateway network.Related Gateway Concepts Data Verification Learn how gateways ensure data integrity through cryptographic verification Gateway Architecture Understand the technical architecture and design decisions of AR.IO gateways Access Data Practical guide to retrieving data from Arweave using various methods Optimize Your Gateway Configure indexing and filtering to optimize gateway performance How is this guide?Architecture Learn about the technical architecture of AR.IO gateways, their core dependencies, and key design decisions Data Verification How AR.IO gateways ensure data integrity by verifying chunks are correctly stored and retrievable from Arweave

---

# 83. Extensions  Sidecars  ARIO Documentation

Document Number: 83
Source: https://docs.ar.io/build/extensions
Words: 249
Quality Score: 0.421
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

What are Extensions?Extensions are additional scripts and tools you can run alongside your gateway to expand its capabilities or enhance the operator experience.The full list of community extensions can be found at gateways.ar.io/#/extensions.What are Sidecars?Sidecars are dockerized services that add additional functionality, APIs, and services to AR.IO gateways. They run as separate containers alongside your gateway, providing specialized capabilities.Getting Started with Team-Supported Sidecars The following sidecars are developed and maintained by the AR.IO team, designed to run alongside your gateway as separate containers.Grafana Monitoring Sidecar Visualize gateway metrics with comprehensive dashboards and performance monitoring.ClickHouse & Parquet Improve query performance for large datasets using columnar storage and
analytical optimization.Bundler Sidecar Accept and process ANS-104 data item uploads with multiple payment methods and
access control.AO Compute Unit Sidecar Execute AO processes locally with WASM module support and state management.Ready to enhance your gateway? Click any sidecar above to get started with detailed setup guides.Explore More Monitor your gateway with Grafana Set up comprehensive monitoring and analytics for your gateway infrastructure Performance Optimization Optimize your gateway for large datasets and high-performance queries Gateway Operations Learn advanced gateway management, troubleshooting, and configuration Developer SDKs Integrate AR.IO services into your applications with our SDKs How is this guide?Troubleshooting Comprehensive troubleshooting guide and FAQ for AR.IO Gateway operators, including common issues, failed epoch guidance, and frequently asked questions.Grafana Comprehensive guide to deploying and configuring Grafana for AR.IO Gateway monitoring and analytics On this page What are Extensions?What are Sidecars?Getting Started with Team-Supported Sidecars Explore More

---

# 84. Architecture  ARIO Documentation

Document Number: 84
Source: https://docs.ar.io/learn/gateways/architecture
Words: 584
Quality Score: 0.420
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Gateways AR.IO gateways are sophisticated data access layers built on top of the Arweave network. They transform the raw Arweave blockchain into a performant, reliable, and developer-friendly platform for storing and retrieving data. Gateways act as bridges between applications and the permanent storage capabilities of Arweave.Core Technology Stack AR.IO gateways are built using modern, scalable technologies designed for high-performance data operations:Runtime and Language Node.js: The primary runtime environment for all gateway services TypeScript: Core services written with flexible interfaces for customization Event-driven architecture: Enables efficient handling of concurrent operations Data Storage SQLite: Four specialized databases handle different aspects of gateway operations:Chain data indexing Bundle transaction processing Data item management Configuration and metadata Redis: High-speed caching layer for frequently accessed data File system storage: Local caching for frequently accessed data Processing Model Worker-based concurrency: Specialized workers handle different background tasks Event-driven processing: Loosely coupled components communicate via events Streaming data handling: Minimizes memory overhead for large data operations Key Architectural Decisions Several important design decisions shape how AR.IO gateways operate:Data Retrieval Strategy AR.IO gateways use a sophisticated hierarchical fallback system for data retrieval:Trusted gateways: Prioritize data from verified, high-performance peers AR.IO network: Leverage the broader network of AR.IO gateways Chunks data items: Reconstruct data from individual chunks when needed Transaction data: Fall back to raw Arweave transaction data This approach ensures data availability while optimizing for speed and reliability.Verification and Trust Model Multi-level cryptographic verification: Data integrity is verified at multiple points Trust hierarchy: Cached verified data → trusted cached data → network streams Self-healing mechanisms: Automatic recovery and re-verification of corrupted data Verification headers: HTTP headers indicate the verification status of returned data Worker Specialization Different background workers handle specific responsibilities:Block synchronization workers: Keep the gateway synchronized with Arweave blocks Bundle processing workers: Handle Layer 2 bundled data items (ANS-104) Data verification workers: Continuously verify stored data integrity Maintenance workers: Perform cleanup and optimization tasks Scalability and Configuration AR.IO gateways are designed to scale from small personal deployments to large enterprise installations:Modular Architecture Gateway services can be independently configured or disabled based on operator needs:Data serving: Serve cached data to applications Data indexing: Index and process new Arweave data Bundle processing: Handle Layer 2 bundled transactions ArNS routing: Provide Arweave Name System resolution Core Philosophy: Builder Independence A fundamental principle of AR.IO gateway architecture is empowering builders to do the things they care about without relying on any centralized resource to leverage Arweave. This philosophy manifests in several key ways:Extensibility Through Modularity Gateways are designed as extensible platforms that operators can customize through Extensions, sidecar services, and plugin architectures for specialized functionality.Data Sovereignty Operators maintain complete control through Data Retrieval strategies and Data Verification systems that ensure independence from trusted intermediaries.Network Resilience The modular design creates a resilient ecosystem where distributed infrastructure and customizable trust models prevent single points of failure.This architecture ensures that builders can create powerful applications on Arweave while maintaining independence from any centralized infrastructure or service provider.Explore Gateway Capabilities Data Retrieval Learn how gateways fetch data from multiple sources with hierarchical fallback strategies Data Verification Understand how gateways ensure data integrity through cryptographic verification Run Your Own Gateway Set up and operate your own AR.IO gateway to join the network Build Extensions Extend gateway functionality with custom plugins and integrations How is this guide?AR.IO Gateways AR.IO gateways bridge the Arweave network and applications, providing fast, reliable access to permanent data through specialized infrastructure.Data Retrieval How AR.IO gateways retrieve and share data from multiple sources including trusted peers and Arweave nodes

---

# 85. Name Registration  ARIO Documentation

Document Number: 85
Source: https://docs.ar.io/learn/arns/name-registration
Words: 693
Quality Score: 0.417
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Arweave Name System (ArNS) There are two different types of name registrations that can be utilized based upon the needs of the user:Registration Types Lease Registration A name may be leased on a yearly basis. A leased name can have its lease extended or renewed but only up to a maximum active lease of five (5) years at any time.Permanent Registration (Permabuy) A name may be purchased for an indefinite duration with no expiration date.Registering a name requires spending ARIO tokens corresponding to the name's character length and purchase type.Name Registry The ArNS Registry is a list of all registered names and their associated ANT Process IDs. Key rules embedded within the smart contract include:Genesis Prices: Set within the contract as starting conditions Dynamic Pricing: Varies based on name length, purchase type (lease vs buy), lease duration, and current Demand Factor Name Records: Include a pointer to the Arweave Name Token process identifier, lease end time (if applicable), and undername allocation Reassignment: Name registrations can be reassigned from one ANT to another Lease Extension: Anyone with available ARIO Tokens can extend any name's active lease Lease to Permanent Buy: Anyone with available ARIO Tokens can convert a name's lease to a permanent buy Undername Capacity: Additional undername capacity can be purchased for any actively registered name Name Removal: Name records can only be removed from the registry if a lease expires, or a permanent name is returned to the protocol Name Validation Rules All names registered must meet the following criteria:Valid characters: Only numbers 0-9, characters a-z and dashes Dash placement: Dashes cannot be leading or trailing characters Single character domains: Dashes cannot be used in single character domains Length limits: 1 character minimum, 51 characters maximum Reserved names: Cannot be an invalid name predesignated to prevent unintentional use/abuse such as www Lease Management Lease Expirations When a lease term ends, there is a grace period of two (2) weeks where the lease can be renewed before it fully expires. If this grace period elapses, the name is considered expired and returns to the protocol for public registration. Once expired, a name's associated undername registrations and capacity also expire.A recently expired name's registration shall be priced subject to the "Returned Name Premium" mechanics.Lease to Permabuy Conversions An actively leased name may be converted to a permanent registration. The price for this conversion shall be treated as if it were a new permanent name purchase.This functionality allows users to transition from leasing to permanent ownership based on changing needs and available resources. It generates additional protocol revenue through conversion fees, contributing to the ecosystem's financial health and reward system.Permanent Name Return Users have the option to "return" their permanently registered names back to the protocol. This process allows users to relinquish their ownership, returning the name to the protocol for public re-registration. Only the Owner of a name can initiate a name return.When a permanent name is returned, the name is subject to a "Returned Name Premium", similar to expired leases. A key difference is that if the name is repurchased during the premium window, the proceeds are split between the returning owner and the protocol balance.Primary Names The Arweave Name System (ArNS) supports the designation of a "Primary Name" for users, simplifying how Arweave addresses are dised across applications. A Primary Name is a user-friendly alias that replaces complex wallet addresses, making interactions and profiles easier to manage and identify.Users can set one of their owned ArNS names as their Primary Name, subject to a small fee. This allows applications to use a single, human-readable identifier for a wallet, improving user experience across the network.Next Steps Now that you understand name registration, learn about Arweave Name Tokens (ANTs) to see how ownership and control work, or explore the Pricing Model to understand how costs are calculated.How is this guide?Arweave Name System (ArNS) ArNS is a censorship-resistant naming system stored on Arweave, powered by ARIO tokens, enabled through AR.IO gateway domains, and used to connect friendly domain names to permaweb apps, web pages, data, and identities.Arweave Name Tokens (ANTs) Learn about Arweave Name Tokens (ANTs) - the ownership and control system for ArNS names

---

# 86. Add to Wander  ARIO Documentation

Document Number: 86
Source: https://docs.ar.io/learn/token/add-to-wander
Words: 638
Quality Score: 0.415
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Token Adding ARIO Token to Wander Wander (formerly ArConnect) is the primary wallet for the Arweave ecosystem and provides native support for AO tokens like ARIO. Follow this guide to add ARIO to your wallet and start viewing your token balance.Prerequisites Before adding ARIO to your Wander wallet, ensure you have:Wander Wallet Installed: Download from wander.app for desktop or mobile Wallet Setup Complete: Your wallet should be created and secured with a backup phrase Active Internet Connection: Required for token import and balance queries Step-by-Step Workflow Open Wander Wallet Launch your Wander wallet application:Desktop: Open the Wander desktop application Mobile: Tap the Wander app icon on your device Access Settings Menu Navigate to the settings section of your wallet:For Mobile Users:Tap the 3 vertical dots (⋮) in the top right corner of the screen Select "Settings" from the dropdown menu For Desktop Users:Click the hamburger menu icon (☰) in the bottom right corner Navigate to the settings section Import New Token Click the "Import Token" button You'll see a form for adding new token details Configure Token Type (Desktop Only) For Desktop Users:Ensure the "Asset/Collectible" dropdown is set to "Asset" This tells Wander that you're adding a fungible token, not an NFT Enter ARIO Token Details In the Process ID field, enter the ARIO token process ID:qNvAoz0TgcH7DMg8BCVn8jF32QH5L6T29VjHxhHqqGE Once you enter the Process ID, Wander will automatically populate:Token Ticker: "ARIO" Token Name: "AR.IO Network" Verify that the auto-populated information is correct Complete the Import Click "Add Token" to complete the import process Wander will add ARIO to your token list and begin querying your balance Verify Token Addition After successful import, you should see:ARIO listed in your wallet's token section Your current ARIO balance (if you hold any tokens) The ARIO token logo and ticker Viewing Your ARIO Balance Once ARIO is added to your Wander wallet:Your total ARIO balance appears alongside other tokens Balances update automatically when you receive or send tokens Tap/click on ARIO to view detailed transaction history Token Details Balance: Current ARIO token holdings Value: Estimated value (if price data is available) Transactions: Recent ARIO transaction history Actions: Send, receive, and manage tokens Managing ARIO Tokens Sending ARIO Select ARIO from your token list Click "Send" Enter recipient address and amount Confirm transaction details and send Receiving ARIO Select ARIO from your token list Click "Receive" Share your wallet address or QR code Incoming tokens will appear automatically Transaction History View all ARIO transactions in the token detail view Check transaction status and confirmations Access transaction IDs for verification Troubleshooting Token Not Appearing If ARIO doesn't appear after import:Refresh: Try refreshing the wallet or restarting the app Process ID: Verify you entered the correct process ID Network: Check your internet connection Support: Contact Wander support if issues persist Balance Not Updating If your balance isn't showing correctly:Sync: Allow time for the wallet to sync with the network Manual Refresh: Use the refresh option in the token list Network Status: Check if there are known network issues Import Errors If you encounter errors during import:Format Check: Ensure the process ID is correctly formatted Network Connection: Verify stable internet connectivity Wallet Version: Update to the latest version of Wander Try Again: Sometimes retrying the import process works Next Steps After successfully adding ARIO to Wander:Buy an ArNS Name: Purchase an ArNS name directly in Wander and set it as your primary name for easy identification Join the Network: Visit https://gateways.ar.io to join as a gateway operator or delegate your tokens to existing operators Stay Connected: Join the Discord community to updates and participate in discussions Your Wander wallet is now configured to manage ARIO tokens, giving you full access to the AR.IO ecosystem's financial features and services.How is this guide?Get the Token Learn how to acquire $ARIO tokens through various methods including exchanges, swaps, and network participation

---

# 87. Use Cases  ARIO Documentation

Document Number: 87
Source: https://docs.ar.io/learn/wayfinder/use-cases
Words: 515
Quality Score: 0.413
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Wayfinder Decentralized Web Hosting with Flexible Access With Wayfinder, not only can websites be hosted on the Arweave network, but their accessibility is also enhanced. By using the Wayfinder Protocol, web developers can ensure that if a specific AR.IO Gateway is down, the content can still be accessed through another gateway, offering a more reliable and resilient user experience.This is particularly valuable for:Personal websites that need to remain accessible Documentation sites that must be always available Portfolio sites for professionals and creators Digital Archives and Preservation with Enhanced Sharing Digitally archiving public domain works, especially in light of events like "banned books week", becomes more efficient with Wayfinder. Historical institutions or enthusiasts can easily share specific Wayfinder links to documents or media.Unlike hardcoded links which might break if a specific gateway goes offline, Wayfinder ensures that the content remains consistently accessible.This is ideal for:Historical documents and public domain works Academic research and scholarly articles Cultural preservation projects Legal documents that need permanent access Media Sharing Platforms with Consistent Content Delivery For platforms hosting user-generated content, the Wayfinder Protocol provides not just decentralized hosting but also a guarantee of content delivery. Even if a content piece becomes viral and one gateway gets congested, Wayfinder ensures that users can still access the content through another gateway, providing a seamless experience.Perfect for:Social media platforms with user-generated content Video sharing sites with viral content Image galleries and art platforms Podcast hosting and audio content Decentralized Applications (DApps) with Reliable Front-End Accessibility DApps, while benefiting from Arweave's permanent hosting, can further ensure their front-end remains consistently accessible to users by using Wayfinder. If a DApp's front-end is accessed frequently, causing strain on one gateway, Wayfinder can help ensure the load is distributed, and the DApp remains online and functional.This is essential for:DeFi applications that need high availability NFT marketplaces with high traffic Gaming platforms with real-time requirements Collaborative tools and productivity apps Branded Content Access Companies and individuals can brand their permaweb content, making it accessible through their domain, enhancing brand visibility and user trust. This is achieved through DNS TXT records that link domain names to Arweave content.Dynamic Content Updates Domain owners can easily update what Permaweb content their ar:// URL resolves to, which is ideal for frequently updated resources like documents, blogs, and application interfaces.Educational and Informational Resources Educational institutions and information providers can make their resources permanently available on the permaweb, accessible through simple, memorable URLs.Next Steps Ready to get started with Wayfinder? Explore Integration Methods to see how to implement Wayfinder in your applications, or go back to the Overview to review the basics.How is this guide?Integration Use the Wayfinder browser extension or integrate Wayfinder libraries into your applications Token Learn about the ARIO token - the multifunction AO Computer based token that powers the AR.IO Network and its suite of permanent cloud applications On this page Decentralized Web Hosting with Flexible Access Digital Archives and Preservation with Enhanced Sharing Media Sharing Platforms with Consistent Content Delivery Decentralized Applications (DApps) with Reliable Front-End Accessibility Branded Content Access Dynamic Content Updates Educational and Informational Resources Next Steps

---

# 88. Observer Selection  ARIO Documentation

Document Number: 88
Source: https://docs.ar.io/learn/oip/observer-selection
Words: 711
Quality Score: 0.413
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Observation & Incentive Protocol Epochs and Selection Timeline The AR.IO network operates on 24-hour epochs, during which the observer selection and evaluation process takes place. At the start of each epoch:50 observers are selected to monitor the network 2 prescribed ArNS names are chosen for all observers to test 8 additional names are selected by each observer individually Gateway subset is selected for chunk/offset validation based on sampling rate This creates a consistent evaluation framework where all observers test the same baseline names while having flexibility to choose additional targets for comprehensive network monitoring, plus advanced data integrity verification.Selection Process Up to fifty (50) gateways are selected as observers per epoch using a sophisticated weighted random selection system. The selection uses hashchain entropy from previous AR.IO contract state messages to ensure unpredictable and tamper-resistant selection.The hashchain-based entropy provides cryptographic randomness for selecting:Observer Gateways: The 50 gateways chosen to perform observations Prescribed ArNS Names: The 2 common names all observers must evaluate This approach prevents manipulation while maintaining weighted probabilities based on gateway performance and commitment. gateways.ar.io/#/observers shows the current epoch prescribed observers and arns names, as well as their
submission status Weighted Selection Criteria Observer selection is based on normalized composite weights that combine multiple performance and commitment factors. These weights determine each gateway's probability of being selected as an observer for the epoch.The selection considers four key factors that are multiplied together to create a composite weight (CW):Stake Weight (SW): Financial commitment to the network Tenure Weight (TW): Length of network participation Gateway Performance Ratio Weight (GPRW): Historical gateway performance Observer Performance Ratio Weight (OPRW): Historical observer performance These weights are then normalized across all eligible gateways to create selection probabilities. For detailed weight calculations and formulas, see Performance Evaluation.Hashchain Random Selection The selection process uses hashchain entropy from previous AR.IO contract state messages to achieve cryptographically secure randomness:How Hashchain Selection Works Entropy Source: Random numbers are generated from the hashchain of previous contract state messages Weighted Mapping: Each random number maps to normalized weight ranges of eligible gateways Observer Selection: The gateway whose weight range contains each random number is selected Prescribed Names: The same entropy selects 2 ArNS names that all observers must test This creates tamper-resistant selection where higher-weighted gateways have proportionally better chances of selection, while maintaining true randomness that cannot be predicted or manipulated.Chunk/Offset Sampling In addition to observer selection, the protocol includes a separate sampling process for chunk/offset validation:Gateway Selection for Chunk Validation Deterministic Selection: Uses PRNG seeded with observation entropy to select gateway subset Sampling Rate: Configurable percentage of gateways tested per observation (default: 1%) Minimum Guarantee: At least 1 gateway is always selected for testing Offset Selection: Random offsets within the stable weave range are chosen for each selected gateway Initial Implementation: During the initial rollout phase, only a very
small portion of gateways will be checked for chunk/offset validation, and the
current validation criteria are extremely lenient to ensure smooth network
operation.Validation Process Chunk Retrieval: Observers request chunk data using GET /chunk/{offset} Merkle Proof Verification: Cryptographic validation ensures data integrity Early ping: Tests immediately upon first successful validation Performance Optimization: Uses LRU caching for efficient transaction lookup Fairness and Meritocracy This system ensures:Meritocratic Selection: Higher-performing gateways have better selection odds Fair Opportunity: All gateways maintain non-zero selection probability Tamper Resistance: Hashchain entropy prevents manipulation Consistent Standards: Prescribed names create common evaluation baseline The selection is saved in the contract state at epoch start to ensure that activities during the epoch do not affect selection or reward distribution. Next Steps Ready to understand how performance is evaluated? Learn about Performance Evaluation to see how gateways are scored, or explore Reward Distribution to understand how rewards are calculated and distributed.How is this guide?Observation & Incentive Protocol The Observation and Incentive Protocol is designed to maintain and enhance the operational integrity of gateways on the AR.IO Network through a combination of incentivizing gateways for good performance and tasking those gateways to fulfill the role of observers Reporting Learn about observer responsibilities for submitting reports to Arweave and the AR.IO Smart Contract On this page Epochs and Selection Timeline Selection Process Weighted Selection Criteria Hashchain Random Selection How Hashchain Selection Works Chunk/Offset Sampling Gateway Selection for Chunk Validation Validation Process Fairness and Meritocracy Next Steps

---

# 89. Deploy a dApp with ArDrive Web  ARIO Documentation

Document Number: 89
Source: https://docs.ar.io/build/guides/deploy-dapp-with-ardrive-web
Words: 654
Quality Score: 0.411
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Guides Create permanent dApps using the ArDrive web interface. This guide shows you how to deploy your dApp or website to the permaweb using ArDrive's user-friendly interface.What You'll Learn How to deploy dApps using ArDrive web Creating manifests for proper file routing Assigning friendly ArNS names Updating your dApp with new versions Prerequisites For simple apps and websites:Your dApp files ready for deployment ArDrive account (free to create) For advanced applications:dApp prepared with hash routing and relative file paths Static files built (for frameworks like React) your dApp for deployment Step-by-Step Deployment Log into ArDrive Go to the ArDrive web app and log in using your preferred method. If you don't have an account, follow the instructions to create one.Select or Create a Drive Navigate to the drive where you want your project hosted. If you need a new drive:Click the big red "New" button at the top left Create a new drive Important: Set the drive to public for others to access your dApp Upload Your Project With your drive selected:Click the big red "New" button again Select "Upload Folder" Navigate to your project's root directory (or built directory if required) Select the entire directory to maintain your project's file structure Confirm Upload Review the upload and associated cost. If everything looks correct, click "Confirm".Create the Manifest While ArDrive diss files as a traditional file structure, they don't actually exist that way on Arweave. The manifest acts as a map to all your dApp files:Navigate into your newly created folder by double-clicking it Click the big red "New" button again Select "New Manifest" in the "Advanced" section Name the manifest and save it inside the folder you just created Get the Data TX ID Once the manifest is created:Click on it to expand its details Go to the "Details" tab Find the "Data TX ID" on the bottom right Copy this unique identifier for your dApp View and Share Your dApp Your dApp is now live on the permaweb forever!Append the Data TX ID to an Arweave gateway URL: https://arweave.net/YOUR-TX-ID It may take a few minutes for files to propagate through the network Once propagated, your dApp is accessible to anyone, anywhere, at any time Assign a Friendly Name (Optional) Make your dApp easier to access with an ArNS name:If you own an ArNS name, you'll be prompted during manifest creation If not, purchase one from arns.app You can also assign an ArNS name later by clicking the three dots next to any file and selecting "Assign ArNS name" Updating Your dApp Files uploaded to Arweave are permanent and immutable - they cannot be changed. However, the Arweave File System (ArFS) protocol lets you "replace" them with new versions while keeping old ones accessible.How Updates Work To update your dApp:Make your changes and build the static directory Upload the entire folder again to the same location Follow the same steps as the original upload Create a new manifest with the same name as the old one The new manifest generates a new TX ID for the updated dApp Important Notes:The old version remains accessible to anyone with the correct TX ID Old files won't dis in ArDrive unless you view file history Each version gets its own unique transaction ID Benefits of ArDrive Web Deployment User-friendly interface - No command line required Automatic manifest creation - Handles file routing for you Integrated ArNS support - Easy domain name assignment Version management - Built-in file history and updates Cost transparency - See upload costs before confirming Ready to Deploy?Try ArDrive Web Deploy your dApp using the ArDrive web interface Get an ArNS Name Learn how to create friendly domain names for your dApp Advanced Deployment Explore more advanced deployment options and tools How is this guide?Hosting Decentralized Websites Build permanent, censorship-resistant websites on Arweave using manifests and deployment tools Working With Primary Names Create web3 identity using ArNS names that resolve to wallet addresses

---

# 90. What is the Permaweb  ARIO Documentation

Document Number: 90
Source: https://docs.ar.io/learn/permaweb
Words: 682
Quality Score: 0.405
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Introduction The permaweb is a decentralized, permanent layer of the internet where data, applications, and websites are stored forever and remain accessible through a global network of gateways.How the Permaweb Works Unlike the traditional web where data can disappear when servers go offline, the permaweb creates a permanent archive of human knowledge through a multi-layer architecture:Foundation: Arweave blockchain provides immutable storage Computation: AO and other platforms enable smart contracts and processing Access: AR.IO gateway network makes everything accessible globally Users: Developers and users interact through familiar web interfaces This architecture ensures that once something is published to the permaweb, it remains accessible forever, creating a truly permanent internet.Permaweb Network Architecture The permaweb operates through a layered system architecture where each component provides specialized services to create a permanent, decentralized internet.Applications & Users Web Apps, dApps, Developers, End Users AO Decentralized Compute AR.IO Decentralized Access Arweave Permanent Storage Foundation Permaweb Architecture: How It All Connects The permaweb operates through a four-layer architecture where each layer serves a specific purpose in creating permanent, accessible internet infrastructure:Layer 1: Permanent Storage (Arweave) Core Responsibility: Forever Data Preservation Arweave's primary job is to store data permanently with mathematical guarantees:Immutable storage - Once written, data cannot be changed or deleted Economic sustainability - Endowment model ensures miners are paid to store data forever Cryptographic verification - Proof that data exists and hasn't been tampered with Decentralized replication - Data survives even if most miners go offline Layer 2: Decentralized Compute (AO) Core Responsibility: Smart Contract Execution AO's primary job is to run programs that work with permanent data:Process execution - Runs smart contracts and applications on permanent data Message routing - Enables communication between different processes State management - Maintains application state using permanent storage Parallel computation - Scales processing across multiple nodes Layer 3: Decentralized Access (AR.IO) Core Responsibility: Data Access & Discovery AR.IO's primary job is to make permanent data fast and accessible:Data retrieval - Fetches and serves content from Arweave storage Content indexing - Organizes and catalogs data for search and discovery ArNS resolution - Converts human-readable names to Arweave transaction IDs Performance optimization - Caches popular content for faster access Quality assurance - Validates data integrity and provides reliable access Layer 4: Applications & Users Core Responsibility: User Interface & Experience Applications and users are responsible for interacting with the permanent web:User interfaces - Create familiar web experiences backed by permanent data Data submission - Upload new content and applications to the permaweb Application logic - Build decentralized apps using permanent storage and compute Content consumption - Browse, search, and interact with permanent web content The Vision of the Permaweb The permaweb represents a fundamental shift from the ephemeral nature of today's internet to a permanent, censorship-resistant foundation for human knowledge and applications. By combining Arweave's immutable storage with AO's decentralized compute and AR.IO's accessible gateway network, the permaweb creates an internet where data never disappears, applications run without central points of failure, and users maintain true ownership of their digital assets.This architecture enables a new generation of applications that can operate indefinitely without relying on traditional hosting services, where digital artifacts become truly permanent, and where the collective knowledge of humanity is preserved for future generations. The permaweb isn't just about storing data forever—it's about building a more resilient, equitable, and permanent foundation for the digital world.Explore the Permaweb What is AR.IO?Learn how AR.IO provides the gateway layer for accessing permanent data What is Arweave?Understand the permanent storage foundation of the permaweb ArNS Names Discover how human-readable names work on the permaweb Start Building Get started building applications on the permanent web How is this guide?What is AR.IO?AR.IO is the world's first permanent cloud network providing infrastructure for timeless, tamper-proof, and universally accessible data What are Bundles?Learn about ANS-104 bundling standards and how they optimize data submission to Arweave On this page How the Permaweb Works Permaweb Network Architecture Permaweb Architecture: How It All Connects Layer 1: Permanent Storage (Arweave) Layer 2: Decentralized Compute (AO) Layer 3: Decentralized Access (AR.IO) Layer 4: Applications & Users The Vision of the Permaweb Explore the Permaweb

---

# 91. Gateway Registry  ARIO Documentation

Document Number: 91
Source: https://docs.ar.io/learn/gateways/gateway-registry
Words: 749
Quality Score: 0.395
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Gateways Overview The AR.IO Network consists of AR.IO gateway nodes, which are identified by their registered Arweave wallet addresses and either their IP addresses or hostnames, as stored in the network's smart contract Gateway Address Registry (GAR).Any gateway operator that wishes to join the AR.IO Network must register their node in the AR.IO smart contract's Gateway Address Registry. Registration involves staking a minimum amount of ARIO tokens and providing additional metadata describing the gateway service offered.These nodes adhere to the AR.IO Network's protocols, creating a collaborative environment of gateway nodes that vary in scale and specialization. The network promotes a fundamental level of service quality and trust minimization among its participants. The gateways.ar.io portal diss all gateways currently in the network, showing their stakes, performance scores, and operational metrics Benefits of Joining the Network Being part of the network grants AR.IO gateways an array of advantages:Simplified advertising of services and discovery by end users via the Gateway Address Registry More rapid bootstrapping of key gateway operational data due to prioritized data request fulfillment among gateways joined to the network Sharing of data processing results Auditability and transparency through the use of AGPL-3 licenses, which mandate public disclosure of any software changes, thereby reinforcing the network's integrity and reliability Improved network reliability and performance through an incentive protocol, which uses a system of evaluations and rewards to encourage high-quality service from gateways Eligibility to accept delegated staking improving a gateway's discoverability and reward opportunities Eligibility to receive distributions from the protocol balance - Gateways that have joined the network are eligible to receive token distributions based on their performance and contributions to the network How the GAR Works After joining the network, the operator's gateway can be easily discovered by permaweb apps, its health can be observed, and it can participate in data sharing protocols. A gateway becomes eligible to participate in the network's incentive protocol in the epoch following the one they joined in.The GAR advertises the specific attributes of each gateway including its stake, delegates, settings and services. This enables permaweb apps and users to discover which gateways are currently available and meet their needs. Apps that read the GAR can sort and filter it using the gateway metadata, for example, ranking gateways with the highest stake, reward performance, or feature set at the top of the list. This allows users to prefer the higher staked, more rewarded gateways with certain capabilities over lower staked, less rewarded gateways.Token Incentives and Network Monitoring The AR.IO network uses a sophisticated incentive system to ensure gateway quality and reliability:Token Incentives: gateways earn rewards and participate in the network economy in the Token section Observer Protocol: The network employs an Observer system that monitors gateway performance and ensures quality of service. Observer & Incentive Protocol and how it maintains network integrity Recap The Gateway Registry is the foundation of the AR.IO network's decentralized infrastructure. Key takeaways:Network Participation: Gateways must register and stake ARIO tokens to join the network Protocol Distributions: Registered gateways are eligible to receive token distributions from the protocol balance Observer Monitoring: The network employs an Observer and Incentives Protocol that monitors gateway performance and ensures quality of service Staking & Rewards: Gateways earn rewards based on performance through a sophisticated staking system that includes delegation opportunities Discoverability: The GAR enables apps and users to find suitable gateways based on their needs Performance-Based Selection: Gateway metadata allows for intelligent routing based on stake, performance, and capabilities Transparent Ecosystem: All gateway information is publicly accessible through the smart contract and at gateways.ar.io By joining the network, gateways become part of a collaborative ecosystem that rewards quality service and ensures reliable access to the permaweb.Explore the Gateway Ecosystem Join the Network Learn how to register your gateway and join the AR.IO Network Delegate Stake Participate in the network by delegating stake to existing gateways Observer Protocol Understand how the network monitors gateway performance and quality Gateway Configuration Learn about gateway settings, optimization, and best practices How is this guide?Data Verification How AR.IO gateways ensure data integrity by verifying chunks are correctly stored and retrievable from Arweave Observation & Incentive Protocol The Observation and Incentive Protocol is designed to maintain and enhance the operational integrity of gateways on the AR.IO Network through a combination of incentivizing gateways for good performance and tasking those gateways to fulfill the role of observers On this page Overview Benefits of Joining the Network How the GAR Works Token Incentives and Network Monitoring Recap Explore the Gateway Ecosystem

---

# 92. Architecture  ARIO Documentation

Document Number: 92
Source: https://docs.ar.io/learn/token/architecture
Words: 548
Quality Score: 0.385
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Token ARIO Contract Architecture The $ARIO token operates through a smart contract built on AO Computer. The system is composed of several interconnected components that work together to provide a comprehensive network infrastructure.Core Components Balances The Balances component manages the fundamental token accounting for the ARIO ecosystem:Token Holdings: Tracks ARIO token balances for all network participants Transfer Logic: Handles secure token transfers between addresses Paginated Queries: Provides efficient balance lookups with cursor-based pagination Integration Layer: Connects with all other components for balance updates Gateway Registry The Gateway Registry manages the network's infrastructure providers and all delegation relationships:Gateway Management: Handles gateway registration, settings updates, and network participation Operator Stakes: Manages gateway operator stakes and minimum staking requirements Delegated Stakes: Coordinates delegated stake from token holders to gateway operators Performance Tracking: Monitors gateway performance metrics and eligibility for rewards ArNS Registry The ArNS (Arweave Name System) Registry provides decentralized domain name services:Name Registration: Manages the purchase and registration of friendly names Lease Management: Handles name renewals and lease extensions Primary Names: Allows users to set primary names for their addresses ANT Integration: Links registered names to their corresponding ANT processes Vaults The Vaults component implements token time-locking mechanisms for various ecosystem purposes:Multi-Purpose Locking: Locks tokens for RFPs, bug bounties, investors, and core team members Flexible Terms: Supports various lock periods and amounts based on purpose and requirements Extension Options: Allows participants to extend vault lock periods when needed Withdrawal Logic: Manages secure token release after lock expiration or completion of terms System Processes ANT Registry Process A utility process that facilitates ANT discovery and management:Discovery Service: Makes it easy to find ANTs owned by specific wallet addresses Ownership Tracking: Provides efficient lookup of ANT ownership relationships Integration Support: Connects with wallets and dApps for seamless ANT management Query Interface: Enables paginated queries for ANT discovery ArNS Name Tokens (ANTs) Transferable token processes that represent ownership and control of ArNS names:Name Ownership: Each ANT process controls a specific ArNS name Record Management: ANT holders manage DNS-like records for their names Undername Control: Support for creating and managing subdomains (undernames) Transferable Rights: ANTs can be bought, sold, and transferred as independent tokens Process-Based: Each ANT is its own AO process with autonomous functionality Security Model The architecture implements multiple layers of security:Economic Security Stake Requirements: Minimum stakes ensure operator commitment and skin in the game Performance-Based Removal: Gateways that fail observation for 30 consecutive epochs are removed from the network Complete Stake Slashing: 100% of stake is returned to the protocol balance when gateways are removed for poor performance Observation Consensus: Peer-to-peer monitoring ensures no single point of failure in performance evaluation Technical Security AO Computer: Leverages Arweave's permanent and decentralized compute layer Process Isolation: Separate processes for different system functions Cryptographic Verification: All transactions and state changes are cryptographically secured Governance Security Current Ownership: Currently owned by a multisig with intentions to make ownership immutable Path to Immutability: Plans to transition to fully immutable protocol without governance control Transparent Operations: All system state is publicly verifiable on Arweave Consensus-Based Evaluation: Gateway performance determined by peer consensus rather than centralized authority How is this guide?Token Learn about the ARIO token - the multifunction AO Computer based token that powers the AR.IO Network and its suite of permanent cloud applications Staking Staking desc

---

# 93. Get the Token  ARIO Documentation

Document Number: 93
Source: https://docs.ar.io/learn/token/get-the-token
Words: 316
Quality Score: 0.385
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Token Acquiring ARIO Tokens There are several ways to acquire ARIO tokens, depending on your needs and preferences. Here are the primary methods available:Exchanges and Trading Platforms Centralized Exchanges ARIO tokens are available on centralized exchanges:Gate.io: Trade ARIO with various cryptocurrency pairs Verify exchange security and reputation before trading Consider factors like trading fees, liquidity, and withdrawal limits Decentralized Exchanges (DEXs) Trade ARIO on decentralized platforms within the AO ecosystem:Dexi: Native AO-based decentralized exchange Botega: AO ecosystem trading platform Vento: Decentralized exchange for AO tokens Wallet Integration Wander App: Mobile wallet with built-in ARIO exchange and swap functionality Wander Extension: Browser extension wallet for seamless ARIO transactions Network Participation Gateway Operation Earn ARIO tokens by operating network infrastructure:Set up a Gateway: Deploy and maintain an AR.IO gateway Stake Initial Tokens: Meet minimum staking requirements Provide Services: Offer reliable data storage and retrieval Earn Rewards: Receive ARIO tokens for network participation Token Delegation Earn rewards by supporting existing gateway operators:Choose an Operator: Research and select a trusted gateway Delegate Tokens: Stake your ARIO with the chosen operator Earn Passively: Receive a portion of the operator's rewards Maintain Flexibility: Undelegate tokens when needed Community Programs Grants and Bounties Participate in ecosystem development programs:Developer Grants: Build applications and tools for the AR.IO ecosystem Bug Bounties: Help secure the network by finding and reporting vulnerabilities Community Initiatives: Contribute to documentation, education, and outreach Ecosystem Participation Earn tokens through various community activities:Governance Participation: Engage in network decision-making processes Content Creation: Produce educational content and tutorials Community Building: Help grow and support the AR.IO community Remember that cryptocurrency investments carry risk, and you should only invest what you can afford to lose. Always do your own research and consider consulting with financial advisors when making investment decisions.How is this guide?Staking Staking desc Add to Wander Step-by-step guide to adding the ARIO token to your Wander wallet for viewing balances and managing tokens

---

# 94. Reporting  ARIO Documentation

Document Number: 94
Source: https://docs.ar.io/learn/oip/reporting
Words: 615
Quality Score: 0.381
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Observation & Incentive Protocol Observer Responsibilities Selected observers have specific duties each epoch: test gateways, document results, and submit findings through two channels. Proper completion of these responsibilities determines observer rewards and future selection chances.Dual Submission Process Observers must submit their findings through both channels to fulfill their duties:1. Detailed Reports to Arweave Format: Comprehensive JSON reports with full evaluation data Purpose: Permanent audit trail and transparency Content: Complete test results, timing data, and failure details 2. Contract Interactions to AR.IO Smart Contract Format: List of failed gateways Purpose: Efficient vote tallying for consensus Content: Binary pass/fail determinations for each gateway tested Observer Evaluations Observers test assigned gateways against 10 ArNS names (2 prescribed + 8 chosen) and document their findings: Evaluation Results Passing Report: Gateway successfully resolves ArNS names
with correct status codes (200), transaction IDs, and data hashes. Failing Report: Gateway fails ArNS resolution tests due
to ownership issues, timeouts (5000ms), or missing content.Observers evaluate gateways based on:Gateway Wallet Ownership: Verifies correct wallet address ArNS Resolution: Tests successful name-to-transaction resolution Content Hash Verification: Ensures data integrity Response Times: Measures performance within limits Chunk/Offset Validation: Cryptographic verification of data chunks (for selected gateways) Chunk/Offset Assessment Reporting For gateways selected for chunk/offset validation, observers perform additional testing and reporting:Validation Process Offset Selection: Random offsets within the stable weave range are chosen for testing Chunk Retrieval: Observers request chunk data using GET /chunk/{offset} endpoint Merkle Proof Verification: Cryptographic validation ensures chunk authenticity Binary Search: Efficient transaction lookup using cached metadata for proof validation Reporting Details Individual Assessments: Each offset test is tracked with pass/fail/skipped status Enforcement Status: Reports include whether chunk/offset failures affect gateway status Performance Metrics: Response times and validation results are documented Early ping: Tests immediately upon first successful validation Report Structure {
"offsetAssessments": {
"plannedOffsets": [12345, 67890, ...],
"actualAssessments": [...],
"validatedOffset": 12345,
"pass": true,
"enforcementEnabled": true
}
} Initial Implementation: During the initial rollout phase, only a very
small portion of gateways will be checked for chunk/offset validation, and the
current validation criteria are extremely lenient to ensure smooth network
operation.Observer Rewards and Penalties Observer performance directly impacts rewards and future participation:Successful Observer Performance Observer Reward: Observers who submit both reports and contract interactions receive the Observer Reward Future Selection: Successful reporting improves Observer Performance Ratio Weight (OPRW) Increased Chances: Higher OPRW increases likelihood of future observer selection and more reward opportunities Failed Observer Performance No Observer Reward: Observers who fail to submit required reports forfeit their Observer Reward Gateway Penalty: If the deficient observer is also a functional gateway, their gateway reward is reduced by 25% Reduced Selection: Failed submissions decrease OPRW, diminishing future observer selection chances Lost Opportunities: Lower selection probability means fewer chances to earn Observer Rewards Observer Accountability The system tracks observer performance to ensure network quality:Submission Tracking: Both Arweave reports and contract interactions must be submitted Performance History: Observer submission record affects future selection probability Reward Impact: Consistent reporting builds credibility and increases earning potential Next Steps Ready to understand how these reports are processed? Learn about Performance Evaluation to see how reports become votes and determine gateway rewards, or explore Reward Distribution to understand the complete incentive structure.How is this guide?Observer Selection Learn about how gateways are selected as observers each epoch and how ArNS names are chosen using weighted random selection and Hashchain entropy Performance and Weights Learn about how gateways are evaluated and how weights impact observer selection On this page Observer Responsibilities Dual Submission Process 1. Detailed Reports to Arweave 2. Contract Interactions to AR.IO Smart Contract Observer Evaluations Evaluation Results Chunk/Offset Assessment Reporting Validation Process Reporting Details Report Structure Observer Rewards and Penalties Successful Observer Performance Failed Observer Performance Observer Accountability Next Steps

---

# 95. Performance and Weights  ARIO Documentation

Document Number: 95
Source: https://docs.ar.io/learn/oip/performance-evaluation
Words: 856
Quality Score: 0.375
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Observation & Incentive ProtocolPerformance and WeightsCopy MarkdownOpenGateway Classifications
Consider the following classifications:
Functional or Passed Gateways: are gateways that meet or surpass the network's performance and quality standards, including ArNS resolution and chunk/offset validation (if selected).
Deficient or Failed Gateways: are gateways that fall short of the network's performance expectations, including failures in ArNS resolution or chunk/offset validation.
Functional or Submitted Observers: are selected observers who diligently perform their duties and submit observation reports and contract interactions.
Deficient or Failed Observers: are selected observers who do not fulfill their duty of submitting observation reports and contract interactions.
Evaluation Process
At the end of an epoch, the AR.IO Smart Contract processes observer submissions to determine gateway performance through a consensus-based vote tallying system. This evaluation transforms individual observer reports into network-wide performance assessments.
Vote Tallying and Gateway Classification
After observers submit their detailed reports (see Reporting for submission details), the smart contract performs consensus calculation:
Vote Processing:
Data Collection: All observer contract interactions for each gateway are collected
Vote Counting: Each observer submission contributes either a PASS or FAIL vote
Majority Determination: If ≥50% of submitted observer interactions indicate PASS, the gateway is considered Functional
Binary Classification: Gateways are classified as either Functional (eligible for rewards) or Deficient (ineligible for rewards)
Consensus Mechanism:
Multiple observers evaluate each gateway independently, ensuring reliable assessment
The 50% threshold requires majority agreement for positive performance determination
Binary scoring provides clear, unambiguous performance classification
Vote tallying occurs after the 40-minute confirmation period to ensure all interactions are finalized
Chunk/Offset Validation Criteria
For gateways selected for chunk/offset validation, additional performance criteria are evaluated:
Validation Requirements
Chunk Retrieval: Gateway must successfully respond to GET /chunk/{offset} requests
Data Integrity: Chunk data must be non-empty and within reasonable size limits (<1MB)
Merkle Proof Validation: Cryptographic proof must decode correctly and validate against transaction data_root
Performance Standards: Response times must meet network expectations
Initial Implementation: During the initial rollout phase, only a very
small portion of gateways will be checked for chunk/offset validation, and the
current validation criteria are extremely lenient to ensure smooth network
operation.
Assessment Process
Binary Scoring: Each offset test results in pass/fail determination
Consensus Integration: Chunk/offset results are integrated into overall gateway assessment
Performance Tracking: Individual offset assessments are tracked and reported
Weight Impact on Gateway Performance
Gateway performance directly affects multiple weighted factors that influence future observer selection and overall network participation:
Gateway Performance Ratio Weight (GPRW)
A gateway's evaluation results directly impact their Gateway Performance Ratio Weight, which affects their likelihood of being selected as an observer in future epochs:
GPRW=1+Passed Epochs1+Participated EpochsGPRW = \frac{1 + \text{Passed Epochs}}{1 + \text{Participated Epochs}}
GPRW=1+Participated Epochs1+Passed Epochs
Impact:
Functional Gateways: Increase their passed epochs count, improving their GPRW
Deficient Gateways: Decrease their GPRW as participated epochs increase without corresponding passes
Observer Selection: Higher GPRW increases chances of being selected as an observer
Observer Performance Ratio Weight (OPRW)
For gateways selected as observers, their performance in submitting reports affects future selection:
OPRW=1+Submitted Epochs1+Selected EpochsOPRW = \frac{1 + \text{Submitted Epochs}}{1 + \text{Selected Epochs}}
OPRW=1+Selected Epochs1+Submitted Epochs
Impact:
Functional Observers: Who submit reports increase their OPRW
Deficient Observers: Who fail to submit reports see their OPRW decrease
Future Selection: Higher OPRW improves chances of future observer selection
Composite Weight Calculation
All performance factors combine to determine overall network influence:
CW=SW×TW×GPRW×OPRWCW = SW \times TW \times GPRW \times OPRW
CW=SW×TW×GPRW×OPRW
Where:
SW = Stake Weight (financial commitment)
TW = Tenure Weight (network longevity)
GPRW = Gateway Performance Ratio Weight
OPRW = Observer Performance Ratio Weight
Long-term Effects:
Consistently functional gateways accumulate higher composite weights
Poor performers see diminishing influence and selection chances
Performance history creates compounding effects on network participation
Evaluation Timeline
Rewards are distributed at the end of each epoch by the AR.IO Smart Contract directly based on the tallied observer votes. The smart contract processes all observer submissions and automatically distributes rewards to functional gateways and observers based on their performance during the epoch.
Key Features
Majority Rule: Gateway performance is determined by majority vote from observers
Binary Scoring: Simple pass/fail system for clear performance assessment
Network Confirmation: Delay ensures all votes are confirmed before evaluation
Transparent Process: All evaluations are based on onchain data
Consequences of Performance
Functional Gateways
Eligible for gateway rewards
Maintain good standing in the network
Continue to be considered for observer selection
Deficient Gateways
Ineligible for gateway rewards
Risk being marked as deficient for multiple epochs
May face additional penalties for prolonged poor performance
Observer Performance
Functional observers receive observer rewards
Deficient observers forfeit observer rewards
Deficient observers who are also functional gateways have their gateway reward reduced by 25%
Next Steps
Ready to understand how rewards are distributed? Learn about Reward Distribution to see the formulas and mechanics, or go back to Observer Selection to review the selection process.How is this guide?GoodBadReportingLearn about observer responsibilities for submitting reports to Arweave and the AR.IO Smart ContractDistributionsLearn about how rewards are calculated and distributed in the OIP systemOn this pageGateway ClassificationsEvaluation ProcessVote Tallying and Gateway ClassificationChunk/Offset Validation CriteriaValidation RequirementsAssessment ProcessWeight Impact on Gateway PerformanceGateway Performance Ratio Weight (GPRW)Observer Performance Ratio Weight (OPRW)Composite Weight CalculationEvaluation TimelineKey FeaturesConsequences of PerformanceFunctional GatewaysDeficient GatewaysObserver PerformanceNext Steps

---

# 96. Turbo APIs  ARIO Documentation

Document Number: 96
Source: https://docs.ar.io/apis/turbo
Words: 320
Quality Score: 0.374
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Turbo provides high-performance upload and payment services for the Arweave network, offering fast, reliable data uploads with instant confirmation and transparent pricing.Services Upload Service Fast, reliable data uploads to Arweave with instant confirmation and metadata management Payment Service Transparent pricing, payment processing, and credit management for Turbo uploads Upload Service The Turbo Upload Service provides high-performance data uploads to the Arweave network with features including:Fast Uploads - Optimized upload processing for quick data submission Instant Confirmation - Immediate upload confirmations and transaction IDs Metadata Management - Comprehensive data tagging and organization Account Management - User account and upload history tracking Service Information - Real-time service status and capabilities Key endpoints include account management, upload processing, pricing information, and transaction data retrieval.Payment Service The Turbo Payment Service handles all financial aspects of data uploads with transparent and flexible payment options:Transparent Pricing - Clear, upfront costs for all upload operations Multiple Currencies - Support for various payment methods and currencies Credit Management - Prepaid credits and balance tracking Payment Processing - Secure payment handling and transaction management Approval Workflows - Payment authorization and confirmation flows Key endpoints include balance management, payment processing, pricing calculations, and credit redemption.Getting Started with Turbo Choose your service - Upload for data submission, Payment for financial operations Review the APIs documentation - Detailed endpoint specifications and examples Test with sample data - Try uploads and payment flows with test data Integrate into your application - Implement the APIs in your workflow Use the Turbo SDK For a more convenient integration experience, consider using the Turbo SDK instead of direct API calls:Interact with Turbo via the SDK Use the Turbo SDK for simplified integration with built-in error handling, retries, and TypeScript support The SDK provides a higher-level interface with built-in error handling, automatic retries, and full TypeScript support, making it easier to integrate Turbo services into your applications.How is this guide?Farcaster Frames Previous Page Account GET Next Page

---

# 97. Token  ARIO Documentation

Document Number: 97
Source: https://docs.ar.io/learn/token
Words: 591
Quality Score: 0.369
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Overview ARIO is the multifunction AO Computer based token that powers the AR.IO Network and its suite of permanent cloud applications. Built on AO, ARIO leverages the computational power and permanence of the Arweave ecosystem to create a robust, decentralized infrastructure token.Key Features Native AO Token: ARIO is built directly on AO Computer, utilizing its decentralized compute capabilities for smart contract execution and network operations Staking-Based Infrastructure: The network operates on a staking-based incentive system where gateway operators secure infrastructure services through token commitment Multi-utility Design: ARIO serves multiple functions within the ecosystem, from network participation to governance and payments Incentive Mechanisms ARIO's design creates powerful incentives for network participants through multiple reward streams:Gateway Operator Incentives Staking Rewards: Gateway operators earn rewards for maintaining network infrastructure and providing reliable data services Performance Bonuses: Additional rewards for gateways that demonstrate high uptime and fast response times Network Growth Rewards: Operators benefit as the network scales and generates more activity Delegator Rewards Delegated Staking: Token holders can delegate their ARIO to trusted gateway operators to participate in network operations Increased Operator Stake: Delegation enhances gateway operator visibility and influence within the network Shared Risk and Rewards: Delegators participate in the risk and rewards of gateway operations Withdrawal Flexibility: Delegated tokens can be withdrawn following the same vault lock period rules Ecosystem Participation ArNS Revenue Sharing: Name registration fees flow back to network participants through the reward distribution mechanism Protocol Growth: As network usage increases, token utility and value proposition strengthen Community Incentives: Active participation in governance and ecosystem development is rewarded Staking Architecture The AR.IO Network implements a robust staking-based incentive system that ensures infrastructure reliability and network participation:Gateway Operator Requirements Gateway operators must stake a minimum amount of ARIO tokens to join the network Staking demonstrates commitment to network objectives and promotes infrastructure reliability Only gateways that pass Observation and Incentive Protocol evaluations receive rewards Staked tokens remain locked until withdrawal is initiated or vault period expires Network Quality Assurance Non-Inflationary Design: Fixed supply of 1 billion ARIO tokens with no minting mechanism Immutable Protocol: No governance control or special write access for upgrades Infrastructure Focus: Staking secures gateway infrastructure for permanent cloud services Peer Monitoring: Gateways serve as observers, testing and evaluating each other's performance Economic Incentives Gateway operators earn rewards only when they pass observation evaluations (≥50% consensus) Staking creates opportunity cost that aligns operator incentives with network health Observer gateways receive additional rewards for monitoring network quality Delegated staking allows broader community participation in successful gateway operations Built on AO Computer ARIO's foundation on AO Computer provides unique advantages:Computational Permanence All token operations and smart contracts benefit from Arweave's permanent storage Network history and token transactions are immutably recorded Computational results are verifiable and permanent Decentralized Execution Token logic runs across distributed AO processes, eliminating single points of failure Smart contract upgrades follow community governance processes Network operations scale with AO's computational capacity Ecosystem Integration Native compatibility with other AO-based applications and tokens Seamless interaction with Arweave's data storage layer Built-in interoperability with the broader permaweb ecosystem Explore the Token Token Architecture Learn about ARIO's technical implementation and AO Computer integration Get the Token Discover where and how to acquire ARIO tokens Staking & Delegation Understand how to stake ARIO and delegate to gateways Add to Wander Learn how to add ARIO to your Wander wallet How is this guide?Use Cases Explore practical applications of the Wayfinder Protocol across different industries and use cases Architecture Explore the technical architecture of the $ARIO contract and the AR.IO Network system components

---

# 98. What are Bundles  ARIO Documentation

Document Number: 98
Source: https://docs.ar.io/learn/ans-104-bundles
Words: 430
Quality Score: 0.356
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Introduction ANS-104 bundles are data packaging standards that efficiently bundle multiple data items and submit them to Arweave as single transactions, reducing transaction overhead and improving network efficiency.The Problem ANS-104 Solves Individual Arweave transactions have inherent limitations:Transaction overhead - Each transaction requires separate processing and storage Network inefficiency - Multiple small transactions consume more network resources Indexing complexity - Individual transactions are harder to organize and query Storage fragmentation - Related data items are stored separately ANS-104 provides:Reduced transaction overhead by batching multiple data items Improved network efficiency through consolidated transactions Better indexing capabilities with structured data item format Standardized data format for interoperability across applications How ANS-104 Bundling Works The ANS-104 Standard ANS-104 is the official specification for bundling data on Arweave:Data Items - Individual pieces of data with standardized binary format Bundle - Single Arweave transaction containing multiple data items Binary Serialization - Consistent format for data item structure Standardized Format - Ensures interoperability across applications How ANS-104 Works Data Item Creation - Create individual data items with ANS-104 format Bundle Assembly - Combine multiple data items into a single bundle Transaction Creation - Submit bundle as one Arweave transaction Network Processing - Miners process the single bundle transaction Data Retrieval - Individual data items can be extracted and indexed Key Benefits of ANS-104 Reduced Overhead - Bundle multiple data items into a single transaction to reduce processing overhead Network Efficiency - Consolidate multiple uploads into fewer network transactions Standardized Format - Consistent binary serialization ensures interoperability across applications Better Indexing - Structured data item format enables more efficient data retrieval and querying Why ANS-104 Matters for the Permaweb ANS-104 bundles are essential for building scalable applications on the permaweb because they:Enable efficient data storage by reducing transaction overhead for multiple data items Improve network performance through consolidated transactions Support better data organization with standardized data item formats Enable scalable applications that need to store many related data items efficiently Explore Bundling Upload Data Learn how to upload data to Arweave using bundling Run a Bundler Deploy your own bundling infrastructure Gateway Extensions Integrate bundling with your AR.IO gateway Turbo SDK Use Turbo SDK for easy data uploads and bundling How is this guide?What is the Permaweb?Understand how the permaweb works through its four-layer architecture: storage, compute, gateways, and applications AR.IO Gateways AR.IO gateways bridge the Arweave network and applications, providing fast, reliable access to permanent data through specialized infrastructure.On this page The Problem ANS-104 Solves How ANS-104 Bundling Works The ANS-104 Standard How ANS-104 Works Key Benefits of ANS-104 Why ANS-104 Matters for the Permaweb Explore Bundling

---

# 99. ARIO Gateways  ARIO Documentation

Document Number: 99
Source: https://docs.ar.io/learn/gateways
Words: 511
Quality Score: 0.306
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

What Are AR.IO Gateways?AR.IO gateways are specialized infrastructure nodes that serve as bridges between the Arweave network and applications. They transform raw Arweave blockchain data into a fast, reliable, and developer-friendly platform for storing and retrieving permanent data.Core Responsibilities AR.IO gateways handle three fundamental responsibilities:Data Writing & Proxying Transaction relay: Forward transaction headers to Arweave miners for mempool inclusion Chunk distribution: Proxy data chunks to Arweave nodes for storage and replication Bundle processing: Receive and bundle ANS-104 data items into base layer transactions Data Retrieval & Serving Fast access: Serve cached data with optimized performance and reliability Multi-source fallback: Retrieve data from trusted gateways, network peers, or directly from Arweave Content delivery: Stream complete transactions, individual chunks, or bundled data items Data Discovery & Indexing Structured queries: Enable efficient searches across transactions, bundles, and wallet data Real-time indexing: Process incoming data streams and maintain searchable databases ArNS routing: Provide human-readable name resolution for Arweave content Key Features Modular Architecture Gateways are built with interchangeable components that operators can customize:Configurable services: Enable or disable features based on specific needs Scalable storage: From SQLite for small deployments to cloud databases for enterprise scale Flexible infrastructure: Adaptable to different operational environments and requirements Network Connectivity Decentralized network: Connect to other AR.IO gateways for data sharing and redundancy Trust-minimized access: Cryptographically verify data integrity without relying on central authorities Performance optimization: Intelligent caching and content delivery strategies Developer Experience HTTP APIs: Standard web interfaces for all gateway functionality Monitoring & telemetry: Built-in observability for operational insights Content moderation: Configurable policies for community and compliance needs What Gateways Are Not It's important to understand the boundaries of what AR.IO gateways do and don't provide:Not Storage Providers Don't enforce Arweave protocol: Gateways don't validate consensus or mining rules Don't guarantee permanence: Storage permanence comes from Arweave itself, not gateways Don't replicate all data: Gateways cache popular content but aren't full blockchain replicas Not Compute Platforms Don't depend on AO: Gateways operate independently of any compute layer Don't execute smart contracts: Computation happens on AO or other platforms, not gateways Don't process application logic: Gateways focus purely on data access and delivery Not Centralized Services Don't control data: Content ownership and control remain with original creators Don't gate access: Anyone can run a gateway and access Arweave data Don't create vendor lock-in: Gateway APIs and protocols are open and interoperable Explore Gateways Gateway Architecture Learn about system design, components, and technology stack Data Retrieval Understand multi-source fallback strategies and performance optimization Data Verification Learn about cryptographic validation and integrity assurance Run a Gateway Deploy and operate your own AR.IO gateway infrastructure How is this guide?What are Bundles?Learn about ANS-104 bundling standards and how they optimize data submission to Arweave Architecture Learn about the technical architecture of AR.IO gateways, their core dependencies, and key design decisions On this page What Are AR.IO Gateways?Core Responsibilities Data Writing & Proxying Data Retrieval & Serving Data Discovery & Indexing Key Features Modular Architecture Network Connectivity Developer Experience What Gateways Are Not Not Storage Providers Not Compute Platforms Not Centralized Services Explore Gateways
