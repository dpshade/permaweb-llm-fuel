# Permaweb Documentation Collection

Generated on: 2025-10-06T12:13:36.771Z
Total documents: 29
Total words: 13277

## Table of Contents

### Included Documents

1. [Running a HyperBEAM Node](https://hyperbeam.arweave.net/run/running-a-hyperbeam-node.html)
2. [Overview](https://hyperbeam.arweave.net/build/devices/hyperbeam-devices.html)
3. [TEE Nodes](https://hyperbeam.arweave.net/run/tee-nodes.html)
4. [Module dev_snperl](https://hyperbeam.arweave.net/build/devices/source-code/dev_snp.html)
5. [JoiningRunning a Router](https://hyperbeam.arweave.net/run/joining-running-a-router.html)
6. [Configuring Your Machine](https://hyperbeam.arweave.net/run/configuring-your-machine.html)
7. [Core Capabilities](https://hyperbeam.arweave.net/build/getting-started/hyperbeam-capabilities.html)
8. [Module dev_fafferl](https://hyperbeam.arweave.net/build/devices/source-code/dev_faff.html)
9. [Core Devices](https://hyperbeam.arweave.net/build/devices/index.html)
10. [Pathing in HyperBEAM](https://hyperbeam.arweave.net/build/getting-started/pathing-in-hyperbeam.html)
11. [Building Devices](https://hyperbeam.arweave.net/build/devices/building-devices.html)
12. [Intro to HyperBEAM](https://hyperbeam.arweave.net/build/introduction/what-is-hyperbeam.html)
13. [Building ao Processes](https://hyperbeam.arweave.net/build/getting-started/building-on-ao.html)
14. [Fuel Your LLM](https://hyperbeam.arweave.net/llms.html)
15. [FAQ](https://hyperbeam.arweave.net/run/reference/faq.html)
16. [Module dev_p4erl](https://hyperbeam.arweave.net/build/devices/source-code/dev_p4.html)
17. [Data Replication](https://hyperbeam.arweave.net/build/devices/application-features/data-replication-at-1-0.html)
18. [Module dev_stackerl](https://hyperbeam.arweave.net/build/devices/source-code/dev_stack.html)
19. [meta10](https://hyperbeam.arweave.net/build/devices/foundational/meta-at-1-0.html)
20. [Glossary](https://hyperbeam.arweave.net/run/reference/glossary.html)
21. [FAQ](https://hyperbeam.arweave.net/build/reference/faq.html)
22. [Authentication Ecosystem](https://hyperbeam.arweave.net/build/devices/application-features/auth-ecosystem-at-1-0.html)
23. [Module dev_patcherl](https://hyperbeam.arweave.net/build/devices/source-code/dev_patch.html)
24. [Home](https://hyperbeam.arweave.net/)
25. [Glossary](https://hyperbeam.arweave.net/build/reference/glossary.html)
26. [Module dev_cronerl](https://hyperbeam.arweave.net/build/devices/source-code/dev_cron.html)
27. [Intro to AO-Core](https://hyperbeam.arweave.net/build/introduction/what-is-ao-core.html)
28. [Troubleshooting](https://hyperbeam.arweave.net/run/reference/troubleshooting.html)
29. [Troubleshooting](https://hyperbeam.arweave.net/build/reference/troubleshooting.html)

---

# 1. Running a HyperBEAM Node - HyperBEAM - Documentation

Document Number: 1
Source: https://hyperbeam.arweave.net/run/running-a-hyperbeam-node.html
Words: 838
Quality Score: 0.691
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Running a HyperBEAM Node This guide provides the basics for running your own HyperBEAM node, installing dependencies, and connecting to the AO network.System Dependencies To successfully build and run a HyperBEAM node, your system needs several software dependencies installed.Install core dependencies using Homebrew:brew install cmake git pkg-config openssl ncurses Install core dependencies using apt:sudo apt-get update && sudo apt-get install -y --no-install-recommends \
build-essential \
cmake \
git \
pkg-config \
ncurses-dev \
libssl-dev \
sudo \
curl \
ca-certificates Erlang/OTP HyperBEAM is built on Erlang/OTP. You need version OTP 27 installed (check the rebar.config or project documentation for specific version requirements, typically OTP 27).Installation methods:brew install erlang@27 sudo apt install erlang=1:27.* Download from erlang.org and follow the build instructions for your platform.Rebar3 Rebar3 is the build tool for Erlang projects.Installation methods:brew install rebar3 Get the rebar3 binary from the official website. Place the downloaded rebar3 file in your system's PATH (e.g., /usr/local/bin) and make it executable (chmod +x rebar3).Node.js Node.js might be required for certain JavaScript-related tools or dependencies. Node version 22+ is required.Installation methods:brew install node Rust Rust is needed if you intend to work with or build components involving WebAssembly (WASM) or certain Native Implemented Functions (NIFs) used by some devices (like ~snp@1.0).The recommended way to install Rust on all platforms is via rustup:curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source "$HOME/.cargo/env" # Or follow the instructions provided by rustup Prerequisites for Running Before starting a node, ensure you have:Installed the system dependencies mentioned above.Cloned the HyperBEAM repository (git clone ...).Compiled the source code (rebar3 compile in the repo directory).An Arweave wallet keyfile (e.g., generated via Wander). The path to this file is typically set via the hb_key configuration option (see Configuring Your HyperBEAM Node).Starting a Basic Node The simplest way to start a HyperBEAM node for development or testing is using rebar3 from the repository's root directory:rebar3 shell This command:Starts the Erlang Virtual Machine (BEAM) with all HyperBEAM modules loaded.Initializes the node with default settings (from hb_opts.erl).Starts the default HTTP server (typically on port 8734), making the node accessible.Drops you into an interactive Erlang shell where you can interact with the running node.This basic setup is suitable for local development and exploring HyperBEAM's functionalities.HyperBEAM uses build profiles to enable optional features, often requiring extra dependencies. To run a node with specific profiles enabled, use rebar3 as ... shell:Available Profiles (Examples):genesis_wasm: Enables Genesis WebAssembly support.rocksdb: Enables the RocksDB storage backend.http3: Enables HTTP/3 support.Example Usage:# Start with RocksDB profile
rebar3 as rocksdb shell
# Start with RocksDB and Genesis WASM profiles
rebar3 as rocksdb, genesis_wasm shell Note: Choose profiles before starting the shell, as they affect compile-time options.Node Configuration HyperBEAM offers various configuration options (port, key file, data storage, logging, etc.). These are primarily set using a config.flat file and can be overridden by environment variables or command-line arguments.See the dedicated Configuring Your HyperBEAM Node guide for detailed information on all configuration methods and options.Verify Installation To quickly check if your node is running and accessible, you can send a request to its ~meta@1.0 device (assuming default port 8734):curl http://localhost:8734/~meta@1.0/info A JSON response containing node information indicates success.Running for Production (Mainnet) While you can connect to the main AO network using the rebar3 shell for testing purposes (potentially using specific configurations or helper functions like hb:start_mainnet/1 if available and applicable), the standard and recommended method for a stable production deployment (like running on the mainnet) is to build and run a release.1. Build the Release:From the root of the HyperBEAM repository, build the release package. You might include specific profiles needed for your mainnet setup (e.g., rocksdb if you intend to use it):# Build release with default profile
rebar3 release
# Or, build with specific profiles (example)
# rebar3 as rocksdb release This command compiles the project and packages it along with the Erlang Runtime System (ERTS) and all dependencies into a directory, typically _build/default/rel/hb.2. Configure the Release:Navigate into the release directory (e.g., cd _build/default/rel/hb). Ensure you have a correctly configured config.flat file here. See the configuration guide for details on setting mainnet parameters (port, key file location, store path, specific peers, etc.). Environment variables can also be used to override settings in the release's config.flat when starting the node.3. Start the Node:Use the generated start script (bin/hb) to run the node:# Start the node in the foreground (logs to console)
./bin/hb console
# Start the node as a background daemon
./bin/hb start
# Check the status
./bin/hb ping
./bin/hb status
# the node
./bin/hb Consult the generated bin/hb script or Erlang/OTP documentation for more advanced start-up options (e.g., attaching a remote shell).Running as a release provides a more robust, isolated, and manageable way to operate a node compared to running directly from the rebar3 shell.ping the Node (rebar3 shell) To the node running within the rebar3 shell, press Ctrl+C twice or use the Erlang command q()..Configure Your Node: Deep dive into configuration options.TEE Nodes: Learn about running nodes in Trusted Execution Environments for enhanced security.Routers: Understand how to configure and run a router node.

---

# 2. Overview - HyperBEAM - Documentation

Document Number: 2
Source: https://hyperbeam.arweave.net/build/devices/hyperbeam-devices.html
Words: 744
Quality Score: 0.648
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

HyperBEAM Devices In AO-Core and its implementation HyperBEAM, Devices are modular components responsible for processing and interpreting Messages. They define the specific logic for how computations are performed, data is handled, or interactions occur within the AO ecosystem.Think of Devices as specialized engines or services that can be plugged into the AO framework. This modularity is key to AO's flexibility and extensibility.Purpose of Devices Define Computation: Devices dictate how a message's instructions are executed. One device might run WASM code, another might manage process state, and yet another might simply relay data.Enable Specialization: Nodes running HyperBEAM can choose which Devices to support, allowing them to specialize in certain tasks (e.g., high-compute tasks, storage-focused tasks, secure TEE operations).Promote Modularity: New functionalities can be added to AO by creating new Devices, without altering the core protocol.Distribute Workload: Different Devices can handle different parts of a complex task, enabling parallel processing and efficient resource utilization across the network.Device Naming and Versioning Devices are typically referenced using a name and version, like ~@ (e.g., ~process@1.0). The tilde (~) often indicates a primary, user-facing device, while internal or utility devices might use a dev_ prefix in the source code (e.g., dev_router).Versioning indicates the specific interface and behavior of the device. Changes to a device that break backward compatibility usually result in a version increment.Familiar Examples HyperBEAM includes many preloaded devices that provide core functionality. Some key examples include:~meta@1.0: Configures the node itself (hardware specs, supported devices, payment info).~process@1.0: Manages persistent, shared computational states (like traditional smart contracts, but more flexible).~scheduler@1.0: Handles the ordering and execution of messages within a process.~wasm64@1.0: Executes WebAssembly (WASM) code, allowing for complex computations written in languages like Rust, C++, etc.~lua@5.3a: Executes Lua scripts.~relay@1.0: Forwards messages between AO nodes or to external HTTP endpoints.~json@1.0: Provides access to JSON data structures.~message@1.0: Manages message state and processing.Authentication Ecosystem: Comprehensive wallet-less authentication (~auth-hook@1.0, ~secret@1.0, ~cookie@1.0, ~http-auth@1.0).Data Discovery Engine: Advanced message search and query capabilities (~query@1.0).Data Replication Engine: External data ingestion and synchronization (~copycat@1.0).~patch@1.0: Applies state updates directly to a process, often used for migrating or managing process data.Beyond the Basics Devices aren't limited to just computation or state management. They can represent more abstract concepts:Security & Authentication Devices (~snp@1.0, dev_codec_httpsig, Authentication Ecosystem): Handle tasks related to Trusted Execution Environments (TEEs), message signing, wallet-less authentication, and session management, adding layers of security and verification.Data Management Devices (Data Discovery Engine, Data Replication Engine): Provide comprehensive data ingestion, search, and discovery capabilities for building data-rich applications with external source integration.Payment/Access Control Devices (~p4@1.0, ~faff@1.0): Manage metering, billing, or access control for node services.Workflow/Utility Devices (dev_cron, dev_stack, dev_monitor): Coordinate complex execution flows, schedule tasks, or monitor process activity.Using Devices Devices are typically invoked via GET requests. The path specifies which Device should interpret the subsequent parts of the path or the request body.# Example: Execute the 'now' key on the process device for a specific process
/~process@1.0/now
# Example: Relay a GET request via the relay device
/~relay@1.0/call?method=GET&path=https://example.com The specific functions or 'keys' available for each Device are documented individually. See the Devices section for details on specific built-in devices. The Potential of Devices The modular nature of AO Devices opens up vast possibilities for future expansion and innovation. The current set of preloaded and community devices is just the beginning. As the AO ecosystem evolves, we can anticipate the development of new devices catering to increasingly specialized needs:Specialized Hardware Integration: Devices could be created to interface directly with specialized hardware accelerators like GPUs (for AI/ML tasks such as running large language models), TPUs, or FPGAs, allowing AO processes to leverage high-performance computing resources securely and verifiably.Advanced Cryptography: New devices could implement cutting-edge cryptographic techniques, such as zero-knowledge proofs (ZKPs) or fully homomorphic encryption (FHE), enabling enhanced privacy and complex computations on encrypted data.Cross-Chain & Off-Chain Bridges: Devices could act as secure bridges to other blockchain networks or traditional Web2 APIs, facilitating seamless interoperability and data exchange between AO and the wider digital world.AI/ML Specific Devices: Beyond raw GPU access, specialized devices could offer higher-level AI/ML functionalities, like optimized model inference engines or distributed training frameworks.Domain-Specific Logic: Communities or organizations could develop devices tailored to specific industries or use cases, such as decentralized finance (DeFi) primitives, scientific computing libraries, or decentralized identity management systems.The Device framework ensures that AO can adapt and grow, incorporating new technologies and computational paradigms without requiring fundamental changes to the core protocol. This extensibility is key to AO's long-term vision of becoming a truly global, decentralized computer.

---

# 3. TEE Nodes - HyperBEAM - Documentation

Document Number: 3
Source: https://hyperbeam.arweave.net/run/tee-nodes.html
Words: 680
Quality Score: 0.633
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Trusted Execution Environment (TEE) Recommended Setup Use HyperBEAM OS for the easiest TEE deployment with pre-configured AMD SEV-SNP support. Note: HB-OS is typically used for TEE operations, but is not necessary for router registration.Overview HyperBEAM supports Trusted Execution Environments (TEEs) through the ~snp@1.0 device, enabling secure, verifiable computation on remote machines. TEEs provide hardware-level isolation and cryptographic attestation that allows users to verify their code is running in a protected environment exactly as intended, even on untrusted hardware.The ~snp@1.0 device generates and validates attestation reports that prove:Code is running inside a genuine AMD SEV-SNP TEE The execution environment hasn't been tampered with Specific software components (firmware, kernel, initramfs) match trusted hashes Debug mode is disabled for security Configuration Files Configuration can be set in either config.json (JSON) or config.flat (flat) format. For full details and examples of both formats, see Configuration Reference.The examples below use JSON for clarity.When to use HB-OS Operation Use HB-OS?Purpose TEE Node (SNP) Recommended Secure, attested computation (hardware isolation) Router Registration Optional Registering/joining a router (TEE not required) If you are registering or running a router, you can do so without HB-OS.If you want to run a TEE node, HB-OS or an equivalent TEE setup is recommended for convenience and security.Quick Start: TEE Node with HyperBEAM OS Prerequisites AMD EPYC processor with SEV-SNP support (Milan generation or newer) Host system with SEV-SNP enabled in BIOS Setup TEE Node # Clone and build TEE-enabled HyperBEAM
# (Only needed for TEE nodes if you choose HB-OS)
git clone https://github.com/permaweb/hb-os.git && cd hb-os
./run init && ./run setup_host && ./run build_base_image && ./run build_guest_image
# Launch TEE-protected node
./run start The VM boots with dm-verity protection, measured boot, and automatic attestation report generation.Using the SNP Device Generate Attestation Report Request an attestation report from a TEE node:curl https://your-tee-node.com/~snp@1.0/generate Returns a signed attestation report containing:
- Nonce: Unique identifier preventing re attacks
- Address: Node's ephemeral public key (only exists inside TEE)
- Measurement: Cryptographic hash of the execution environment
- Report: AMD SEV-SNP hardware attestation with certificate chain Verify Attestation Report The verification process validates:
1. Nonce integrity: Ensures report freshness and prevents re2. Signature validity: Confirms the report was signed by the claimed address
3. Address authenticity: Verifies the signing key exists only in the TEE
4. Debug disabled: Ensures no debugging capabilities that could compromise security
5. Trusted software: Validates firmware, kernel, and initramfs hashes match approved versions
6. Measurement accuracy: Confirms the reported environment matches actual execution
7. Hardware attestation: Verifies AMD's cryptographic signature on the report Configuration Trusted Software Hashes (config.json example) Configure which software components are trusted by setting snp_trusted in your node options:"snp_trusted": [
// Trusted software hashes here
] Custom Trust Validation Implement custom trust policies by specifying an is-trusted-device:curl -X POST https://your-node.com/~snp@1.0/verify \
-H "is-trusted-device: my-custom-validator@1.0" \
-d '{"report": "...", "target": "self"}' Security Considerations SEV-SNP capable CPU: AMD EPYC Milan or newer Firmware support: Recent AMD firmware with SEV-SNP enabled Memory encryption: SME (Secure Memory Encryption) recommended RMP table: Sufficient memory reserved for Reverse Map Page Table Attestation Tools HyperBEAM OS includes several attestation utilities:get_report: Generate attestation reports with custom data verify_report: Validate attestation report signatures sev_feature_info: Check host SEV-SNP capabilities idblock_generator: Create signed VM configuration blocks Integration Examples Router Registration with TEE (Advanced, config.json example) If you want to register a TEE-protected router node, use the following configuration (see also the router registration guide):{
"operator": "trustless",
"initialized": "permanent",
"snp_trusted": [ /* ... */ ],
"on": {
"request": {
"device": "p4@1.0",
"ledger-device": "lua@5.3a",
"pricing-device": "simple-pay@1.0",
"ledger-path": "/ledger~node-process@1.0",
"module": ""
},
"response": {
"device": "p4@1.0",
"ledger-device": "lua@5.3a",
"pricing-device": "simple-pay@1.0",
"ledger-path": "/ledger~node-process@1.0",
"module": ""
}
},
"p4_non_chargable_routes": [
{"template": "/.*~node-process@1.0/.*"},
{"template": "/.*~greenzone@1.0/.*"},
{"template": "/.*~router@1.0/.*"},
{"template": "/.*~meta@1.0/.*"},
{"template": "/schedule"},
{"template": "/push"},
{"template": "/~hyperbuddy@1.0/.*"}
],
"node_process_spawn_codec": "ans104@1.0",
"node_processes": {
"ledger": {
"device": "process@1.0",
"execution-device": "lua@5.3a",
"scheduler-device": "scheduler@1.0",
"authority-match": 1,
"admin": "",
"token": "",
"module": "",
"authority": ""
}
},
"router_opts": {
"offered": [ /* ... */ ]
},
"green_zone_peer_location": "",
"green_zone_peer_id": "",
"p4_recipient": ""
} TEE attestation TEE-protected computation Trusted software validation HyperBEAM OS Repository See the router registration guide for non-TEE router setup.Configuration Reference

---

# 4. Module dev_snperl - HyperBEAM - Documentation

Document Number: 4
Source: https://hyperbeam.arweave.net/build/devices/source-code/dev_snp.html
Words: 426
Quality Score: 0.584
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Module dev_snp.erl This device offers an interface for validating AMD SEV-SNP commitments,
as well as generating them, if called in an appropriate environment.Function Index execute_is_trusted/3* Ensure that all of the software hashes are trusted.generate/3 Generate an commitment report and emit it as a message, including all of
the necessary data to generate the nonce (ephemeral node address + node
message ID), as well as the expected measurement (firmware, kernel, and VMSAs
hashes).generate_nonce/2* Generate the nonce to use in the commitment report.is_debug/1* Ensure that the node's debug policy is disabled.real_node_test/0* report_data_matches/3* Ensure that the report data matches the expected report data.trusted/3 Validates if a given message parameter matches a trusted value from the SNP trusted list
Returns {ok, true} if the message is trusted, {ok, false} otherwise.verify/3 Verify an commitment report message; validating the identity of a
remote node, its ephemeral private address, and the integrity of the report.Function Details execute_is_trusted/3 * execute_is_trusted(M1, Msg, NodeOpts) -> any() Ensure that all of the software hashes are trusted. The caller may set
a specific device to use for the is-trusted key. The device must then
implement the trusted resolver.generate/3 generate(M1, M2, Opts) -> any() Generate an commitment report and emit it as a message, including all of
the necessary data to generate the nonce (ephemeral node address + node
message ID), as well as the expected measurement (firmware, kernel, and VMSAs
hashes).generate_nonce/2 * generate_nonce(RawAddress, RawNodeMsgID) -> any() Generate the nonce to use in the commitment report.is_debug/1 * is_debug(Report) -> any() Ensure that the node's debug policy is disabled.real_node_test/0 * real_node_test() -> any() report_data_matches/3 * report_data_matches(Address, NodeMsgID, ReportData) -> any() Ensure that the report data matches the expected report data.trusted/3 trusted(Msg1, Msg2, NodeOpts) -> any() Validates if a given message parameter matches a trusted value from the SNP trusted list
Returns {ok, true} if the message is trusted, {ok, false} otherwise verify/3 verify(M1, M2, NodeOpts) -> any() Verify an commitment report message; validating the identity of a
remote node, its ephemeral private address, and the integrity of the report.
The checks that must be performed to validate the report are:
1. Verify the address and the node message ID are the same as the ones
used to generate the nonce.
2. Verify the address that signed the message is the same as the one used
to generate the nonce.
3. Verify that the debug flag is disabled.
4. Verify that the firmware, kernel, and OS (VMSAs) hashes, part of the
measurement, are trusted.
5. Verify the measurement is valid.
6. Verify the report's certificate chain to hardware root of trust.

---

# 5. JoiningRunning a Router - HyperBEAM - Documentation

Document Number: 5
Source: https://hyperbeam.arweave.net/run/joining-running-a-router.html
Words: 906
Quality Score: 0.562
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Router Networks: Joining vs Running Router networks in HyperBEAM have two distinct roles that are often confused:Two Different Concepts Joining a router = Registering your worker node with an existing router to receive work Running a router = Operating a router that manages and distributes work to other nodes When to use HB-OS Operation Use HB-OS?Purpose TEE Node (SNP) Recommended Secure, attested computation (hardware isolation) Router Registration Optional Registering/joining a router (TEE not required) You can join or run a router without HB-OS.If you want to run a TEE node, HB-OS or an equivalent TEE setup is recommended for convenience and security.Configuration Files: config.json vs config.flat Configuration can be set in either config.json (JSON syntax) or config.flat (flat syntax). The examples below use JSON for clarity, but you can use either format depending on your deployment. The syntax differs:config.json uses standard JSON structure (see examples below) config.flat uses key-value pairs Joining a Router Network (Worker Node) Most users want to join an existing router to offer computational services. This does NOT require HB-OS or TEE unless you specifically want TEE security.1. Prepare Your Configuration (config.json example) Use the following configuration as a template for your worker node:{
// ─── Initial Configuration ─────────────────────────────────────────────────
// Lock this configuration so it cannot be changed again
"operator": "trustless",
"initialized": "permanent",
// ─── SNP-Based TEE Attestation Parameters ──────────────────────────────────
// These values let the TEE verify its own environment—and any other VM
// instantiated from the same image—before granting access.
"snp_trusted": [],
// ─── Request/Response Processing Configuration ─────────────────────────────
// Defines how requests and responses are processed through the p4 device
"on": {
"request": {
"device": "p4@1.0",
"ledger-device": "lua@5.3a",
"pricing-device": "simple-pay@1.0",
"ledger-path": "/ledger~node-process@1.0",
"module": "" // Automatically injected
},
"response": {
"device": "p4@1.0",
"ledger-device": "lua@5.3a",
"pricing-device": "simple-pay@1.0",
"ledger-path": "/ledger~node-process@1.0",
"module": "" // Automatically injected
}
},
// ─── Non-Chargeable Routes Configuration ──────────────────────────────────
// Routes that should not incur charges when accessed through p4
"p4_non_chargable_routes": [
{ "template": "/.*~node-process@1.0/.*" },
{ "template": "/.*~greenzone@1.0/.*" },
{ "template": "/.*~router@1.0/.*" },
{ "template": "/.*~meta@1.0/.*" },
{ "template": "/schedule" },
{ "template": "/push" },
{ "template": "/~hyperbuddy@1.0/.*" }
],
// ─── Node Process Spawn Configuration ─────────────────────────────────────
// Codec used for spawning new node processes
"node_process_spawn_codec": "ans104@1.0",
// ─── Node Process Definitions ─────────────────────────────────────────────
// Configuration for individual node processes
"node_processes": {
"ledger": {
"device": "process@1.0",
"execution-device": "lua@5.3a",
"scheduler-device": "scheduler@1.0",
"authority-match": 1,
"admin": "", // Automatically injected
"token": "", // Automatically injected
"module": "", // Automatically injected
"authority": "" // Automatically injected
}
},
// ─── Router Registration Options ──────────────────────────────────────────
// Configuration for how processes register with the router
"router_opts": {
"offered": [
// {
// "registration-peer": {}, // Automatically injected
// "template": "/*~process@1.0/*", // The routes that the node will register with
// "prefix": "", // Automatically injected
// "price": 4500000 // Registration fee in smallest units
// }
]
},
// ─── Greenzone Registration Options ────────────────────────────────────────
// Configuration for how processes register with the greenzone
"green_zone_peer_location": "", // Automatically injected
"green_zone_peer_id": "", // Automatically injected
// ─── P4 Recipient ──────────────────────────────────────────────────────────
// The Address of the node that will receive the P4 messages
"p4_recipient": "" // Automatically injected
} Perform the following API calls in order:Meta Info Post:Endpoint: ~meta@1.0/info POST Example:
Join Green Zone:Endpoint: ~greenzone@1.0/join GET Become Green Zone Member:Endpoint: ~greenzone@1.0/become GET Register as Router:Endpoint: ~router@1.0/register GET 3. Verify Registration Check your node's status in the network Confirm green zone membership Test routing functionality 4. Troubleshooting If registration fails:
1. Verify all configuration parameters are correct
2. Check network connectivity to the node URL
3. Ensure proper headers are set in API requests
4. Review logs for specific error messages
5. Confirm green zone availability and accessibility Running Your Own Router (Advanced) If you want to operate a router that manages other worker nodes:Deploy the dynamic router Lua process to handle registrations Configure trusted software hashes for TEE validation (if using TEE) Set up load balancing and performance monitoring Manage worker node admissibility policies Example Router Configuration (config.json example) {
// ─── Router Node Preprocessing Settings ───────────────────────────────────
// Defines the router process and how it preprocesses incoming requests
"on": {
"request": {
"device": "router@1.0",
"path": "preprocess",
"commit-request": true // Enable request commitment for routing
}
},
// ─── Route Provider Configuration ─────────────────────────────────────────
// Specifies where to get routing information from the router node process
"router_opts": {
"provider": {
"path": "/router~node-process@1.0/compute/routes~message@1.0"
},
"registrar": {
"path": "/router~node-process@1.0"
},
"registrar-path": "schedule"
},
// ─── Relay Configuration ──────────────────────────────────────────────────
// Allow the relay to commit requests when forwarding
"relay_allow_commit_request": true,
// ─── Router Node Process Configuration ────────────────────────────────────
// Specifies the Lua-based router logic, weights for scoring, and admission check
"node_processes": {
"router": {
"type": "Process",
"device": "process@1.0",
"execution-device": "lua@5.3a",
"scheduler-device": "scheduler@1.0",
"pricing-weight": 9, // Weight for pricing in routing decisions
"performance-weight": 1, // Weight for performance in routing decisions
"score-preference": 4, // Preference scoring for route selection
"performance-period": 2, // Period for performance measurement
"initial-performance": 1000, // Initial performance score
// Default admission policy (currently set to false)
"is-admissible": {
"path": "default",
"default": "false"
},
"module": "", // Automatically injected
"trusted-peer": "", // Automatically injected
"trusted": "" // Automatically injected
}
}
} Advanced Configuration Running a production router requires careful consideration of security, performance, and economic incentives. Most users should join existing routers rather than run their own.Further Exploration Examine the dev_router.erl source code for detailed implementation.Review the scripts/dynamic-router.lua for router-side logic.Review the available configuration options in hb_opts.erl related to routing (routes, strategies, etc.).Consult community channels for best practices on deploying production routers.

---

# 6. Configuring Your Machine - HyperBEAM - Documentation

Document Number: 6
Source: https://hyperbeam.arweave.net/run/configuring-your-machine.html
Words: 801
Quality Score: 0.561
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Configuring Your HyperBEAM Node This guide details the various ways to configure your HyperBEAM node's behavior, including ports, storage, keys, and logging.Configuration (config.flat) The primary way to configure your HyperBEAM node is through a config.flat file located in the node's working directory or specified by the HB_CONFIG_LOCATION environment variable.This file uses a simple Key = Value. format (note the period at the end of each line).Example config.flat:% Set the HTTP port
port = 8080.
% Specify the Arweave key file
priv_key_location = "/path/to/your/wallet.json".
% Set the data store directory
% Note: Storage configuration can be complex. See below.
% store = [{local, [{root, <<"./node_data_mainnet">>}]}]. % Example of complex config, not for config.flat
% Enable verbose logging for specific modules
% debug_print = [hb_http, dev_router]. % Example of complex config, not for config.flat Below is a reference of commonly used configuration keys. Remember that config.flat only supports simple key-value pairs (Atoms, Strings, Integers, Booleans). For complex configurations (Lists, Maps), you must use environment variables or hb:start_mainnet/1.Core Configuration These options control fundamental HyperBEAM behavior.Option Type Default Description port Integer 8734 HTTP API port hb_config_location String "config.flat" Path to configuration file priv_key_location String "hyperbeam-key.json" Path to operator wallet key file mode Atom debug Execution mode (debug, prod) Server & Network Configuration These options control networking behavior and HTTP settings.Option Type Default Description host String "localhost" Choice of remote node for non-local tasks gateway String "https://arweave.net" Default gateway bundler_ans104 String "https://up.arweave.net:443" Location of ANS-104 bundler protocol Atom http2 Protocol for HTTP requests (http1, http2, http3) http_client Atom gun HTTP client to use (gun, httpc) http_connect_timeout Integer 5000 HTTP connection timeout in milliseconds http_keepalive Integer 120000 HTTP keepalive time in milliseconds http_request_send_timeout Integer 60000 HTTP request send timeout in milliseconds relay_http_client Atom httpc HTTP client for the relay device Security & Identity These options control identity and security settings.Option Type Default Description scheduler_location_ttl Integer 604800000 TTL for scheduler registration (7 days in ms) Caching & Storage These options control caching behavior. Note: Detailed storage configuration (store option) involves complex data structures and cannot be set via config.flat.Option Type Default Description cache_lookup_heuristics Boolean false Whether to use caching heuristics or always consult the local data store access_remote_cache_for_client Boolean false Whether to access data from remote caches for client requests store_all_signed Boolean true Whether the node should store all signed messages await_inprogress Atom/Boolean named Whether to await in-progress executions (false, named, true) Execution & Processing These options control how HyperBEAM executes messages and processes.Option Type Default Description scheduling_mode Atom local_confirmation When to inform recipients about scheduled assignments (aggressive, local_confirmation, remote_confirmation) compute_mode Atom lazy Whether to execute more messages after returning a result (aggressive, lazy) process_workers Boolean true Whether the node should use persistent processes client_error_strategy Atom throw What to do if a client error occurs wasm_allow_aot Boolean false Allow ahead-of-time compilation for WASM Device Management These options control how HyperBEAM manages devices.Option Type Default Description load_remote_devices Boolean false Whether to load devices from remote signers Debug & Development These options control debugging and development features.Option Type Default Description debug_stack_depth Integer 40 Maximum stack depth for debug printing debug_print_map_line_threshold Integer 30 Maximum lines for map printing debug_print_binary_max Integer 60 Maximum binary size for debug printing debug_print_indent Integer 2 Indentation for debug printing debug_print_trace Atom short Trace mode (short, false) short_trace_len Integer 5 Length of short traces debug_hide_metadata Boolean true Whether to hide metadata in debug output debug_ids Boolean false Whether to print IDs in debug output debug_hide_priv Boolean true Whether to hide private data in debug output Note: For the absolute complete and most up-to-date list, including complex options not suitable for config.flat, refer to the default_message/0 function in the hb_opts module source code.Overrides (Environment Variables & Args) You can override settings from config.flat or provide values if the file is missing using environment variables or command-line arguments.Using Environment Variables:Environment variables typically use an HB_ prefix followed by the configuration key in uppercase.HB_PORT=: Overrides hb_port.Example: HB_PORT=8080 rebar3 shell HB_KEY=: Overrides hb_key.Example: HB_KEY=~/.keys/arweave_key.json rebar3 shell HB_STORE=: Overrides hb_store.Example: HB_STORE=./node_data_1 rebar3 shell HB_PRINT=: Overrides hb_print. can be true (or 1), or a comma-separated list of modules/topics (e.g., hb_path,hb_ao,ao_result).Example: HB_PRINT=hb_http,dev_router rebar3 shell HB_CONFIG_LOCATION=: Specifies a custom location for the configuration file.Using erl_opts (Direct Erlang VM Arguments):You can also pass arguments directly to the Erlang VM using the - format within erl_opts. This is generally less common for application configuration than config.flat or environment variables.rebar3 shell --erl_opts "-hb_port 8080 -hb_key path/to/key.json" Order of Precedence:Command-line arguments (erl_opts).Settings in config.flat.Environment variables (HB_*).Default values from hb_opts.erl.Configuration in Releases When running a release build (see Running a HyperBEAM Node), configuration works similarly:A config.flat file will be present in the release directory (e.g., build/default/rel/hb/config.flat). Edit this file to set your desired parameters for the release environment.Environment variables (HB*) can still be used to override the settings in the release's config.flat when starting the node using the bin/hb script.

---

# 7. Core Capabilities - HyperBEAM - Documentation

Document Number: 7
Source: https://hyperbeam.arweave.net/build/getting-started/hyperbeam-capabilities.html
Words: 681
Quality Score: 0.555
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

HyperBEAM: Your Decentralized Development Toolkit HyperBEAM is a versatile, multi-purpose tool that serves as the primary gateway to the AO Computer. It's not a single-purpose application, but rather a powerful, extensible engine—a "Swiss Army knife"—for developers building in the decentralized ecosystem.Designed to be modular, composable, and extensible, HyperBEAM lets you build anything from simple data transformations to complex, high-performance decentralized applications.Thinking in HyperBEAM While AO-Core establishes the foundational concepts of Messages, Devices, and Paths, building on HyperBEAM can be simplified to four key principles:Everything is a message. You can compute on any message by calling its keys by name. The device specified in the message determines how these keys are resolved. The default device, message@1.0, resolves keys to their literal values within the message.Paths are pipelines of messages. A path defines a sequence of 'request' messages to be executed. You can set a key in a message directly within the path using the &key=value syntax. Headers and parameters added after a ? are applied to all messages in the pipeline.Device-specific requests with ~x@y. The ~x@y syntax allows you to apply a request as if the base message had a different device. This provides a powerful way to execute messages using specific compute or storage logic defined by a device.Signed responses over HTTP. The final message in a pipeline is returned as an HTTP response. This response is signed against the hashpath that generated it, ensuring the integrity and verifiability of the computation.Ready to build an AO process?The serverless compute capability is a powerful application of HyperBEAM's modular design. To learn how to create and manage AO processes with WASM or Lua, please refer to the AO Processes Cookbook.Modularity: A System of Devices At its core, HyperBEAM is a modular system built on Devices. Each device is a specialized module responsible for a specific task. This modular architecture means you can think of HyperBEAM's functionality as a set of building blocks.Use Case: Imagine you need to create a serverless API that takes a number, runs a calculation, and returns a result.You would use the ~wasm64@1.0 or ~lua@5.3a devices to execute your calculation logic without needing to manage a server.If your API needs to return JSON, you can pipe the output to the ~json@1.0 device to ensure it's formatted correctly.Composability: Chaining Logic with URL Paths HyperBEAM's modular devices become even more powerful when combined. Its pathing routing mechanism leverages standard URLs to create powerful, composable pipelines. By constructing a URL, you can define a "path" of messages that are executed in sequence, with the output of one message becoming the input for the next.Use Case: Suppose you have a token process and want to calculate the total circulating supply without making the client download and compute all balances. You can construct a single URL that:Reads the latest state of the AO process.Pipes the state to a Lua script and calls the sum function, which sums the balances from the state.Formats the final result as a JSON object.The request would look something like this:/{process-id}~process@1.0/now/~lua@5.3a&module={module-id}/sum/serialize~json@1.0 This path chains together the operations, returning just the computed supply in a single, efficient request.Find the full example in the AO Process Cookbook in HyperBEAM.Extensibility: Building Beyond the Core HyperBEAM is not a closed system. It is designed to be extended, allowing developers to add new functionality tailored to their specific needs.Build Custom Devices You can build and deploy your own devices in Erlang to introduce entirely new, high-level functionality to the network.Use Case: You could build a custom device that acts as a bridge to another blockchain's API, allowing your AO processes to interact with external systems seamlessly.Learn how to Build Your Own Device.Achieve Raw Performance with Native Code For the most demanding, performance-critical tasks, you can write Native Implemented Functions (NIFs) in low-level languages like C or Rust. These NIFs integrate directly with the Erlang VM, offering the highest possible performance.Use Case: If you were building a sophisticated cryptographic application, you could implement a new, high-speed hashing algorithm as a NIF to ensure maximum performance and security. This "raw" extensibility provides an escape hatch for ultimate control.

---

# 8. Module dev_fafferl - HyperBEAM - Documentation

Document Number: 8
Source: https://hyperbeam.arweave.net/build/devices/source-code/dev_faff.html
Words: 180
Quality Score: 0.540
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Module dev_faff.erl A module that implements a 'friends and family' pricing policy.Description It will allow users to process requests only if their addresses are
in the allow-list for the node.Fundamentally against the spirit of permissionlessness, but it is useful if
you are running a node for your own purposes and would not like to allow
others to make use of it -- even for a fee. It also serves as a useful
example of how to implement a custom pricing policy, as it implements stubs
for both the pricing and ledger P4 APIs.Function Index charge/3 Charge the user's account if the request is allowed.estimate/3 Decide whether or not to service a request from a given address.is_admissible/2* Check whether all of the signers of the request are in the allow-list.Function Details charge/3 charge(X1, Req, NodeMsg) -> any() Charge the user's account if the request is allowed.estimate/3 estimate(X1, Msg, NodeMsg) -> any() Decide whether or not to service a request from a given address.is_admissible/2 * is_admissible(Msg, NodeMsg) -> any() Check whether all of the signers of the request are in the allow-list.

---

# 9. Core Devices - HyperBEAM - Documentation

Document Number: 9
Source: https://hyperbeam.arweave.net/build/devices/index.html
Words: 646
Quality Score: 0.534
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Core Devices HyperBEAM provides a comprehensive suite of devices that handle different aspects of computation, data management, authentication, and system operations. This page provides a complete overview of all available devices organized by their primary function.Essential Core Devices These devices provide the fundamental building blocks for HyperBEAM applications:Process & State Management ~process@1.0 - Manages persistent, shared computational states and orchestrates device execution ~scheduler@1.0 - Handles ordering and execution of messages within processes ~meta@1.0 - Configures node settings, hardware specs, and operational parameters Message & Data Handling ~message@1.0 - Core message state and processing management ~json@1.0 - Provides structured access to JSON data ~relay@1.0 - Forwards messages between AO nodes and external endpoints Execution Environments ~wasm64@1.0 - Executes WebAssembly code for high-performance computation ~lua@5.3a - Executes Lua scripts for flexible scripting capabilities Device Ecosystems These comprehensive ecosystems provide advanced functionality through coordinated device interactions:Authentication & Security Ecosystem Authentication Ecosystem - Complete wallet-less authentication system Included Devices:~auth-hook@1.0 - Main authentication interceptor and request signer ~secret@1.0 - Wallet generation and secret management with access control ~cookie@1.0 - HTTP cookie-based session authentication ~http-auth@1.0 - HTTP Basic authentication with PBKDF2 key derivation Key Capabilities:Zero-friction blockchain authentication Server-side wallet management Session persistence across requests Enterprise HTTP authentication Multi-signature wallet support Data Management Ecosystem Data Discovery Engine Data Discovery Engine - Advanced message search and query system Primary Device:~query@1.0 - Flexible message discovery with multiple search modes and return formats Key Capabilities:Complex message searching with flexible filtering GraphQL query support for advanced data operations Multiple return formats (paths, messages, counts, booleans) Integration with authentication for access-controlled queries Data Replication Engine Data Replication Engine - External data ingestion and synchronization Primary Device:~copycat@1.0 - Orchestrates data replication from external sources Key Capabilities:GraphQL endpoint data replication Direct Arweave node integration Automatic pagination and batch processing Comprehensive error handling and recovery Security & TEE Devices Advanced security features and Trusted Execution Environment support:~snp@1.0 - Secure Network Protocol for TEE operations dev_codec_httpsig - HTTP signature validation and processing Payment & Access Control Devices Metering, billing, and access management:~p4@1.0 - Payment processing and metering system ~faff@1.0 - Fine-grained access control and permissions Workflow & Utility Devices Process coordination and system utilities:dev_cron - Scheduled task execution and automation dev_stack - Device stack management and coordination dev_monitor - System monitoring and health checks Storage & Cache Devices Data persistence and caching infrastructure:dev_cache - Message caching and retrieval system hb_store - Persistent storage backend management Communication & Network Devices Inter-node communication and network operations:hb_gateway_client - Gateway communication client hb_http_client - HTTP client operations hb_http_server - HTTP server management Development & Testing Devices Tools for development, testing, and debugging:dev_test - Testing framework and utilities hb_debugger - Debugging tools and inspection dev_multipass - Multi-pass processing utilities Legacy & Specialized Devices Specialized functionality and legacy support:~patch@1.0 - Direct state updates for process migration dev_wasi - WebAssembly System Interface support dev_poda - Proof of Data Availability validation Device Integration Patterns Complete Application Stack Authentication → Data Replication → Data Discovery → Process Execution
↓ ↓ ↓ ↓
Auth Ecosystem Copycat Device Query Device Process Device Data Workflow Integration Ingestion: Copycat replicates external data into local cache Discovery: Query provides search and filtering over cached data Authentication: Auth ecosystem controls access to data operations Processing: Process devices utilize data for computation Security Integration Authentication ecosystem provides transparent user authentication TEE devices enable secure computation environments Access control devices manage permissions and resource usage HTTP signature devices ensure message integrity Getting Started For Authentication:Start with the Authentication Ecosystem to enable wallet-less blockchain applications.For Data Management:Begin with Data Replication to import external data, then use Data Discovery for search and analysis.For Process Development:Review ~process@1.0 for state management and ~scheduler@1.0 for message ordering.For Custom Devices:See Building Devices for guidance on creating your own devices. Next Steps:- Building Devices - Learn to create custom devices
- HyperBEAM Overview - Understand the device architecture
- Source Code Reference - Detailed technical documentation

---

# 10. Pathing in HyperBEAM - HyperBEAM - Documentation

Document Number: 10
Source: https://hyperbeam.arweave.net/build/getting-started/pathing-in-hyperbeam.html
Words: 844
Quality Score: 0.534
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Pathing in HyperBEAM Overview Understanding how to construct and interpret paths in AO-Core is fundamental to working with HyperBEAM. This guide explains the structure and components of AO-Core paths, enabling you to effectively interact with processes and access their data.HyperBEAM Path Structure Let's examine a typical HyperBEAM endpoint piece-by-piece:https://forward.computer/~process@1.0/now Node URL (forward.computer) The HTTP response from this node includes a signature from the host's key. By accessing the ~snp@1.0 device, you can verify that the node is running in a genuine Trusted Execution Environment (TEE), ensuring computation integrity. You can replace forward.computer with any HyperBEAM TEE node operated by any party while maintaining trustless guarantees.Process Path (/~process@1.0) Every path in AO-Core represents a program. Think of the URL bar as a Unix-style command-line interface, providing access to AO's trustless and verifiable compute. Each path component (between / characters) represents a step in the computation. In this example, we instruct the AO-Core node to:Load a specific message from its caches (local, another node, or Arweave) Interpret it with the ~process@1.0 device The process device implements a shared computing environment with consistent state between users State Access (/now or /compute) Devices in AO-Core expose keys accessible via path components. Each key executes a function on the device:now: Calculates real-time process state compute: Serves the latest known state (faster than checking for new messages) Under the surface, these keys represent AO-Core messages. As we progress through the path, AO-Core applies each message to the existing state. You can access the full process state by visiting:/~process@1.0/now State Navigation You can browse through sub-messages and data fields by accessing them as keys. For example, if a process stores its interaction count in a field named cache, you can access it like this:/~process@1.0/compute/cache This shows the 'cache' of your process. Each response is:A message with a signature attesting to its correctness A hashpath describing its generation Transferable to other AO-Core nodes for uninterrupted execution Query Parameters and Type Casting Beyond path segments, HyperBEAM URLs can include query parameters that utilize a special type casting syntax. This allows specifying the desired data type for a parameter directly within the URL using the format key+type=value.Syntax: A + symbol separates the parameter key from its intended type (e.g., count+integer=42, items+list="apple",7).Mechanism: The HyperBEAM node identifies the +type suffix (e.g., +integer, +list, +map, +float, +atom, +resolve). It then uses internal functions (hb_singleton:maybe_typed and dev_codec_structured:decode_value) to decode and cast the provided value string into the corresponding Erlang data type before incorporating it into the message.Supported Types: Common types include integer, float, list, map, atom, binary (often implicit), and resolve (for path resolution). List values often follow the HTTP Structured Fields format (RFC 8941).This powerful feature enables the expression of complex data structures directly in URLs.Examples The following examples illustrate using HTTP paths with various AO-Core processes and devices. While these cover a few specific use cases, HyperBEAM's extensible nature allows interaction with any device or process via HTTP paths. For a deeper understanding, we encourage exploring the source code and experimenting with different paths.Example 1: Accessing Full Process State To get the complete, real-time state of a process identified by , use the /now path component with the ~process@1.0 device:GET /~process@1.0/now This instructs the AO-Core node to load the process and execute the now function on the ~process@1.0 device.Example 2: Navigating to Specific Process Data If a process maintains its state in a map and you want to access a specific field, like at-slot, using the faster /compute endpoint:GET /~process@1.0/compute/cache This accesses the compute key on the ~process@1.0 device and then navigates to the cache key within the resulting state map. Using this path, you will see the latest 'cache' of your process (the number of interactions it has received). Every piece of relevant information about your process can be accessed similarly, effectively providing a native API.(Note: This represents direct navigation within the process state structure. For accessing data specifically published via the ~patch@1.0 device, see the documentation on Exposing Process State, which typically uses the /cache/ path.) Example 3: Basic ~message@1.0 Usage Here's a simple example of using ~message@1.0 to create a message and retrieve a value:GET /~message@1.0&greeting="Hello"&count+integer=42/count Base:/ - The base URL of the HyperBEAM node.Root Device:~message@1.0 Query Params:greeting="Hello" (binary) and count+integer=42 (integer), forming the message #{ <<"greeting">> => <<"Hello">>, <<"count">> => 42 }.Path:/count tells ~message@1.0 to retrieve the value associated with the key count.Response: The integer 42.Example 4: Using the ~message@1.0 Device with Type Casting The ~message@1.0 device can be used to construct and query transient messages, utilizing type casting in query parameters.Consider the following URL:GET /~message@1.0&name="Alice"&age+integer=30&items+list="apple",1,"banana"&config+map=key1="val1";key2=true/[PATH] HyperBEAM processes this as follows:Base:/ - The base URL of the HyperBEAM node.Root Device:~message@1.0 Query Parameters (with type casting):name="Alice" -> #{ <<"name">> => <<"Alice">> } (binary) age+integer=30 -> #{ <<"age">> => 30 } (integer) items+list="apple",1,"banana" -> #{ <<"items">> => [<<"apple">>, 1, <<"banana">>] } (list) config+map=key1="val1";key2=true -> #{ <<"config">> => #{<<"key1">> => <<"val1">>, <<"key2">> => true} } (map) Initial Message Map: A combination of the above key-value pairs.Path Evaluation:If [PATH] is /items/1, the response is the integer 1.If [PATH] is /config/key1, the response is the binary <<"val1">>.

---

# 11. Building Devices - HyperBEAM - Documentation

Document Number: 11
Source: https://hyperbeam.arweave.net/build/devices/building-devices.html
Words: 150
Quality Score: 0.513
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Extending HyperBEAM with Devices We encourage you to extend HyperBEAM with devices for functionality that is general purpose and reusable across different applications.What are Devices?As explained in the introduction, devices are the core functional units within HyperBEAM. They are self-contained modules that process messages and perform specific actions, forming the building blocks of your application's logic.HyperBEAM comes with a set of powerful built-in devices that handle everything from process management (~process@1.0) and message scheduling (~scheduler@1.0) to executing WebAssembly (~wasm64@1.0) and Lua scripts (~lua@5.3a).Creating Your Own Devices (Coming Soon) We will create more in depth guides for building devices in Lua and Erlang in the future.Further Reading In the meantime, community-contributed guides are available that can walk you through the process. For example:Rust:Building Rust Devices with HyperBEAM M3 Beta: mini-Roam API (Vol. 1) - A tutorial from Decent Land Labs that covers how to build a custom Rust device from scratch.

---

# 12. Intro to HyperBEAM - HyperBEAM - Documentation

Document Number: 12
Source: https://hyperbeam.arweave.net/build/introduction/what-is-hyperbeam.html
Words: 307
Quality Score: 0.509
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Skip to content
What is HyperBEAM? HyperBEAM is the primary, production-ready implementation of the AO-Core protocol, built on the robust Erlang/OTP framework. It serves as a decentralized operating system, powering the AO Computer —a scalable, trust-minimized, distributed supercomputer built on permanent storage of Arweave.Implementing AO-Core HyperBEAM transforms the abstract concepts of AO-Core—Messages, Devices, and Paths—into a concrete, operational system. It provides the runtime environment and essential services to execute these
computations across a network of distributed nodes. Messages Modular Data Packets In HyperBEAM, every interaction within the AO Computer is handled as a message. A message is a binary item or a map of functions. These cryptographically-linked data units are the foundation for communication, allowing processes to trigger computations, query state, and transfer value. HyperBEAM nodes are responsible for routing and processing these messages according to the rules of the AO-Core protocol. Devices Extensible Execution Engines HyperBEAM introduces a uniquely modular architecture centered around Devices. These pluggable components are Erlang modules that define specific computational logic—like running WASM, managing state, or relaying data—allowing for unprecedented flexibility. This design allows developers to extend the system by creating custom Devices to fit their specific computational needs. Paths Composable Pipelines HyperBEAM exposes a powerful HTTP API that uses structured URL patterns to interact with processes and data. This pathing mechanism allows developers to create verifiable data pipelines, composing functionality from multiple devices into a single, atomic request. The URL bar effectively becomes a command-line interface for AO's trustless compute environment.A Robust and Scalable Foundation Built on the Erlang/OTP framework, HyperBEAM provides a robust and secure foundation that leverages the BEAM virtual machine for exceptional concurrency, fault tolerance, and scalability. This abstracts away underlying hardware, allowing diverse nodes to contribute resources without compatibility issues. The system governs how nodes coordinate and interact, forming a decentralized network that is resilient and permissionless.

---

# 13. Building ao Processes - HyperBEAM - Documentation

Document Number: 13
Source: https://hyperbeam.arweave.net/build/getting-started/building-on-ao.html
Words: 92
Quality Score: 0.508
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Building on HyperBEAM with ao The guides for building applications on HyperBEAM and interacting with ao processes have been moved to the AO Processes Cookbook to provide a centralized resource for developers.Here are some helpful resources from the AO Processes Cookbook:Get Started with ao to learn the basics of ao and how to start building processes.Migration Guide for moving processes from legacynet and using new HyperBEAM features.Using aos with HyperBEAM for using the aos command-line tool with HyperBEAM.Using aoconnect with HyperBEAM for using the aoconnect library to interact with processes on HyperBEAM.

---

# 14. Fuel Your LLM - HyperBEAM - Documentation

Document Number: 14
Source: https://hyperbeam.arweave.net/llms.html
Words: 166
Quality Score: 0.503
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

LLM Context Files This section provides access to specially formatted files intended for consumption by Large Language Models (LLMs) to provide context about the HyperBEAM documentation.LLM Summary (llms.txt) Content: Contains a brief summary of the HyperBEAM documentation structure and a list of relative file paths for all markdown documents included in the build.Usage: Useful for providing an LLM with a high-level overview and the available navigation routes within the documentation.LLM Full Content (llms-full.txt) Content: A single text file containing the complete, concatenated content of all markdown documents from the specified documentation directories (begin, run, guides, devices, resources). Each file's content is clearly demarcated.Usage: Ideal for feeding the entire documentation content into an LLM for comprehensive context, analysis, or question-answering based on the full documentation set.Generation Process These files are automatically generated by the docs/build-all.sh script during the documentation build process. They consolidate information from the following directories:docs/run docs/build Permaweb LLMs.txt An interactive tool for selecting and curating Permaweb documentation into llms.txt format for feeding to LLMs.

---

# 15. FAQ - HyperBEAM - Documentation

Document Number: 15
Source: https://hyperbeam.arweave.net/run/reference/faq.html
Words: 327
Quality Score: 0.500
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Node Operator FAQ This page answers common questions about running and maintaining a HyperBEAM node.What is HyperBEAM?HyperBEAM is a client implementation of the AO-Core protocol written in Erlang. It serves as the node software for a decentralized operating system that allows operators to offer computational resources to users in the AO network.What are the system requirements for running HyperBEAM?Currently, HyperBEAM is primarily tested and documented for Ubuntu 22.04 and macOS. Other platforms will be added in future updates. For detailed requirements, see the System Requirements page.Can I run HyperBEAM in a container?While technically possible, running HyperBEAM in Docker containers or other containerization technologies is currently not recommended. The containerization approach may introduce additional complexity and potential performance issues. We recommend running HyperBEAM directly on the host system until container support is more thoroughly tested and optimized.How do I update HyperBEAM to the latest version?To update HyperBEAM:Pull the latest code from the repository (check Discord for the branch of Beta releases) Rebuild the application Restart the HyperBEAM service Specific update instructions will vary depending on your installation method.Can I run multiple HyperBEAM nodes on a single machine?Yes, you can run multiple HyperBEAM nodes on a single machine, but you'll need to configure them to use different ports and data directories to avoid conflicts. However, this is not recommended for production environments as each node should ideally have a unique IP address to properly participate in the network. Running multiple nodes on a single machine is primarily useful for development and testing purposes.Is there a limit to how many processes can run on a node?The practical limit depends on your hardware resources. Erlang is designed to handle millions of lightweight processes efficiently, but the actual number will be determined by:Available memory CPU capacity Network bandwidth Storage speed The complexity of your processes Where can I get help if I encounter issues?If you encounter issues:Check the Troubleshooting guide Search or ask questions on GitHub Issues Join the community on Discord

---

# 16. Module dev_p4erl - HyperBEAM - Documentation

Document Number: 16
Source: https://hyperbeam.arweave.net/build/devices/source-code/dev_p4.html
Words: 550
Quality Score: 0.497
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Module dev_p4.erl The HyperBEAM core payment ledger.Description This module allows the operator to
specify another device that can act as a pricing mechanism for transactions
on the node, as well as orchestrating a payment ledger to calculate whether
the node should fulfil services for users.The device requires the following node message settings in order to function:p4_pricing-device: The device that will estimate the cost of a request.p4_ledger-device: The device that will act as a payment ledger.The pricing device should implement the following keys:`GET /estimate?type=pre|post&body=[...]&request=RequestMessage``GET /price?type=pre|post&body=[...]&request=RequestMessage The body key is used to pass either the request or response messages to the
device. The type key is used to specify whether the inquiry is for a request
(pre) or a response (post) object. Requests carry lists of messages that will
be executed, while responses carry the results of the execution. The price key may return infinity if the node will not serve a user under any
circumstances. Else, the value returned by the price key will be passed to
the ledger device as the amount key.A ledger device should implement the following keys:POST /credit?message=PaymentMessage&request=RequestMessage``POST /charge?amount=PriceMessage&request=RequestMessage``GET /balance?request=RequestMessage` The type key is optional and defaults to pre. If type is set to post,
the charge must be applied to the ledger, whereas the pre type is used to
check whether the charge would succeed before execution.Function Index balance/3 Get the balance of a user in the ledger.faff_test/0* Simple test of p4's capabilities with the faff@1.0 device.hyper_token_ledger/0* hyper_token_ledger_test_/0* Ensure that Lua scripts can be used as pricing and ledger devices.is_chargable_req/2* The node operator may elect to make certain routes non-chargable, using
the routes syntax also used to declare routes in router@1.0.non_chargable_route_test/0* Test that a non-chargable route is not charged for.request/3 Estimate the cost of a transaction and decide whether to proceed with
a request.response/3 Postprocess the request after it has been fulfilled.test_opts/1* test_opts/2* test_opts/3* Function Details balance/3 balance(X1, Req, NodeMsg) -> any() Get the balance of a user in the ledger.faff_test/0 * faff_test() -> any() Simple test of p4's capabilities with the faff@1.0 device.hyper_token_ledger/0 * hyper_token_ledger() -> any() hyper_token_ledger_test_/0 * hyper_token_ledger_test_() -> any() Ensure that Lua scripts can be used as pricing and ledger devices. Our
scripts come in two components:
1. A process script which is executed as a persistent local-process on the
node, and which maintains the state of the ledger. This process runs hyper-token.lua as its base, then adds the logic of hyper-token-p4.lua to it. This secondary script implements the charge function that p4@1.0 will call to charge a user's account.
2. A client script, which is executed as a p4@1.0 ledger device, which
uses ~push@1.0 to send requests to the ledger process.is_chargable_req/2 * is_chargable_req(Req, NodeMsg) -> any() The node operator may elect to make certain routes non-chargable, using
the routes syntax also used to declare routes in router@1.0.non_chargable_route_test/0 * non_chargable_route_test() -> any() Test that a non-chargable route is not charged for.request/3 request(State, Raw, NodeMsg) -> any() Estimate the cost of a transaction and decide whether to proceed with
a request. The default behavior if pricing-device or p4_balances are
not set is to proceed, so it is important that a user initialize them.response/3 response(State, RawResponse, NodeMsg) -> any() Postprocess the request after it has been fulfilled.test_opts/1 * test_opts(Opts) -> any() test_opts/2 * test_opts(Opts, PricingDev) -> any() test_opts/3 * test_opts(Opts, PricingDev, LedgerDev) -> any()

---

# 17. Data Replication - HyperBEAM - Documentation

Document Number: 17
Source: https://hyperbeam.arweave.net/build/devices/application-features/data-replication-at-1-0.html
Words: 450
Quality Score: 0.483
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Device: ~copycat@1.0 Overview The ~copycat@1.0 device replicates data from external sources into HyperBEAM node caches. It fetches messages from GraphQL endpoints and Arweave nodes, enabling offline-first applications through local data caching.Core Concept: Data Ingestion The ~copycat@1.0 device acts as a data ingestion orchestrator that fetches messages from external sources and imports them into the local node's cache system. It supports multiple engines (GraphQL, Arweave) and handles pagination automatically during large-scale replication operations.Key Functions (Keys) POST /~copycat@1.0/graphql Action: Queries remote GraphQL endpoints and indexes results locally.Parameters:query: GraphQL query string or structured specification variables: Query variables for parameterized queries operationName: Specific operation in multi-operation queries node: Target GraphQL endpoint URL Response: Total number of successfully indexed messages with batch statistics.Processing: Automatic pagination handling, message parsing, and cache integration.POST /~copycat@1.0/arweave Action: Connects directly to Arweave nodes and imports transaction/block data.Parameters:node: Target Arweave node URL from: Starting block height to: Ending block height filter: Transaction filtering criteria Response: Replication status with imported message count and range coverage.Integration: Uses ~arweave@2.9-pre device for native Arweave communication.Data Sources GraphQL Endpoints: Arweave Gateway APIs (arweave.net, ar.io gateways), custom GraphQL services, and federated endpoints with multi-endpoint coordination.Arweave Nodes: Direct node integration for block-level replication with height-based ranges and transaction indexing.Filter Examples Tag-Based Filtering:Owner-Based Filtering:Multi-Tag Filtering:Comprehensive Replication:Replication Workflow The device processes data through these steps:Fetch Batch: Retrieve data from GraphQL endpoints Parse Messages: Convert to HyperBEAM format Validate Format: Ensure structure compliance Write to Cache: Store in node cache Update Progress: Track statistics Automatic pagination continues fetching until all data is replicated, with configurable batch sizes for optimal performance.Integration Example Query replicated data after import:// Phase 1: Replicate application data
POST /~copycat@1.0/graphql
{
"tag": "App-Name",
"value": "MyApp",
"node": "https://arweave.net/graphql"
}
// Phase 2: Query replicated data locally
GET /~query@1.0/all
{
"tag": "App-Name",
"return": "count"
} Practical Implications For Application Developers:Copycat transforms your HyperBEAM node into a complete data mirror. Instead of hitting external gateways for every query, replicate once and query locally via ~query@1.0. This enables offline-first architectures where your application continues functioning even when external networks fail. Automatic pagination handles large datasets without memory constraints.For Node Operators:Strategic replication reduces external API dependencies and improves response times. Replicate application-specific data subsets using tag filters rather than entire chains. Monitor cache growth—replicated data consumes disk space proportional to message count and size. Schedule periodic replication jobs to keep local caches synchronized with source networks.For End Users:Applications using copycat load faster and work offline. Once data replicates to your node, subsequent interactions happen instantly without network round-trips. This is particularly valuable for mobile or low-connectivity scenarios where traditional blockchain applications struggle.See Also ~query@1.0 - For querying replicated data ~cache@1.0 - Storage target for replicated data ~arweave@2.9-pre - Arweave node communication copycat module

---

# 18. Module dev_stackerl - HyperBEAM - Documentation

Document Number: 18
Source: https://hyperbeam.arweave.net/build/devices/source-code/dev_stack.html
Words: 1145
Quality Score: 0.475
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Module dev_stack.erl A device that contains a stack of other devices, and manages their
execution.Description It can run in two modes: fold (the default), and map.In fold mode, it runs upon input messages in the order of their keys. A
stack maintains and passes forward a state (expressed as a message) as it
progresses through devices.For example, a stack of devices as follows:Device -> Stack
Device-Stack/1/Name -> Add-One-Device
Device-Stack/2/Name -> Add-Two-Device When called with the message:#{ Path = "FuncName", binary => `<<"0">>` } Will produce the output:#{ Path = "FuncName", binary => `<<"3">>` }
{ok, #{ bin => `<<"3">>` }} In map mode, the stack will run over all the devices in the stack, and
combine their results into a single message. Each of the devices'
output values have a key that is the device's name in the Device-Stack (its number if the stack is a list).You can switch between fold and map modes by setting the Mode key in the Msg2 to either Fold or Map, or set it globally for the stack by
setting the Mode key in the Msg1 message. The key in Msg2 takes
precedence over the key in Msg1.The key that is called upon the device stack is the same key that is used
upon the devices that are contained within it. For example, in the above
scenario we resolve FuncName on the stack, leading FuncName to be called on
Add-One-Device and Add-Two-Device.A device stack responds to special statuses upon responses as follows:skip: Skips the rest of the device stack for the current pass.pass: Causes the stack to increment its pass number and re-execute
the stack from the first device, maintaining the state
accumulated so far. Only available in fold mode.In all cases, the device stack will return the accumulated state to the
caller as the result of the call to the stack.The dev_stack adds additional metadata to the message in order to track
the state of its execution as it progresses through devices. These keys
are as follows:Stack-Pass: The number of times the stack has reset and re-executed
from the first device for the current message.Input-Prefix: The prefix that the device should use for its outputs
and inputs.Output-Prefix: The device that was previously executed.All counters used by the stack are initialized to 1.Additionally, as implemented in HyperBEAM, the device stack will honor a
number of options that are passed to it as keys in the message. Each of
these options is also passed through to the devices contained within the
stack during execution. These options include:Error-Strategy: Determines how the stack handles errors from devices.
See maybe_error/5 for more information.Allow-Multipass: Determines whether the stack is allowed to automatically
re-execute from the first device when the pass tag is returned. See maybe_pass/3 for more information.Under-the-hood, dev_stack uses a default handler to resolve all calls to
devices, aside set/2 which it calls itself to mutate the message's device key in order to change which device is currently being executed. This method
allows dev_stack to ensure that the message's HashPath is always correct,
even as it delegates calls to other devices. An example flow for a dev_stack execution is as follows:/Msg1/AlicesExcitingKey ->
dev_stack:execute ->
/Msg1/Set?device=/Device-Stack/1 ->
/Msg2/AlicesExcitingKey ->
/Msg3/Set?device=/Device-Stack/2 ->
/Msg4/AlicesExcitingKey
... ->
/MsgN/Set?device=[This-Device] ->
returns {ok, /MsgN+1} ->
/MsgN+1 In this example, the device key is mutated a number of times, but the
resulting HashPath remains correct and verifiable.Function Index benchmark_test/0* example_device_for_stack_test/0* generate_append_device/1 generate_append_device/2* increment_pass/2* Helper to increment the pass number.info/1 input_and_output_prefixes_test/0* input_output_prefixes_passthrough_test/0* input_prefix/3 Return the input prefix for the stack.many_devices_test/0* maybe_error/5* no_prefix_test/0* not_found_test/0* output_prefix/3 Return the output prefix for the stack.output_prefix_test/0* pass_test/0* prefix/3 Return the default prefix for the stack.reinvocation_test/0* resolve_fold/3* The main device stack execution engine.resolve_fold/4* resolve_map/3* Map over the devices in the stack, accumulating the output in a single
message of keys and values, where keys are the same as the keys in the
original message (typically a number).router/3* router/4 The device stack key router.simple_map_test/0* simple_stack_execute_test/0* skip_test/0* test_prefix_msg/0* transform/3* Return Message1, transformed such that the device named Key from the Device-Stack key in the message takes the place of the original Device key.transform_external_call_device_test/0* Ensure we can generate a transformer message that can be called to
return a version of msg1 with only that device attached.transform_internal_call_device_test/0* Test that the transform function can be called correctly internally
by other functions in the module.transformer_message/2* Return a message which, when given a key, will transform the message
such that the device named Key from the Device-Stack key in the message
takes the place of the original Device key.Function Details benchmark_test/0 * benchmark_test() -> any() example_device_for_stack_test/0 * example_device_for_stack_test() -> any() generate_append_device/1 generate_append_device(Separator) -> any() generate_append_device/2 * generate_append_device(Separator, Status) -> any() increment_pass/2 * increment_pass(Message, Opts) -> any() Helper to increment the pass number.info/1 info(Msg) -> any() input_and_output_prefixes_test/0 * input_and_output_prefixes_test() -> any() input_output_prefixes_passthrough_test/0 * input_output_prefixes_passthrough_test() -> any() input_prefix/3 input_prefix(Msg1, Msg2, Opts) -> any() Return the input prefix for the stack.many_devices_test/0 * many_devices_test() -> any() maybe_error/5 * maybe_error(Message1, Message2, DevNum, Info, Opts) -> any() no_prefix_test/0 * no_prefix_test() -> any() not_found_test/0 * not_found_test() -> any() output_prefix/3 output_prefix(Msg1, Msg2, Opts) -> any() Return the output prefix for the stack.output_prefix_test/0 * output_prefix_test() -> any() pass_test/0 * pass_test() -> any() prefix/3 prefix(Msg1, Msg2, Opts) -> any() Return the default prefix for the stack.reinvocation_test/0 * reinvocation_test() -> any() resolve_fold/3 * resolve_fold(Message1, Message2, Opts) -> any() The main device stack execution engine. See the moduledoc for more
information.resolve_fold/4 * resolve_fold(Message1, Message2, DevNum, Opts) -> any() resolve_map/3 * resolve_map(Message1, Message2, Opts) -> any() Map over the devices in the stack, accumulating the output in a single
message of keys and values, where keys are the same as the keys in the
original message (typically a number).router/3 * router(Message1, Message2, Opts) -> any() router/4 router(Key, Message1, Message2, Opts) -> any() The device stack key router. Sends the request to resolve_stack,
except for set/2 which is handled by the default implementation in dev_message.simple_map_test/0 * simple_map_test() -> any() simple_stack_execute_test/0 * simple_stack_execute_test() -> any() skip_test/0 * skip_test() -> any() test_prefix_msg/0 * test_prefix_msg() -> any() transform/3 * transform(Msg1, Key, Opts) -> any() Return Message1, transformed such that the device named Key from the Device-Stack key in the message takes the place of the original Device key. This transformation allows dev_stack to correctly track the HashPath
of the message as it delegates execution to devices contained within it.transform_external_call_device_test/0 * transform_external_call_device_test() -> any() Ensure we can generate a transformer message that can be called to
return a version of msg1 with only that device attached.transform_internal_call_device_test/0 * transform_internal_call_device_test() -> any() Test that the transform function can be called correctly internally
by other functions in the module.transformer_message/2 * transformer_message(Msg1, Opts) -> any() Return a message which, when given a key, will transform the message
such that the device named Key from the Device-Stack key in the message
takes the place of the original Device key. This allows users to call
a single device from the stack:/Msg1/Transform/DeviceName/keyInDevice ->
keyInDevice executed on DeviceName against Msg1.

---

# 19. meta10 - HyperBEAM - Documentation

Document Number: 19
Source: https://hyperbeam.arweave.net/build/devices/foundational/meta-at-1-0.html
Words: 346
Quality Score: 0.475
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Device: ~meta@1.0 Overview The ~meta@1.0 device provides access to metadata and configuration information about the local HyperBEAM node and the broader AO network.This device is essential for:Core Functions (Keys) info Retrieves or modifies the node's configuration message (often referred to as NodeMsg internally).GET /~meta@1.0/info Action: Returns the current node configuration message.Response: A message map containing the node's settings. Sensitive keys (like private wallets) are filtered out. Dynamically generated keys like the node's public address are added if a wallet is configured.POST /~meta@1.0/info Action: Updates the node's configuration message. Requires the request to be signed by the node's configured operator key/address.Request Body: A message map containing the configuration keys and values to update.Response: Confirmation message indicating success or failure.Note: Once a node's configuration is marked as initialized = permanent, it cannot be changed via this method.Key Configuration Parameters Managed by ~meta While the info key is the primary interaction point, the NodeMsg managed by ~meta holds crucial configuration parameters affecting the entire node's behavior, including (but not limited to):port: HTTP server port.priv_wallet / key_location: Path to the node's Arweave key file.operator: The address designated as the node operator (defaults to the address derived from priv_wallet).initialized: Status indicating if the node setup is temporary or permanent.preprocessor / postprocessor: Optional messages defining pre/post-processing logic for requests.routes: Routing table used by dev_router.store: Configuration for data storage.trace: Debug tracing options.p4_*: Payment configuration.faff_*: Access control lists.(Refer to hb_opts.erl for a comprehensive list of options.) Utility Functions (Internal/Module Level) The dev_meta.erl module also contains helper functions used internally or callable from other Erlang modules:is_operator(, ) -> boolean(): Checks if the signer of RequestMsg matches the configured operator in NodeMsg.Pre/Post-Processing Hooks The ~meta device applies the node's configured preprocessor message before resolving the main request and the postprocessor message after obtaining the result, allowing for global interception and modification of requests/responses.Initialization Before a node can process general requests, it usually needs to be initialized. Attempts to access devices other than ~meta@1.0/info before initialization typically result in an error. Initialization often involves setting essential parameters like the operator key via a POST to info.meta module

---

# 20. Glossary - HyperBEAM - Documentation

Document Number: 20
Source: https://hyperbeam.arweave.net/run/reference/glossary.html
Words: 286
Quality Score: 0.473
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Skip to content
Node Operator Glossary This glossary provides definitions for terms and concepts relevant to running a HyperBEAM node.AO-Core Protocol The underlying protocol that HyperBEAM implements, enabling decentralized computing and communication between nodes.Checkpoint A saved state of a process that can be used to resume execution from a known point, used for persistence and recovery.Compute Unit (CU) The NodeJS component of HyperBEAM that executes WebAssembly modules. While developers interact with it more, operators should know it's a key part of the stack.Erlang The programming language used to implement the HyperBEAM core, known for its robustness and support for building distributed, fault-tolerant applications.~flat@1.0 A format used for encoding settings files in HyperBEAM configuration, using HTTP header styling.HyperBEAM The Erlang-based node software that handles message routing, process management, and device coordination in the HyperBEAM ecosystem.Node An instance of HyperBEAM running on a physical or virtual machine that participates in the distributed network.~meta@1.0 A device used to configure the node's hardware, supported devices, metering and payments information, amongst other configuration options.~p4@1.0 A device that runs as a pre-processor and post-processor in HyperBEAM, enabling a framework for node operators to sell usage of their machine's hardware to execute AO-Core devices.~simple-pay@1.0 A simple, flexible pricing device that can be used in conjunction with p4@1.0 to offer flat-fees for the execution of AO-Core messages.~snp@1.0 A device used to generate and validate proofs that a node is executing inside a Trusted Execution Environment (TEE).Trusted Execution Environment (TEE) A secure area inside a processor that ensures the confidentiality and integrity of code and data loaded within it. Used in HyperBEAM for trust-minimized computation.Permaweb Glossary For a more comprehensive glossary of terms used in the permaweb, try the Permaweb Glossary. Or use it below:

---

# 21. FAQ - HyperBEAM - Documentation

Document Number: 21
Source: https://hyperbeam.arweave.net/build/reference/faq.html
Words: 275
Quality Score: 0.472
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Developer FAQ This page answers common questions about building applications and processes on HyperBEAM.What can I build with HyperBEAM?You can build a wide range of applications, including:Decentralized applications (dApps) Distributed computation systems Peer-to-peer services Resilient microservices IoT device networks Decentralized storage solutions What is the current focus or phase of HyperBEAM development?The initial development phase focuses on integrating AO processes more deeply with HyperBEAM. A key part of this is phasing out the reliance on traditional "dryrun" simulations for reading process state. Instead, processes are encouraged to use the ~patch@1.0 device to expose specific parts of their state directly via GET requests. This allows for more efficient and direct state access, particularly for web interfaces and external integrations. You can mechanism in the Exposing Process State with the Patch Device guide.What is the difference between HyperBEAM and Compute Unit?HyperBEAM: The Erlang-based node software that handles message routing, process management, and device coordination.Compute Unit (CU): A NodeJS implementation that executes WebAssembly modules and handles computational tasks.Together, these components form a complete execution environment for AO processes.What programming languages can I use with HyperBEAM?You can use any programming language that compiles to WebAssembly (WASM) for creating modules that run on the Compute Unit. This includes languages like:Lua Rust C/C++ And many others with WebAssembly support How do I debug processes running in HyperBEAM?Debugging processes in HyperBEAM can be done through:Logging messages to the system log (DEBUG=HB_PRINT rebar3 shell) Monitoring process state and message flow Inspecting memory usage and performance metrics Where can I get help if I encounter issues?If you encounter issues:Check the Troubleshooting guide Search or ask questions on GitHub Issues Join the community on Discord

---

# 22. Authentication Ecosystem - HyperBEAM - Documentation

Document Number: 22
Source: https://hyperbeam.arweave.net/build/devices/application-features/auth-ecosystem-at-1-0.html
Words: 461
Quality Score: 0.468
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Device: Authentication Ecosystem (~auth-hook@1.0, ~secret@1.0, ~cookie@1.0, ~http-auth@1.0) Overview The Authentication Ecosystem provides wallet-less blockchain applications through server-side key management. The ecosystem consists of ~auth-hook@1.0 (authentication interceptor), ~secret@1.0 (wallet storage), ~cookie@1.0 (session management), and ~http-auth@1.0 (HTTP Basic authentication).Core Concept: Zero-Friction Authentication Users interact with decentralized applications like traditional web apps while HyperBEAM handles cryptographic operations server-side. The &! parameter triggers automatic request signing with node-hosted wallets.Primary Device: ~auth-hook@1.0 Intercepts HTTP requests containing the &! parameter and processes them through a configured secret provider.Key Functions request Action: Detects &! pattern, validates configuration, generates/retrieves secrets, creates wallets via ~secret@1.0, signs requests, and applies provider post-processing.Configuration:Activation Conditions:"when": {
"committers": "uncommitted" | "always" | ["address1"],
"keys": "always" | ["authorization"]
} Supporting Devices ~secret@1.0 Manages wallet creation, storage, and signing operations.generate: Creates wallets with persistence modes (client, in-memory, non-volatile) commit: Signs messages with access-control and multi-signature support export / sync: Manages wallet portability and cross-node synchronization ~cookie@1.0 Implements HTTP cookie-based session management with HMAC-SHA256 commitments.generate: Creates/retrieves secrets from cookies finalize: Adds Set-Cookie headers to responses Security: HTTPOnly, Secure, SameSite attributes; wallet- patterns ~http-auth@1.0 Provides HTTP Basic authentication with PBKDF2 key derivation (1,200,000 iterations, SHA256).generate: Processes Authorization headers and derives signing keys Flow: Returns 401 with WWW-Authenticate when credentials missing, otherwise derives key and signs Performance PBKDF2 performs ~5-10 derivations/second for brute-force protection.Device Integration The authentication workflow: HTTP request with &! → auth-hook intercepts → provider generates secret → secret device signs → authenticated response returned.Integration with Core Devices:~process@1.0: Automatic signing of process communications ~query@1.0: Authenticated data discovery ~copycat@1.0: Authenticated data replication ~meta@1.0: Authentication provider configuration Multi-Provider Configuration:Security Considerations Security Layers: Provider authentication (Cookie/HTTP) → Access control messages → Controller verification → Request signing (RSA-PSS/HMAC) Best Practices: HTTPS-only, secure cookie attributes, strong PBKDF2 parameters, session key rotation, audit logging Trust Model Intended for deployment in Trusted Execution Environments (TEE) with ~snp@1.0 or trusted nodes. Private keys never leave server memory. All operations create cryptographically auditable signatures.Configuration Examples Cookie Authentication:HTTP Basic Authentication:"secret-provider": {"device": "http-auth@1.0", "realm": "Protected", "iterations": 2000000} Multi-Signature:Practical Implications For Application Developers:This ecosystem eliminates blockchain onboarding friction. Users access your dApp without installing wallets or managing keys—authentication happens transparently via cookies or HTTP Basic Auth. Your application simply adds &! to requests that need signing.For Node Operators:You control the trust model. Deploy in TEE for trustless environments or trusted nodes for enterprise scenarios. Cookie-based auth suits consumer applications, while HTTP Basic Auth serves API integrations and enterprise SSO systems. Multi-signature configurations enable shared custody models.For End Users:Single-click access to blockchain applications with traditional web experience. No seed phrases to manage, no browser extensions to install. Sessions persist across devices when using non-volatile storage mode. Authentication state syncs via cookies or HTTP headers.See Also ~process@1.0 - Process communication signing ~query@1.0 - Authenticated data queries ~snp@1.0 - Trusted execution environment

---

# 23. Module dev_patcherl - HyperBEAM - Documentation

Document Number: 23
Source: https://hyperbeam.arweave.net/build/devices/source-code/dev_patch.html
Words: 375
Quality Score: 0.462
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Module dev_patch.erl A device that can be used to reorganize a message: Moving data from
one path inside it to another.Description This device's function runs in two modes:When using all to move all data at the path given in from to the
path given in to.When using patches to move all submessages in the source to the target,if they have a method key of PATCH or a device key of patch@1.0.Source and destination paths may be prepended by base: or req: keys to
indicate that they are relative to either of the message's that the
computation is being performed on.The search order for finding the source and destination keys is as follows,
where X is either from or to:The patch-X key of the execution message.The X key of the execution message.The patch-X key of the request message.The X key of the request message.Additionally, this device implements the standard computation device keys,
allowing it to be used as an element of an execution stack pipeline, etc.Function Index all/3 Get the value found at the patch-from key of the message, or the from key if the former is not present.all_mode_test/0* compute/3 init/3 Necessary hooks for compliance with the execution-device standard.move/4* Unified executor for the all and patches modes.normalize/3 patch_to_submessage_test/0* patches/3 Find relevant PATCH messages in the given source key of the execution
and request messages, and apply them to the given destination key of the
request.req_prefix_test/0* snapshot/3 uninitialized_patch_test/0* Function Details all/3 all(Msg1, Msg2, Opts) -> any() Get the value found at the patch-from key of the message, or the from key if the former is not present. Remove it from the message and set
the new source to the value found.all_mode_test/0 * all_mode_test() -> any() compute/3 compute(Msg1, Msg2, Opts) -> any() init/3 init(Msg1, Msg2, Opts) -> any() Necessary hooks for compliance with the execution-device standard.move/4 * move(Mode, Msg1, Msg2, Opts) -> any() Unified executor for the all and patches modes.normalize/3 normalize(Msg1, Msg2, Opts) -> any() patch_to_submessage_test/0 * patch_to_submessage_test() -> any() patches/3 patches(Msg1, Msg2, Opts) -> any() Find relevant PATCH messages in the given source key of the execution
and request messages, and apply them to the given destination key of the
request.req_prefix_test/0 * req_prefix_test() -> any() snapshot/3 snapshot(Msg1, Msg2, Opts) -> any() uninitialized_patch_test/0 * uninitialized_patch_test() -> any()

---

# 24. HyperBEAM - Documentation

Document Number: 24
Source: https://hyperbeam.arweave.net/
Words: 140
Quality Score: 0.458
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

A Decentralized Operating System.
Built on AO.What is hyperBEAM? Hyperbeam. Powering the decentralized supercomputer: AO.Access, build, and lease hardware for applications and services at any scale.Your gateway to AO, a decentralized supercomputer network built on top of Arweave. AO and Arweave power a cyberspace which guarantees the rights of users, outside of the control of any individual or group. Communicate via asynchronous
message passing for unheard
of throughput.
Get resilient compute in
your terminal with one
command.
What Do I Do With Hyperbeam?01 Monetize Your Hardware.Access a shared economy for hardware in the new cyberspace.
All while earning $AO Offer compute to AO processes and
their users, earning fees in return.
Run your own gateway. Empower builders to launch trust-minimized, serverless WASM functions using built-in TEE integrations.
Coming Soon: Offer support for GPUs.
Sorry, your browser doesn’t support embedded video.

---

# 25. Glossary - HyperBEAM - Documentation

Document Number: 25
Source: https://hyperbeam.arweave.net/build/reference/glossary.html
Words: 250
Quality Score: 0.458
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Skip to content
Developer Glossary This glossary provides definitions for terms and concepts relevant to building on HyperBEAM.AO-Core Protocol The underlying protocol that HyperBEAM implements, enabling decentralized computing and communication between nodes. AO-Core provides a framework into which any number of different computational models, encapsulated as primitive devices, can be attached.Asynchronous Message Passing A communication paradigm where senders don't wait for receivers to be ready, allowing for non-blocking operations and better scalability.Compute Unit (CU) The NodeJS component of HyperBEAM that executes WebAssembly modules and handles computational tasks.Device A functional unit in HyperBEAM that provides specific capabilities to the system, such as storage, networking, or computational resources.Hashpaths A mechanism for referencing locations in a program's state-space prior to execution. These state-space links are represented as Merklized lists of programs inputs and initial states.Message A data structure used for communication between processes in the HyperBEAM system. Messages can be interpreted as a binary term or as a collection of named functions (a Map of functions).Module A unit of code that can be loaded and executed by the Compute Unit, typically in WebAssembly format.Process An independent unit of computation in HyperBEAM with its own state and execution context.Process ID A unique identifier assigned to a process within the HyperBEAM system.WebAssembly (WASM) A binary instruction format that serves as a portable compilation target for programming languages, enabling deployment on the web and other environments.Permaweb Glossary For a more comprehensive glossary of terms used in the permaweb, try the Permaweb Glossary. Or use it below:

---

# 26. Module dev_cronerl - HyperBEAM - Documentation

Document Number: 26
Source: https://hyperbeam.arweave.net/build/devices/source-code/dev_cron.html
Words: 300
Quality Score: 0.441
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Module dev_cron.erl A device that inserts new messages into the schedule to allow processes
to passively 'call' themselves without user interaction.Function Index every/3 Exported function for scheduling a recurring message.every_worker_loop/4* every_worker_loop_test/0* This test verifies that a recurring task can be scheduled and executed.info/1 Exported function for getting device info.info/3 once/3 Exported function for scheduling a one-time message.once_executed_test/0* This test verifies that a one-time task can be scheduled and executed.once_worker/3* Internal function for scheduling a one-time message.parse_time/1* Parse a time string into milliseconds./3 Exported function for ping a scheduled task._every_test/0* This test verifies that a recurring task can be ped by
calling the function with the task ID._once_test/0* test_worker/0* This is a helper function that is used to test the cron device.test_worker/1* Function Details every/3 every(Msg1, Msg2, Opts) -> any() Exported function for scheduling a recurring message.every_worker_loop/4 * every_worker_loop(CronPath, Req, Opts, IntervalMillis) -> any() every_worker_loop_test/0 * every_worker_loop_test() -> any() This test verifies that a recurring task can be scheduled and executed.info/1 info(X1) -> any() Exported function for getting device info.info/3 info(Msg1, Msg2, Opts) -> any() once/3 once(Msg1, Msg2, Opts) -> any() Exported function for scheduling a one-time message.once_executed_test/0 * once_executed_test() -> any() This test verifies that a one-time task can be scheduled and executed.once_worker/3 * once_worker(Path, Req, Opts) -> any() Internal function for scheduling a one-time message.parse_time/1 * parse_time(BinString) -> any() Parse a time string into milliseconds./3 (Msg1, Msg2, Opts) -> any() Exported function for ping a scheduled task._every_test/0 * _every_test() -> any() This test verifies that a recurring task can be ped by
calling the function with the task ID._once_test/0 * _once_test() -> any() test_worker/0 * test_worker() -> any() This is a helper function that is used to test the cron device.
It is used to increment a counter and update the state of the worker.test_worker/1 * test_worker(State) -> any()

---

# 27. Intro to AO-Core - HyperBEAM - Documentation

Document Number: 27
Source: https://hyperbeam.arweave.net/build/introduction/what-is-ao-core.html
Words: 435
Quality Score: 0.440
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

What is AO-Core? Your browser does not support the video tag.AO-Core is a protocol and standard for distributed computation that forms the foundation of the AO Computer. Inspired by and built upon concepts from the Erlang language, AO-Core embraces the actor model for concurrent, distributed systems. It defines a minimal, generalized model for decentralized computation built around standard web technologies like HTTP.Think of it as a way to interpret the Arweave permaweb not just as static storage, but as a dynamic, programmable, and infinitely scalable computing environment. Unlike traditional blockchain systems, AO-Core defines a flexible, powerful computation protocol that enables a wide range of applications beyond just running Lua programs.Core Concepts AO-Core revolves around three fundamental components: Messages Modular Data Packets Messages are cryptographically linked, forming a verifiable computation graph. Devices Extensible Execution Engines AO-Core introduces a modular architecture centered around Devices. These are pluggable components—typically implemented as modules—that define specific computational logic, such as executing WASM, managing state, or relaying data. Devices interpret and process messages, allowing for flexible and extensible computation. This design enables developers to extend the system by creating custom Devices to fit their specific needs, making the network highly adaptable and composable. Paths Composable Pipelines Paths in AO-Core are structures that link messages over time, creating a verifiable history of computations. They allow users to navigate the computation graph and access specific states or results. AO-Core leverages HashPaths —cryptographic fingerprints representing the sequence of operations leading to a specific message state—ensuring traceability and integrity. This pathing mechanism enables developers to compose complex, verifiable data pipelines and interact with processes and data in a flexible, trustless manner.Key Features AO-Core is inherently resilient, running across a global network of machines that eliminates any single point of failure. Its computations are permanent, immutably stored on Arweave so they can be recalled—or continued—at any time. The protocol remains permissionless, meaning anyone can participate. And it is trustless, with every state mathematically verifiable so no central authority is required.The Actor Model in AO Inspired by Erlang, AO-Core implements the actor model to provide a foundation for inherently concurrent, distributed, and scalable systems. In this model, computation is performed by independent actors (or processes). These actors communicate exclusively by passing messages to one another, and each can make local decisions, send more messages, and create new actors.Beyond Processes While AO Processes (smart contracts built using the AO-Core protocol) are a powerful application, AO-Core itself enables a much broader range of computational patterns:Serverless functions with trustless guarantees Hybrid applications combining smart contracts and serverless functionality Custom execution environments through new devices Composable systems using the path language

---

# 28. Troubleshooting - HyperBEAM - Documentation

Document Number: 28
Source: https://hyperbeam.arweave.net/run/reference/troubleshooting.html
Words: 330
Quality Score: 0.418
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Node Operator Troubleshooting Guide This guide addresses common issues you might encounter when installing and running a HyperBEAM node.Installation Issues Erlang Installation Fails Symptoms: Errors during Erlang compilation or installation Solutions:Ensure all required dependencies are installed: sudo apt-get install -y libssl-dev ncurses-dev make cmake gcc g++ Try configuring with fewer options: ./configure --without-wx --without-debugger --without-observer --without-et Check disk space, as compilation requires several GB of free space Rebar3 Bootstrap Fails Symptoms: Errors when running ./bootstrap for Rebar3 Solutions:Verify Erlang is correctly installed: erl -eval 'erlang:dis(erlang:system_info(otp_release)), halt().' Ensure you have the latest version of the repository: git fetch && git reset --hard origin/master Try manually downloading a precompiled Rebar3 binary HyperBEAM Issues HyperBEAM Won't Start Symptoms: Errors when running rebar3 shell or the HyperBEAM startup command Solutions:Check for port conflicts: Another service might be using the configured port Verify the wallet key file exists and is accessible Examine Erlang crash dumps for detailed error information Ensure all required dependencies are installed HyperBEAM Crashes During Operation Symptoms: Unexpected termination of the HyperBEAM process Solutions:Check system resources (memory, disk space) Examine Erlang crash dumps for details Reduce memory limits if the system is resource-constrained Check for network connectivity issues if connecting to external services Compute Unit Issues Compute Unit Won't Start Symptoms: Errors when running npm start in the CU directory Solutions:Verify Node.js is installed correctly: node -v Ensure all dependencies are installed: npm i Check that the wallet file exists and is correctly formatted Verify the .env file has all required settings Integration Issues HyperBEAM Can't Connect to Compute Unit Symptoms: Connection errors in HyperBEAM logs when trying to reach the CU Solutions:Verify the CU is running: curl http://localhost:6363 Ensure there are no firewall rules blocking the connection Verify network configuration if components are on different machines Getting Help If you're still experiencing issues after trying these troubleshooting steps:Check the GitHub repository for known issues Join the Discord community for support Open an issue on GitHub with detailed information about your problem

---

# 29. Troubleshooting - HyperBEAM - Documentation

Document Number: 29
Source: https://hyperbeam.arweave.net/build/reference/troubleshooting.html
Words: 146
Quality Score: 0.385
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Developer Troubleshooting Guide This guide addresses common issues you might encounter when developing processes for HyperBEAM.Process Execution Fails Symptoms: Errors when deploying or executing processes Solutions:Check both HyperBEAM and CU logs for specific error messages Verify that the WASM module is correctly compiled and valid Test with a simple example process to isolate the issue Adjust memory limits if the process requires more resources Memory Errors in Compute Unit Symptoms: Out of memory errors or excessive memory usage during process execution Solutions:Adjust the PROCESS_WASM_MEMORY_MAX_LIMIT environment variable Enable garbage collection by setting an appropriate GC_INTERVAL_MS Monitor memory usage and adjust limits as needed If on a low-memory system, reduce concurrent process execution Getting Help If you're still experiencing issues after trying these troubleshooting steps:Check the GitHub repository for known issues Join the Discord community for support Open an issue on GitHub with detailed information about your problem
