# Permaweb Documentation Collection

Generated on: 2025-09-11T12:16:27.656Z
Total documents: 62
Total words: 27974

## Table of Contents

### Included Documents

1. [Github Action](https://cookbook.arweave.net/tooling/deployment/github-action.html)
2. [HyperBEAM Introduction](https://cookbook.arweave.net/fundamentals/decentralized-computing/hyperbeam/hyperbeam-introduction.html)
3. [Exposing Process State to HyperBEAM](https://cookbook.arweave.net/fundamentals/decentralized-computing/hyperbeam/getting-ao-state.html)
4. [HyperBEAM Devices](https://cookbook.arweave.net/fundamentals/decentralized-computing/hyperbeam/hyperbeam-devices.html)
5. [Lua Serverless Functions](https://cookbook.arweave.net/fundamentals/decentralized-computing/hyperbeam/lua-serverless.html)
6. [Hello World (Code)](https://cookbook.arweave.net/getting-started/quick-starts/hw-code.html)
7. [What are AO Processes](https://cookbook.arweave.net/fundamentals/decentralized-computing/ao-processes/what-are-ao-processes.html)
8. [SvelteVite Starter Kit](https://cookbook.arweave.net/kits/svelte/vite.html)
9. [Hello World (CLI)](https://cookbook.arweave.net/getting-started/quick-starts/hw-cli.html)
10. [Minimal Svelte Starter Kit](https://cookbook.arweave.net/kits/svelte/minimal.html)
11. [Data Model](https://cookbook.arweave.net/tooling/specs/arfs/data-model.html)
12. [React Starter Kit wvite ArDrive](https://cookbook.arweave.net/kits/react/turbo.html)
13. [Permaweb Deploy](https://cookbook.arweave.net/tooling/deployment/permaweb-deploy.html)
14. [ANS-109 Vouch-For (Assertion of Identity)](https://cookbook.arweave.net/tooling/specs/ans/ANS-109.html)
15. [GraphQL Queries](https://cookbook.arweave.net/fundamentals/accessing-arweave-data/graphql.html)
16. [Create React App Starter Kit](https://cookbook.arweave.net/kits/react/create-react-app.html)
17. [Create Vue Starter Kit](https://cookbook.arweave.net/kits/vue/create-vue.html)
18. [Posting Transactions](https://cookbook.arweave.net/fundamentals/transactions/post-transactions.html)
19. [ar-gql](https://cookbook.arweave.net/tooling/graphql/ar-gql.html)
20. [Svelte Starter Kits](https://cookbook.arweave.net/kits/svelte/index.html)
21. [Transaction Metadata (Tags)](https://cookbook.arweave.net/fundamentals/transactions/tags.html)
22. [Vue Starter Kits](https://cookbook.arweave.net/kits/vue/index.html)
23. [ANS-103 Succinct Proofs of Random Access](https://cookbook.arweave.net/tooling/specs/ans/ANS-103.html)
24. [ANS-106 Do-Not-Store Request](https://cookbook.arweave.net/tooling/specs/ans/ANS-106.html)
25. [ANS-110 Asset Discoverability](https://cookbook.arweave.net/tooling/specs/ans/ANS-110.html)
26. [Querying Arweave with GraphQL](https://cookbook.arweave.net/tooling/querying-arweave.html)
27. [React Starter Kits](https://cookbook.arweave.net/kits/react/index.html)
28. [arkb](https://cookbook.arweave.net/tooling/deployment/arkb.html)
29. [Entity Types](https://cookbook.arweave.net/tooling/specs/arfs/entity-types.html)
30. [Accessing Arweave Data](https://cookbook.arweave.net/fundamentals/accessing-arweave-data/index.html)
31. [Community](https://cookbook.arweave.net/community/index.html)
32. [Cooking with the Permaweb](https://cookbook.arweave.net/index.html)
33. [ArNS - Arweave Name System](https://cookbook.arweave.net/fundamentals/accessing-arweave-data/arns.html)
34. [ANS-105 License Tags](https://cookbook.arweave.net/tooling/specs/ans/ANS-105.html)
35. [Gateways in the Arweave Network](https://cookbook.arweave.net/fundamentals/accessing-arweave-data/gateways.html)
36. [Creating A Wallet](https://cookbook.arweave.net/fundamentals/wallets-and-keyfiles/creating-a-wallet.html)
37. [Index](https://cookbook.arweave.net/getting-started/index.html)
38. [Privacy](https://cookbook.arweave.net/tooling/specs/arfs/privacy.html)
39. [ANS-102 Bundled Data - JSON Serialization](https://cookbook.arweave.net/tooling/specs/ans/ANS-102.html)
40. [Developing on the Permaweb](https://cookbook.arweave.net/getting-started/welcome.html)
41. [Wallets and Keys](https://cookbook.arweave.net/fundamentals/wallets-and-keyfiles/index.html)
42. [Path Manifests](https://cookbook.arweave.net/fundamentals/accessing-arweave-data/manifests.html)
43. [ANS-101 Gateway Capabilities Endpoint](https://cookbook.arweave.net/tooling/specs/ans/ANS-101.html)
44. [ANS-104 Bundled Data v20 - Binary Serialization](https://cookbook.arweave.net/tooling/specs/ans/ANS-104.html)
45. [References](https://cookbook.arweave.net/references/index.html)
46. [ArFS Protocol A Decentralized File System on Arweave](https://cookbook.arweave.net/tooling/specs/arfs/arfs.html)
47. [Contributing Workflow](https://cookbook.arweave.net/getting-started/contributing.html)
48. [GraphQL Tools](https://cookbook.arweave.net/tooling/graphql/index.html)
49. [Decentralized Computing](https://cookbook.arweave.net/fundamentals/decentralized-computing/index.html)
50. [Content Types](https://cookbook.arweave.net/tooling/specs/arfs/content-types.html)
51. [Guides](https://cookbook.arweave.net/guides/index.html)
52. [Hello World (No Code)](https://cookbook.arweave.net/getting-started/quick-starts/hw-no-code.html)
53. [Transactions](https://cookbook.arweave.net/fundamentals/transactions/transaction-types.html)
54. [Schema Diagrams](https://cookbook.arweave.net/tooling/specs/arfs/schema-diagrams.html)
55. [LLMstxt](https://cookbook.arweave.net/references/llms-txt.html)
56. [Bundling Services](https://cookbook.arweave.net/tooling/bundlers.html)
57. [Transaction Bundles](https://cookbook.arweave.net/fundamentals/transactions/bundles.html)
58. [Deployment Publishing Tools](https://cookbook.arweave.net/tooling/deployment.html)
59. [Goldsky Search GraphQL Gateway](https://cookbook.arweave.net/tooling/graphql/search-indexing-service.html)
60. [Tooling](https://cookbook.arweave.net/tooling/index.html)
61. [Core Concepts](https://cookbook.arweave.net/fundamentals/index.html)
62. [Glossary](https://cookbook.arweave.net/references/glossary.html)

---

# 1. Github Action  Cooking with the Permaweb

Document Number: 1
Source: https://cookbook.arweave.net/tooling/deployment/github-action.html
Words: 618
Quality Score: 0.745
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Github Action WARNING This guide is for educational purposes only, and you should use to learn options of how you might want to deploy your application. In this guide, we are trusting a 3rd party resource github owned by microsoft to protect our secret information, in their documentation they encrypt secrets in their store using libsodium sealed box, you can find more information about their security practices here. https://docs.github.com/en/actions/security-guides/encrypted-secrets Github Actions are CI/CD pipelines that allows developers to trigger automated tasks via events generated from the github workflow system. These tasks can be just about anything, in this guide we will show how you can use github actions to deploy your permaweb application to the permaweb using permaweb-deploy and ArNS.TIP This guide requires understanding of github actions, and you must have some Turbo Credits and an ArNS name. Go to https://ar.io/arns/ for more details on acquiring an ArNS name.WARNING This guide does not include testing or any other checks you may want to add to your production workflow.Prerequisites Before setting up GitHub Actions deployment, you'll need:An Arweave wallet with sufficient Turbo Credits for deployment An ArNS name that you own A built application (e.g., in a ./dist folder) Install permaweb-deploy Add permaweb-deploy as a development dependency to your project:npm install --save-dev permaweb-deploy Configure Deployment Script Add a deployment script to your package.json that builds your application and deploys it using permaweb-deploy:{
"scripts": {
"dev": "vuepress dev src",
"build": "vuepress build src",
"deploy": "npm run build && permaweb-deploy --arns-name YOUR_ARNS_NAME"
}
} Replace YOUR_ARNS_NAME with your actual ArNS name (e.g., my-app).Advanced Configuration You can customize the deployment with additional options:{
"scripts": {
"deploy": "npm run build && permaweb-deploy --arns-name my-app --deploy-folder ./dist --undername @"
}
} Available options:--arns-name (required): Your ArNS name --deploy-folder: Folder to deploy (default: ./dist) --undername: ANT undername to update (default: @) --ario-process: ARIO process (default: mainnet) Create GitHub Action Create a .github/workflows/deploy.yml file in your repository:name: Deploy to Permaweb
on:
push:
branches:
- "main"
jobs:
deploy:
runs-on: ubuntu-latest
steps:
- uses: actions/checkout@v4
- uses: actions/setup-node@v4
with:
node-version: 20.x
- run: npm install
- run: npm run deploy
env:
DEPLOY_KEY: ${{ secrets.DEPLOY_KEY }} Setup GitHub Secrets 1. Prepare Your Wallet First, encode your Arweave wallet as base64:base64 -i wallet.json Copy the output (it will be a long base64 string).2. Add Secret to GitHub Go to your repository on GitHub Navigate to Settings → Secrets and variables → Actions Click New repository secret Name: DEPLOY_KEY Value: Paste the base64 encoded wallet string Click Add secret Fund Your Wallet Ensure your deployment wallet has sufficient Turbo Credits. You can fund it using:# Check current balance
npx @ardrive/turbo-cli balance --wallet-file wallet.json
# Add credits (amount in Winston - 1 AR = 1,000,000,000,000 Winston)
npx @ardrive/turbo-cli top-up --value 500000000000 --wallet-file wallet.json Security Best Practices Use a dedicated wallet solely for deployments Keep minimal funds in the deployment wallet Never commit wallet files to your repository Regularly rotate deployment keys Test Your Deployment Local Testing Test your deployment locally before pushing:DEPLOY_KEY=$(base64 -i wallet.json) npm run deploy Verify Deployment After a successful GitHub Action run:Check the action logs for the deployment transaction ID Wait 10-20 minutes for ArNS propagation Visit your ArNS name: https://YOUR_ARNS_NAME.arweave.net Troubleshooting Common Issues:Insufficient Credits: Ensure your wallet has enough Turbo Credits ArNS Propagation: Wait 10-20 minutes after deployment for changes to appear Build Failures: Ensure your build command works locally first Secret Issues: Verify the DEPLOY_KEY secret is properly set and base64 encoded Check Deployment Status:Monitor your deployments through:GitHub Actions logs ArNS resolver: https://arns.arweave.net/resolve/YOUR_ARNS_NAME 🎉 You now have automated permaweb deployment with GitHub Actions!Your application will automatically deploy to the permaweb whenever you push to the main branch, and your ArNS name will point to the latest version.

---

# 2. HyperBEAM Introduction  Cooking with the Permaweb

Document Number: 2
Source: https://cookbook.arweave.net/fundamentals/decentralized-computing/hyperbeam/hyperbeam-introduction.html
Words: 1473
Quality Score: 0.709
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

HyperBEAM Introduction HyperBEAM is the primary, production-ready implementation of the AO-Core protocol, built on the robust Erlang/OTP framework. It serves as a decentralized operating system, powering the AO Computer—a scalable, trust-minimized, distributed supercomputer built on the permanent storage of Arweave.For the most current technical specifications and implementation details, refer to the official HyperBEAM documentation.What is HyperBEAM?Think of HyperBEAM as your "Swiss Army knife" for decentralized development. It's not a single-purpose application, but rather a powerful, extensible engine that transforms the abstract concepts of AO-Core into a concrete, operational system.HyperBEAM provides the runtime environment and essential services to execute computations across a network of distributed nodes, making the AO Computer accessible through familiar web technologies like HTTP.HyperBEAM serves as the bridge between standard HTTP interfaces and the AO Computer, managing message routing, device execution, state queries, and cryptographic verification.Core AO-Core Concepts in HyperBEAM HyperBEAM implements the three fundamental components of AO-Core:Messages: Modular Data Packets In HyperBEAM, every interaction within the AO Computer is handled as a message. Messages are cryptographically-linked data units that form the foundation for communication, allowing processes to trigger computations, query state, and transfer value.// Example message structure in HyperBEAM
const message = {
Id: "MESSAGE_TX_ID",
Process: "TARGET_PROCESS_ID",
Owner: "SENDER_ADDRESS",
Data: "Hello, AO Computer!",
Tags: [
{ name: "Action", value: "Greet" },
{ name: "Device", value: "~lua@5.3a" }
]
};HyperBEAM nodes are responsible for routing and processing these messages according to the rules of the AO-Core protocol, ensuring reliable delivery and execution.Devices: Extensible Execution Engines HyperBEAM introduces a uniquely modular architecture centered around Devices. These pluggable components are Erlang modules that define specific computational logic—like running WASM, managing state, or relaying data—allowing for unprecedented flexibility.Common HyperBEAM Devices:~process@1.0: Manages persistent, shared computational states (like smart contracts) ~lua@5.3a: Executes Lua scripts for serverless functions ~wasm64@1.0: Executes WebAssembly code for high-performance computing ~json@1.0: Provides JSON data structure manipulation ~relay@1.0: Forwards messages between nodes or external HTTP endpoints ~scheduler@1.0: Handles message ordering and execution timing For a complete list of devices and their latest specifications, see the HyperBEAM Devices documentation.# Using the Lua device to execute a calculation
GET /~lua@5.3a&script=return 2 + 2/result
# Response: 4
# Using the process device to query state
GET /PROCESS_ID~process@1.0/now/balance
# Response: Current process balance Paths: Composable Pipelines HyperBEAM exposes a powerful HTTP API that uses structured URL patterns to interact with processes and data. This pathing mechanism allows developers to create verifiable data pipelines, composing functionality from multiple devices into a single, atomic request.The URL bar becomes a command-line interface for AO's trustless compute environment.# Complex pipeline example: Calculate token supply and format as JSON
GET /TOKEN_PROCESS~process@1.0/now/cache/~lua@5.3a&module=CALC_MODULE/sum/serialize~json@1.0
# This path:
# 1. Reads latest state of TOKEN_PROCESS on the cache variable
# 2. Pipes state to Lua script
# 3. Calls 'sum' function to calculate total supply
# 4. Formats result as JSON Four Key Principles of HyperBEAM Building with HyperBEAM can be simplified to four core principles:1. Everything is a Message You can compute on any message by calling its keys by name. The device specified in the message determines how these keys are resolved.# Direct message access
GET /~message@1.0&greeting="Hello"&count+integer=42/count
# Response: 42
# Process message
GET /PROCESS_ID~process@1.0/compute/userCount
# Response: Number of users in the process 2. Paths are Pipelines of Messages A path defines a sequence of 'request' messages to be executed. You can set a key in a message directly within the path using the &key=value syntax.# Pipeline: Get process data → Transform with Lua → Format as JSON
GET /PROCESS~process@1.0/now/~lua@5.3a&script=transform_data/result~json@1.0 3. Device-Specific Requests with ~x@y The ~device@version syntax allows you to apply a request as if the base message had a different device, providing powerful compute and storage logic.# Execute Lua on process state
GET /PROCESS~process@1.0/now/~lua@5.3a&func=calculateMetrics/metrics
# Execute WASM for high-performance computing
GET /DATA~message@1.0/~wasm64@1.0&module=WASM_MODULE/compute 4. Signed Responses over HTTP The final message in a pipeline is returned as an HTTP response. This response is signed against the hashpath that generated it, ensuring integrity and verifiability of the computation.# Every response includes cryptographic proof
HTTP/1.1 200 OK
X-HyperBEAM-Signature: 0x123abc...
X-HyperBEAM-HashPath: path_to_computation_verification
Content-Type: application/json
{"result": 42, "verified": true} HyperBEAM Architecture Built on Erlang/OTP Framework HyperBEAM leverages the battle-tested Erlang/OTP platform, providing:Exceptional Concurrency Handle millions of lightweight processes simultaneously Actor model naturally maps to AO processes Message passing between isolated processes Fault Tolerance "Let it crash" philosophy with supervised restarts System continues operating even if individual components fail Automatic recovery and error isolation Hot Code Swapping Update running code without ping the system Zero-downtime deployments and upgrades Live system maintenance and improvements Distributed Systems Built-in clustering and node discovery Network partitioning tolerance Transparent inter-node communication %% Example of HyperBEAM device implementation
-module(my_custom_device).
-export([handle_message/2]).
handle_message(Message, State) ->
case maps:get(<<"action">>, Message, null) of
<<"calculate">> ->
Result = perform_calculation(Message),
{ok, Result, State};
_ ->
{error, unknown_action, State}
end.Hardware Abstraction HyperBEAM abstracts away underlying hardware differences, allowing diverse nodes to contribute resources without compatibility issues. Whether running on:Consumer laptops Enterprise servers Cloud instances Edge devices Specialized hardware (GPUs, TPUs) All nodes can participate in the AO Computer through the common HyperBEAM interface.Use Cases and Applications Serverless Computing with Trustless Guarantees Replace traditional cloud functions with permanently available, cryptographically verifiable compute:// Traditional serverless function
exports.handler = async (event) => {
return { statusCode: 200, body: "Hello World" };
};
// HyperBEAM equivalent - permanently available on AO
// Accessible via: /PROCESS~process@1.0/hello
Handlers.add(
"hello",
function() { return true; },
function(msg) {
ao.send({
Target = msg.From,
Data = "Hello from the permanent web!"
})
}
) Hybrid Smart Contract + Serverless Applications Combine persistent state management with on-demand compute:# Smart contract state management
GET /TOKEN_CONTRACT~process@1.0/now/balance
# + Serverless data processing
GET /DATA_PROCESSOR~lua@5.3a&module=ANALYTICS/process/result
# + External API integration
GET /~relay@1.0/call?method=GET&path=https://api.external.com/data Custom Execution Environments Build specialized computational environments through custom devices:AI/ML Inference: Custom devices for model serving and GPU acceleration Scientific Computing: Devices for mathematical libraries and simulations Cryptographic Applications: Specialized devices for zero-knowledge proofs Cross-chain Bridges: Devices for interacting with other blockchain networks Composable Data Pipelines Create complex, verifiable data processing workflows:# Data pipeline: Fetch → Validate → Transform → Store → Notify
GET /DATA_SOURCE/fetch/
~validator@1.0&schema=SCHEMA/validate/
~transformer@1.0&rules=RULES/transform/
~storage@1.0&destination=DEST/store/
~notifier@1.0&webhook=WEBHOOK/notify Getting Started with HyperBEAM Accessing HyperBEAM Nodes HyperBEAM nodes are accessible via HTTP. You can use any node while maintaining trustless guarantees:// Example HyperBEAM node URLs (verify node availability before use)
// Note: Node availability can change. Always verify endpoints are operational.
const EXAMPLE_NODES = [
'https://forward.computer', // Community HyperBEAM node
// Additional nodes can be found in the AO ecosystem
// Use official node directories for current endpoints
];
// Example: Query process state from a HyperBEAM node
const processId = 'YOUR_PROCESS_ID';
const nodeUrl = 'YOUR_HYPERBEAM_NODE_URL'; // Replace with verified node URL
const response = await fetch(`${nodeUrl}/${processId}~process@1.0/now`);
const state = await response.json();Basic Operations Query Process State:GET /PROCESS_ID~process@1.0/compute
# Returns the latest known state (faster)
GET /PROCESS_ID~process@1.0/now
# Returns real-time state (slower, more accurate) Execute Lua Code:GET /~lua@5.3a&script=return os.time()/result
# Returns current timestamp Send Messages to Processes:import { connect, createDataItemSigner } from "@permaweb/aoconnect";
const ao = connect({
MU_URL: "YOUR_HYPERBEAM_NODE_URL" // Replace with verified HyperBEAM node
});
await ao.message({
process: "PROCESS_ID",
tags: [
{ name: "Action", value: "Transfer" },
{ name: "Recipient", value: "RECIPIENT_ADDRESS" },
{ name: "Quantity", value: "100" }
],
signer: createDataItemSigner(wallet)
});Security and Trust Model Cryptographic Verification Every HyperBEAM response includes cryptographic proofs:Signatures: All responses signed by the executing node HashPaths: Verifiable computation trails State Hashes: Merkle proofs of state integrity Message IDs: Tamper-evident message identification Trusted Execution Environments (TEEs) Many HyperBEAM nodes run in TEEs for additional security:# Verify node is running in genuine TEE
GET /~snp@1.0/attestation
# Returns cryptographic attestation report Decentralized Trust No single point of failure or control:Computation can be verified independently Multiple nodes can execute the same request Consensus mechanisms for critical operations Open network - anyone can run a node Performance Characteristics Concurrency Millions of concurrent processes per node Lightweight message passing between processes Non-blocking I/O for network operations Parallel device execution for complex pipelines Scalability Horizontal scaling through additional nodes Load balancing across node network Caching layers for frequently accessed data Eventual consistency model for global state Efficiency Compiled code execution via BEAM VM Memory management with garbage collection Hot code reloading for zero-downtime updates Optimized message serialization for network transport Network Effects As more nodes join the HyperBEAM network:Increased Resilience: More redundancy and fault tolerance Better Performance: Load distribution and edge computing Enhanced Security: More verification nodes and cryptographic diversity Expanded Capabilities: New devices and specialized services Lower Costs: Competition drives down execution costs Explore HyperBEAM's capabilities in detail:Learn Querying: Querying AO Process State Build Serverless Functions: Lua Serverless Functions Understand Devices: HyperBEAM Devices Start Building: Builder's Journey Resources HyperBEAM Official Documentation: HyperBEAM Docs AO Cookbook: AO Documentation HyperBEAM Migration Guide: Migration from AO Connect Note: Node endpoints and availability may change over time. Always verify node status and select reliable endpoints for production use. Consider running your own HyperBEAM node for maximum reliability and control.

---

# 3. Exposing Process State to HyperBEAM  Cooking with the Permaweb

Document Number: 3
Source: https://cookbook.arweave.net/fundamentals/decentralized-computing/hyperbeam/getting-ao-state.html
Words: 447
Quality Score: 0.692
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Exposing Process State to HyperBEAM HyperBEAM introduces a powerful feature for exposing parts of a process's state for immediate reading over HTTP. This improves performance for web frontends and data services by replacing the need for dryrun calls.The Patch Device The ~patch@1.0 device is the mechanism that allows AO processes to make parts of their internal state readable via direct HTTP GET requests.How it Works Exposing state is a four-step process:Process Logic: Send an outbound message to the ~patch@1.0 device from your process.Patch Message Format: The message must include device and cache tags.Send({ Target = ao.id, device = 'patch@1.0', cache = { mydatakey = MyValue } }) HyperBEAM Execution: HyperBEAM's dev_patch module processes this message, mapping the key-value pairs from the cache table to a URL path.HTTP Access: The exposed data is then immediately available via a standard HTTP GET request:GET /~process@1.0/now/cache/ Initial State Sync (Optional) To make data available immediately on process creation:-- Place this logic at the top level of your process script
Balances = { token1 = 100, token2 = 200 } -- A table of balances
TotalSupply = 1984 -- A single total supply value
-- 1. Initialize Flag:
InitialSync = InitialSync or 'INCOMPLETE'
-- 2. Check Flag:
if InitialSync == 'INCOMPLETE' then
-- 3. Patch State:
Send({ device = 'patch@1.0', cache = { balances = Balances, totalsupply = TotalSupply } })

-- 4. Update Flag:
InitialSync = 'COMPLETE'
end Practical Example Here's a complete example of a token contract that exposes its balance state:-- Token Process with State Exposure
Balances = Balances or { [ao.id] = 1000000 }
TotalSupply = TotalSupply or 1000000
-- Initial state sync
InitialSync = InitialSync or 'INCOMPLETE'
if InitialSync == 'INCOMPLETE' then
Send({ device = 'patch@1.0', cache = {
balances = Balances,
totalsupply = TotalSupply
}})
InitialSync = 'COMPLETE'
end
-- Transfer handler
Handlers.add("transfer", "Transfer", function(msg)
local from = msg.From
local to = msg.Tags.Recipient or msg.Recipient
local amount = tonumber(msg.Tags.Quantity or msg.Quantity)

if Balances[from] and Balances[from] >= amount then
Balances[from] = Balances[from] - amount
Balances[to] = (Balances[to] or 0) + amount

-- Update exposed state after transfer
Send({ device = 'patch@1.0', cache = {
balances = Balances
}})

ao.send({ Target = from, Data = "Transfer successful" })
else
ao.send({ Target = from, Data = "Insufficient balance" })
end
end) Accessing Exposed Data Once state is exposed via the patch device, you can query it directly over HTTP:# Get all balances
curl https://hyperbeam-node.arweave.net/~process@1.0/compute/cache/balances
# Get total supply
curl https://hyperbeam-node.arweave.net/~process@1.0/compute/cache/totalsupply Benefits Performance: Direct HTTP access is significantly faster than traditional dryrun calls.Simplicity: Standard REST-like patterns instead of complex message handling.Real-time Updates: State changes are immediately reflected in HTTP responses.Caching: HyperBEAM can cache frequently accessed data for even better performance.

---

# 4. HyperBEAM Devices  Cooking with the Permaweb

Document Number: 4
Source: https://cookbook.arweave.net/fundamentals/decentralized-computing/hyperbeam/hyperbeam-devices.html
Words: 1713
Quality Score: 0.691
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

HyperBEAM Devices HyperBEAM devices are the modular building blocks that power the AO Computer. Think of them as specialized engines or services that can be plugged into the AO framework to provide specific computational capabilities. This modularity is key to AO's flexibility, extensibility, and ability to evolve with new technologies.Understanding the Device Architecture What Are Devices?In AO-Core and HyperBEAM, Devices are modular components responsible for processing and interpreting Messages. They define the specific logic for how computations are performed, data is handled, or interactions occur within the AO ecosystem.Each device is essentially an Erlang module that implements a specific interface, allowing it to:Define computation logic - Dictate how message instructions are executed Enable specialization - Allow nodes to focus on specific computational tasks Promote modularity - Add new functionality without altering the core protocol Distribute workload - Handle different parts of complex tasks in parallel HyperBEAM Device Architecture:HTTP Request
↓
HyperBEAM Router
↓
Device Selection
↓
┌─────────────────────────────────────────┐
│ Device Types: │
│ • ~process@1.0 → Process State Mgmt │
│ • ~lua@5.3a → Lua Script Execution │
│ • ~wasm64@1.0 → WebAssembly Execution│
│ • ~json@1.0 → JSON Processing │
└─────────────────────────────────────────┘
↓
Processing Results
↓
HTTP Response
Device Ecosystem:
┌─────────────────────────────────────────┐
│ • Security Devices (authentication) │
│ • Utility Devices (routing, caching) │
│ • Custom Devices (domain-specific) │
│ • Communication Devices (relays) │
│ • Storage Devices (state management) │
└─────────────────────────────────────────┘ This modular architecture allows HyperBEAM to handle diverse computational tasks by routing requests to specialized devices, each optimized for specific types of processing.Device Naming and Versioning Devices follow a consistent naming convention that makes them easy to identify and use:Format:~name@version or dev_name (for internal devices) Examples:~process@1.0 - Primary process management device ~lua@5.3a - Lua 5.3 execution device ~wasm64@1.0 - WebAssembly 64-bit execution device dev_router - Internal routing device (development prefix) The tilde (~) indicates a primary, user-facing device, while the dev_ prefix is used for internal or utility devices in the source code.Versioning Strategy Versioning indicates the specific interface and behavior of the device:Semantic versioning - Major.minor.patch format Backward compatibility - Breaking changes increment major version Feature additions - New features increment minor version Bug fixes - Patches increment patch version Core HyperBEAM Devices Process Management Devices ~process@1.0 - Process State Manager The process device manages persistent, shared computational states similar to traditional smart contracts, but with greater flexibility.# Access current process state
GET /PROCESS_ID~process@1.0/now
# Get cached state (faster)
GET /PROCESS_ID~process@1.0/compute
# Access specific state fields
GET /PROCESS_ID~process@1.0/now/balance
GET /PROCESS_ID~process@1.0/compute/users/USER_ADDRESS Key Functions:now - Calculates real-time process state by processing all messages compute - Returns the latest known state without checking for new messages State persistence - Automatic state snapshots to Arweave Message ordering - Ensures deterministic state transitions Use Cases:Token contracts and DeFi applications Voting and governance systems Game state management Decentralized databases ~scheduler@1.0 - Message Scheduling Handles the ordering and execution timing of messages within processes.# Query scheduler status
GET /PROCESS_ID~scheduler@1.0/status
# Get message queue information
GET /PROCESS_ID~scheduler@1.0/queue/pending Responsibilities:Message ordering and consensus Execution timing coordination Load balancing across compute units Fault tolerance and recovery Execution Devices ~lua@5.3a - Lua Script Execution Executes Lua scripts for serverless functions and data processing.# Simple calculation
GET /~lua@5.3a&script=return 2 + 3 * 4/result
# With parameters
GET /~lua@5.3a&script=return Args.name .. " is " .. Args.age .. " years old"&name="Alice"&age+integer=25/result
# Using modules
GET /~lua@5.3a&module=MODULE_TX_ID&script=return math_utils.factorial(Args.n)&n+integer=5/result Capabilities:Full Lua 5.3 language support Module loading from Arweave transactions JSON processing and manipulation String processing and regex Mathematical computations HTTP client functionality (via libraries) Performance Characteristics:Lightweight execution overhead Fast startup time (no cold starts) Memory efficient for small to medium computations Excellent for data transformation and business logic ~wasm64@1.0 - WebAssembly Execution Executes WebAssembly code for high-performance computations written in languages like Rust, C++, Go, and others.# Execute WASM module
GET /~wasm64@1.0&module=WASM_MODULE_TX_ID/function_name
# With parameters
GET /~wasm64@1.0&module=WASM_MODULE_TX_ID&arg1+integer=100&arg2="test"/compute Advantages:High performance - Near-native execution speed Multiple languages - Support for Rust, C++, Go, AssemblyScript Sandboxed execution - Secure isolated environment Predictable performance - No garbage collection s Use Cases:Cryptographic operations (hashing, signatures, ZK proofs) Image and video processing Machine learning inference Scientific computing Game engines and simulations Example WASM Module (Rust):// Compile to WASM and deploy to Arweave
use wasm_bindgen::prelude::*;
#[wasm_bindgen]
pub fn fibonacci(n: u32) -> u32 {
match n {
0 | 1 => n,
_ => fibonacci(n - 1) + fibonacci(n - 2),
}
}
#[wasm_bindgen]
pub fn hash_data(data: &str) -> String {
use sha2::{Sha256, Digest};
let mut hasher = Sha256::new();
hasher.update(data);
format!("{:x}", hasher.finalize())
} Data Processing Devices ~json@1.0 - JSON Manipulation Provides JSON data structure access and manipulation capabilities.# Format process state as JSON
GET /PROCESS_ID~process@1.0/now~json@1.0
# Pretty-print JSON
GET /PROCESS_ID~process@1.0/compute~json@1.0&pretty=true
# Extract specific JSON fields
GET /~json@1.0&data={"users":{"alice":{"balance":100}}}/users/alice/balance Features:JSON serialization and deserialization Path-based field access Pretty printing and formatting Schema validation (when configured) Type conversion and casting ~message@1.0 - Message Processing The default device that resolves keys to their literal values within messages.# Create temporary message with data
GET /~message@1.0&greeting="Hello"&count+integer=42/count
# Response: 42
# Complex data structures
GET /~message@1.0&config+map=host="localhost";port+integer=3000&items+list="a","b","c"/config/port
# Response: 3000 Type Casting Support:+integer - Convert to integer +float - Convert to floating point +boolean - Convert to boolean +list - Parse comma-separated values +map - Parse key-value pairs +binary - Treat as binary string (default) Communication Devices ~relay@1.0 - Message Relay Forwards messages between AO nodes or to external HTTP endpoints.# Relay GET request to external API
GET /~relay@1.0/call?method=GET&path=https://api.example.com/data
# Relay POST with data
POST /~relay@1.0/call?method=POST&path=https://webhook.site/your-webhook
Content-Type: application/json
{"message": "Hello from AO"}
# Relay to another AO process
GET /~relay@1.0/process/TARGET_PROCESS_ID?action=GetBalance&user=ALICE Use Cases:Cross-chain bridges - Connect to other blockchain networks External API integration - Fetch data from Web2 services Inter-process communication - Route messages between AO processes Webhook delivery - Send notifications to external services Security and Verification Devices ~snp@1.0 - Secure Enclave Verification Handles Trusted Execution Environment (TEE) attestation and verification.# Get TEE attestation report
GET /~snp@1.0/attestation
# Verify node is running in genuine TEE
GET /~snp@1.0/verify Security Features:AMD SEV-SNP attestation Intel TXT support Hardware security verification Remote attestation protocols Cryptographic proof generation dev_codec_httpsig - HTTP Signature Processing Manages HTTP message signing and verification for authentication.Capabilities:HTTP signature generation and verification Multiple signature algorithms (RSA, ECDSA, EdDSA) Request/response integrity verification Authentication and authorization Utility and System Devices ~meta@1.0 - Node Configuration Configures the HyperBEAM node itself including hardware specs, supported devices, and payment information.# Get node capabilities
GET /~meta@1.0/capabilities
# Get supported devices
GET /~meta@1.0/devices
# Get node status
GET /~meta@1.0/status Configuration Options:Hardware specifications Available compute resources Supported device list Payment and billing information Network connectivity options dev_cron - Task Scheduling Coordinates scheduled task execution and workflow management.Features:Cron-like task scheduling Recurring job management Event-driven automation Workflow orchestration dev_monitor - System Monitoring Monitors process activity, performance metrics, and system health.Monitoring Capabilities:Process execution metrics Resource utilization tracking Error rate monitoring Performance benchmarking Alert generation Financial and Access Control Devices ~p4@1.0 - Payment Processing Manages metering, billing, and micropayments for node services.# Check payment status
GET /~p4@1.0/balance/USER_ADDRESS
# Get pricing information
GET /~p4@1.0/pricing/compute Payment Features:Micropayment processing Usage-based billing Multi-token support Payment channel management Revenue sharing protocols ~faff@1.0 - Access Control Handles authorization and access control for protected resources.Access Control Features:Role-based access control (RBAC) Attribute-based access control (ABAC) Token-based authentication Multi-signature authorization Temporary access grants Data Storage and Management ~patch@1.0 - State Management Applies state updates directly to processes, often used for data migration and management.# Apply state patch to process
POST /PROCESS_ID~patch@1.0/apply
Content-Type: application/json
{
"operation": "update",
"path": "/users/alice/balance",
"value": 1500
}
# Get patch history
GET /PROCESS_ID~patch@1.0/history Patch Operations:State updates and migrations Data consistency maintenance Version control for process state Rollback and recovery operations Advanced Device Concepts Device Composition and Pipelines Devices can be chained together to create sophisticated processing pipelines:# Multi-device pipeline:
# 1. Get process state
# 2. Transform with Lua
# 3. Format as JSON
# 4. Apply template
GET /TOKEN_PROCESS~process@1.0/now/~lua@5.3a&module=ANALYTICS_MODULE/calculateMetrics/~json@1.0/format~template@1.0&type=dashboard Device Specialization Nodes can choose which devices to support, allowing for specialization:Compute-Optimized Nodes:Focus on ~wasm64@1.0 and ~lua@5.3a devices High-performance processors and memory Optimized for CPU-intensive workloads Storage-Optimized Nodes:Specialize in ~process@1.0 and ~patch@1.0 devices Large storage capacity and fast I/O Optimized for state management and data persistence Security-Focused Nodes:Run ~snp@1.0 and security-related devices Hardware security modules (HSMs) Trusted Execution Environments (TEEs) Custom Device Development While HyperBEAM comes with a comprehensive set of built-in devices, you can create custom devices in Erlang to extend functionality for specialized use cases. This is an advanced topic that allows you to build domain-specific functionality tailored to your exact needs.For detailed guidance on building custom devices, see the HyperBEAM Device Development Guide.Device Discovery and Routing HyperBEAM automatically routes requests to the appropriate devices based on the URL path. You can discover available devices on any node:# List all available devices
GET /~meta@1.0/devices
# Get information about a specific device
GET /~meta@1.0/device/~lua@5.3a Devices are automatically load-balanced across available instances, with HyperBEAM handling routing optimization internally.Performance Considerations Different devices have varying performance characteristics:~lua@5.3a - Fast startup, low resource usage, ideal for simple logic ~wasm64@1.0 - Higher performance for complex computations ~process@1.0 - Use /compute for cached state, /now for real-time updates ~json@1.0 - Very lightweight for data serialization Optimization Tips:Use device pipelines to chain operations in a single request Cache frequently accessed data at the application level Choose the right device for your workload (Lua for simple logic, WASM for computation) Extensible Device Ecosystem The modular nature of HyperBEAM devices enables endless possibilities for expansion. The community and ecosystem are continuously developing new devices for:Specialized Hardware - GPU computing, AI/ML acceleration, quantum computing Domain-Specific Logic - DeFi protocols, scientific computing, media processing Cross-Chain Integration - Bridges to other blockchain networks Industry Solutions - Custom devices for specific business needs This extensibility ensures HyperBEAM can adapt to new technologies and use cases without requiring changes to the core protocol.Security Considerations HyperBEAM devices run in isolated environments with built-in security features:Sandboxing - Each device operates in its own isolated environment Resource Limits - Automatic memory and execution time constraints Verification - Device signatures and integrity checking Access Control - Permission-based device access Best Practices:Always specify device versions (e.g., ~lua@5.3a not just ~lua) Validate inputs when building applications that use devices Use TEE-enabled nodes (~snp@1.0) for sensitive computations Explore the broader HyperBEAM ecosystem:Build Custom Devices: Device Development Guide Lua Programming: Lua Serverless Functions Process Integration: AO Process Development Production Deployment: Builder's Journey Resources HyperBEAM Device Documentation: Official Device Docs Erlang/OTP Documentation: Erlang Reference

---

# 5. Lua Serverless Functions  Cooking with the Permaweb

Document Number: 5
Source: https://cookbook.arweave.net/fundamentals/decentralized-computing/hyperbeam/lua-serverless.html
Words: 541
Quality Score: 0.685
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Lua Serverless Functions HyperBEAM's ~lua@5.3a device enables you to run serverless Lua functions with permanent availability, instant execution, and cryptographic verification. Unlike traditional serverless platforms, your functions are deployed permanently to Arweave and executed on the decentralized HyperBEAM network.How HyperBEAM Lua Works HyperBEAM executes Lua functions through HTTP requests using a specific URL structure:https://forward.computer/~lua@5.3a/{function_name}/~json@1.0/serialize?param1=value1&module={ARWEAVE_TX_ID} URL Components:~lua@5.3a - The Lua execution device {function_name} - The function to call from your deployed module ~json@1.0/serialize - Output formatting set to JSON Query parameters - Function arguments with optional type casting module - Arweave transaction ID of your deployed Lua code Function Parameters HyperBEAM calls your Lua functions with three parameters:Example Functions 1. Simple Calculator -- calculator.lua
function add(base, req, opts)
base = base or {}

local a = tonumber(req.a) or 0
local b = tonumber(req.b) or 0

base.a = a
base.b = b
base.result = a + b
base.operation = "addition"

return base
end 2. Text Analysis function analyze_text(base, req, opts)
base = base or {}

local text = req.text or ""
if text == "" then
base.error = "Text parameter required"
return base
end

-- Word count
local word_count = 0
for word in string.gmatch(text, "%S+") do
word_count = word_count + 1
end

-- Character counts
local char_count = string.len(text)
local char_count_no_spaces = string.len(string.gsub(text, "%s", ""))

base.text_length = char_count
base.text_length_no_spaces = char_count_no_spaces
base.word_count = word_count

return base
end 3. Data Processing function process_numbers(base, req, opts)
base = base or {}

local numbers_str = req.numbers or ""
local numbers = {}

-- Parse comma-separated numbers
for num_str in string.gmatch(numbers_str, "[^,]+") do
local num = tonumber(num_str:gsub("^%s*(.-)%s*$", "%1"))
if num then
table.insert(numbers, num)
end
end

if #numbers == 0 then
base.error = "No valid numbers found"
return base
end

-- Calculate basic statistics
local sum = 0
local min_val = numbers[1]
local max_val = numbers[1]

for i, num in ipairs(numbers) do
sum = sum + num
if num < min_val then min_val = num end
if num > max_val then max_val = num end
end

base.count = #numbers
base.sum = sum
base.average = sum / #numbers
base.min = min_val
base.max = max_val
base.numbers = numbers

return base
end Deployment 1. Deploy to Arweave Propagation Delay After deployment, it can take up to 20 minutes for your Lua module to fully propagate across the Arweave network. You may not be able to access it via HyperBEAM until propagation is complete.2. Execute Your Function # Simple addition
curl 'https://forward.computer/~lua@5.3a/add/~json@1.0/serialize?a+integer=10&b+integer=20&module=YOUR_MODULE_ID'
# Text analysis
curl 'https://forward.computer/~lua@5.3a/analyze_text/~json@1.0/serialize?text=Hello%20world%20example&module=YOUR_MODULE_ID'
# Number processing
curl 'https://forward.computer/~lua@5.3a/process_numbers/~json@1.0/serialize?numbers=1,2,3,4,5&module=YOUR_MODULE_ID' Type Casting Parameters Use type casting to convert parameters from strings:Available Type Casts:+integer - Convert to integer +float - Convert to floating point number +boolean - Convert to boolean +list - Convert comma-separated values to array Example:curl 'https://forward.computer/~lua@5.3a/add/~json@1.0/serialize?a+integer=10&b+integer=20&module=YOUR_MODULE_ID' JavaScript Integration async function callLuaFunction(moduleId, functionName, params = {}) {
const queryParams = new URLSearchParams();
queryParams.append('module', moduleId);

for (const [key, value] of Object.entries(params)) {
if (typeof value === 'number') {
queryParams.append(`${key}+${Number.isInteger(value) ? 'integer' : 'float'}`, value.toString());
} else {
queryParams.append(key, value.toString());
}
}

const url = `https://forward.computer/~lua@5.3a/${functionName}/~json@1.0/serialize?${queryParams}`;
const response = await fetch(url);

if (!response.ok) {
throw new Error(`HTTP ${response.status}: ${response.statusText}`);
}

return await response.json();
}
// Usage
const result = await callLuaFunction('YOUR_MODULE_ID', 'add', { a: 10, b: 20 });
console.log(result); // { a: 10, b: 20, result: 30, operation: "addition" }

---

# 6. Hello World (Code)  Cooking with the Permaweb

Document Number: 6
Source: https://cookbook.arweave.net/getting-started/quick-starts/hw-code.html
Words: 300
Quality Score: 0.654
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Hello World (Code) This guide walks you through a quick way to get a static HTML, CSS and JavaScript webpage onto the Permaweb using a few lines of code and a command-line interface (CLI).Requirements NodeJS LTS or greater Basic knowledge of HTML, CSS and JavaScript A text editor (VS Code, Sublime, or similar) Description Using a terminal/console window create a new folder called hello-world.Setup cd hello-world
npm init -y
mkdir src && cd src
touch index.js index.html style.css Next open your text editor and import the hello-world directory.Generate a wallet node -e "require('arweave').init({}).wallets.generate().then(JSON.stringify).then(console.log.bind(console))" > wallet.json The wallet.json file must be in the root of the hello-world folder and not inside of your src folder.Create a webpage This webpage is using basic HTML, CSS and JavaScript to create a styled button that when you click it the header text changes color. Once finished, we will be using permaweb-deploy and our previously generated wallet to deploy a fully functioning, static and permanent webpage to Arweave.Paste the code from the following code blocks into their files:index.html Click to view HTML






Cookbook Hello World!


Click Me!
# Hello World!

style.css Click to view CSS.button {
padding: "10px";
background-color: #4caf50;
} index.js Click to view JS Now that there is a static site to deploy, it can be checked to ensure it all functions properly by typing open src/index.html in your console/terminal. If everything is working as expected it is time to deploy to Arweave!Upload using permaweb-deploy Install and configure permaweb-deploy for deployment:npm install --save-dev permaweb-deploy Add a deployment script to your package.json:{
"scripts": {
"deploy": "permaweb-deploy --arns-name my-hello-world --deploy-folder src"
}
} Deploy your application:DEPLOY_KEY=$(base64 -i wallet.json) npm run deploy For detailed deployment instructions, see Permaweb Deploy.Congrats!!You just published a static site on Arweave using a few commands and a few lines of code!

---

# 7. What are AO Processes  Cooking with the Permaweb

Document Number: 7
Source: https://cookbook.arweave.net/fundamentals/decentralized-computing/ao-processes/what-are-ao-processes.html
Words: 1399
Quality Score: 0.638
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

What are AO Processes AO processes are autonomous compute units that run on the Arweave network, enabling decentralized applications to execute complex logic permanently and trustlessly. Think of them as serverless functions that never go down and can maintain state across invocations.Core Architecture AO processes represent a paradigm shift from traditional smart contracts. Unlike Ethereum's synchronous execution model, AO processes operate asynchronously, communicating through message passing in a distributed network.AO Process Architecture:User/Application
↓ (Message)
AO Process ←→ Another Process
↓ ↑ (Messages)
State Update/Read
↓ ↑
Arweave Storage This architecture demonstrates how AO processes communicate through asynchronous message passing while maintaining persistent state on Arweave. Each process operates independently while being able to interact with other processes in the network.Key Components Process Instance Unique process ID (43-character string) Lua-based execution environment Persistent state storage on Arweave Message inbox for receiving communications Message System Asynchronous message passing Tagged messages for routing and filtering Cryptographic signatures for authentication Permanent message history on Arweave State Management Deterministic state transitions Immutable state snapshots Conflict-free replicated data types (CRDTs) Rollback and re capabilities Process Lifecycle 1. Process Creation Creating an AO process involves deploying Lua code to the network:import { connect } from "@permaweb/aoconnect";
const ao = connect();
// Deploy a new process
const processId = await ao.spawn({
module: "MODULE_TX_ID", // Pre-compiled Lua module
scheduler: "SCHEDULER_ADDRESS", // Network scheduler
signer: createDataItemSigner(wallet), // Wallet signer
tags: [
{ name: "App-Name", value: "MyApp" },
{ name: "App-Version", value: "1.0.0" }
]
});
console.log("Process created:", processId);2. Process Initialization Once spawned, the process can be initialized with initial state:// Send initialization message
await ao.message({
process: processId,
tags: [
{ name: "Action", value: "Initialize" }
],
data: JSON.stringify({
owner: "USER_ADDRESS",
name: "My Process",
version: "1.0.0"
}),
signer: createDataItemSigner(wallet)
});3. Message Processing Processes receive and handle messages according to their Lua handlers:-- Example Lua handler in the process
Handlers.add(
"Initialize",
Handlers.utils.hasMatchingTag("Action", "Initialize"),
function(msg)
local data = json.decode(msg.Data)
State.owner = data.owner
State.name = data.name
State.initialized = true

ao.send({
Target = msg.From,
Data = "Process initialized successfully"
})
end
) State Management Patterns Deterministic State Updates AO processes maintain deterministic state through ordered message processing:-- State variables
Balance = Balance or 0
Transactions = Transactions or {}
-- Handler for balance updates
Handlers.add(
"UpdateBalance",
Handlers.utils.hasMatchingTag("Action", "UpdateBalance"),
function(msg)
local amount = tonumber(msg.Tags.Amount)
local operation = msg.Tags.Operation

if operation == "credit" then
Balance = Balance + amount
elseif operation == "debit" and Balance >= amount then
Balance = Balance - amount
else
ao.send({
Target = msg.From,
Data = "Insufficient balance"
})
return
end

-- Record transaction
table.insert(Transactions, {
id = msg.Id,
from = msg.From,
amount = amount,
operation = operation,
timestamp = msg.Timestamp,
balance = Balance
})

ao.send({
Target = msg.From,
Data = json.encode({
success = true,
balance = Balance,
transactionId = msg.Id
})
})
end
) State Persistence State is automatically persisted to Arweave through the process lifecycle:-- State checkpoint handler
Handlers.add(
"SaveCheckpoint",
Handlers.utils.hasMatchingTag("Action", "SaveCheckpoint"),
function(msg)
local checkpoint = {
balance = Balance,
transactions = Transactions,
lastUpdate = msg.Timestamp,
version = "1.0.0"
}

-- State is automatically persisted
ao.send({
Target = msg.From,
Data = "Checkpoint saved",
Tags = {
{ name = "Checkpoint-Data", value = json.encode(checkpoint) }
}
})
end
) Common Use Cases 1. Token Contracts AO processes excel at implementing token logic:-- Token contract implementation
Name = "MyToken"
Ticker = "MTK"
Denomination = 12
TotalSupply = 1000000 * 10^Denomination
Balances = { [Owner] = TotalSupply }
Handlers.add(
"Transfer",
Handlers.utils.hasMatchingTag("Action", "Transfer"),
function(msg)
local target = msg.Tags.Recipient
local quantity = tonumber(msg.Tags.Quantity)

if Balances[msg.From] and Balances[msg.From] >= quantity then
Balances[msg.From] = Balances[msg.From] - quantity
Balances[target] = (Balances[target] or 0) + quantity

-- Emit events
ao.send({ Target = msg.From, Data = "Transfer successful" })
ao.send({ Target = target, Data = "Tokens received" })
else
ao.send({ Target = msg.From, Data = "Insufficient balance" })
end
end
) 2. Decentralized Applications Build complex dApps with multiple interacting processes:-- DAO voting process
Proposals = Proposals or {}
Votes = Votes or {}
Handlers.add(
"CreateProposal",
Handlers.utils.hasMatchingTag("Action", "CreateProposal"),
function(msg)
local proposalId = msg.Id
Proposals[proposalId] = {
title = msg.Tags.Title,
description = msg.Data,
creator = msg.From,
created = msg.Timestamp,
status = "active",
votesFor = 0,
votesAgainst = 0
}

ao.send({
Target = msg.From,
Data = "Proposal created: " .. proposalId
})
end
) 3. Data Processing Pipelines Chain processes together for complex workflows:-- Data processing handler
Handlers.add(
"ProcessData",
Handlers.utils.hasMatchingTag("Action", "ProcessData"),
function(msg)
local data = json.decode(msg.Data)

-- Process the data
local processed = transformData(data)

-- Send to next process in pipeline
ao.send({
Target = msg.Tags.NextProcess,
Data = json.encode(processed),
Tags = {
{ name = "Action", value = "ReceiveProcessedData" },
{ name = "Source", value = ao.id }
}
})
end
) Process Communication Patterns Direct Messaging Processes communicate directly through tagged messages:// Send message to specific process
await ao.message({
process: targetProcessId,
tags: [
{ name: "Action", value: "GetBalance" },
{ name: "Account", value: userAddress }
],
signer: createDataItemSigner(wallet)
});
// Receive response
const result = await ao.result({
message: messageId,
process: targetProcessId
});Pub/Sub Patterns Implement publish-subscribe messaging:Development Best Practices Implement robust error handling in your processes:-- Comprehensive error handling
Handlers.add(
"SafeOperation",
Handlers.utils.hasMatchingTag("Action", "SafeOperation"),
function(msg)
local success, result = pcall(function()
-- Your operation logic here
local data = json.decode(msg.Data)
if not data.required_field then
error("Missing required field")
end

return processData(data)
end)

if success then
ao.send({
Target = msg.From,
Data = json.encode({ success = true, result = result })
})
else
ao.send({
Target = msg.From,
Data = json.encode({
success = false,
error = result,
timestamp = msg.Timestamp
})
})
end
end
) Access Control Implement proper authorization:-- Role-based access control
Roles = {
[Owner] = "admin",
-- Add other role assignments
}
local function hasRole(address, requiredRole)
return Roles[address] == requiredRole
end
Handlers.add(
"AdminOnly",
Handlers.utils.hasMatchingTag("Action", "AdminOnly"),
function(msg)
if not hasRole(msg.From, "admin") then
ao.send({
Target = msg.From,
Data = "Access denied: Admin role required"
})
return
end

-- Admin logic here
end
) Testing Strategies Use AOS (AO Studio) for local development and testing:# Install AOS for local testing
npm install -g https://get_ao.g8way.io
# Start AOS REPL
aos
# Load your process code
.load process.lua
# Test message handling
Send({ Action = "Test", Data = "test data" }) Performance Considerations Message Optimization Structure messages for efficient processing:-- Batch operations for efficiency
Handlers.add(
"BatchTransfer",
Handlers.utils.hasMatchingTag("Action", "BatchTransfer"),
function(msg)
local transfers = json.decode(msg.Data)
local results = {}

for i, transfer in ipairs(transfers) do
local success = executeTransfer(transfer.to, transfer.amount)
table.insert(results, {
index = i,
success = success,
to = transfer.to,
amount = transfer.amount
})
end

ao.send({
Target = msg.From,
Data = json.encode(results)
})
end
) State Management Optimization Keep state lean and efficient:-- Use efficient data structures
-- Instead of storing full transaction history:
-- Transactions = {} -- Can grow very large
-- Use rolling window or summary data:
RecentTransactions = {} -- Last 100 transactions
TransactionSummary = {
total_count = 0,
total_ = 0,
last_updated = 0
} Security Considerations Input Validation Always validate incoming data:local function validateTransfer(msg)
local recipient = msg.Tags.Recipient
local quantity = tonumber(msg.Tags.Quantity)

if not recipient or recipient == "" then
return false, "Invalid recipient"
end

if not quantity or quantity <= 0 then
return false, "Invalid quantity"
end

if not Balances[msg.From] or Balances[msg.From] < quantity then
return false, "Insufficient balance"
end

return true, "Valid"
end Reentrancy Protection Protect against message re attacks:ProcessedMessages = ProcessedMessages or {}
local function isProcessed(messageId)
return ProcessedMessages[messageId] ~= nil
end
local function markProcessed(messageId)
ProcessedMessages[messageId] = true
end
Handlers.add(
"IdempotentHandler",
Handlers.utils.hasMatchingTag("Action", "IdempotentHandler"),
function(msg)
if isProcessed(msg.Id) then
return -- Already processed
end

-- Process the message
-- ... handler logic ...

markProcessed(msg.Id)
end
) Monitoring and Debugging Process Health Checks Implement health monitoring:Handlers.add(
"HealthCheck",
Handlers.utils.hasMatchingTag("Action", "HealthCheck"),
function(msg)
local health = {
status = "healthy",
uptime = msg.Timestamp - (StartTime or 0),
balance = Balance,
message_count = #ProcessedMessages,
last_activity = LastActivity or StartTime
}

ao.send({
Target = msg.From,
Data = json.encode(health)
})
end
) Debugging Tools Use logging for debugging:-- Debug logging handler
local DEBUG_MODE = true
local function debugLog(message, data)
if DEBUG_MODE then
print("DEBUG [" .. os.date() .. "]: " .. message)
if data then
print("Data: " .. json.encode(data))
end
end
end
Handlers.add(
"DebugHandler",
function() return DEBUG_MODE end,
function(msg)
debugLog("Received message", {
action = msg.Tags.Action,
from = msg.From,
id = msg.Id
})
end
) Now that you understand AO processes fundamentals:Learn process communication - Process Communication Master state management - State Management Explore HyperBEAM - HyperBEAM Introduction Build your first process - Builder's Journey Resources AO Documentation: Official AO Docs AOS (AO Studio): Development Environment Code Examples: AO Cookbook Repository Community: AO Discord Channel

---

# 8. SvelteVite Starter Kit  Cooking with the Permaweb

Document Number: 8
Source: https://cookbook.arweave.net/kits/svelte/vite.html
Words: 549
Quality Score: 0.610
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Svelte/Vite Starter Kit Svelte is the framework that compiles out of the way, that results is small packages, which is perfect for the permaweb. As developers, we value Dev Experience as much as we value User Experience. This kit uses the vite bundle system to give developers a great DX experience.Installing vite with svelte and typescript npm create vite@latest my-perma-app --template svelte-ts npm create vite@latest my-perma-app -- --template svelte-ts yarn create vite my-perma-app --template svelte-ts pnpm create vite my-perma-app --template svelte-ts Project Info The vite build system places your index.html file in the root directory, this is where you would include any css or global script dependencies if needed. For more information about the vite project layout check out the vite documentation Setup hash-router To setup the hash-router we will use tinro. tinro is a tiny declarative routing library, that is similar to React Router.npm install --save-dev tinro yarn add -D tinro Telling Svelte to use hash routing In the src/App.svelte file, you want to configure the router to use the hash routing mode.The router.mode.hash function turns on hash router mode. The router.subscribe callback is nice to reset the page to the top on page transfers Adding some transition components These component will manage the transition between one page to another page when routing.Create a directory under the src directory called components and add these two files:announcer.svelte This component is for screen readers announcing when a page changes transition.svelte
{#key $router.path}

{/key} This component adds a fade to the page transition Adding Routes to the app
Adding the Announcer and Transition components to our routing system will handle announcing page transitions as well as animating the transition.Create some pages home.svelte
# Hello Permaweb
Inc
Count: {count}
About about.svelte # About Page
Svelte/Vite About Page
Home Modify App.svelte
...Deploy Permanently Generate Wallet We need the arweave package to generate a wallet npm install --save arweave yarn add arweave -D then run this command in the terminal node -e "require('arweave').init({}).wallets.generate().then(JSON.stringify).then(console.log.bind(console))" > wallet.json Fund Wallet You will need to fund your wallet with ArDrive Turbo credits. To do this, enter ArDrive and import your wallet. Then, you can purchase turbo credits for your wallet.Setup Permaweb-Deploy npm install --global permaweb-deploy yarn global add permaweb-deploy Update vite.config.ts import { defineConfig } from 'vite'
import { svelte } from '@sveltejs/vite-plugin-svelte'
export default defineConfig({
plugins: [svelte()],
base: './'
}) Update package.json Update package.json {
...
"scripts": {
...
"deploy": "DEPLOY_KEY=$(base64 -i wallet.json) permaweb-deploy --ant-process << ANT-PROCESS >> --deploy-folder build"
}
...
} Replace << ANT-PROCESS >> with your ANT process id.Run build Now it is time to generate a build, run npm run build yarn build Run deploy Finally we are good to deploy our first Permaweb Application npm run deploy yarn deploy ERROR If you receive an error Insufficient funds, make sure you remembered to fund your deployment wallet with ArDrive Turbo credits.Response You should see a response similar to the following:Deployed TxId [<>] to ANT [<>] using undername [<>] Your Svelte app can be found at https://arweave.net/<< tx-id >>.SUCCESS You should now have a Svelte Application on the Permaweb! Great Job!Summary This is a minimal version of publishing a Svelte application on the permaweb, but you may want more features, like hot-reloading and tailwind, etc. Check out hypar for a turnkey starter kit. HypAR

---

# 9. Hello World (CLI)  Cooking with the Permaweb

Document Number: 9
Source: https://cookbook.arweave.net/getting-started/quick-starts/hw-cli.html
Words: 142
Quality Score: 0.609
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Hello World (CLI) This guide walks you through the most simple way to get data on to the Permaweb using a command-line interface (CLI).Requirements NodeJS open in new window LTS or greater Description Using a terminal/console window create a new folder called hw-permaweb-1.Setup cd hw-permaweb-1
npm init -y
npm install arweave ardrive-cli Generate a wallet npx -y @permaweb/wallet > ~/.demo-arweave-wallet.json Create a web page echo "# Hello Permaweb
" > index.html Upload using Ardrive CLI # Create a Drive
FOLDER_ID=$(npx ardrive create-drive -n public -w ~/.demo-arweave-wallet.json --turbo | jq -r '.created[] | select(.type == "folder") | .entityId')
# Upload file
TX_ID=$(npx ardrive upload-file -l index.html --content-type text/html -w ~/.demo-arweave-wallet.json --turbo -F ${FOLDER_ID} | jq -r '.created[] | select(.type == "file
") | .dataTxId')
# open file from ar.io gateway
open https://arweave.net/${TX_ID} Built with ❤️ by the Arweave community. Learn more at Arweave.org

---

# 10. Minimal Svelte Starter Kit  Cooking with the Permaweb

Document Number: 10
Source: https://cookbook.arweave.net/kits/svelte/minimal.html
Words: 525
Quality Score: 0.575
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Minimal Svelte Starter Kit This guide will walk you through in a step by step flow to configure your development environment to build and deploy a permaweb application.Prerequisites Know typescript NodeJS v18 or greater Know Svelte - https://svelte.dev Know git and common terminal commands Development Dependencies TypeScript esbuild w3 Steps Create Project mkdir myproject
cd myproject
npm init -y
npm install -D svelte esbuild typescript esbuild-svelte tinro svelte-preprocess mkdir myproject
cd myproject
yarn init -y
yarn add -D svelte esbuild typescript esbuild-svelte tinro svelte-preprocess Create buildscript.js import fs from "fs";
import esbuild from "esbuild";
import esbuildSvelte from "esbuild-svelte";
import sveltePreprocess from "svelte-preprocess";
//make sure the directoy exists before stuff gets put into it
if (!fs.existsSync("./dist/")) {
fs.mkdirSync("./dist/");
}
esbuild
.build({
entryPoints: [`./src/main.ts`],
bundle: true,
outdir: `./dist,
mainFields: ["svelte", "browser", "module", "main"],
// logLevel: info,
splitting: true,
write: true,
format: esm,
plugins: [
esbuildSvelte({
preprocess: sveltePreprocess(),
}),
],
})
.catch((error, location) => {
console.warn(Errors: `, error, location);
process.exit(1);
});
//use a basic html file to test with
fs.copyFileSync("./index.html", "./dist/index.html");Modify package.json Set type to module, add a build script {
"type": "module"
...
"scripts": {
"build": "node buildscript.js"
}
} Create src directory and some src files mkdir src
touch src/main.ts
touch src/app.svelte
touch src/counter.svelte
touch src/about.svelte Main.ts import App from "./app.svelte";
new App({
target: document.body,
});app.svelte Hash Routing You will notice the router.mode.hash() setting in the script session, this is important to configure your application to use hash based routing, which will enable url support when running that application on a path, like https://[gateway]/[TX] counter.svelte
# Hello Permaweb
Inc
Count: {count}
about.svelte # About Page
Minimal About Page
Home Add index.html




Vite + Svelte + TS





Deploy Permanently Generate Wallet We need the arweave package to generate a wallet npm install --save arweave yarn add arweave -D then run this command in the terminal node -e "require('arweave').init({}).wallets.generate().then(JSON.stringify).then(console.log.bind(console))" > wallet.json Fund Wallet You will need to fund your wallet with ArDrive Turbo credits. To do this, enter ArDrive and import your wallet. Then, you can purchase turbo credits for your wallet.Setup Permaweb-Deploy npm install --global permaweb-deploy yarn global add permaweb-deploy Update vite.config.ts import { defineConfig } from 'vite'
import { svelte } from '@sveltejs/vite-plugin-svelte'
export default defineConfig({
plugins: [svelte()],
base: './'
}) Update package.json {
...
"scripts": {
...
"deploy": "DEPLOY_KEY=$(base64 -i wallet.json) permaweb-deploy --ant-process << ANT-PROCESS >> --deploy-folder build"
}
...
} Replace << ANT-PROCESS >> with your ANT process id.Run build Now it is time to generate a build, run npm run build yarn build Run deploy Finally we are good to deploy our first Permaweb Application npm run deploy yarn deploy ERROR If you receive an error Insufficient funds, make sure you remembered to fund your deployment wallet with ArDrive Turbo credits.Response You should see a response similar to the following:Deployed TxId [<>] to ANT [<>] using undername [<>] Your Svelte app can be found at https://arweave.net/<< tx-id >>.SUCCESS You should now have a Svelte Application on the Permaweb! Great Job!Summary This is a minimal version of publishing a Svelte application on the permaweb, but you may want more features, like hot-reloading and tailwind, etc. Check out hypar for a turnkey starter kit. HypAR

---

# 11. Data Model  Cooking with the Permaweb

Document Number: 11
Source: https://cookbook.arweave.net/tooling/specs/arfs/data-model.html
Words: 344
Quality Score: 0.569
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Data Model Because of Arweave's permanent and immutable nature, traditional file structure operations such as renaming and moving files or folders cannot be accomplished by simply updating on-chain data. ArFS works around this by defining an append-only transaction data model based on the metadata tags found in the Arweave Transaction Headers.This model uses a bottom-up reference method, which avoids race conditions in file system updates. Each file contains metadata that refers to the parent folder, and each folder contains metadata that refers to its parent drive. A top-down data model would require the parent model (i.e. a folder) to store references to its children.These defined entities allow the state of the drive to be constructed by a client to look and feel like a file system Drive Entities contain folders and files Folder Entities contain other folders or files File Entities contain both the file data and metadata Snapshot entities contain a state rollups of all files and folder metadata within a drive Entity relationships The following diagram shows the high level relationships between drive, folder, and file entities, and their associated data. More detailed information about each Entity Type can be found here. Entity Relationship Diagram As you can see, each file and folder contains metadata which points to both the parent folder and the parent drive. The drive entity contains metadata about itself, but not the child contents. So clients must build drive states from the lowest level and work their way up.Metadata stored in any Arweave transaction tag will be defined in the following manner:{ "name": "Example-Tag", "value": "example-data" } Metadata stored in the Transaction Data Payload will follow JSON formatting like below:{
"exampleField": "exampleData"
} fields with a ? suffix are optional.{
"name": "My Project",
"description": "This is a sample project.",
"version?": "1.0.0",
"author?": "John Doe"
} Enumerated field values (those which must adhere to certain values) are defined in the format "value 1 | value 2".All UUIDs used for Entity-Ids are based on the Universally Unique Identifier standard.There are no requirements to list ArFS tags in any specific order.

---

# 12. React Starter Kit wvite  ArDrive  Cooking with the Permaweb

Document Number: 12
Source: https://cookbook.arweave.net/kits/react/turbo.html
Words: 540
Quality Score: 0.567
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

React Starter Kit w/vite & ArDrive This guide will walk you through in a step by step flow to configure your development environment to build and deploy a permaweb react application.Prerequisites Basic Typescript Knowledge (Not Mandatory) - https://www.typescriptlang.org/docs/ NodeJS v16.15.0 or greater - https://nodejs.org/en/download/ Knowledge of ReactJS - https://reactjs.org/ Know git and common terminal commands Development Dependencies TypeScript NPM or Yarn Package Manager Steps Create React App npm create vite my-arweave-app --template react-ts
cd my-arweave-app
npm install yarn create vite my-arweave-app --template react-ts
cd my-arweave-app
yarn Add React Router DOM npm install react-router-dom yarn add react-router-dom We need to use the hash-router to create a working app on arweave.Page Components touch src/Home.tsx src/About.tsx src/Home.tsx import { Link } from "react-router-dom";
function Home() {
return (
Welcome to the Permaweb!

About
);
}
export default Home;src/About.tsx import { Link } from "react-router-dom";
function About() {
return (
Welcome to the About page!

Home
);
}
export default About;Modify App.tsx We need to update the App.tsx to manage different pages import { HashRouter } from "react-router-dom";
import { Routes, Route } from "react-router-dom";
import Home from "./Home";
import About from "./About";
function App() {
return (


} />
} />


);
}
export default App;Modify index.css Alter the body selector body {
margin: 0;
padding-top: 200px;
dis: flex;
flex-direction: column;
place-items: center;
min-width: 100%;
min-height: 100vh;
} Run the project npm run dev yarn dev Building React App Modify vite.config.ts import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'
// https://vitejs.dev/config/
export default defineConfig({
base: "",
plugins: [react()],
}) Build App yarn build Deploy Permanently Generate Wallet We need the arweave package to generate a wallet npm install --save arweave yarn add arweave -D then run this command in the terminal node -e "require('arweave').init({}).wallets.generate().then(JSON.stringify).then(console.log.bind(console))" > wallet.json Fund Wallet You will need to fund your wallet with ArDrive Turbo credits. To do this, enter ArDrive and import your wallet. Then, you can purchase turbo credits for your wallet.Setup Permaweb-Deploy npm install --save-dev permaweb-deploy yarn add permaweb-deploy --dev --ignore-engines You will need to add AR to your wallet and fund it with Turbo credits to be able to upload this app. See Turbo SDK for more information.Update package.json {
...
"scripts": {
...
"deploy": "npm run build && permaweb-deploy --arns-name my-react-app"
}
...
} Replace my-react-app with your actual ArNS name. You can also add additional options like --undername staging for staging deployments.Run build Now it is time to generate a build, run npm run build yarn build Run deploy Finally we are good to deploy our first Permaweb Application npm run deploy yarn deploy Insufficient Funds If you receive an error Insufficient funds, make sure you remembered to fund your deployment wallet with Turbo credits. See Turbo SDK for more information.Response You should see a response similar to the following:-------------------- DEPLOY DETAILS --------------------
Tx ID: abc123def456ghi789jkl012mno345pqr678stu901v
ArNS Name: my-react-app
Undername: @
ANT: xyz789abc012def345ghi678jkl901mno234pqr567s
AR IO Process: bh9l1cy0aksiL_x9M359faGzM_yjralacHIUo8_nQXM
TTL Seconds: 3600
--------------------------------------------------------
Deployed TxId [abc123def456ghi789jkl012mno345pqr678stu901v] to name [my-react-app] for ANT [xyz789abc012def345ghi678jkl901mno234pqr567s] using undername [@] Your React app can be found at https://my-react-app.arweave.net (if using ArNS) or https://arweave.net/abc123def456ghi789jkl012mno345pqr678stu901v.SUCCESS You should now have a React Application on the Permaweb! Great Job!Congrats!You just published a react application on the Permaweb! This app will be hosted forever!

---

# 13. Permaweb Deploy  Cooking with the Permaweb

Document Number: 13
Source: https://cookbook.arweave.net/tooling/deployment/permaweb-deploy.html
Words: 707
Quality Score: 0.548
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Permaweb Deploy permaweb-deploy is a Node.js command-line tool that streamlines deployment of web applications and files to the Permaweb using Arweave. It uploads your build folder or single files, creates Arweave manifests, and automatically updates ArNS (Arweave Name Service) records with the new transaction ID.Features Turbo SDK Integration: Fast, reliable file uploads to Arweave Arweave Manifest v0.2.0: Creates manifests with fallback support for SPAs ArNS Updates: Automatically updates ArNS records via ANT with new transaction IDs Automated Workflow: Integrates seamlessly with GitHub Actions Git Hash Tagging: Automatically tags deployments with Git commit hashes 404 Fallback Detection: Automatically detects and sets 404.html as fallback Network Support: Supports mainnet, testnet, and custom ARIO process IDs Flexible Deployment: Deploy folders or single files Installation npm install permaweb-deploy --save-dev For Yarn users:yarn add permaweb-deploy --dev --ignore-engines Prerequisites Wallet Configuration For Arweave signer (default): Encode your Arweave wallet key in base64 format:base64 -i wallet.json | pbcopy Set the encoded wallet as the DEPLOY_KEY environment variable.For Ethereum/Polygon/KYVE signers: Use your raw private key (no encoding needed) as the DEPLOY_KEY.Security Best Practice Use a dedicated wallet for deployments to minimize security risks. Ensure your wallet has sufficient Turbo Credits for uploads.Basic Usage Add deployment scripts to your package.json:{
"scripts": {
"build": "vite build",
"deploy": "npm run build && permaweb-deploy --arns-name my-app"
}
} Deploy your application:npm run deploy CLI Options Option Alias Description Default --arns-name -n Required. The ArNS name to update - --ario-process -p ARIO process (mainnet, testnet, or process ID) mainnet --deploy-folder -d Folder to deploy./dist --deploy-file -f Deploy a single file instead of a folder - --undername -u ANT undername to update @ --ttl-seconds -t TTL in seconds for the ANT record (60-86400) 3600 --sig-type -s Signer type (arweave, ethereum, polygon, kyve) arweave Examples Deploy Application DEPLOY_KEY=$(base64 -i wallet.json) npx permaweb-deploy --arns-name my-app Deploy Specific Folder DEPLOY_KEY=$(base64 -i wallet.json) npx permaweb-deploy --arns-name my-app --deploy-folder ./build Deploy Single File DEPLOY_KEY=$(base64 -i wallet.json) npx permaweb-deploy --arns-name my-app --deploy-file ./script.lua Deploy to Undername DEPLOY_KEY=$(base64 -i wallet.json) npx permaweb-deploy --arns-name my-app --undername staging Deploy with Custom TTL DEPLOY_KEY=$(base64 -i wallet.json) npx permaweb-deploy --arns-name my-app --ttl-seconds 7200 Deploy with Ethereum Signer DEPLOY_KEY= npx permaweb-deploy --arns-name my-app --sig-type ethereum Network Configurations Mainnet (Default) {
"scripts": {
"deploy": "npm run build && permaweb-deploy --arns-name my-app"
}
} Testnet {
"scripts": {
"deploy:test": "npm run build && permaweb-deploy --arns-name my-app --ario-process testnet"
}
} Custom Process ID {
"scripts": {
"deploy:custom": "npm run build && permaweb-deploy --arns-name my-app --ario-process PROCESS_ID"
}
} GitHub Actions Integration Create .github/workflows/deploy.yml:name: Deploy to Permaweb
on:
push:
branches:
- main
jobs:
deploy:
runs-on: ubuntu-latest
steps:
- uses: actions/checkout@v4
- uses: actions/setup-node@v4
with:
node-version: 20
- run: npm install
- run: npm run deploy
env:
DEPLOY_KEY: ${{ secrets.DEPLOY_KEY }} Deployment Output After successful deployment, you'll see output similar to:-------------------- DEPLOY DETAILS --------------------
Tx ID: abc123def456ghi789jkl012mno345pqr678stu901v
ArNS Name: my-app
Undername: @
ANT: xyz789abc012def345ghi678jkl901mno234pqr567s
AR IO Process: bh9l1cy0aksiL_x9M359faGzM_yjralacHIUo8_nQXM
TTL Seconds: 3600
--------------------------------------------------------
Deployed TxId [abc123def456ghi789jkl012mno345pqr678stu901v] to name [my-app] for ANT [xyz789abc012def345ghi678jkl901mno234pqr567s] using undername [@] Security Best Practices Use dedicated wallets: Create deployment-specific wallets to minimize security risks Secure secret management: Never commit your DEPLOY_KEY to version control Build verification: Always check your build for exposed secrets before deployment Sufficient credits: Ensure your wallet has enough Turbo Credits before deployment Base64 encoding: Arweave wallets must be base64 encoded for the deployment script Troubleshooting "ARNS_NAME not configured" Ensure you're passing the --arns-name flag with a valid ArNS name "DEPLOY_KEY not configured" Verify your base64 encoded wallet is set as the DEPLOY_KEY environment variable "deploy-folder does not exist" Check that your build folder exists and the path is correct Run your build command first "ARNS name does not exist" Verify the ArNS name is correct and exists in the specified network "Upload timeouts" Files have a 10-second upload timeout Large files may fail and require optimization "Insufficient Turbo Credits" Check your wallet balance and add more credits if needed Debug Information Enable verbose logging by setting the DEBUG environment variable:DEBUG=permaweb-deploy* npm run deploy Dependencies @ar.io/sdk: ANT operations and ArNS management @ardrive/turbo-sdk: Fast file uploads to Arweave @permaweb/aoconnect: AO network connectivity yargs: CLI argument parsing ArNS Setup: ArNS Names Turbo Credits: Turbo SDK GitHub Actions: CI/CD Integration Resources GitHub Repository: permaweb/permaweb-deploy Turbo SDK Documentation: docs.ardrive.io/turbo ArNS Documentation: ar.io/arns Arweave Ecosystem: arweave.org

---

# 14. ANS-109 Vouch-For (Assertion of Identity)  Cooking with the Permaweb

Document Number: 14
Source: https://cookbook.arweave.net/tooling/specs/ans/ANS-109.html
Words: 303
Quality Score: 0.543
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

ANS-109: Vouch-For (Assertion of Identity) Status: Draft (Version 0.1) Authors: Abhav Kedia (abhav@arweave.org), Sam Williams (sam@arweave.org), Tom Wilson (tom@hyper.io) Abstract This document specifies a transaction format that allows addresses to vouch for the identity of other addresses on the permaweb.Motivation Sybil resistance is a necessary component of most applications on the permaweb. A transaction format that allows addresses to vouch for the identity of other addresses enables human and programmatic Verifiers to confirm the humanity of addresses. All other applications can then utilize this information as a primitive for identity verification, with various safeguards that can be built on top.One example of abstractions and safeguards built on top of such a system could be a "VouchDAO" - a community that specifies which human "Verifiers" or "Verification Services" they deem to be trustworthy at a given point in time.Specfication Transaction Format A Verifier can assert the identity of an address using the Vouch-For standard by sending a transaction with the following tags.Tag Name Optional?Tag Value App-Name False Vouch Vouch-For False Arweave address that is being vouched for in this transaction App-Version True 0.1 Verification-Method True Method of verification of identity for the person. Example - Twitter / In-Person / Gmail / Facebook User-Identifier True An identifier for the user based on the Verification Method. Example - abhav@arweave.org Usage Users of this standard can run a graphql query on the arweave network with transactions of the Vouch-For standard that vouch for a particular address to be verified. For example,query {
transactions(
tags:{name:"Vouch-For", values:["0L_z90sYv36VDoDhrRBffo9KrADWpCaaGQz7hJhhP9g"]}
) {
edges {
node {
id
tags {
name
value
}
}
}
}
} This query returns all vouches for the address 0L_z90sYv36VDoDhrRBffo9KrADWpCaaGQz7hJhhP9g. Additional filters (such as those by an implementation of "VouchDAO" as outlined above) can be applied by filtering for specific owners that have been designated as Verifiers.

---

# 15. GraphQL Queries  Cooking with the Permaweb

Document Number: 15
Source: https://cookbook.arweave.net/fundamentals/accessing-arweave-data/graphql.html
Words: 248
Quality Score: 0.540
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

GraphQL Queries Overview Over time, indexing services that implement a GraphQL interface have became the preferred method for querying transaction data on Arweave. An indexing service reads transaction and block headers as they are added to the network (usually from a full Arweave node which the service operates). Once read, the header info is inserted into a database where it can be indexed and efficiently queried. The indexing service uses this database to provide a GraphQL endpoint for clients to query.GraphQL has a few advantages that make it ideal for retrieving query data sets. It enables indexing services to create a single endpoint that can then be used to query all types data. The service is able to return multiple resources in a single request as opposed to making an HTTP request for each resource (like one would with a REST API). With GraphQL, clients can batch multiple requests in a single round-trip and specify exactly what data is needed which increases performance.Basic Query Example The following GraphQL example queries all the transaction ids from a given owners wallet address that have a "Type" tag with a value of "manifest". For more information about tags, read the guide on Transaction Tags.const queryObject = {
query:
`{
transactions (
owners:["${address}"],
tags: [
{
name: "Type",
values: ["manifest"]
}
]
) {
edges {
node {
id
}
}
}
}`
};
const results = await arweave.api.post('/graphql', queryObject);Public Indexing Services https://arweave.net/graphql https://arweave-search.goldsky.com/graphql Resources Querying Arweave Guide ar-gql package GraphQL Reference

---

# 16. Create React App Starter Kit  Cooking with the Permaweb

Document Number: 16
Source: https://cookbook.arweave.net/kits/react/create-react-app.html
Words: 693
Quality Score: 0.524
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Create React App Starter Kit This guide will walk you through in a step by step flow to configure your development environment to build and deploy a permaweb react application.Prerequisites Basic Typescript Knowledge (Not Mandatory) - https://www.typescriptlang.org/docs/ NodeJS v16.15.0 or greater - https://nodejs.org/en/download/ Knowledge of ReactJS - https://reactjs.org/ Know git and common terminal commands Development Dependencies TypeScript NPM or Yarn Package Manager Steps Create Project If you are not familiar with typescript you can exclude the extra check --template typescript npx create-react-app permaweb-create-react-app --template typescript yarn create react-app permaweb-create-react-app --template typescript Change into the Project Directory cd permaweb-create-react-app Install react-router-dom You have to install this package to manage routing between different pages npm install react-router-dom --save yarn add react-router-dom -D Run the App Now we need to check if everything is working before jumping into next step, run npm start yarn start This will start a new development server locally on your machine. By default it uses `PORT 3000`, if this PORT is already in use it may ask you to switch to another available PORT in Terminal Modify the package.json to contain the following config Setup Routing Now modify the application and add a new route such as an about page, first create 2 more.tsx files. (if you have exluceded the extra check --template typescript, then your component file extension should be .jsx or .js) HomePage.tsx About.tsx import { Link } from "react-router-dom";
function About() {
return (
Welcome to the About page!

Home
);
}
export default About;Modify App.tsx We need to update the App.tsx to manage the different pages Hash Routing Note that we are wrapping the routes in a HashRouter and using the react-router-dom Link component to build links. This is important on the permaweb in its current state, it will ensure the routes work properly because applications are served on a path like https://[gateway]/[TX] Deploy Permanently Generate Wallet Existing Wallet This step will generate a new, empty, Arweave wallet. If you already have an existing Arweave wallet you may provide its keyfile and skip this step.We need the arweave package to generate a wallet npm install --save arweave yarn add arweave -D then run this command in the terminal node -e "require('arweave').init({}).wallets.generate().then(JSON.stringify).then(console.log.bind(console))" > wallet.json It is very important to make sure that your wallet file is not included in any folder you want uploaded to Arweave.Setup Turbo We need Turbo to deploy our app to the Permaweb.Fund Wallet You will need to fund your wallet with ArDrive Turbo credits. To do this, enter ArDrive and import your wallet. Then, you can purchase turbo credits for your wallet.Setup Permaweb-Deploy npm install --global permaweb-deploy yarn global add permaweb-deploy Fund Your Wallet Turbo uses Turbo Credits to upload data to Arweave. You can purchase Turbo Credits with a variety of fiat currencies or crypto tokens. Below is an example for funding your wallet with 10 USD. It will open a browser window to complete the purchase using Stripe.npm install @ardrive/turbo-sdk
turbo top-up --wallet-file wallet.json --currency USD --value 10 Be sure to replace wallet.json with the path to your Arweave wallet.Update package.json {
...
"scripts": {
...
"deploy": "turbo upload-folder --folder-path ./build --wallet-file wallet.json > latest-manifest.json"
}
...
} This will upload your build folder to the permaweb, and save all of the details of the upload to a file named "latest-manifest.json". That way, you'll have a reference for the manifest TxId to use later.Run build Now it is time to generate a build, run npm run build yarn build Run deploy Finally we are good to deploy our first Permaweb Application npm run deploy yarn deploy ERROR If you receive an error Insufficient funds, make sure you remembered to fund your deployment wallet with ArDrive Turbo credits.Response You should see a response similar to the following:Deployed TxId [<>] to ANT [<>] using undername [<>] Your React app can be found at https://arweave.net/<< tx-id >>.SUCCESS You should now have a React Application on the Permaweb! Great Job!Summary This is a Create React App version of publishing a React app on the permaweb. You may discover new ways to deploy an app on the permaweb or checkout other starter kits in this guide!

---

# 17. Create Vue Starter Kit  Cooking with the Permaweb

Document Number: 17
Source: https://cookbook.arweave.net/kits/vue/create-vue.html
Words: 705
Quality Score: 0.522
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Create Vue Starter Kit This guide will provide step-by-step instructions to configure your development environment and build a permaweb Vue application.Prerequisites Basic Typescript Knowledge (Not Mandatory) - Learn Typescript NodeJS v16.15.0 or greater - Download NodeJS Knowledge of Vue.js (preferably Vue 3) - Learn Vue.js Know git and common terminal commands Development Dependencies TypeScript (Optional) NPM or Yarn Package Manager Steps Create Project The following command installs and launches create-vue, the official scaffolding tool for Vue projects.npm init vue@latest yarn create vue During the process, you'll be prompted to select optional features such as TypeScript and testing support. I recommend selecting the Vue Router with yes, the rest can be selected as per your preference.✔ Project name: …
✔ Add TypeScript? … No / Yes
✔ Add JSX Support? … No / Yes
✔ Add Vue Router for Single Page Application development? … No / *Yes*
✔ Add Pinia for state management? … No / Yes
✔ Add Vitest for Unit testing? … No / Yes
✔ Add Cypress for both Unit and End-to-End testing? … No / Yes
✔ Add ESLint for code quality? … No / Yes
✔ Add Prettier for code formatting? … No / Yes Change into the Project Directory cd Install Dependencies npm install yarn Setup Router Vue Router is the official router for Vue.js and seamlessly integrates with Vue. To make it work with Permaweb, switch from a browser history router to a hash router as the URL cannot be sent to the server. Change createWebHistory to createWebHashHistory in your src/router/index.ts or src/router/index.js file.import { createRouter, createWebHashHistory } from "vue-router";
import HomeView from "../views/HomeView.vue";
const router = createRouter({
history: createWebHashHistory(import.meta.env.BASE_URL),
routes: [
{
path: "/",
name: "home",
component: HomeView,
},
{
path: "/about",
name: "about",
component: () => import("../views/AboutView.vue"),
},
],
});
export default router;Setup Build Configure the build process in the vite.config.ts or vite.config.js file. To serve Permaweb apps from a sub-path (https://[gateway]/[TX_ID]), update the base property to./ in the config file.export default defineConfig({
base: './',
...
}) Run the App Before moving forward, it is crucial to verify that everything is working correctly. Run a check to ensure smooth progress.npm run dev yarn dev it will start a new development server locally on your machine by default it uses `PORT 5173. If this PORT is already in use it may increase the PORT number by 1 (PORT 5174`) and try again. Deploy Permanently Generate Wallet We need the arweave package to generate a wallet npm install --save arweave yarn add arweave -D then run this command in the terminal node -e "require('arweave').init({}).wallets.generate().then(JSON.stringify).then(console.log.bind(console))" > wallet.json Fund Wallet You will need to fund your wallet with ArDrive Turbo credits. To do this, enter ArDrive and import your wallet. Then, you can purchase turbo credits for your wallet.Setup Permaweb-Deploy npm install --global permaweb-deploy yarn global add permaweb-deploy Fund Your Wallet Turbo uses Turbo Credits to upload data to Arweave. You can purchase Turbo Credits with a variety of fiat currencies or crypto tokens. Below is an example for funding your wallet with 10 USD. It will open a browser window to complete the purchase using Stripe.npm install @ardrive/turbo-sdk
turbo top-up --wallet-file wallet.json --currency USD --value 10 Be sure to replace wallet.json with the path to your Arweave wallet.Update package.json {
...
"scripts": {
...
"deploy": "DEPLOY_KEY=$(base64 -i wallet.json) permaweb-deploy --ant-process << ANT-PROCESS >> --deploy-folder build"
}
...
} Replace << ANT-PROCESS >> with your ANT process id.Run build Now it is time to generate a build, run npm run build yarn build Run deploy Finally we are good to deploy our first Permaweb Application npm run deploy yarn deploy ERROR If you receive an error Insufficient funds, make sure you remembered to fund your deployment wallet with ArDrive Turbo credits.Response You should see a response similar to the following:Deployed TxId [<>] to ANT [<>] using undername [<>] Your Vue app can be found at https://arweave.net/<< tx-id >>.SUCCESS You should now have a Vue Application on the Permaweb! Great Job!Summary This guide provides a simple step-by-step method to publish a Vue.js app on the Permaweb using Create Vue. If you need additional features Tailwind, consider exploring alternative starter kits listed in the guide to find a suitable solution for your requirements.

---

# 18. Posting Transactions  Cooking with the Permaweb

Document Number: 18
Source: https://cookbook.arweave.net/fundamentals/transactions/post-transactions.html
Words: 635
Quality Score: 0.519
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Posting Transactions There are several ways to post transactions to Arweave. Each has its own unique affordances and constraints. The diagram below illustrates the four main approaches to posting transactions.Direct to Peer,Direct to Gateway, Bundled, and Dispatched. Guaranteed Transactions When posting a large quantity of transactions or when fast settlement time is desireable consider using a bundling service. Bundlers settle large s of transactions immediately and make the transaction data available within milliseconds. The bundling service holds onto posted transactions until they are confirmed on-chain. If the transactions are not included in the most recent block the bundling service re-posts them with each new block until they are recorded on chain with a sufficient number of confirmations.Direct Transactions Transactions posted directly to Arweave come in two varieties wallet-to-wallet transactions and data transactions. The first transfers AR tokens between wallet addresses. The second posts data to Arweave and pays the associated storage costs.Interestingly, data transactions may also transfer AR tokens to a wallet address while paying storage costs at the same time.All transactions allow the user to specify up to 2KB worth of metadata in the form of custom tags.Direct to Peer Transactions may be posted directly to an Arweave peer (mining node). This is perhaps the most decentralized means of posting a transaction as clients can choose what peer they wish to post to.This approach is not without drawbacks. Peers may come and go making it difficult to reliably post transactions from an app. While it's possible to query a list of active peers and choose one before posting it adds overhead and friction to the process. Additionally, transactions posted to peers are only queryable at the gateway after being mined in a block. This introduces a 1-2 minute delay between posting the transaction to a peer and it being available to read in a browser from a gateway.For the above reasons, developers tend to configure arweave-js to point to a gateway when posting direct transactions as the optimistic cache at the gateway makes the transaction available almost immediately.Direct to Gateway Gateways sit between clients and Arweave's network of peers. One of the primary functions of the gateway is to index transactions and optimistically cache the data posted to the network while waiting for it to be included in a block. This makes the transaction queryable in a "Pending" state almost instantly which allows applications built on top of a gateway to be more responsive. There is still a risk of transactions dropping out of the optimistic cache if they are not mined in a block by the peers.An example of how to post a direct transaction using arweave-js can be found in this guide.Bundled Transactions Services built on top of Arweave that provide additional utility for Permaweb builders are sometimes called Permaweb Services. A bundler is one such service. Bundlers take multiple individual transactions and bundle them together into a single transaction that is posted directly to Arweave. In this way a single transaction at the protocol level can contain tens of thousands of bundled transactions. There is one restriction, however, only data transactions can be included in a bundle. Wallet-to-wallet transactions (that transfer AR tokens between wallet addresses) must be done as individual transactions posted directly to Arweave.Dispatched Transactions Another way to post bundled transactions is from the browser. While browsers enforce some constraints around the size of data that can be uploaded, browser based wallets are able to post transactions to bundlers. Arweave browser wallets implement a dispatch() API method. If you are posting small transactions (100KB or less) you can use the wallets dispatch() method to take advantage of bundled transactions.An example of how to post a 100KB or less bundled transaction with an Arweave wallets dispatch() method can be found in this guide.Resources arweave-js example dispatch example Turbo SDK example

---

# 19. ar-gql  Cooking with the Permaweb

Document Number: 19
Source: https://cookbook.arweave.net/tooling/graphql/ar-gql.html
Words: 127
Quality Score: 0.515
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

ar-gql This package is a minimal layer on top of GraphQL, it supports parameterized queries with query variables. It also implements management of paged results.Installation To install `ar-gql run npm i ar-gql yarn add ar-gql Example import { arGql } from "ar-gql"
const argql = arGql()
(async () => {
let results = await argql.run(`query( $count: Int ){
transactions(
first: $count,
tags: [
{
name: "App-Name",
values: ["PublicSquare"]
},
{
name: "Content-Type",
values: ["text/plain"]
},
]
) {
edges {
node {
id
owner {
address
}
data {
size
}
block {
height
timestamp
}
tags {
name,
value
}
}
}
}
}`, {count: 1});
console.log(results);
})();Resources ar-gql github page open in new window Built with ❤️ by the Arweave community. Learn more at Arweave.org

---

# 20. Svelte Starter Kits  Cooking with the Permaweb

Document Number: 20
Source: https://cookbook.arweave.net/kits/svelte/index.html
Words: 115
Quality Score: 0.512
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Svelte Starter Kits Svelte is a framework that compiles to a JavaScript bundle and in the process removes the framework from the distribution of the app. This results in a much smaller footprint than other frameworks. Svelte is the perfect framework for Permaweb Applications. A Permaweb Application is built on the principles of a Single Page Application, but lives on the Arweave network and is distributed by Permaweb gateways.Svelte Starter Kit Guides:Minimal - the minimum required to build a svelte permaweb app Vite - Svelte, Typescript and Vite Permaweb Application Constraints 100% Front-end application (No Server-Side Backend) Applications are served from a sub-path (https://[gateway]/[TX_ID]) Built with ❤️ by the Arweave community. Learn more at Arweave.org

---

# 21. Transaction Metadata (Tags)  Cooking with the Permaweb

Document Number: 21
Source: https://cookbook.arweave.net/fundamentals/transactions/tags.html
Words: 559
Quality Score: 0.510
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Arweave can be thought of as a permanent append-only hard drive where each entry on the drive is its own unique transaction. Transactions have a unique ID, signature, and owner address for the address that signed and paid for the transaction to be posted. Along with those header values, the Arweave protocol allows users to tag transactions with custom tags. These are specified as a collection name value pairs appended to the transaction. These tags make it possible to query Arweave and find all the Transactions that include a particular tag or tags. The ability to query and filter transactions is critical to supporting apps built on Arweave.What are Transaction Tags?Transaction tags are key-value pairs, where the combination of base64URL keys and values must be less than the maximum of 2048 bytes for an arweave native transaction.Some common examples of transaction tags include:Content-Type: Used to specify the MIME type of content for render on the permaweb.App-Name: This tag describes the app that is writing the data App-Version: This tag is the version of the app, paired with App-Name Unix-Time: This tag is the a unix timestamp, seconds since epoch.Title: Used to give a name or brief description of the content stored in the transaction.Description: Used to provide a longer description of the content.Transaction tags can be used for a variety of purposes, such as indexing transactions for search, organizing transactions into categories, or providing metadata about the content stored in a transaction.Some good things to know about Transaction Tags Transaction tags are encoded as Base64URL encoded strings for both the key and value. This makes it possible to post arrays of bytes as keys or values and transfer them safely over http. While it's not human readable without decoding, it shouldn't be considered encryption.The max total size of Transaction tags for transaction posted directly to Arweave is 2048 bytes. This size is determined by the concatenation of all keys and all values of the transaction tags.Transaction tags can be used in GraphQL queries to return a filtered set of transaction items.Common Tags used in the community Tag Name Description Use Cases App-Name Most commonly used to identify applications using Arweave Common uses are the project's name, sometimes also used in specific ANS transactions App-Version The version of this data, it may represent the app consuming this information E.g. 0.3.0 Content-Type MIME Type to identify the data contained in the transaction text/html, application/json, image/png Unix-Time This tag is the a unix timestamp, seconds since epoch The time the transaction is submitted Title ANS-110 Standard for describing content Providing a name for an Atomic Asset Type ANS-110 Standard for categorization of data a type can classify a permaweb asset Examples const tx = await arweave.createTransaction({ data: mydata });
tx.addTag("Content-Type", "text/html");
tx.addTag("Title", "My incredible post about Transaction Tags");
tx.addTag("Description", "This is one post you do not want to miss!");
tx.addTag("Topic:Amazing", "Amazing");
tx.addTag("Type", "blog-post");
await arweave.transactions.sign(tx, jwk);
await arweave.transactions.post(tx);Summary Understanding how Transaction Tags factor into the Arweave tech stack can provide context on how to solve problems using the Permaweb as an application platform. Tags provide a tool to consume and create common data standards and patterns to encourage a non-rivalous data experience on the Permaweb. The result gives users of the ecosystem the choice of applications to consume and create content as their data is always with the user not the application.

---

# 22. Vue Starter Kits  Cooking with the Permaweb

Document Number: 22
Source: https://cookbook.arweave.net/kits/vue/index.html
Words: 117
Quality Score: 0.509
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Vue Starter Kits Vue.js is a progressive JavaScript framework that allows building user interfaces. Unlike other frameworks, it compiles the template into JavaScript during runtime, resulting in a smaller file size and faster performance. Vue is ideal for building performant and scalable single-page applications, making it a popular choice among front-end developers.Vue Starter Kit Guides:Note: - Since npm init vue@latest alredy uses vite, we have not included a vite guide for Vue.Create Vue App - Use Create Vue to efficiently build a Vue.js-based with TypeScript and Vite modern permaweb application Permaweb Application Constraints 100% Front-end application (No Server-Side Backend) Applications are served from a sub-path (https://[gateway]/[TX_ID]) Built with ❤️ by the Arweave community. Learn more at Arweave.org

---

# 23. ANS-103 Succinct Proofs of Random Access  Cooking with the Permaweb

Document Number: 23
Source: https://cookbook.arweave.net/tooling/specs/ans/ANS-103.html
Words: 1126
Quality Score: 0.503
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

ANS-103: Succinct Proofs of Random Access Status: Draft Authors: Sam Williams sam@arweave.org, Lev Berman ldmberman@protonmail.com Abstract This document describes the new consensus mechanism for the Arweave network based on the competition to find a chunk of the past data in a set of historical chunks inferred from the latest agreed-upon blockweave state.Motivation At the time when this specification is written, the consensus mechanism employed by the Arweave network is a classical Proof of Work with an additional requirement of including a chunk (up to 256 KiB) of the past data into the hash preimage where the chunk is deterministically determined by the latest state of the blockweave.While this approach incentivizes the network to keep historical data, it does not impose any significant restrictions on the speed of access to data a miner needs to be competitive. Specifically, miners can benefit from using a remote storage pool. Moreover, combined with a computation pool, it can serve Proof of Work preimages to millions of clients per second via a Gbit Internet link. A storage and computation pool has been evidenced in the Arweave network by a decreased number of public nodes and a simultaneous increase of the network hashpower and people claiming to be part of the pool.Therefore, the new consensus algorithm's first goal is to make the mining advantage grow sharply with the growing speed of access to data, promoting replication more aggressively.The second but not less important goal is to reduce the energy consumed by the network. Proof of Work networks are known for their energy-intensity. Reduced energy consumption reduces the carbon footprint, widely believed to be very harmful to the planet. We believe the environment-friendliness of the consensus mechanism is crucial for the long-term sustainability of the Arweave platform.To sum up, the consensus algorithm described here aims at two major goals.Disincentivize miners from retrieving data on demand from the network. In other words, incentivize miners to store data as close to the mining machine as possible.Reduce network's energy consumption.Reference Implementation Link.Specification Prerequsites Indexed Dataset The core of the new mechanism - continuous retrieval of chunks of the past data. Every chunk is identified by a global offset, as we want to make the possession of any byte equally incentivized. Therefore, the whole weave has to be indexed so that every chunk is quickly accessible by its global offset.Starting from the release 2.1, the Arweave Erlang client maintains such an index.Slow Hash The consensus mechanism needs a deterministic but unpredictable way to choose candidate chunks, to make the miners continuously access storage. However, choosing candidate chunks cannot be too easy as it would allow miners to reduce the number of chunks they ever work with. There are two threats associated with that. One threat is the lower cost of the computation expenditure, as compared to the cost of storing extra data required for the same probability of a reward. The second threat is the existing computation technology that, although being more expensive than storing the entire weave, is so efficient that it outperforms even the most efficient data retrieval based client.Starting from release 1.7, the Arweave protocol relies on RandomX, a proof-of-work algorithm optimized for general-purpose CPUs.Algorithm Description Every block uniquely determines a Search Space - a set of offsets (Recall Bytes) on the [0, weave size at a certain block (Search Space Upper Bound)] interval.Miner Steps Generate a random nonce and generate a slow hash (H0) of the hash of a Merkle tree containing the current state, the candidate block, and the nonce.Compute the unique recall byte from H0, the hash of the previous block (PrevH), and Search Space Upper Bound.Search the local storage for the chunk containing the computed Recall Byte. If not found, repeat from the first step.Compute a fast hash of the hash of the Merkle tree containing the slow hash computed at the first step and the located chunk.Check whether the computed hash is bigger than the current mining difficulty (the number computed from its binary digit big-endian representation is bigger). If not, repeat from the first step. If yes, pack and distribute the block (the block contains the nonce and the chunk).The solution chunk together with the Merkle proofs of its inclusion in the blockweave we call Succinct Proof of Random Access (or SPoRA) and use as a name for the new consensus mechanism.Verifier Steps Perform one iteration over the miner steps where the nonce and the chunk are found in the verified block.Rationale Search Space Constraints Search Space needs to be big enough for two reasons:make it prohibitively expensive to download the entire search space on demand; note that the prior consensus mechanism can be viewed as an edge case of SPoRA where the search space consists of a single chunk; the efficiency of serving data to the computing agents on demand depends on the network bandwidth, which grows over time.make it prohibitively expensive to compensate for the lack of data by hashing.On the other hand, Search Space needs to be small enough to incentivize miners to replicate the rarer parts of the weave, which would give them and advantage over miners who replicated less of the corresponding area at the corresponding blocks.We choose the Search Space size to be 10% of the weave. In this case, 10% of the miners storing unique 10% of the weave in the network where everybody stores 90% of the weave are roughly 1.2 times more efficient than the rest of the miners. It holds for various ratios of the time it takes to compute a RandomX hash and the time it takes to look up a chunk.Pseudocode The ar_deep_hash definition.mine(Nonce, BlockPreimage, PrevH, SearchSpaceUpperBound):
// Compute a slow hash.
H0 := randomx_hash(concat(Nonce, BlockPreimage))
RecallByte := pick_recall_byte(H0, PrevH, SearchSpaceUpperBound)
// Search the local storage for the chunk containing Recall Byte.
SPoA := get_spoa_by_byte(RecallByte)
if SPoA == not_found
mine(random_nonce(), BlockPreimage, PrevH, SearchSpaceUpperBound)
Chunk := get_chunk(SPoA)
SolutionHash := randomx_hash(concat(H0, PrevH, Timestamp, Chunk))
if validate(Candidate, Diff)
return
mine(random_nonce(), BlockPreimage, PrevH, SearchSpaceUpperBound)
pick_recall_byte(H0, PrevH, SearchSpaceUpperBound):
SubspaceNumber := remainder(hash_to_number(H0), SUBSPACES_COUNT)
SearchSpaceSize := integer_division(SearchSpaceUpperBound, 10)
EvenSubspaceSize := integer_division(SearchSpaceUpperBound, SUBSPACES_COUNT)
SearchSubspaceSize := integer_division(SearchSpaceSize, SUBSPACES_COUNT)
SubspaceStart := SubspaceNumber * EvenSubspaceSize
SubspaceSize := min(SearchSpaceUpperBound - SubspaceStart, EvenSubspaceSize)
EncodedSubspaceNumber := number_to_binary(SubspaceNumber)
SearchSubspaceSeed := hash_to_number(sha256(concat(PrevH, EncodedSubspaceNumber)))
SearchSubspaceStart := remainder(SearchSubspaceSeed, SubspaceSize)
SearchSubspaceByteSeed := hash_to_number(sha256(H))
SearchSubspaceByte := remainder(SearchSubspaceByteSeed, SearchSubspaceSize)
return AbsoluteSubspaceStart + remainder(SearchSubspaceStart + SearchSubspaceByte, SubspaceSize) The work was heavily inspired by Permacoin: Repurposing Bitcoin Work for Data Preservation by Andrew Miller, Ari Juels, Elaine Shi, Bryan Parno, and Jonathan Katz from Microsoft Research.We suggest to use the existing, growing, and always accessible Arweave dataset instead of one pre-generated by a trusted dealer. We use a slow specialized hardware-resistant hash to make it prohibitively expensive to compensate for the lack of local data with computation. Finally, we provide the network with the incentive to replicate data uniformly.

---

# 24. ANS-106 Do-Not-Store Request  Cooking with the Permaweb

Document Number: 24
Source: https://cookbook.arweave.net/tooling/specs/ans/ANS-106.html
Words: 324
Quality Score: 0.503
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

ANS-106: Do-Not-Store Request Status: Draft-1 Authors: Abhav Kedia abhav@arweave.org, Sam Williams sam@arweave.org Abstract This document describes a transaction format that users of the Arweave network can use to request miners to not store certain kinds of data, for various reasons. In order to request non-storage, upload a transaction with the transaction ID of the data in question, along with tags as specified here. Upon receiving this data, nodes in the network will independently decide whether or not to accept the request.Motivation The Arweave permanent storage protocol enables a truly permanent digital store of media and documents.There might be various reasons why persons or entities might wish to remove some data from the network. These include privacy, government regulation and copyright violations. By uploading a transaction that adheres to this standard, users of the network can ensure that their request is broadcast to all relevant storage node operators.Specification Transaction Format A Do-Not-Store Request transaction MUST be a transaction with the following tags:Tag Name Optional?Tag Value App-Name False Do-Not-Store Do-Not-Store False Arweave Txn ID of the data in question Category True Category-Tag Geography True If requesting removal in particular countries, include the 2 letter Country-Code (Alpha-2, ISO 3166) Content-Type True A guide to the type of content included in the body of the transaction, in order to aid rendering.The body of the transaction must then include a text description of the reason for the case describing why the data should not be stored. Multiple Do-Not-Store tags may be added to request non-storage of multiple data items at once.Category-Tags Category tags are a short-hand way of specifying the reason for removal. Common tags include Private, Regulation, Copyright. Custom category tags may be used as appropriate. Custom tags must not exceed 50 characters.Future work There may be a need to request removal based on various properties of data or tags associated with them. This standard may be extended to allow for lists of transactions and/or associated filtering criteria.

---

# 25. ANS-110 Asset Discoverability  Cooking with the Permaweb

Document Number: 25
Source: https://cookbook.arweave.net/tooling/specs/ans/ANS-110.html
Words: 379
Quality Score: 0.503
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

ANS-110: Asset Discoverability Status: Draft Authors: Tom Wilson (tom@hyper.io), Sam Williams (sam@arweave.org), Abhav Kedia (abhav@arweave.org) Abstract This document specifies a data protocol that allows assets to be discovered and uniformly dised on the permaweb.Motivation The permaweb is a rich collection of various kinds of data -- media, content, functions, and applications. A standard protocol for identifying assets enables discoverability for dashboards, exchanges, and higher-level permaweb services. By providing an extensible data protocol for transactions, creators and publishers can harness the power of permaweb-wide content discoverability -- making it easily appear in various applications and contexts across the permaweb.This protocol would enable, for example, a marketplace or exchange where users trade media assets to render them in a user-friendly way. By extending asset transactions using these identifiers, creators provide a clear and composable set of identifiers that marketplaces or exchanges can use to give a detailed description of the asset. Another example would be a search engine service that may want to index specific types of assets.Specfication Transaction Format To utilize Asset Discoverability, a creator or publisher can dispatch or post an Arweave transaction specifying the following tags.Tag Name Optional?Tag Value Title False A maximum of 150 characters used to identify the content, this title can provide a quick eye catching description of the asset Type* False Type of asset. One or more of: meme, image, video, podcast, blog-post, social-post, music, token, web-page, profile Topic* True Zero to many topics that can be used to locate assets of a given type by a specific topic. For example: an asset of type meme might have the following two topics, Funny, Sports.Description True A longer description of 300 characters that can provide a set of details further describing the asset Usage The primary purpose of these tags is to allow content devs to leverage GraphQL to find asset transactions of a specific type or topic for use in their applications.query {
transactions(
first: 100,
tags: [
{ name: "Type", values: ["meme", "blog-post"] },
{ name: "Topic:Funny", values: ["Funny"] },
{ name: "Topic:Jokes", values: ["Jokes"] }
]) {
edges {
node {
id
owner {
address
}
tags {
name
value
}
}}
}
} This GraphQL query filters based on Type and Topic tags to filter Assets for an aggregate list dis.

---

# 26. Querying Arweave with GraphQL  Cooking with the Permaweb

Document Number: 26
Source: https://cookbook.arweave.net/tooling/querying-arweave.html
Words: 812
Quality Score: 0.498
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Querying Arweave with GraphQL Arweave provides a simple way of querying for transactions and filtering them by tags. Arweave GraphQL-compatible indexing services provide endpoints users can post GraphQL queries to, and also provide a ground for trying queries.GraphQL is a flexible query language that services can use to build a customized data schema for clients to query. GraphQL also allows clients to specify which elements of the available data structure they would like to see in the results.Public Indexing Services arweave.net graphql the original graphql endpoint, managed by ar.io goldsky search service a public service specifically optimized for search using a superset of the graphql syntax, managed by goldsky ar.io decentralized indexing A decentralized network for indexing services. Currently in testing with L1 transactions available.Executing a GraphQL Query To query arweave we’ll need to access it through an indexing service that supports GraphQL. Use one of the GraphQL grounds listed above to get started!Copy and paste in the following query query {
transactions(tags: [{
name: "App-Name",
values: ["PublicSquare"]
}])
{
edges {
node {
id
tags {
name
value
}
}
}
}
} If you’re not familiar with GraphQL it can seem a little overwhelming at first but once you know the structure, it’s fairly easy to read and understand.query { ( ) { } } In the example query we pasted our is transactions but we could also query for blocks. A full description of Arweave's GraphQL schema is written up in the Arweave GraphQL Guide. The guide refers to the filter criteria as “Query Structures” and the complete data structure definition of transactions and blocks as “Data Structures”.When it comes to the , the thing to note is that you can specify a subset of the complete data structure you’re interested in. For example, the complete data structure for a transactions schema is listed here.In our case we’re interested in the id and complete list of tags for any transaction matching our filter criteria.Hit the big “” button in the middle of the ground to run the query. You’ll notice we get back a list of transactions in the results data structure we specified in our original query.If you’re new to blockchains this is unexpected, we haven’t built anything, why do these results exist? It turns out, the “PublicSquare”: “App-Name” tag we’ve filtered for has been in use for a while.Arweave protocol's founder, Sam Williams, proposed the transaction format a few years ago in a github code snippet. Since then builders in the ecosystem have been building on and around it, experimenting, posting transactions with those tags.Back to querying Arweave. You’ll notice in the GraphQL results that there are no readable post messages, just tags and information about posts.This is because the GraphQL indexing service is concerned with indexing and retrieving header data for transactions and blocks but not their associated data.To get the data of a transaction we need to look it up using another HTTP endpoint.https://arweave.net/ Copy and paste one of the id’s in your query results and modify the above link, appending the id. It should look something like this… https://arweave.net/eaUAvulzZPrdh6_cHwUYV473OhvCumqT3K7eWI8tArk The result of navigating to that URL in the browser (HTTP GET) would be retrieving the content of the post (stored in the transactions data). In this example it’s… Woah that's pretty cool 😎 (For a complete listing arweave HTTP endpoints visit the HTTP API documentation.) Posting a Query From JavaScript Posting a GraphQL query from javascript isn't much different than posting it in the ground.First install the arweave-js package for easy access to a GraphQL endpoint.npm install --save arweave Then enter a slightly more advanced version of the example query from above and await the results of posting it.import Arweave from 'arweave';
// initialize an arweave instance
const arweave = Arweave.init({});
// create a query that selects tx data the first 100 tx with specific tags
const queryObject = {
query:
`{
transactions(
first:100,
tags: [
{
name: "App-Name",
values: ["PublicSquare"]
},
{
name: "Content-Type",
values: ["text/plain"]
}
]
)
{
edges {
node {
id
tags {
name
value
}
}
}
}
}`
};
const results = await arweave.api.post('/graphql', queryObject);Multiple Queries It is possible to post multiple queries in a single round-trip to the GraphQL endpoint. This example queries the name transaction (each as a separate query) for two wallet addresses using the now obsolete (replaced by ar-profile) but still permanent arweave-id protocol.query {
account1: transactions(first: 1, owners:["89tR0-C1m3_sCWCoVCChg4gFYKdiH5_ZDyZpdJ2DDRw"],
tags: [
{
name: "App-Name",
values: ["arweave-id"]
},
{
name: "Type",
values: ["name"]
}
]
) {
edges {
node {
id
owner {
address
}
}
}
}
account2: transactions(first: 1, owners:["kLx41ALBpTVpCAgymxPaooBgMyk9hsdijSF2T-lZ_Bg"],
tags: [
{
name: "App-Name",
values: ["arweave-id"]
},
{
name: "Type",
values: ["name"]
}
]
) {
edges {
node {
id
owner {
address
}
}
}
}
} Resources Arweave GQL Reference ArDB package ar-gql package Search Indexing Service

---

# 27. React Starter Kits  Cooking with the Permaweb

Document Number: 27
Source: https://cookbook.arweave.net/kits/react/index.html
Words: 100
Quality Score: 0.497
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

React Starter Kits React is a popular library used for building user interfaces. Alongside other popular tools such as create-react-app, a React project can be compiled into a bundle. This bundle can be uploaded as a transaction to the permaweb where it will serve as a single page application.React Starter Kit Guides:Vite - React + Vite, publish with permaweb-deploy Create React App - utilize Create React App to build a React permaweb app Permaweb Application Constraints 100% Front-end application (No Server-Side Backend) Applications are served from a sub-path (https://[gateway]/[TX_ID]) Built with ❤️ by the Arweave community. Learn more at Arweave.org

---

# 28. arkb  Cooking with the Permaweb

Document Number: 28
Source: https://cookbook.arweave.net/tooling/deployment/arkb.html
Words: 243
Quality Score: 0.495
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

arkb Requirements An Arweave wallet is required to deploy using arkb for covering the data transaction costs.Installation To install arkb run npm install -g arkb yarn add ar-gql Deploying When uploading a directory of files or a Permaweb application, by default arkb deploys each file separately as an L1 transaction, with the option to bundle the transactions using Bundlr.Static Build Permaweb applications are statically generated, meaning that the code and content are generated ahead of time and stored on the network.Below is an example of a static site. To deploy this to the Permaweb, the build directory will be passed in as the argument for the deploy flag.|- build
|- index.html
|- styles.css
|- index.js Default Deployment Deploying as an L1 transaction can take longer to confirm as it is directly uploaded to the Arweave network.arkb deploy [folder] --wallet [path to wallet] Bundled Deployment To deploy using Bundlr you will need to fund a Bundlr node.Bundlr node2 allows free transactions under 100kb.You can add custom identifiable tags to the deployment using tag-name/tag-value syntax.arkb deploy [folder] --use-bundler [bundlr node] --wallet [path to wallet] --tag-name [tag name] --tag-value [tag value] Other Commands Fund Bundlr arkb fund-bundler [amount] --use-bundler [bundlr node] * Funding a Bundlr instance can take up to 30 minutes to process Saving Keyfile arkb wallet-save [path to wallet] After saving your key you can now run commands without the --wallet-file option, like this arkb deploy [path to directory] Check Wallet Balance arkb balance

---

# 29. Entity Types  Cooking with the Permaweb

Document Number: 29
Source: https://cookbook.arweave.net/tooling/specs/arfs/entity-types.html
Words: 1168
Quality Score: 0.491
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Entity Types Overview Arweave transactions are composed of transaction headers and data payloads.ArFS entities, therefore, have their data split between being stored as tags on their transaction header and encoded as JSON and stored as the data of a transaction. In the case of private entities, JSON data and file data payloads are always encrypted according to the protocol processes defined below.Drive entities require a single metadata transaction, with standard Drive tags and encoded JSON with secondary metadata.Folder entities require a single metadata transaction, with standard Folder tags and an encoded JSON with secondary metadata.File entities require a metadata transaction, with standard File tags and an encoded Data JSON with secondary metadata relating to the file.File entities also require a second data transaction, which includes a limited set of File tags and the actual file data itself.Snapshot entities require a single transaction. which contains a Data JSON with all of the Drive’s rolled up ArFS metadata and standard Snapshot GQL tags that identify the Snapshot.Drive A drive is the highest level logical grouping of folders and files. All folders and files must be part of a drive, and reference the Drive ID of that drive.When creating a Drive, a corresponding folder must be created as well. This will act as the root folder of the drive. This separation of drive and folder entity enables features such as folder view queries, renaming, and linking.Drive Entity Transaction Example Folder A folder is a logical grouping of other folders and files. Folder entity metadata transactions without a parent folder id are considered the Drive Root Folder of their corresponding Drives. All other Folder entities must have a parent folder id. Since folders do not have underlying data, there is no Folder data transaction required.ArFS: "0.13"
Cipher?: "AES256-GCM"
Cipher-IV?: "<12 byte initialization vector as Base64>"
Content-Type: ""
Drive-Id: ""
Entity-Type: "folder"
Folder-Id: ""
Parent-Folder-Id?: ""
Unix-Time: ""
Data JSON {
"name": ""
} Folder Entity Transaction Example File A File contains uploaded data, like a photo, document, or movie.In the Arweave File System, a single file is broken into 2 parts - its metadata and its data.In the Arweave File System, a single file is broken into 2 parts - its metadata and its data.A File entity metadata transaction does not include the actual File data. Instead, the File data must be uploaded as a separate transaction, called the File Data Transaction. The File JSON metadata transaction contains a reference to the File Data Transaction ID so that it can retrieve the actual data. This separation allows for file metadata to be updated without requiring the file itself to be reuploaded. It also ensures that private files can have their JSON Metadata Transaction encrypted as well, ensuring that no one without authorization can see either the file or its metadata.ArFS: "0.13"
Cipher?: "AES256-GCM"
Cipher-IV?: "<12 byte initialization vector as Base64>"
Content-Type: ""
Drive-Id: ""
Entity-Type: "file"
File-Id: ""
Parent-Folder-Id: ""
Unix-Time: ""
Data JSON {
"name": "",
"size": "",
"lastModifiedDate": "",
"dataTxId": "",
"dataContentType": "",
"pinnedDataOwner": "" # Optional
} Pin Files Since the version v0.13, ArFS suports Pins. Pins are files whose data may be any transaction uploaded to Arweave, that may or may not be owned by the wallet that created the pin.When a new File Pin is created, the only created transaction is the Metadata Transaction. The dataTxId field will point it to any transaction in Arweave, and the optional pinnedDataOwner field is gonna hold the address of the wallet that owns the original copy of the data transaction.File Data Transaction Example The File Data Transaction contains limited information about the file, such as the information required to decrypt it, or the Content-Type (mime-type) needed to view in the browser.Cipher?: "AES256-GCM"
Cipher-IV?: "<12 byte initialization vector as Base64>"
Content-Type: ""
{ File Data - Encrypted if private } File Metadata Transaction Example The the File Metadata Transaction contains the GQL Tags necessary to identify the file within a drive and folder.Its data contains the JSON metadata for the file. This includes the file name, size, last modified date, data transaction id, and data content type.ArFS: "0.13"
Cipher?: "AES256-GCM"
Cipher-IV?: "<12 byte initialization vector as Base64>"
Content-Type: ""
Drive-Id: ""
Entity-Type: "file"
File-Id: ""
Parent-Folder-Id: ""
Unix-Time: ""
{ File JSON Metadata - Encrypted if private } Snapshot ArFS applications generate the latest state of a drive by querying for all ArFS transactions made relating to a user's particular Drive-Id. This includes both paged queries for indexed ArFS data via GQL, as well as the ArFS JSON metadata entries for each ArFS transaction.For small drives (less than 1000 files), a few thousand requests for very small s of data can be achieved relatively quickly and reliably. For larger drives, however, this results in long sync times to pull every piece of ArFS metadata when the local database cache is empty. This can also potentially trigger rate-limiting related ArWeave Gateway delays.Once a drive state has been completely, and accurately generated, in can be rolled up into a single snapshot and uploaded as an Arweave transaction. ArFS clients can use GQL to find and retrieve this snapshot in order to rapidly reconstitute the total state of the drive, or a large portion of it. They can then query individual transactions performed after the snapshot.This optional method offers convenience and resource efficiency when building the drive state, at the cost of paying for uploading the snapshot data. Using this method means a client will only have to iterate through a few snapshots instead of every transaction performed on the drive.Snapshot Entity Tags Snapshot entities require the following tags. These are queried by ArFS clients to find drive snapshots, organize them together with any other transactions not included within them, and build the latest state of the drive.ArFS: "0.13"
Drive-Id: ""
Entity-Type: "snapshot"
Snapshot-Id: ""
Content-Type: ""
Block-Start: ""
Block-End: ""
Data-Start: "" Snapshot Transaction GQL tags example Snapshot Entity Data A JSON data object must also be uploaded with every ArFS Snapshot entity. THis data contains all ArFS Drive, Folder, and File metadata changes within the associated drive, as well as any previous Snapshots. The Snapshot Data contains an array txSnapshots. Each item includes both the GQL and ArFS metadata details of each transaction made for the associated drive, within the snapshot's start and end period.A tsSnapshot contains a gqlNode object which uses the same GQL tags interface returned by the Arweave Gateway. It includes all of the important block, owner, tags, and bundledIn information needed by ArFS clients. It also contains a dataJson object which stores the correlated Data JSON for that ArFS entity.For private drives, the dataJson object contains the JSON-string-escaped encrypted text of the associated file or folder. This encrypted text uses the file's existing Cipher and Cipher-IV. This ensures clients can decrypt this information quickly using the existing ArFS privacy protocols.Snapshot Transaction JSON data example Schema Diagrams The following diagrams show complete examples of Drive, Folder, and File entity Schemas.Public Drive Public Drive Schema Private Drive Private Drive Schema

---

# 30. Accessing Arweave Data  Cooking with the Permaweb

Document Number: 30
Source: https://cookbook.arweave.net/fundamentals/accessing-arweave-data/index.html
Words: 385
Quality Score: 0.488
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Accessing Arweave Data One of Arweave's core strengths is permanent data storage, but stored data is only valuable if it can be efficiently discovered and retrieved. Arweave provides multiple methods for accessing data, each optimized for different use cases and requirements.Data Access Fundamentals All data on Arweave is accessible through gateways - HTTP endpoints that serve as bridges between users and the Arweave network. These gateways expose various interfaces and methods for retrieving data:Direct data retrieval - Access data by transaction ID Query interfaces - Search and filter data based on metadata Name resolution - Access data through human-readable names Path-based access - Navigate data collections like websites Access Methods 1. HTTP API The simplest way to access Arweave data is through direct HTTP requests using a transaction ID:https://arweave.net/{transaction-id} This method is ideal for:Retrieving known data by ID Simple integrations Direct data access without queries & Access → 2. GraphQL Queries For more complex data discovery and filtering, Arweave gateways provide GraphQL endpoints that enable sophisticated queries based on:Owner addresses Transaction tags Block heights Time ranges GraphQL is the preferred method for:Searching large datasets Building applications that need to discover data Complex filtering based on metadata → 3. Path Manifests Path manifests enable organizing multiple files into navigable collections, similar to traditional websites:https://arweave.net/{manifest-id}/{path/to/file} Use manifests for:Hosting websites and web applications Creating browsable file collections Organizing related content → 4. ArNS (Arweave Name System) ArNS provides human-readable names that resolve to Arweave transaction IDs:https://{name}.arweave.dev ArNS is perfect for:User-friendly URLs Updatable references to content Building permanent web applications → Choosing the Right Method Method Best For Example Use Case HTTP API Direct access by ID Loading a specific image or file GraphQL Data discovery and filtering Finding all transactions with specific tags Manifests Multi-file collections Hosting a website or application ArNS Human-readable addressing Creating a permanent blog or dApp Gateway Infrastructure All these access methods are provided by Arweave gateways. Gateways can be:Public gateways like arweave.net - Open for anyone to use Private gateways - Run by individuals or organizations for their own use AR.IO gateways - Decentralized gateway network providing enhanced features Set up gateway access for your application Query data with GraphQL to build dynamic applications Create path manifests for organizing content Register ArNS names for user-friendly addressing Additional Resources Querying Arweave Guide GraphQL Reference

---

# 31. Community  Cooking with the Permaweb

Document Number: 31
Source: https://cookbook.arweave.net/community/index.html
Words: 109
Quality Score: 0.481
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Community Resources for the Permaweb developer community and archived content.Developer Resources Forums and discussion channels Community projects and collaborations Developer meetups and events Contribution guidelines Archive (Deprecated Content) Historical documentation for reference:SmartWeave (Legacy) SmartWeave - Legacy smart contract system Profit Sharing Tokens (PSTs) - Legacy token standard Atomic Tokens - Legacy NFT implementation Warp SDK (Legacy) Introduction Deploying Contracts Reading State Write Interactions Contract Evolution Deprecated Guides Atomic Tokens Guide Migration Notes The archived content represents older approaches and tools that have been superseded by newer, more efficient solutions. Refer to the current Concepts and Guides for up-to-date information.Built with ❤️ by the Arweave community. Learn more at Arweave.org

---

# 32. Cooking with the Permaweb  Cooking with the Permaweb

Document Number: 32
Source: https://cookbook.arweave.net/index.html
Words: 227
Quality Score: 0.479
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Cooking with the Permaweb The Permaweb Cookbook is a developer resource that provides the essential concepts and references for buiding applications on the Permaweb. Each concept and reference will focus on specific aspects of the Permaweb development ecosystem while providing additional details and usage examples.Developers Welcome to the Arweave development community, where the past is forever etched in the blockchain and the future is full of endless possibilities. Let's build the decentralized web together!Read More Contributing The Cookbook is designed in a way that makes it easy for new Permaweb developers to contribute. Even if you don't know how to do something, contributing to the cookbook is a great way to learn!Check out all open issues here. Contribution guidelines here. if you find the cookbook is missing a concept, guide or reference, please add an issue.Read More How to Read the Cookbook The Permaweb Cookbook is split into different sections, each aimed at a different goal.Section Description Core Concepts Building blocks of the Permaweb that are good to know for development Guides Snack-sized guides about different tools for development References References to commonly needed code snippets Starter Kits Front-end Framework Starters to get you started building on the Permaweb in no time Quick Starts These are small guides to help developers from every experience level to ship code the the permaweb.Hello World (No Code) Hello World (CLI)

---

# 33. ArNS - Arweave Name System  Cooking with the Permaweb

Document Number: 33
Source: https://cookbook.arweave.net/fundamentals/accessing-arweave-data/arns.html
Words: 523
Quality Score: 0.475
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

ArNS - Arweave Name System Overview The Arweave Name System (ArNS) is the phonebook of the Permaweb.It is a decentralized and censorship-resistant naming system that is enabled by AR.IO Gateways and used to connect friendly names to Permaweb apps, pages and data.This system works similarly to traditional DNS, where a user can purchase a name in a registry and DNS Name servers resolve these names to IP addresses.With ArNS, the registry is decentralized, permanent and stored on Arweave (via AO), and each AR.IO gateway acts as both cache and name resolver. Users can register a name within the ArNS Registry, like "my-name" and set a pointer to any Arweave Transaction ID.AR.IO Gateways will resolve that name as one of their own subdomains, eg. https://laserilla.arweave.net and proxy all requests to the associated Arweave Transaction ID. Each registered name can also have under names associated with it that each point to an Arweave Transaction ID, like https://v1_laserilla.arweave.net, giving even more flexibility and control to its owner.The ArNS Registry ArNS uses AO to manage its name records. Each record, or name, is leased by a user or bought permanently and tied to an ANT token. You can register multiple ArNS names to a single ANT, but you cannot register multiple ANTs to a single ArNS name - the gateways wouldn't know where to point the routing ID.ArNS names can be up to 32 characters, including numbers [0-9], letters [a-z], and dashes [-]. The dashes cannot be trailing dashes, e.g. -myname.ANTs (Arweave Name Tokens) ANTs are a crucial part of the ArNS ecosystem - they are the actual key to owning an ArNS name. When you register an ArNS name to an ANT, the ANT then becomes the transfer method for that name. The ArNS registry does not care who owns the ANT, it simply knows what name ANT it belongs to.Within ANTs you can build out whatever functionality you wish, within the scope ArNS registry approved source code transaction list.Under_Names Undernames are records held and managed by your ANT (Arweave Name Token). These records can be created and managed without even owning an ARNS name, and will be transferred along with the ant when sent to a new owner. Likewise if your ArNS name expires, and you register your ANT to a new ArNS name, all your undername will remain intact.Example: you own oldName.arweave.net.then: You create the undername "my" - my_oldName.arweave.net.then: oldName.arweave.net expires, and you register newName.arweave.net to your ANT.now: my_ undername is accessable on newName - my_newName.arweave.net.Below is an example of an ANT contract State:{
balances:{ QGWqtJdLLgm2ehFWiiPzMaoFLD50CnGuzZIPEdoDRGQ : 1 },
controller: "QGWqtJdLLgm2ehFWiiPzMaoFLD50CnGuzZIPEdoDRGQ",
evolve: null,
name: "ArDrive OG Logo",
owner: "QGWqtJdLLgm2ehFWiiPzMaoFLD50CnGuzZIPEdoDRGQ",
records:{
@:{ transactionId: "xWQ7UmbP0ZHDY7OLCxJsuPCN3wSUk0jCTJvOG1etCRo" },
undername1:{ transactionId: "usOLUmbP0ZHDY7OLCxJsuPCN3wSUk0jkdlvOG1etCRo" }
},
ticker:"ANT-ARDRIVE-OG-LOGO"
} the base "@" record is the initial routing id for the ANT. if you registered 'my-name' to this ANT, and tried to access it via my-name.arweave.net, you would be redirected to the @ record's transactionId.if you tried to access undername1_my-name.arweave.net, you would get 'undername1's transactionId.ANT's, in theory, have an UNLIMITED number of undernames. However, how many will be served depends on which tier is used with your ArNS name.Resources ArNS App ArNS Docs

---

# 34. ANS-105 License Tags  Cooking with the Permaweb

Document Number: 34
Source: https://cookbook.arweave.net/tooling/specs/ans/ANS-105.html
Words: 453
Quality Score: 0.473
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Authors: Sam Williams sam@arweave.org, Abhav Kedia abhav@arweave.org Abstract This standard outlines a mechanism for arbitrarily tagging any transaction on the permaweb with the license under which it is published. The standard focuses on simplicity and ease of use in order to encourage broad adoption across the permaweb ecosystem.Motivation The goal of the Arweave ecosystem is to create a permanent, collective commons of all valuable knowledge and history, available to all people at any time. Just like the original web, by its open nature this ecosystem encourages wide reuse and copying of data. On the traditional web, this has led to a broad corpus of widely shared information that lacks associated licensing data.By making simple use of the tagging system exposed by Arweave transactions and data entries we can avoid a repeat of this situation, and instead build a web where it is common practice to communicate the license of any piece of data. Due to the inseparable nature of Arweave tags from their associated data, the licensing data of all complying transactions will be atomically communicated to uses -- it is impossible to communicate a link to the data, without also transmitting its licensing information. Due to the nature of Arweave's tagging system, this is achieved without any mandatory or noticeable effect on user experience (when the data is rendered in browsers, etc).Specification The license tagging format is composed of a single additional tag on any transaction on the Arweave network, as well as two additional transaction formats for defining license types.In order to publish the data of a transaction under a given transaction format, simply add the following tags:Tag Name Optional?Tag Value License False TXID of License Definition Title True The title of the work Creator True The name/identifier of the creator(s) of the work Source True A link to the source where the material was obtained, if applicable In order to assert that a previously uploaded transaction has a given license, provide the following tags:Tag Name Optional?Tag Value App-Name False "License-Assertion" Original False TXID of original upload License False TXID of updated License Definition In order to define a license or related legal tool (such as CC0), submit a transaction with the following tags:Tag Name Optional?Tag Value App-Name True "License-Definition" Logo True TXID of License Logo Short-Name True A short (max 64 characters) 'ticker' with which to refer to the license Content-Type True The MIME type of the contained file, describing the license The body of the transaction must contain the legal text of the license being defined.License Logo transactions should be defined as follows:Tag Name Optional?Tag Value Content-Type False The MIME type of the contained file The body of the transaction must contain the visual representation of the license's logo.

---

# 35. Gateways in the Arweave Network  Cooking with the Permaweb

Document Number: 35
Source: https://cookbook.arweave.net/fundamentals/accessing-arweave-data/gateways.html
Words: 275
Quality Score: 0.473
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Gateways in the Arweave Network Gateways serve as the interface between the Arweave network and end-users, making permaweb data easily accessible through standard web browsers. Often described as the "front door to the permaweb," these services allow users to interact with blockchain-stored content in a familiar web-like experience.When you access content on Arweave, you typically use a URL structure like:https:/// This allows HTML files to render as web pages, images to dis properly, and other data types to be served appropriately—creating an experience similar to the traditional web despite the content being stored on a decentralized network.Key Functions of Gateways Gateways provide several critical services beyond basic content delivery:Content Caching: Store frequently accessed transactions to improve performance Data Indexing: Provide GraphQL interfaces for querying transactions by tags and metadata Network Seeding: Help distribute transactions throughout the Arweave network Content Moderation: Apply content policies to determine which data is served Relationship to Core Protocol It's important to understand that gateways are not part of the core Arweave protocol. This distinction has several implications:Operating a gateway is separate from running a node that secures the network There is no built-in protocol-level incentive structure for gateway operators Gateway services can implement their own economic models and incentives Applications can operate their own gateways for improved performance This separation allows for a more flexible and decentralized ecosystem where different gateway operators can experiment with various service models.Several gateway services currently serve the Arweave ecosystem:arweave.net - Operated by the Arweave team arweave.world arweave.asia arweave.live g8way.io The AR.IO project is working to make gateway operation more accessible, potentially increasing the decentralization of access points to the network.ArWiki Gateway Documentation AR.IO Project

---

# 36. Cooking with the Permaweb

Document Number: 36
Source: https://cookbook.arweave.net/fundamentals/wallets-and-keyfiles/creating-a-wallet.html
Words: 167
Quality Score: 0.471
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Creating a Wallet Users can create Arweave and AO wallets without requiring any technical knowledge by using wallets like Wander open in new window or Beacon open in new window.These are third-party applications, so as with most of crypto DYOR before choosing a wallet.Generating a wallet programmatically Arweave wallets can also be generated programatically.Creating a wallet with arweave-js npm install arweave arweave.wallets.generate().then((key) => {
console.log(key);
// {
// "kty": "RSA",
// "n": "3WquzP5IVTIsv3XYJjfw5L-t4X34WoWHwOuxb9V8w...",
// "e": ...
});Creating a wallet from the command line If you would prefer to create an Arweave wallet through a command-line application, you can use the ArDrive CLI.npm install -g ardrive-cli You can generate a seed phrase with the command generate-seedphrase:# Generate seed-phrase
ardrive generate-seedphrase
"this is an example twelve word seed phrase that you could use" Or, you can generate a wallet file using generate wallet:# Generate a wallet and store it in a chosen output file
ardrive generate-wallet > /path/to/wallet/file.json Built with ❤️ by the Arweave community. Learn more at Arweave.org

---

# 37. Getting Started  Cooking with the Permaweb

Document Number: 37
Source: https://cookbook.arweave.net/getting-started/index.html
Words: 160
Quality Score: 0.471
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Getting Started Welcome to the Permaweb Cookbook! This guide will help you get started building decentralized applications on Arweave.Start Here Welcome & Overview - Introduction to Arweave and the Permaweb Zero-deployed Minimal Full Stack App - Build your first app without writing code Contributing - How to contribute to this cookbook What is the Permaweb?The Permaweb is a global, community-owned web that anyone can contribute to or get paid to maintain. It's built on top of Arweave, a decentralized storage network that permanently stores data.Quick Start Options Choose your path based on your experience level:No-Code - Use visual tools to deploy your first app Frontend Developer - Deploy a React/Vue/Svelte app Full-Stack - Build applications with data storage Blockchain Developer - Integrate with smart contracts Next Steps Once you've completed the getting started guide, explore:Core Concepts to understand how Arweave works Guides for step-by-step tutorials Tooling for development tools Built with ❤️ by the Arweave community. Learn more at Arweave.org

---

# 38. Privacy  Cooking with the Permaweb

Document Number: 38
Source: https://cookbook.arweave.net/tooling/specs/arfs/privacy.html
Words: 700
Quality Score: 0.467
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Privacy The Arweave blockweave is inherently public. But with apps that use ArFS, like ArDrive, your private data never leaves your computer without using military grade (and quantum resistant) encryption. This privacy layer is applied at the Drive level, and users determine whether a Drive is public or private when they first create it. Private drives must follow the ArFS privacy model.Every file within a Private Drive is symmetrically encrypted using AES-256-GCM. Every Private drive has a master "Drive Key" which uses a combination of the user's Arweave wallet signature, a user defined drive password, and a unique drive identifier (uuidv4). Each file has its own "File Key" derived from the "Drive Key". This allows for single files to be shared without exposing access to the other files within the Drive.Once a file is encrypted and stored on Arweave, it is locked forever and can only be decrypted using its file key.Deriving Keys Private drives have a global drive key, D, and multiple file keys F, for encryption. This enables a drive to have as many uniquely encrypted files as needed. One key is used for all versions of a single file (since new file versions use the same File-Id) D is used for encrypting both Drive and Folder metadata, while F is used for encrypting File metadata and the actual stored data. Having these different keys, D and F, allows a user to share specific files without revealing the contents of their entire drive.D is derived using HKDF-SHA256 with an unsalted RSA-PSS signature of the drive's id and a user provided password.F is also derived using HKDF-SHA256 with the drive key and the file's id. Other wallets (like Wander) integrate with this Key Derivation protocol just exposing an API to collect a signature from a given Arweave Wallet in order to get the SHA-256 signature needed for the HKDF to derive the Drive Key.An example implementation, using Dart, is available here, with a Typescript implementation here.Private Drives Drives can store either public or private data. This is indicated by the Drive-Privacy tag in the Drive entity metadata.If a Drive entity is private, an additional tag Drive-Auth-Mode must also be used to indicate how the Drive Key is derived. ArDrive clients currently leverage a secure password along with the Arweave Wallet private key signature to derive the global Drive Key.Drive-Auth-Mode?: 'password' On every encrypted Drive Entity, a Cipher tag must be specified, along with the public parameters for decrypting the data. This is done by specifying the parameter with a Cipher-* tag. eg. Cipher-IV. If the parameter is byte data, it must be encoded as Base64 in the tag.ArDrive clients currently leverage AES256-GCM for all symmetric encryption, which requires a Cipher Initialization Vector consisting of 12 random bytes.Cipher?: "AES256-GCM"
Cipher-IV?: "<12 byte initialization vector as Base64>" Additionally, all encrypted transactions must have the Content-Type tag application/octet-stream as opposed to application/json Private Drive Entities and their corresponding Root Folder Entities will both use these keys and ciphers generated to symmetrically encrypt the JSON files that are included in the transaction. This ensures that only the Drive Owner (and whomever the keys have been shared with) can open the drive, discover the root folder, and continue to load the rest of the children in the drive.Private Files When a file is uploaded to a private drive, it by default also becomes private and leverages the same drive keys used for its parent drive. Each unique file in a drive will get its own set of file keys based off of that file's unique FileId. If a single file gets a new version, its File-Id will be reused, effectively leveraging the same File Key for all versions in that file's history.These file keys can be shared by the drive's owner as needed.Private File entities have both its metadata and data transactions encrypted using the same File Key, ensuring all facets of the data is truly private. As such, both the file's metadata and data transactions must both have a unique Cipher-IV and Cipher tag:Cipher?: "AES256-GCM"
Cipher-IV?: "<12 byte initialization vector as Base64>" Just like drives, private files must have the Content-Type tag set as application/octet-stream in both its metadata and data transactions:Content-Type: "application/octet-stream"

---

# 39. ANS-102 Bundled Data - JSON Serialization  Cooking with the Permaweb

Document Number: 39
Source: https://cookbook.arweave.net/tooling/specs/ans/ANS-102.html
Words: 708
Quality Score: 0.467
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

ANS-102: Bundled Data - JSON Serialization Status: Standard Abstract This document describes the data format and directions for reading and writing bundled data. Bundled data is a way of writing multiple logical data transactions (referred to as DataItems in this document) into one top level transaction. A DataItem shares many of the same properties as normal data transaction, in that it has an owner, data, tags, target, signature, and id. It differs in that it has no ability to transfer tokens, and no reward, as the top level transaction pays the reward for all bundled data.Motivation Bundling multiple logical data transactions into one transaction provides a number of benefits:To allow delegation of payment for a DataItem to a 3rd party, while maintaining the identity and signature of person who created the DataItem, without them needing to have a wallet with funds.Allow multiple DataItems to be written as a group.To increase the throughput of logically independent data writes to the Arweave network Reference Implementation There is a reference implementation for the creation, signing, and verification of DataItems and working with bundles in TypeScript Specification 1. Transaction Format 1.1 Transaction Tags A bundle of DataItems MUST have the following two tags present Bundle-Format a string describing the bundling format. The format for this standard is json Bundle-Version a version string. The version referred to in this standard is 1.0.0 1.2 Transaction Body Format This format for the transaction body is a JSON object in the following format {
items: [
{ DataItem },
{ DataItem }
]
} 1.3 DataItem Format A DataItem is a JSON object that has similar properties to a transaction:B64U Encoding indicates the field is Base64Url encoded binary.All properties MUST be present, for optional values the value in 'Empty Value' MUST be used.Field Description Encoding Empty Value owner The public key of the owner B64U target An address that this DataItem is being sent to B64U Empty String nonce A value to prevent re attacks B64U Empty String tags An array of tag objects Json Array Empty Json Array data The data contents B64U signature A signature produced by owner B64U id The id the item B64U A tag object is a JSON object with the following two keys. A tag object MUST NOT have any other keys.Field Description Encoding Empty Value name Name of the tag B64U value Value of the tag B64U The fields in the DataItem and Tags objects can be handled in an identical way as their counterpart in a regular Arweave transaction.The nonce field in DataItem is optional, and is an arbitrary value to allow bundling gateways to provide protection from re attacks against them or their users.2. DataItem signature and id The signature, and id for a DataItem is built in a manner similar to Arweave 2.0 transaction signing. It uses the Arweave 2.0 deep-hash algorithm. The 2.0 deep-hash algorithm operates on arbitrarily nested arrays of binary data, i.e a recursive type of DeepHashChunk = Uint8Array | DeepHashChunk[].There is reference implementations for the deep-hash algorithm in TypeScript and Erlang To generate a valid signature for a DataItem, the contents of the DataItem and static version tags, are passed to the deep-hash algorithm to obtain a message. This message is signed by the owner of the DataItem to produce the signature. The id of the DataItem, is the SHA256 digest of this signature.The exact structure and content passed into the deep-hash algorithm to obtain the message to sign is as follows:[
utf8Encoded("dataitem"),
utf8Encoded("1"),
owner,
target,
nonce,
[
... [ tag.name, tag.value ],
... [ tag.name, tag.value ],
...
],
data
] 3. Expanding a bundle of DataItems To read and expand a bundle of DataItems, each DataItem in the items should be verified using the verification algorithm. Individual items that fail verification MUST be discarded.In rare cases, an identical DataItem may exist in more that one transaction. That is, the contents and id of the DataItem are identical but exist in multiple Arweave transactions. Since they are identical, any of the copies can be discarded.4. Writing a bundle of DataItems To write a bundle of DataItems, each DataItem should constructed and signed, and placed in a transaction with the transaction body format and transaction tags specified in Section 1. Transaction Format.

---

# 40. Developing on the Permaweb  Cooking with the Permaweb

Document Number: 40
Source: https://cookbook.arweave.net/getting-started/welcome.html
Words: 203
Quality Score: 0.465
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Developing on the Permaweb Welcome to the Permaweb Creating applications on the Permaweb, which is built on the Arweave protocol, is similar to building traditional web applications but with some key differences.One major difference is that data is stored on the Permaweb permanently, as the name suggests, rather than on a centralized server. This means that once data is uploaded to the Permaweb, it cannot be deleted or altered. This can be beneficial for applications that require tamper-proof data storage, such as supply chain management or voting systems.Another difference is that the Permaweb is decentralized, meaning there is no central point of control or failure. This can provide increased security and reliability for applications.Additionally, the Permaweb uses a unique token, called AR, to pay for the storage of data on the network. This can add a new layer of complexity to application development, as developers need to consider how to integrate AR into their applications and handle payments.Overall, the experience of creating applications on the Permaweb can be challenging, but it can also be rewarding as it offers unique benefits over traditional web development.Hello Worlds Hello World (No Code) Hello World (CLI) Built with ❤️ by the Arweave community. Learn more at Arweave.org

---

# 41. Wallets and Keys  Cooking with the Permaweb

Document Number: 41
Source: https://cookbook.arweave.net/fundamentals/wallets-and-keyfiles/index.html
Words: 515
Quality Score: 0.459
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Wallets and Keys Arweave wallets serve as the gateway to interact with the Arweave blockchain network. They don't physically store tokens but instead manage the cryptographic keys needed to access and control your on-chain assets and data.What is an Arweave wallet?A wallet on Arweave is a cryptographic tool that secures your unique blockchain address. This address tracks your $AR token balance and enables network interactions such as sending transactions or working with AO Processes.It's important to understand that wallets don't actually "hold" tokens. Instead, they store the cryptographic public-private key pair that allows you to sign transactions and manage your on-chain assets. Token balances exist on the blockchain itself, linked to your wallet's address.Key Points Wallets contain the cryptographic keys needed to sign transactions and access funds on the Arweave network Only the wallet owner (with access to the private key) can authorize transactions for their address Arweave uses 4096-bit RSA-PSS key-pairs stored in JWK (JSON Web Keys) format Wallet addresses are derived from the public key using SHA-256 hashing and Base64URL encoding Private keys must be kept secure at all times, as they control access to your funds Keypair and Wallet Format Arweave utilizes 4096-bit RSA-PSS key-pairs stored in the JWK (JSON Web Keys) format. A typical JWK file for an Arweave wallet looks like this (with abbreviated values):{
"d": "cgeeu66FlfX9wVgZr5AXKlw4MxTlxSuSwMtTR7mqcnoE...",
"dp": "DezP9yvB13s9edjhYz6Dl...",
"dq": "SzAT5DbV7eYOZbBkkh20D...",
"e": "AQAB",
"ext": true,
"kty": "RSA",
"n": "o4FU6y61V1cBLChYgF9O37S4ftUy4newYWLApz4CXlK8...",
"p": "5ht9nFGnpfW76CPW9IEFlw...",
"q": "tedJwzjrsrvk7o1-KELQxw...",
"qi": "zhL9fXSPljaVZ0WYhFGPU..."
} In this JWK file:The n value represents your wallet's public key, which can be safely shared The d value (along with other fields) comprises your wallet's private key, which must be kept confidential These JWK files can be created and exported from wallet applications like Arweave.app or generated programmatically using arweave-js When using certain wallet applications, your private key may also be represented as a mnemonic seed phrase, which can be used to sign transactions or recover your wallet.Wallet Addresses Arweave wallet addresses are derived from the public key through a deterministic process:The SHA-256 hash of the public key is calculated This hash is then Base64URL encoded The result is a 43-character wallet address that's more convenient to use than the full 4096-bit public key This process creates a secure and verifiable link between your wallet address and public key, while providing a more human-readable format for everyday use.Wallet Security Your private key grants complete control over your wallet and funds. Anyone with access to your private key can transfer tokens from your address. As a developer, exercise extreme caution:Never include your keyfile in public GitHub repositories Don't store your private key on unsecured devices or cloud services Back up your private key or seed phrase securely Consider using hardware wallets for significant holdings Available Wallets Several wallet options are available for interacting with the Arweave network:Wander - Browser extension and mobile wallet for Arweave and AO Beacon - Browser extension and mobile wallet for Arweave and AO Arweave.app - Web wallet for deploying permanent data, connecting to dApps, and navigating the weave (Limited AO/HyperBEAM support) Arweave Docs JSON Web Key Format (RFC 7517)

---

# 42. Path Manifests  Cooking with the Permaweb

Document Number: 42
Source: https://cookbook.arweave.net/fundamentals/accessing-arweave-data/manifests.html
Words: 370
Quality Score: 0.456
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Path Manifests Overview When uploading files to Arweave each file is assigned its own unique transaction ID. By default these ID's aren't grouped or organized in any particular manner.One picture of your cat might be stored with a transaction ID of bVLEkL1SOPFCzIYi8T_QNnh17VlDp4RylU6YTwCMVRw, while another with FguFk5eSth0wO8SKfziYshkSxeIYe7oK9zoPN2PhSc0 as its transaction ID.Cat1 Cat2 bVLEkL1SOPFCzIYi8T_QNnh17VlDp4...FguFk5eSth0wO8SKfziYshkSxeIYe7oK9zoPN2PhSc0 These transaction ID's are a bit unwieldy and make it difficult to find all of your relevant files. Without a path manifest, if you uploaded 100 pictures of your cat you would need to keep track of 100 different IDs and links!Path Manifests are a way to link multiple transactions together under a single base transaction ID and give them human readable file names. In relation to the cat example, you could have one base transaction ID to remember and use it like a folder - accessing your cat pictures with more memorable filenames like {base id}/cat1.jpg, {base id}/cat2.jpg, etc.Creating grouped sets of readable file names is essential for creating practical applications on Arweave, and unlocks the ability to host websites or other file collections as explored in the examples below.What Can You Use Manifests For? Any time you need to group files in a hierarchical way, manifests can be useful. For example:Storing NFT collections:https://arweave.net/X8Qm…AOhA/0.png https://arweave.net/X8Qm…AOhA/1.png This mirrors the common base path approach used by NFT collections when linking to NFT images and metadata on a storage API or IPFS.Hosting websites:https://arweave.net/X8Qm…AOhA/index.html https://arweave.net/X8Qm…AOhA/styles.css https://arweave.net/X8Qm…AOhA/public/favicon.png Manifest Structure Path Manifests are a special format of transaction created and posted to Arweave using the Tags:{ name: "Content-type", value: "application/x.arweave-manifest+json" } and having JSON formatted transaction data that matches the example below.{
"manifest": "arweave/paths",
"version": "0.2.0",
"index": {
"path": "index.html"
},
"fallback": {
"id": "cG7Hdi_iTQPoEYgQJFqJ8NMpN4KoZ-vH_j7pG4iP7NI"
},
"paths": {
"index.html": {
"id": "cG7Hdi_iTQPoEYgQJFqJ8NMpN4KoZ-vH_j7pG4iP7NI"
},
"js/style.css": {
"id": "fZ4d7bkCAUiXSfo3zFsPiQvpLVKVtXUKB6kiLNt2XVQ"
},
"css/style.css": {
"id": "fZ4d7bkCAUiXSfo3zFsPiQvpLVKVtXUKB6kiLNt2XVQ"
},
"css/mobile.css": {
"id": "fZ4d7bkCAUiXSfo3zFsPiQvpLVKVtXUKB6kiLNt2XVQ"
},
"assets/img/logo.png": {
"id": "QYWh-QsozsYu2wor0ZygI5Zoa_fRYFc8_X1RkYmw_fU"
},
"assets/img/icon.png": {
"id": "0543SMRGYuGKTaqLzmpOyK4AxAB96Fra2guHzYxjRGo"
}
}
} fallback:Manifest version 0.2.0 introduced the fallback attribute. fallback is an object that accepts the sub attribute id, which defines an Arweave data item transaction id for the resolver to fall back to if it fails to correctly resolve a requested path.Source and Further Reading in the official Arweave Path Manifest docs: Arweave Docs

---

# 43. ANS-101 Gateway Capabilities Endpoint  Cooking with the Permaweb

Document Number: 43
Source: https://cookbook.arweave.net/tooling/specs/ans/ANS-101.html
Words: 248
Quality Score: 0.454
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

ANS-101: Gateway Capabilities Endpoint Status: Draft Version: - Abstract This document describes a HTTP endpoint and schema that Arweave Gateways should expose to allow users of the gateway to determine the capabilities of the gateway.Motivation As the ecosystem of gateways onto the Arweave blockchain grows, these gateways will provide different capabilities. Users of the gateway, need to be able to determine if the gateway supports the capabilities they need to run a particular app or use for a particular purpose.Specification 1. HTTP Endpoint Gateways that conforming to this specification MUST expose a HTTP endpoint that responds to a GET request at the path /info/capabilities with a JSON document conforming to the schema in section 2, which accurately lists the capabilities supported by the gateway.2. Response Schema The JSON document returned by the endpoint MUST be an object with a capabilities key, which is an array of capability objects.A capability object has the following schema at a minimum - name capability name. This MUST be a globally unique name.version capability version. This MUST be a semver version string.Capability objects MAY conform to additional schema particular to that capability.Example response body: ( names, versions, and capability objects are examples only. ) {
"capabilities": [
{ "name": "arql", "version": "1.0.0" },
{ "name": "graphql", "version": "1.0.0" },
{ "name": "arweave-id-lookup", "verson": "1.0.0" },
{ "name": "post-bundled-tx-json", "version": "1.0.0" },
{ "name": "post-delegated-tx", "version": "1.0.0", "maxFee": "0.00125" },
{ "name": "push-on-event-api", "version": "1.0.0", "platforms": ["push-android", "push-ios", "web-push-firefox", "webhook" ] }
]
}

---

# 44. ANS-104 Bundled Data v20 - Binary Serialization  Cooking with the Permaweb

Document Number: 44
Source: https://cookbook.arweave.net/tooling/specs/ans/ANS-104.html
Words: 1589
Quality Score: 0.454
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

ANS-104: Bundled Data v2.0 - Binary Serialization Status: Standard Abstract This document describes the data format and directions for reading and writing bundled binary data. Bundled data is a way of writing multiple independent data transactions (referred to as DataItems in this document) into one top level transaction. A DataItem shares many of the same properties as a normal data transaction, in that it has an owner, data, tags, target, signature, and id. It differs in that is has no ability to transfer tokens, and no reward, as the top level transaction pays the reward for all bundled data.Motivation Bundling multiple data transactions into one transaction provides a number of benefits:Allow delegation of payment for a DataItem to a 3rd party, while maintaining the identity and signature of the person who created the DataItem, without them needing to have a wallet with funds Allow multiple DataItems to be written as a group Increase the throughput of logically independent data-writes to the Arweave network Reference Implementation There is a reference implementation for the creation, signing, and verification of DataItems and working with bundles in TypeScript Specification 1. Transaction Format 1.1 Transaction Tags A bundle of DataItems MUST have the following two tags present:Bundle-Format a string describing the bundling format. The format for this standard is binary Bundle-Version a version string. The version referred to in this standard is 2.0.0 Version changes may occur due to a change in encoding algorithm in the future 1.2 Transaction Body Format This format for the transaction body is binary data in the following bytes format N = number of DataItems Bytes Purpose 32 Numbers of data items N x 64 Pairs of size and entry ids [size (32 bytes), entry ID (32 bytes)] Remaining bytes Binary encoded data items in bundle 1.3 DataItem Format A DataItem is a binary encoded object that has similar properties to a transaction Field Description Encoding Length (in bytes) Optional signature type Type of key format used for the signature Binary 2 ❌ signature A signature produced by owner Binary Depends on signature type ❌ owner The public key of the owner Binary 512 ❌ target An address that this DataItem is being sent to Binary 32 (+ presence byte) ✔️ anchor A value to prevent re attacks Binary 32 (+ presence byte) ✔️ number of tags Number of tags Binary 8 ❌ number of tag bytes Number of bytes used for tags Binary 8 ❌ tags An avro array of tag objects Binary Variable ❌ data The data contents Binary Variable ❌ All optional fields will have a leading byte which describes whether the field is present (1 for present, 0 for not present). Any other value for this byte makes the DataItem invalid.A tag object is an Apache Avro encoded stream representing an object { name: string, value: string }. Prefixing the tags objects with their bytes length means decoders may skip them if they wish.The anchor and target fields in DataItem are optional. The anchor is an arbitrary value to allow bundling gateways to provide protection from re attacks against them or their users.1.3.1 Tag format Parsing the tags is optional, as they are prefixed by their bytes length.To conform with deployed bundles, the tag format is Apache Avro with the following schema:{
"type": "array",
"items": {
"type": "record",
"name": "Tag",
"fields": [
{ "name": "name", "type": "bytes" },
{ "name": "value", "type": "bytes" }
]
}
} Usually the name and value fields are UTF-8 encoded strings, in which case "string" may be specified as the field type rather than "bytes", and avro will automatically decode them.To encode field and list sizes, avro uses a long datatype that is first zig-zag encoded, and then variable-length integer encoded, using existing encoding specifications. When encoding arrays, avro provides for a streaming approach that separates the content into blocks.1.3.1.1 ZigZag coding ZigZag is an integer format where the sign bit is in the 1s place, such that small negative numbers have no high bits set. In surrounding code, normal integers are almost always stored in a twos-complement manner instead, which can be converted as below.Converting to ZigZag:zigzag = twos_complement << 1;
if (zigzag < 0) zigzag = ~zigzag;Converting from ZigZag:if (zigzag & 1) zigzag = ~zigzag;
twos_complement = zigzag >> 1;1.3.1.2 Variable-length integer coding Variable-length integer is a 7-bit little-endian integer format, where the 8th bit of each byte indicates whether another byte (of 7 bits greater significance) follows in the stream.Converting to VInt:// writes 'zigzag' to 'vint' buffer
offset = 0;
do {
vint_byte = zigzag & 0x7f;
zigzag >>= 7;
if (zigzag)
vint_byte |= 0x80;
vint.writeUInt8(vint_byte, offset);
offset += 1;
} while(zigzag);Converting from VInt:// constructs 'zigzag' from 'vint' buffer
zigzag = 0;
offset = 0;
do {
vint_byte = vint.readUInt8(offset);
zigzag |= (vint_byte & 0x7f) << (offset*7);
vint_byte &= 0x80;
offset += 1;
} while(vint_byte);1.3.1.3 Avro tag array format Avro arrays may arrive split into more than one sequence of items. Each sequence is prefixed by its length, which may be negative, in which case a byte length is inserted between the length and the sequence content. This is used in schemas of larger data to provide for seeking. The end of the array is indicated by a sequence of length zero.The complete tags format is a single avro array, consisting solely of blocks of the below format. The sequence is terminated by a block with a count of 0. The size field is only present if the count is negative, in which case its absolute value should be used.Field Description Encoding Length Optional count Number of items in block ZigZag VInt Variable ❌ size Number of bytes if count<0 ZigZag VInt Variable ✔️ block Concatenated tag items Binary size ❌ 1.3.1.4 Avro tag item format Each item of the avro array is a pair of avro strings or bytes objects, a name and a value, each prefixed by their length.Field Description Encoding Length Optional name_size Number of bytes in name ZigZag VInt Variable ❌ name Name of the tag Binary name_size ❌ value_size Number of bytes in value ZigZag VInt Variable ❌ value Value of the tag Binary value_size ❌ 2. DataItem signature and id The signature and id for a DataItem is built in a manner similar to Arweave 2.0 transaction signing. It uses the Arweave 2.0 deep-hash algorithm. The 2.0 deep-hash algorithm operates on arbitrarily nested arrays of binary data, i.e a recursive type of DeepHashChunk = Uint8Array | DeepHashChunk[].There are reference implementations for the deep-hash algorithm in TypeScript and Erlang To generate a valid signature for a DataItem, the contents of the DataItem and static version tags are passed to the deep-hash algorithm to obtain a message. This message is signed by the owner of the DataItem to produce the signature. The id of the DataItem, is the SHA256 digest of this signature.The exact structure and content passed into the deep-hash algorithm to obtain the message to sign is as follows:[
utf8Encoded("dataitem"),
utf8Encoded("1"),
owner,
target,
anchor,
[
... [ tag.name, tag.value ],
... [ tag.name, tag.value ],
...
],
data
] 2.1 Verifying a DataItem DataItem verification is a key to maintaining consistency within the bundle standard. A DataItem is valid iff.1:id matches the signature (via SHA-256 of the signature) signature matches the owner's public key tags are all valid an anchor isn't more than 32 bytes A tag object is valid iff.:there are <= 128 tags each key is <= 1024 bytes each value is <= 3072 bytes only contains a key and value both the key and value are non-empty strings 3. Writing a Bundle of DataItems To write a bundle of DataItems, each DataItem should be constructed, signed, encoded, and placed in a transaction with the transaction body format and transaction tags specified in Section 1.3.1 Nested bundle Arweave Transactions and DataItems have analogous specifications for tagging and bearing of a binary payload. As such, the ANS-104 Bundle Transaction tagging and binary data format specification can be applied to the tags and binary data payload of a DataItem. Assembling a DataItem this way provides for the nesting of ANS-104 Bundles with one-to-many relationships between "parent" and "child" bundles and theoretically unbounded levels of nesting. Additionally, nested DataItem Bundles can be mixed heterogeneously with non-Bundle DataItems at any depth in the Bundle tree.To construct an ANS-104 DataItem as a nested Bundle:Add tags to the DataItem as described by the specification in section 1.1 Provide a binary payload for the DataItem matching the Bundle Transaction Body Format described in section 1.2, i.e. the Bundle header outlining the count, size, and IDs of the subsequent, nested DataItems, each of which should be verifiable using the method described in section 2.1.Gateway GQL queries for DataItem headers should, upon request, contain a bundledIn field whose value indicates the parent-child relationship of the DataItem to its immediate parent. Any nested bundle should be traceable to a base layer Arweave Transaction by recursively following the bundledIn field up through the chain of parents.4. Reading a Bundle of DataItems To read a bundle of DataItems, the list of bytes representing the DataItems can be partitioned using the offsets in each pair. Subsequently, each partition can be parsed to a DataItem object (struct in languages such as Rust/Go etc. or JSON in TypeScript).This allows for querying of a singleton or a bundle as a whole.4.1 Indexing DataItems This format allows for indexing of specific fields in O(N) time. Some form of caching or indexing could be performed by gateways to improve lookup times.1 - if and only if

---

# 45. References  Cooking with the Permaweb

Document Number: 45
Source: https://cookbook.arweave.net/references/index.html
Words: 85
Quality Score: 0.449
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

References Reference documentation, specifications, and resources for Permaweb development.Quick References Glossary - Definitions of key terms and concepts LLMs.txt - Machine-readable documentation for AI assistants Technical Specifications ArFS Specification - Arweave File System standard Data Model Entity Types Content Types Privacy Schema Diagrams External Resources Arweave Documentation open in new window Community Forum open in new window Developer Discord open in new window API References For specific tool and service APIs, see the Tooling section.Built with ❤️ by the Arweave community. Learn more at Arweave.org

---

# 46. ArFS Protocol A Decentralized File System on Arweave  Cooking with the Permaweb

Document Number: 46
Source: https://cookbook.arweave.net/tooling/specs/arfs/arfs.html
Words: 404
Quality Score: 0.446
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

ArFS Protocol: A Decentralized File System on Arweave Arweave File System, or “ArFS” is a data modeling, storage, and retrieval protocol designed to emulate common file system operations and to provide aspects of mutability to your data hierarchy on Arweave 's otherwise permanent, immutable data storage blockweave.Due to Arweave's permanent, immutable and public nature traditional file system operations such as permissions, file/folder renaming and moving, and file updates cannot be done by simply updating the on-chain data model.ArFS works around this by implementing a privacy and encryption pattern and defining an append-only transaction data model using tags within Arweave Transaction headers.Key Features File Structure ArFS organizes files and folders using a hierarchical structure. Files are stored as individual transactions on the Arweave blockchain, while folders are metadata that reference these file transactions.Each file and folder has associated metadata, such as the name, type, size, and modification timestamp. ArFS leverages Arweave's tagging system to store this metadata in a standardized format, which allows for easy querying and organization.File Permissions ArFS supports public and private file permissions. Public files can be accessed by anyone on the network, while private files are encrypted using the owner's private key, ensuring only they can decrypt and access the content.File Versioning ArFS supports versioning of files, allowing users to store multiple versions of a file and access previous versions at any time. This is achieved by linking new file transactions to previous versions through the use of metadata tags.Data Deduplication To minimize storage redundancy and costs, ArFS employs data deduplication techniques. If a user tries to store a file that already exists on the network, the protocol will simply create a new reference to the existing file instead of storing a duplicate copy.Search and Discovery ArFS enables users to search and discover files based on their metadata, such as file names, types, and tags. This is made possible by indexing the metadata stored within the Arweave blockchain.Interoperability ArFS is designed to be interoperable with other decentralized applications and services built on the Arweave network. This allows for seamless integration and collaboration between different applications and users.Getting Started To start using ArFS, you'll need to familiarize yourself with the Arweave ecosystem, acquire AR tokens to cover storage costs, and choose a compatible client or library to interact with the ArFS protocol.Resources For more information, documentation, and community support, refer to the following resources:Arweave Official Website Arweave Developer Documentation Arweave Community Forums

---

# 47. Contributing Workflow  Cooking with the Permaweb

Document Number: 47
Source: https://cookbook.arweave.net/getting-started/contributing.html
Words: 315
Quality Score: 0.443
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Contributing Workflow Anyone in the community is welcome to contribute to the Permaweb Cookbook, as community members we want a high quality reference guide of little snack bite sized nuggets of information. Below is a step by step workflow of how anyone can contribute to this project.What do you need to know?Git and Github - publishes content to github.com.Markdown - Markdown is a text based markup language that can be transformed into HTML Arweave and the Permaweb - Have some knowledge about the Permaweb that should be shared Steps to Contribute Commiting work We are using conventional commits for this repository.General flow for making a contribution:Fork the repo on GitHub Clone the project to your own machine Commit changes to your own branch Push your work back up to your fork Submit a Pull request so that we can review your changes NOTE: Be sure to merge the latest from "upstream" before making a pull request!Style Here are some suggestions on tone and style from some contributors:TIP In writing them, I'm getting a feeling for the tone that's appropriate for each. CoreConcepts should be rather textbook like, neutral voice, objective. "This is how Arweave works" For Guides, I think it's ok to have a more personal voice. Refer to the reader as "you" and speak in the collaborative voice "next we'll take a look at..." This may just be personal preference, but in general I feel this tone much more supportive and accessible when following a longer form guide. Indeed, its the voice that most popular tutorials from other ecosystems are written in. For Resources, I think it shares the same voice as core concepts, with a preference for brevity.dmac TIP Conceptual and referencial data should have a more cold scientific tone and guides should be a supportive or even humorous tone. Longer form content needs to pull readers in without them zoning out.Arch_Druid CONTRIBUTING

---

# 48. GraphQL Tools  Cooking with the Permaweb

Document Number: 48
Source: https://cookbook.arweave.net/tooling/graphql/index.html
Words: 253
Quality Score: 0.418
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

GraphQL Tools This section covers the tools and libraries available for querying Arweave data using GraphQL. GraphQL provides a powerful and flexible way to retrieve exactly the data you need from the Arweave network.Core GraphQL Tools ar-gql - JavaScript Library Lightweight GraphQL client for Arweave TypeScript support Easy integration with web applications Comprehensive query building Querying Arweave - Comprehensive Guide Complete overview of Arweave querying methods GraphQL query examples and patterns Best practices for data retrieval Advanced Querying Goldsky Search Gateway - Search & Indexing Advanced search capabilities Full-text search across Arweave data Indexing and aggregation features High-performance querying Getting Started Basic GraphQL Query import { gql } from 'ar-gql'
const query = gql`
query {
transactions(
owners: ["YOUR_WALLET_ADDRESS"]
first: 10
) {
edges {
node {
id
block {
height
}
tags {
name
value
}
}
}
}
}
` Query Patterns Transaction Queries Filter by owner, recipient, or tags Retrieve transaction metadata and content Search across time ranges Block Queries Get block information and statistics Query network state at specific heights Analyze network activity Bundle Queries Access bundled transactions Query bundle metadata Retrieve nested transaction data Best Practices Use Specific Queries: Request only the data you need Implement Pagination: Handle large result sets efficiently Cache Results: Store frequently accessed data locally Error Handling: Implement robust error handling for network issues Rate Limiting: Respect API rate limits and implement backoff strategies Start with ar-gql: ar-gql Library Learn Querying: Querying Arweave Advanced Search: Goldsky Search Gateway Explore Examples: Zero to Deployed App

---

# 49. Decentralized Computing  Cooking with the Permaweb

Document Number: 49
Source: https://cookbook.arweave.net/fundamentals/decentralized-computing/index.html
Words: 921
Quality Score: 0.418
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Decentralized Computing The Permaweb enables a new paradigm of decentralized computing that goes beyond simple data storage. Through technologies like AO and HyperBEAM, developers can build sophisticated applications that run permanently and trustlessly on a global, decentralized computer.Overview Traditional computing relies on centralized servers and cloud providers, creating single points of failure and control. Decentralized computing on the Permaweb distributes computation across a network of nodes, ensuring permanence, censorship resistance, and trustless execution.Key Components AO Processes - Autonomous computational units that maintain state and execute logic permanently on Arweave HyperBEAM - The production implementation of AO-Core that provides HTTP access to decentralized computing resources Decentralized Computing Architecture:User/Application
↓ (HTTP Request)
HyperBEAM Node ←──────→ HTTP Response
↓ (Route Message)
AO Process ←──────→ Other AO Process
↓ (Execute Logic) (Messages)
Lua/WASM Runtime
↓ (Update State)
Arweave Storage
Decentralized Computing Network:
┌─────────────────────────────────────┐
│ Node 1 Node 2 Node 3 ... Node N │
│ ↑ ↑ ↑ ↑ │
│ └───────┼───────┼──────────┘ │
│ └───────┘ │
│ (Distributed across network) │
└─────────────────────────────────────┘ This system enables permanent, trustless computation where HyperBEAM nodes provide HTTP access to AO processes that execute on various runtimes and persist state to Arweave.Core Concepts Permanent Computation Unlike traditional serverless functions that can be shut down or modified, AO processes run permanently on the Arweave network. Once deployed, they continue executing indefinitely without requiring maintenance or hosting fees.Trustless Execution All computation is cryptographically verifiable. Results can be independently verified by anyone, eliminating the need to trust centralized providers or intermediaries.Message-Based Architecture AO processes communicate through asynchronous message passing, enabling sophisticated distributed computing patterns while maintaining consistency and ordering.Device Modularity HyperBEAM's device architecture allows different computational engines (Lua, WebAssembly, custom modules) to be plugged in as needed, creating a flexible and extensible computing environment.Why Decentralized Computing Matters Permanence Applications never go offline or disappear No vendor lock-in or platform dependencies Permanent accessibility for users worldwide Censorship Resistance No single authority can shut down applications Global network distribution prevents blocking Permissionless participation in the network Economic Efficiency Pay once for permanent deployment No ongoing hosting or maintenance costs Competitive pricing through decentralized markets Trust Minimization Cryptographically verifiable execution Open source and auditable code Mathematical guarantees instead of institutional trust Architecture Comparison Aspect Traditional Cloud Decentralized Computing Uptime 99.9% SLA 100% (permanent) Control Platform controlled User controlled Costs Monthly recurring One-time deployment Scalability Manual scaling Automatic network scaling Verification Trust-based Cryptographically provable Censorship Platform policies Censorship resistant Learning Path 1. Start with AO Processes Understand the fundamental building blocks of decentralized computing:What are AO Processes - Learn the core concepts and architecture Process Communication - Master message passing and inter-process communication State Management - Understand persistent state and data consistency 2. Explore HyperBEAM Learn how to interact with and leverage the AO Computer:HyperBEAM Introduction - Understand the HTTP gateway to AO Querying AO Process State - Master the HTTP API for data access Lua Serverless Functions - Build serverless functions with permanent availability HyperBEAM Devices - Understand the modular device architecture 3. Build Applications Apply your knowledge to real-world projects:Builder's Journey - End-to-end development workflow Zero-deployed Full Stack App - Quick start guide Advanced Patterns - Sophisticated application architectures Use Cases Decentralized Applications (dApps) Token contracts and DeFi protocols Voting and governance systems Social media and content platforms Gaming and virtual worlds Serverless Computing API endpoints with permanent availability Data processing and transformation Scheduled tasks and automation Microservices architecture Data Processing ETL pipelines and analytics Machine learning inference Content delivery and caching Database and storage systems Integration and Automation Cross-chain bridges and oracles Webhook endpoints and notifications Workflow automation Third-party API integration Technical Benefits Developer Experience Familiar interfaces - HTTP APIs and standard programming languages No infrastructure management - Deploy and forget Instant scaling - Network automatically handles load Built-in persistence - State management included Performance Characteristics Low latency - Global edge network High availability - No single points of failure Elastic scaling - Resources scale with demand Predictable costs - One-time deployment fees Security Model Cryptographic verification - All execution is provable Isolated execution - Sandboxed environments Immutable code - Deployed logic cannot be changed Transparent operations - All activity is publicly auditable Getting Started Prerequisites Basic understanding of blockchain concepts Familiarity with HTTP APIs Programming experience (JavaScript/Lua preferred) Quick Start Deploy your first process - Zero-deployed App Guide Query process state - HyperBEAM Querying Build serverless functions - Lua Functions Guide Development Tools AOS - AO Studio development environment ao-connect - JavaScript SDK for AO interaction HyperBEAM nodes - HTTP gateways to the AO Computer Future of Decentralized Computing Emerging Capabilities AI/ML integration - Permanent machine learning models Advanced cryptography - Zero-knowledge proofs and privacy Cross-chain bridges - Seamless blockchain interoperability IoT integration - Edge computing with global state Network Effects As the decentralized computing network grows:More computational resources become available Specialized devices and capabilities emerge Costs decrease through competition Innovation accelerates through composability Industry Impact Decentralized computing enables:Platform independence - Applications that outlive their creators Global accessibility - Permanent availability worldwide Economic inclusion - Lower barriers to application deployment Innovation freedom - Censorship-resistant development Community and Resources Documentation AO Computer Docs - ao.arweave.net HyperBEAM Documentation - hyperbeam.arweave.net Arweave Developer Docs - docs.arweave.org Community Discord - discord.gg/arweave GitHub - github.com/permaweb Twitter - @ArweaveEco Tools and SDKs AO Connect - JavaScript SDK for AO processes AOS - Local development environment Permaweb Deploy - Deployment tools and utilities Ready to build? Start with What are AO Processes to understand the fundamentals, then move to HyperBEAM Introduction to learn how to interact with the AO Computer.

---

# 50. Content Types  Cooking with the Permaweb

Document Number: 50
Source: https://cookbook.arweave.net/tooling/specs/arfs/content-types.html
Words: 159
Quality Score: 0.417
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Content Types All transaction types in ArFS leverage a specific metadata tag for the Content-Type (also known as mime-type) of the data that is included in the transaction. ArFS clients must determine what the mime-type of the data is, in order for Arweave gateways and browswers to render this content appropriately.All public drive, folder, and file (metadata only) entity transactions all use a JSON standard, therefore they must have the following content type tag:Content-Type: '' However, a file's data transaction must have its mime-type determined. This is stored in the file's corresponding metadata transaction JSON's dataContentType as well as the content type tag in the data transaction itself.Content-Type: "" All private drive, folder, and file entity transactions must have the following content type, since they are encrypted:Content-Type: '' ArDrive-Core open in new window includes methods to determine a file's content type.Other Tags ArFS enabled clients should include the following tags on their transactions to identify their application App-Name: "

---

# 51. Guides  Cooking with the Permaweb

Document Number: 51
Source: https://cookbook.arweave.net/guides/index.html
Words: 142
Quality Score: 0.416
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Guides Step-by-step tutorials and practical guides for building on the Permaweb. Guides are currently being reorganized for better user experience.Coming Soon This section is being revamped to organize guides by user personas and use cases:Builder - Frontend and full-stack development guides Explorer - Data querying and analysis tutorials Gamer - Gaming and NFT development Quant - Advanced data analysis techniques Node Operator - Infrastructure and network participation Jack of All Trades - No-code and low-code solutions Current Resources While we reorganize, you can find existing guides in:Posting Transactions - How to send data to Arweave Deploying Manifests - Publishing applications and websites Deployment Tools - CLI tools and automation Querying Arweave - Finding and retrieving data Framework Integration Development kits and framework integrations are being moved to dedicated sections for better organization.Built with ❤️ by the Arweave community. Learn more at Arweave.org

---

# 52. Hello World (No Code)  Cooking with the Permaweb

Document Number: 52
Source: https://cookbook.arweave.net/getting-started/quick-starts/hw-no-code.html
Words: 90
Quality Score: 0.415
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Hello World (No Code) In this quick start we are going to upload an image to the Permaweb with no code.Requirements Computer Internet Modern web browser Create a wallet https://arweave.app/add open in new window or https://wander.app open in new window Send some data to Arweave Go to https://hello_cookbook.arweave.net open in new window Enter some data and click publish, connect your wallet and "BAM" Congratulations!You just published some data on Arweave using zero code.To check out the project -> https://github.com/twilson63/pw-no-code-hello Built with ❤️ by the Arweave community. Learn more at Arweave.org

---

# 53. Transactions  Cooking with the Permaweb

Document Number: 53
Source: https://cookbook.arweave.net/fundamentals/transactions/transaction-types.html
Words: 149
Quality Score: 0.412
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Transactions Transactions are the fundamental building blocks of the Arweave network. This section covers how transactions work, how to post them, and the different types available for various use cases.Core Transaction Concepts All data on Arweave is stored as transactions. Each transaction contains data and metadata (tags) that can be queried and retrieved. Understanding these concepts is essential for building on the permaweb.Transaction Guides Posting Transactions Learn the different ways to post transactions to Arweave, including direct posting, bundling services, and dispatched transactions. Understand the trade-offs between settlement time, cost, and reliability.Transaction Tags Discover how to use tags to organize and query transaction data. Tags are key-value pairs that make transactions discoverable and enable complex applications on Arweave.Transaction Bundles Understand how multiple transactions can be bundled together for improved scalability and guaranteed settlement. Bundles are crucial for high-throughput applications.Built with ❤️ by the Arweave community. Learn more at Arweave.org

---

# 54. Cooking with the Permaweb

Document Number: 54
Source: https://cookbook.arweave.net/tooling/specs/arfs/schema-diagrams.html
Words: 62
Quality Score: 0.411
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Schema Diagrams The following diagrams show complete examples of Drive, Folder, and File entity Schemas.Public Drive Public Drive Schema Private Drive Private Drive Schema Arweave GQL Tag Byte Limit is restricted to 2048. There is no determined limit on Data JSON custom metadata, though more data results in a higher upload cost.Built with ❤️ by the Arweave community. Learn more at Arweave.org

---

# 55. LLMstxt  Cooking with the Permaweb

Document Number: 55
Source: https://cookbook.arweave.net/references/llms-txt.html
Words: 36
Quality Score: 0.403
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

LLMs.txt The following is a tool open in new window that allows you to build your own LLMs.txt files based on docs from the permaweb ecosystem.Built with ❤️ by the Arweave community. Learn more at Arweave.org

---

# 56. Bundling Services  Cooking with the Permaweb

Document Number: 56
Source: https://cookbook.arweave.net/tooling/bundlers.html
Words: 523
Quality Score: 0.402
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Bundling Services With bundling services users can post their data transactions to a bundling service to have it "bundled" together with other users transactions and posted as a single Arweave transaction in an upcoming Arweave block.What is a bundle?A description of transaction bundles and their benefits can be found here.Bundles follow the ANS-104 standard, which defines how multiple data items can be efficiently packaged together into a single Arweave transaction. This enables:Cost Efficiency: Multiple small transactions can be bundled together, reducing overall transaction costs Scalability: Higher throughput by processing many data items in a single base layer transaction Flexibility: Support for different payment tokens while the bundler handles AR token payments What is a Bundler node?A bundler is a node which is responsible for accepting transactions or data items from users, bundling them, and posting them to the Arweave network (with a guarantee they will be uploaded with a specific transaction ID).Key Bundling Services:Turbo Repository: Turbo Upload Service Description: A high-performance bundling service developed by ArDrive Features: Fast upload processing, reliable data persistence, and efficient bundling Integration: Widely used across the Arweave ecosystem for production applications How Bundlers Work Data Acceptance: Bundlers receive data items from users along with payment Validation: Each data item is validated for proper formatting and signatures Bundling: Multiple data items are packaged together using ANS-104 standard Network Submission: The bundle is submitted to Arweave as a single base layer transaction Persistence Guarantee: Bundlers ensure data is stored until confirmed on-chain Supporting Multiple Currencies A key feature of bundling services is that because they pay for the base Arweave transaction to be posted (using AR tokens) they can choose to enable payments of storage fees on a variety of different tokens. This is the main entry point for other chains to enable Arweave's permanent storage for their users.Payment Token Support Bundlers can accept various cryptocurrencies for payment while handling the AR token requirements internally:Native AR tokens: Direct payment in Arweave's native currency Ethereum tokens: ETH, USDC, DAI, and other ERC-20 tokens Solana tokens: SOL and SPL tokens Other chains: Support varies by bundler implementation Benefits for Developers Simplified Integration: Developers don't need to manage AR tokens directly User Experience: Users can pay with familiar tokens from their preferred chains Cost Predictability: Bundlers often offer fixed pricing in stable currencies Automatic Handling: Bundlers manage all Arweave network interactions Data Verification and Integrity Modern bundling services implement comprehensive verification systems:Signature Verification: All data items must be properly signed Data Root Verification: Bundle contents are cryptographically verified against Arweave chain data Background Verification: Continuous validation ensures data integrity over time Chunk-based Retrieval: Data can be retrieved and verified through Arweave's chunk system Code Examples Using Turbo SDK Basic Upload with Turbo Upload with Payment (ETH) Using arbundles Library Create and Upload Bundle Manually React Component Example Node.js Batch Upload Check Upload Status Integration with AR.IO Gateways AR.IO gateways provide enhanced support for bundled data:Automatic Unbundling: Gateways can automatically extract and index data items from bundles Optimistic Indexing: Data items can be made available before final confirmation Peer-to-Peer Retrieval: Enhanced data availability through gateway networks Caching: Intelligent caching systems improve data access performance

---

# 57. Transaction Bundles  Cooking with the Permaweb

Document Number: 57
Source: https://cookbook.arweave.net/fundamentals/transactions/bundles.html
Words: 296
Quality Score: 0.400
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Transaction Bundles What is a Bundle? A transaction bundle is a special type of Arweave transaction. It enables multiple other transactions and/or data items to be bundled inside it. Because transaction bundles contain many nested transactions they are key to Arweave's ability to scale to thousands of transactions per second.Users submit transactions to a bundling service, such as turbo, which combines them into a 'bundle' with other transactions and posts them to the network.How Do Bundles Help Arweave? Availability Bundling services guarantee that bundled transactions are reliably posted to Arweave without dropping.Transaction IDs of the bundled transactions are immediately made available, meaning the data can instantly be accessed as if it was already on the Arweave network.Reliability Transactions posted to Arweave can occasionally fail to confirm (resulting in a dropped transaction) due to a number of reasons, such as high network activity. In these instances transactions can become orphaned, i.e. stuck in the mempool and eventually removed.Bundlers solve this problem by continually attempting to post bundled data to Arweave, assuring that it does not fail or get stuck in the mempool.Scalability Bundles can store up to 2 256 transactions, each of which are settled as a single transaction on Arweave. This makes Arweave blockspace scale to support almost any use case.What are Nested Bundles? Bundles can include data items for uploading to Arweave and those data item can themselves be a bundle.This means it is possible to upload a bundle of bundles, or in other words nested bundles.Nested bundles have no theoretical limit on nesting depth, meaning that transaction throughput can be increased drastically.Nested bundles might be useful for when you have different groups of bundled data that you want to guarantee reach Arweave altogether, and at the same time.Sources and Further Reading:Ardrive Turbo ANS-104 Standard

---

# 58. Deployment  Publishing Tools  Cooking with the Permaweb

Document Number: 58
Source: https://cookbook.arweave.net/tooling/deployment.html
Words: 62
Quality Score: 0.396
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Deployment & Publishing Tools Tools for deploying applications and publishing content to the permaweb.CLI Tools arkb A command-line tool for deploying static websites and applications to Arweave.permaweb-deploy Modern deployment tool with built-in bundling and optimization.CI/CD Integration GitHub Actions Automated deployment workflows for continuous integration.Other CI Platforms Integration guides for popular CI/CD platforms.Built with ❤️ by the Arweave community. Learn more at Arweave.org

---

# 59. Goldsky Search GraphQL Gateway  Cooking with the Permaweb

Document Number: 59
Source: https://cookbook.arweave.net/tooling/graphql/search-indexing-service.html
Words: 616
Quality Score: 0.386
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

A specialized GraphQL gateway that extends Arweave's querying capabilities with advanced search features.TL;DR Backwards compatible syntax with Arweave GraphQL Faster response times for complex queries (ie multi-tag search) More query options including fuzzy and wildcard search Enhanced filtering capabilities Goldsky 's free search service is a GraphQL gateway that uses an optimized backend to provide faster searches for complex queries across arweave blocks and transactions, and also introduces additional querying syntax for fuzzy and wildcard search use-cases.The Search GraphQL syntax is a superset of the Arweave GraphQL syntax. It's fully backwards compatible and will return the same results for the same queries, but has some additional modifiers that can be useful.Flexible tag filters Search for just a tag name or value Advanced tag filters Fuzzy search Wildcard search Filter for L1 transactions only Result set total counts For any custom needs or feature ideas, feel free to contact the Goldsky team through email or on discord!Search Gateway Endpoints Currently, the only service with this syntax is hosted Goldsky. If anybody is interested in hosting their own gateway with the same syntax, feel free to contact the Goldsky for help.Goldsky Search Service Features Flexible Tag Filters The Search Gateway Syntax is less strict, and allows for searching just for the Tag name or value Examples Search for transactions with the tag value 'cat' query just_values {
transactions(
first: 10,
tags: [
{
values: ["cat"]
}
]
)
{
edges {
node {
id
tags {
name
value
}
}
}
}
} Search for transactions that have an In-Response-To-ID query just_name {
transactions(
first: 10,
tags: [
{
name: "In-Response-To-ID"
}
]
)
{
edges {
node {
id
tags {
name
value
}
}
}
}
} Advanced tag filters The Search Gateway Syntax offers an additional parameter to the tag filter, match.Match value Description EXACT (default) exact matches only.WILDCARD Enables * to match any amount of characters, ie. text/* FUZZY_AND Fuzzy match containing all search terms FUZZY_OR Fuzzy match containing at least one search term Open up the ground and try some of the following queries!Searching all transactions with an image content type using a wildcard {
transactions(
tags: [
{ name: "Content-Type", values: "image/*", match: WILDCARD}
]
first: 10
) {
edges {
cursor
node {
id
tags {
name
value
}
block { height }
bundledIn {id}
}
}
}
} Fuzzy search is very powerful, and can search for 'similar' text with many variations.Searching all transactions with 'cat' OR 'dog' (or CAT or doG or cAts or CAAts etcs). So the tag could contain at least of cat-like or dog-like term.{
transactions(
tags: [
{ name: "Content-Type", values: ["cat", "dog"], match: "FUZZY_OR"}
]
first: 10
) {
edges {
cursor
node {
id
tags {
name
value
}
block { height }
bundledIn {id}
}
}
}
} Search for transactions that have cat-like AND dog-like tag values {
transactions(
tags: [
{ name: "Content-Type", values: ["cat", "dog"], match: "FUZZY_AND"}
]
first: 10
) {
edges {
cursor
node {
id
tags {
name
value
}
block { height }
bundledIn {id}
}
}
}
} Exclude Bundled (L2) Transactions Simply set bundledIn: NULL query just_l1 {
transactions(
first: 10,
bundledIn: null
)
{
edges {
node {
id
signature
owner {
address
}
block {
height
}
}
}
}
} Getting total counts given a query If you'd like to understand how many transactions fit a certain set of filters, just use the count field. This will trigger an additional optimized count operation. This will likely double the time it would take to return the query, so use only when needed.query count_mirror {
{
transactions(tags:{values:["MirrorXYZ"]})
{
count
}
}
}

---

# 60. Tooling  Cooking with the Permaweb

Document Number: 60
Source: https://cookbook.arweave.net/tooling/index.html
Words: 135
Quality Score: 0.375
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Tooling Tools and services organized by the problems they solve for Permaweb developers.Data Upload & Bundling Tools for efficiently uploading data to Arweave:Bundlers - Services that bundle multiple transactions together Data Querying & Indexing Tools for discovering and retrieving data:GraphQL - Powerful query interfaces for transaction data Deployment & Publishing Tools for deploying applications to the Permaweb:CLI Tools - Command-line deployment utilities Framework Integration Development kits are available in the Kits section for:React applications Vue applications Svelte applications When to Use Each Tool Bundlers - When posting multiple transactions or need guaranteed settlement GraphQL - For complex data queries and analytics (optional for most apps) CLI Tools - For automated deployment and CI/CD integration Framework Kits - When building frontend applications with modern frameworks Built with ❤️ by the Arweave community. Learn more at Arweave.org

---

# 61. Core Concepts  Cooking with the Permaweb

Document Number: 61
Source: https://cookbook.arweave.net/fundamentals/index.html
Words: 116
Quality Score: 0.269
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Core Concepts Understanding the fundamental concepts of Arweave and the Permaweb is essential for building robust decentralized applications.Transaction Fundamentals Transactions - How data is stored and transactions work Posting Transactions Bundles Transaction Types Core Architecture Manifests & Path Resolution - How files and applications are organized Querying Fundamentals - How to find and retrieve data Wallets & Keys - Identity and authentication Gateways & Access - How to access the network Advanced Topics ArNS Introduction - Decentralized naming system Vouch Protocol - Content moderation and reputation File System Specifications ArFS Specification - Arweave File System standard Data Model Entity Types Content Types Privacy Schema Diagrams Built with ❤️ by the Arweave community. Learn more at Arweave.org

---

# 62. Glossary  Cooking with the Permaweb

Document Number: 62
Source: https://cookbook.arweave.net/references/glossary.html
Words: 26
Quality Score: 0.257
Extraction Method: defuddle_semantic
Extraction Reason: defuddle_returned_html_semantic_extracted

Glossary The following is an embedded glossary tool open in new window for the permaweb ecosystem.Built with ❤️ by the Arweave community. Learn more at Arweave.org
